---
# model_name: gpt-3.5-turbo
model_name: gpt-3.5-turbo-16k
num_topics: [3]  # number of topics to put into the conversation
num_test_samples: 50 # number of test samples in each test case
question_dist: 100  # will ask what is the topic discussed every # topics eg. 1st, 4th
# run_models: False   # if set to False, only outputs token size
run_models: True
# generate_conversations: True # if set to False, will ask for a path to conversations to form the prompt
generate_conversations: False
use_fixed_testcases: True
testcases_dir: ./evaluation/topics/testcases
local_model: True
gpu_id: 1

########LRT configs#######
num_lines: [300, 400]  # 1 lines is about 10-15 tokens, 500 lines is 5513 tokens
generate_lrt_prompt: True
lrt_testcases_dir: ./evaluation/lrt_testcases
