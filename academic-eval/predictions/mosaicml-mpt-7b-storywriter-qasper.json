{
    "b6f15fb6279b82e34a5bf4828b7b5ddabfdf1d54": " A. C. would like to acknowledge the support from Alibaba Joint Postgraduate Research Chair Fellowship.\nReference\n\n[1]\n\nX. Zhou, P. Zhang, M. Huang, D. Zhao, M. Yen, D. Wang, W. Cui, G. Garg, S. Zheng, M.-H. Liu.\nNeural machine translation for low resource languages.\nIn Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics: Short Papers, pp. 3-4, 2017.\n\n[2]\n\nP. Ganchev, C. Tuffery, C. Sankar.\n\nZero-shot machine translation between different languages.\nIn Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics: Short Papers, pp. 1706-1710, 2018.\n\n\n[3]\n\nJingyun Huang, Lei Wang, Yanwei Liu, Xiaojing Liao, Zi Han, Jianxin Liu, Jun Zhang, Jiawei Zhou, Xiaoling Huang, Muli Chen.\n\nZero-shot neural machine translation and cross-lingual transfer learning.\nIn Proceedings of the 12th International Conference on World Wide Web, pp. 2833-2845, 2015.\n\n\n[4]\n\nJingyun Huang, Xiaojing Dong, Yanwei Liu, Lei Wang, Xiaojing Liao, Jun Zhang.\n\nZero-shot neural machine translation on massive parallel data.\nIn AAAI/ACM 2018 Conference, January 28\u2013February 1, 2018, Melbourne, Australia, 2018, pp. 1018-1024.\n\n\n[5]\n\nYuqiang Li, Zhe Liu, Xiaojing Liao, Meng Zhao, Jun Zhang and Quntao Xu.\n\nNeural machine translation for zero-resource languages via pivot-based pivoting.\n\nIn Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics: Short Papers, pp. 4-5, 2016.\n\n\n[6]\n\nYou Chen, Zhijing Liu, Zhe Liu, Xiaojing Liao, Jun Zhang, Shunyin Zhang, Jingyun Huang, Yuqiang Li.\n\nReinforced multilingual cross-lingual machine translation via pivot-",
    "f5e6f43454332e0521a778db0b769481e23e7682": " We acknowledge Zichen Chen for his work on the bilingual pre-training approach and Nianfeng Jing's help in the early stage of MLM+BRLM-SA pretraining. This work also partially owes to the support of the Ministry of Science and Technology (MOST) of China (Grant No. 2016YFB0406100). We are grateful for the support of the National University of Singapore (NUS) through the NUS Seed Funding.\n\nReferences\n\n[1] A. Agudo, C. Zoph, S. Neubig, D. C. Blei, & D. Anghel. Understanding and using representations of language models. CoRR, abstr. 2108.0235, 2008.\n\n[2] G. Arbe, A. G. Karlin, & J. K. Lai. Neural machine translation as a transfer learning problem: A case study for machine translation quality estimation. In EACL, 2016, pp. 3018\u20133025.\n\n[3] Y. Arce, M. J. Giesens, K. Y. Wu, & A. G. Karlin. Zero-shot translation using pivoting. In ACL-IJCNLP, 2018, pp. 974\u2013986.\n\n[4] D. Banerjee, D. Gers, D. Jannsen, & O. Vinyals. Rethinking multilingual machine translation with back-translation. In NLP, 2017, pp. 1783\u20131796.\n\n[5] H. Baker, H.-K. Choi, M. J. Paul, & F. S. Rosa. The effect of bilingual corpus size on pivoting-based machine translation from scratch. In EMNLP, 2016, pp. 814\u2013824.\n\n[6 ] Hou, Y., Z. Chen, Z. Xiong, I. Lv, & Y. Chen. Nmtkitcoder: A toolkit for Neural Machine Translation. In IJCNLP, 2019, p. 731.\n\n[7] M. Bak, A. Joulin, D. Schuetze, & G. Zilly. Multilingual language modeling with multi-task learning. In EMNLP, 2013, pp. 1241\u20131249.\n\n[8] B",
    "9a05a5f4351db75da371f7ac12eb0b03607c4b87": " We acknowledge the Tian-Xin-Tian Cloud Computing Platform, part of the National Super Computing Infrastructure Research Center (Phase II-HPC) supported by National Administration of Science, Technology and Innovation, China.\n \nTable of Contents\n\nTitle Page\n\nCopyright Page\n\nAcknowledgements\n\nChapter 1\n\nChapter 2\n\nChapter 3\n\nChapter 4\n\nChapter 5\n\nChapter 6\n\nChapter 7\n\nChapter 8\n\nChapter 9\n\nChapter 10\n\nChapter 11\n\nChapter 12\n\nChapter 13\n\nChapter 14\n\nAlso by Lee Child\n\nPreview of _The Midnight Line_\n\n**PRAISE FOR Lee Child and ** **_Jack Reacher_** **:_**\n\n**THE JACK REACHER NOVELS**\n\n_The Killing Floor_   \n_Devil's Gate_   \n_Persuader_   \n_The Hard Way_   \n_Running Blind_   \n_The Sienese Schism_   \n_Without Fail_   \n_One Shot_   \n_The Third Gate_   \n_Persuader_   \n_The Affair_   \n_The Enemy_   \n_Gone Tomorrow_   \n_Tripwire_   \n_61 Hours_   \n_The Suspect_\n\n**PREVIOUSLY PUBLISHED**\n\n_Bad Luck and Trouble: Stories_   \n****THE SUSAN ORSINI NOVELS**\n\n_The Better Angels: A Novel_   \n_A Trick of the Light: A Novel_   \n_One Last Shot: A Novel_   \n_The Third Gate: A Jack Reacher Novel_\n\n**OTHER WORKS**\n\n_The Affair: A Stand-Alone Jack Reacher Novel_   \n**NOVELLAS**\n\n_Training Day_   \n_Without Fail_\n\n_Rainwater_   \n_Not a Drill_   \n_Gone Tomorrow_   \n_Tourist_\nTHE NEXT THOMAS  \n_JACK_  \n _REACHER_\n\nA Bantam Books/   \nDoubleday Dell Book / published by arrangement   \nwith Bantam Dell\n\nPUBLISHING HISTORY   \nBantam edition published 1994.",
    "5eda469a8a77f028d0c5f1acd296111085614537": " The authors also would like to thank the organizers of the International Joint Workshop on Neural Machine Translation (IJWNMT).\n \n#  \n**NINE MEN**\n\n**AND NOT A ONE**  \n **MISSING**\n\n_A Jack Sigler**  \n **Hard-boiled Detective Story_  \n ** _by_ Robert Louis Stevenson**\n\n### Contents\n\n#  One\n\n#  Two\n\n#  Three\n\n#  Four\n\n#  Five\n\n#  Six\n\n#  Seven\n\n#  Eight\n\n#  Nine\n\n#  Ten\n\n#  Eleven\n\n#  Twelve\n\n#  Thirteen\n\n#  Fourteen\n\nThis eBook is copyright material and must not be copied, reproduced, transferred, distributed, leased, licensed or publicly performed or used in any way except as specifically permitted in writing by the publishers, as allowed under the terms and conditions under which it was purchased or as strictly permitted by applicable copyright law. Any unauthorised distribution or use of this text may be a direct infringement of the author's and publisher's rights and those responsible may be liable in law accordingly.\n\nVersion 1.0\n\nEpub ISBN 9781448177881\n\nwww.randomhouse.co.uk\n\n## One\n\n## I\n\nA black fellow with a face like a whitewashed wall who had the name of Pawelczek, or something like it, and had been some time in England, called at this moment, as he was passing the shop. He had two small pieces of pasteboard in his hand and a penny in his pocket. Pawelczek was his real name I believe, but he called himself the Gentleman from Warsaw. His business had to do with some documents stolen, or presumed stolen from a friend of his in an hotel in Portman Square. He was the friend, or thought he was, who had had the two pasteboards; he had bought them, or paid them out for, because he gave them the impression that they were worthless. They were forgeries, perhaps an artist or an honest rogue of the sort used them. In some way Pawelczek had come on to the right track so far as a person of this sort was concerned; but that track led in a curious way, and he had got",
    "18c5d366b1da8447b5404eab71f4cc658ba12e6f": "\nAcknowledgments\nWe would like to thank Anna Baraszewska, Daniel de Albuquerque, Janos Benk\u0151 & Csilla Vargha for helping us with the translation of the articles into English.\n\nReferences\n\n[1] M. Korkontzelos et al. Training An Armenian Named Entity Recognizer using Wikipedia data. In: Proceedings of the Fifth International Conference on Language Resources and Evaluation. ELRA, 2014.\n\n[2] C. H. Ng, M. Weinberger, M. Tingley, Y. Yates and R. Cho. Recognizing Named Entities from Text with a Recurrent Neural Network and Crf. In: Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing. EMNLP, 2011: 735-742.\n\n[3] C. Speronis and S. Ginter. BBN Named Entity Recognizer. In: D. Laird, T. Derczinski, N. Hearn and S. Tufte. Proceedings of the First European Workshop on Treebanks and Linguistic Theories. ELRA, 2003: 57-62. http://www.lear.ed.ac.uk/works/BBN-NeReC/BBN-NER.pdf.\n\n[4] J. Weber, A. P\u00f6tzl, X. He and C. Meurers. Named Entity Recognition using Wikipedia and Gazetteers. In: Proceedings of the 2015 Conference of the European Chapter of the Association for Computational Linguistics (EACL), 2015.\n\n[5] P. Nothman et al. Using Wikipedia data for Language Modeling, Corpora Building and Question Answering. Workshop paper, ICFHR 2015.\n\n[6] V. Sysoev, E. Andrianov and A. Filatova. Extracting Entity-Related Information from Wikipedia and Web Databases for Named Entity Recognition. In: Proceedings of the 2015 Workshop on Resources and Evaluation for the World and Flavors of Languages (REW and FLAVOR). University of Duisburg-Essen, 2015. www.sysoev.com/files/paper.pdf.\n\n[7] Y. D. Nothman, B. Y. Li and S. N",
    "b5e4866f0685299f1d7af267bbcc4afe2aab806f": " The use of external resources and tools are also an interesting approach, as proposed by Nothman et al., BIBREF4, BIBREF5, BIBREF7 and BIBREF10, BIBREF9 and BIBREF18.\nAcknowledgements\nWe thank the anonymous reviewers, whose insightful comments have helped to improve the work. We also thank our colleagues, who helped to improve certain steps of annotation from the description and initial evaluation.\nThe presented work was funded partly by the IDeA Foundation and the International Conference on Computational Linguistics.\nReferences\n[1] Anastasia Melamid, Liliam Sargsyan, and Vladimir Petrov, \"Named entity recognition in the Armenian Wikitionary,\" in Proceedings of the International Conference of Language Resources and Evaluation, 2015.\n[2] Liliam Sargsyan, Vahan Ardadian, Vahan Hovanessian, Ani Hayrapetyan, and Vardan Mouradian, \"Analysis and evaluation of Armenian Wikipedia sentences used for named entity recognition\", to appear in LREC 2018, 2018\n[3] Klesti Hoxha, Artur Baxhaku, and Artur Hoxha, \"Named entity identification in the Albanian Web,\" in Proceedings of the Fourteenth International Conference on Intelligent Text Processing and Computational Linguistics, 2015.\n[4] Nairi M. Weber, G\u00fcnter P\u00f6tzl, and Philipp Koehn, \"Rule-based named entity recognition,\" in Proceedings of the Eleventh International Conference on Language Resources and Evaluation, 2014.\n[5] Sergey Sysoev and Igor V. Andrianov, \"Named entity recognition for the Russian language,\" in Proceedings of the Fourteenth International Conference on Language Resources and Evaluation, 2015.\n[6] Andrey Nothman, A. Chishti, Riva Tchertchian, and Lori Diamantas, \"Extracting entity pairs from Wikipedia with gazetteer projection,\" in Proceedings of the Thirty-fourth Annual Meeting of the Association for Computational Linguistics, 2013.\n[7] Anastasia Ulyanov, Dmitry Babkova, Dmitriy Babkin, Valery Luchansky, and Evgenia Mendeleev, \"A silver-standard corpus for cross-lingual named entity recognition,\" in Proceedings of the Thirteenth Conference of",
    "1f085b9bb7bfd0d6c8cba1a9d73f08fcf2da7590": "\nThis work was carried out within \"Deep Learning for Natural Language Processing (NLP) and Speech Processing (Speech)\" PhD School of the Center for Machine Learning. We would like to thank all the instructors, especially David J. J. Molina, for all the help. The study would not have been possible without the resources provided by Center for Machine Learning Inc. and the generous financial support from Google Armenia R&D, Aris, and the National Program of Science and Technology BIBREF24.\nThe work described in the paper was carried out in collaboration with Armenia's Ministry of Education and Science and supported by the following Armenian foundations: ARAMAIS.\n\nAcknowledgments\n\nWe are grateful to Armenian Wikipedia community for the resources and the guidance of \u053f\u0631\u057a\u0631 \u053b\u0561\u056d\u0561\u0576, Armen Shahinian, Hayk Ghazaryan, \u0531\u0580\u06cc\u0627\u0646 \u0647\u0645\u0627\u0647\u0627 \u06a9\u060c and Hayk Karapetyan. For linguistic support, we are indebted to \u06cc\u0639\u0637\u0627 \u0645\u0641\u0631\u0645\u0627\u0646\u06cc \u06cc\u0627 \u0642\u0627\u0646\u0648\u0646 \u0633\u0631\u0647 \u062f\u0646\u0648\u0645 \u0628\u0631\u0646\u0627\u0645\u060c \u200c \u0633\u0631 \u0647\u0627\u0646\u06af \u0648 \u0686\u0627\u0647\u06cc \u0633\u0631\u062a\u0627\u0646 (Arastun Gharamian) and \u200c \u062a\u0645 \u0627\ufffd \u0647\u0633\u0627\u0646 \u0628\u062f\u0633\u0631\u0627 \u062a\u0628\u0631\u062f\u0627\u0646 \u0642\u062f\u0631\u062a\u0631 (\u0645\u0647\u0631\u0627\u0628 \u06cc\u062a\u0631 \u06cc\u0627\u0637\u0627 (Shahram Farmanian). We are grateful to Arman Ajemian for valuable advice regarding named entity recognition and word embeddings.\n\nReferences\n\nAmmar Z. & Roussinos P. (2011) A unified view of named entity recognition. In: Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL '11), pp. 1138\u20131146.\n\nAmmar Z. & Roussinos P. (2012) Unlabeled co-training for named entity recognition. In: Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL '12), pp. 711\u2013719.\n\nChen, L., Yu, D., & Wan, G. H. Z. (2017) Neural architecture for joint text classification and chunking. In: Proceedings of the 54th Annual Meeting of the Association for Computational",
    "b6ae8e10c6a0d34c834f18f66ab730b670fb528c": "\nAppendix A. Model Design\nFor our dogmatism prediction model, we use logistic regression with bag-of-words features and sentiment signals to predict the probability of dogmatism in a comment. Specifically, the model tries to predict the probability of a comment being dogmatic (y) based on its bag-of-words features (x) and its sentiment attributes (s).\ny = f(x,s)\nTo evaluate the performance of each feature, we run a leave-one-out cross-validation on the Reddit corpus. First, we randomly remove one post from the Reddit corpus and hold out an unseen prediction on this comment. Then, we compute the performance of each feature, based on:\nwhere each feature is computed as follows.\nBag of words: We count number of occurrences of each term in the comment to build a vocabulary based on words that appear in at least one post in the training corpus. For example, given a comment \"It's hard to imagine how anyone could be so deluded.\", we would count the number of occurrences of the terms \"be\" or \"deluded\" to build up a vocabulary. Each term is assigned a weight, drawn from the log-likelihood (L) of its term frequency in the corpus and then normalized by the word count (W):\nAveraging over each post in the corpus, we define the total frequency of a word based on its log-vocabulary score, which gives us total frequency of each term to create a unigram bag-of-words model.\nTo avoid overcounting terms that appear across many posts, we limit each term to its top 10,000 most frequent occurrences, giving us an effectively weighted vocabulary:\nThe BOW model then uses these word counts to compute predictive scores for comment x. Specifically, for each comment, we compute the probability that x is dogmatic by taking the maximum value of the product of all word counts (weighted by L) divided by the number of terms found in x (weighted by W):\nSimilarly for sentiment. We compute the probability of dogmatism (s) by taking word counts and using the standard sentiment score formula from Section 3.1:\nLinguistic features: We compute the probability of each feature for comment x (f(xj) based on the trained logistic regression model. The linguistic features used in this paper are: sentiment (f(s)) certainty (f(c))",
    "a87a009c242d57c51fc94fe312af5e02070f898b": " For example, many dogmatic people seem to believe their personal beliefs are held with more certainty than they should be, for example regarding matters of religion. If more dogmatic people participated in debates and discussions that were more balanced, how might their confidence levels shift? Further, other work has addressed how the presentation of new research can affect the beliefs of dogmatic people BIBREF27, providing a rich venue for future work.\nWe plan to make all code and data available to the community, allowing others to build on our foundation and further explore ways to promote evidence-based discussions. In particular, we think our work can provide a foundational tool for understanding more broadly the effects of dogmatism on online conversation BIBREF28, by relating the properties of dogmatic users to their discourse with other people.\n\n\n# The Shadow Prince\n\nDavid Eddings\n\n_To my sons, who have given me two grandsons and a granddaughter and a great deal of joy_.\n\n# 1  \n _Shadows_\n\nHigh above the trees and meadows of Vega, at the very center of the southernmost continent, the two great cities of Melcene held each other in shadow. At the top of one of the peaks was the city of Anderland, with its great palace of Aillard. To the north lay the massive walls and spires of Melcene.\n\nNo one in the west had ever seen the city of Anderland as the sun went down behind the walls of Melcene. The eastern edge of the wall ran just as far west, a vast swath of empty plain as the sunset touched the peaks. Then there was the city in Anderland, a giant mountain of shadow beside the cliffs and the river that flowed through the center of the world.\n\nA cold white light filled the sky as the sun slipped below the rim of the world and the sun struck the western wall. This was the light by which the children of Melcene were said to be able to send out the great shadow which drove the great beast of the world. That would be no light such as any normal man might catch with his eyes. The people of Melcene saw this as light in which truth and reality could be read. It was the light of knowledge.\n\nA bird flew in circles over the towers and spires of Melcene. It was no ordinary bird, either.",
    "ef4dba073d24042f24886580ae77add5326f2130": "\n\nThe authors would like to thank two anonymous reviewers and the senior editor of NeURIPS for useful suggestions. We also acknowledge support from the China Scholarship Council.\n\nCorrespondence to: <wenlei.wang@alibaba.com>\n\nReferences\n\n1. M. W. Chen and B. Zhou. A survey on NamedEntity Recognition: Challenges and Future Directions. ACM Computing Surveys. 2018.\n\n2. J. Lample, S. Conneau and A. Barone-Neumann. Neural Machine Translation by Minimizing the Zero-Shot Error: Experimental Results on Parallel Texts in 100 Languages. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 1112\u20131123.\n\n3. H. Ngo, T. Kim, E. Lee and I. Titov. Using Crowdsourcing to Learn Annotator-Specific Models for Multi-Label Sequence Labelling. Proceedings of the 2017 Conference on Empirical Methods on Natural Language Processing (EMNLP), pp. 1185\u20131195.\n\n4. N. Nguyen and O. Chapelle. Learning Labels for Multiple Annotators in Crowdsourcing. 2017.\n\n5. A. J. Blytherman, S. Krych, A. Chaudhury, B. Nallapon-Sutthijitkamnan and F. Szporek. Collective Learning of Annotator-Generic Information through Collaborative Feedback. In Proceedings of the International Joint Conference on Neural Networks (IJCNN), pp. 659\u2013669.\n\n6. H. Ngo, S. Yang and I. Titov. Adversarial Training for Cross-lingual POS Tagging. 2017.\n\n7. H. Ngo, Y. Liu, S. Kim and I. Titov. Adversarial Crowd Label Learning for Crowdsourced Sequence Labeling and Domain Adaptation. 2018.\n\n8. A. Wang, H. Wang, D. Chai, J. Yuan and W. Zhao. Collective Chatbots: How Deep is Crowd Collaboration? In Proceedings of the 2018 World Wide Web Conference (WWW), pp. 3109\u20133119.\n\n9. T. Mikolov, T. Chen and",
    "2df4a045a9cd7b44874340b6fdf9308d3c55327a": " We thank the anonymous reviewers for their comprehensive comments and suggestions.\n\n\n# **The Troll**\n\n## John Romeril\n\n##  \n\n## Dedication\n\nForeword\n\nThe Troll is a work of fiction. Names, places, and incidents either are the product of the author's imagination or are used fictitiously. Any resemblance to events or locales or persons living or dead, is entirely coincidental.\n\n## Contents\n\nForeword\n\nMap\n\n1 The Black Lake\n\n2 The Enchantress\n\n3 The Silver Bridge\n\n4 The Troll\n\n5 Into the Sun\n\n6 The Troll and the Queen\n\n7 The Wandering Mountain\n\n8 The Last Battle\n\n9 The Troll\n\n10 The Secret of the Queen\n\n11 Riddle\n\n12 Swordsman\n\n13 The Black Lake\n\n14 Faces\n\n15 The Troll King\n\n16 The Bridge of Lies\n\nAcknowledgments\n\nAbout the Author\n\nAbout the Author\n\nOther Books By John Romeril\n\nPraise\n\nCopyright\n\nAbout the Publisher\n\n# **THE TROLL**\n\n## _1_  \nTHE BLACK LAKE\n\nThere are many trolls in the world. Not all of them walk like he walked. Not all trolls are as big.\n\nThe one I knew was not very old, or he would have been much larger. Not all trolls can be compared to him in any way. The biggest of them do not walk on two feet. He was as tall as a troll, but not quite as big. Not all trolls have three black eyes. He was not just ugly, he was the most horrible creature you will ever see, and the most fearsome. But as I say, there are many trolls in the world.\n\nI have no idea why he was called a troll, but he was so large that he ate mountains, even whole mountains. I used to see his giant form in the distant valley when I came back from the river. I used to see him where the foothills of the mountains met. It was his kingdom. His castle stood at the crest of a mountain. It was a place to go for miles and miles around. He liked being by the Black Lake because it gave him something new to think about",
    "a313e98994fc039a82aa2447c411dda92c65a470": " Also, pre-ordering can be further improved by considering additional features like word forms, POS tags and dependency relation.\n\nIt would be interesting to validate that the gains obtained from pre-ordering is stable for other language pairs. It would be interesting to try pre-ordering approaches for other NLP tasks that have a lexical similarity between input languages. Some of the possible candidates are low-resource NMT for other language pairs INLINEFORM31 where a larger parallel corpus is available. Also, pre-ordering could be extended to addressing word order divergence between input and helping languages in other NLP tasks, e.g. multilingual Sentence Classification, where the problem arises for input languages with different word order.\nAcknowledgements\n\nThe work in this paper is partially supported by Google India Research and Development Grant, by Google.ai Fellowship, and Intel Parallel Computing Centre (India).\n\nWe would like to thank Google AI, Google.ai India program and IIT Bombay for the support. We are grateful to Prof Anurag Kumar (IIT Bombay) for providing the English-Hindi parallel corpus and for his valuable suggestions during the project development.\n\n[1]\n\nI. Bollegala, P. Li, P. Nguyen, and D. Tsoory. Neural machine translation by back-translation with unsupervised neural machine translation and unsupervised phrase-based translation. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pp. 1729\u20131739. Stroudsburg, Penn., USA, September 2017.\n\n[2]\n\nS. Cheng, G. Diao, P. Nguyen, P. Li, P. Vass, and N. Zhang. Learning to translate with bilingual neural machine translation: a framework and empirical study on Chinese to English, Spanish to English and German to English translation. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pp. 1490\u20131498. Stroudsburg, Penn., USA, September 2016.\n\n[3]\n\nX. Chen, L. Zhang, X. Ji, W. Wang, and X. Zhang. Multilingual deep neural machine translation. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, pp. 775\u2013783. Stroudsburg, Penn., USA, September 2014.\n\n[4]\n\nM. Cho, K. Lee,",
    "37861be6aecd9242c4fdccdfcd06e48f3f1f8f81": " In future work, we intend to explore whether the results observed with one assisting language can be generalized to other languages.\n\nA. Asadfar BABREF31\n\nB. Babu et al. BABREF32\n\nC. Cacciarelli et al. BABREF33\n\nD. Cucurulls BABREF34\n\nE. Dalmia et al. BABREF35\n\nF. Demiris et al. BABREF36\n\nG. Djuric BABREF37\n\nH. Galindo et al. BABREF38\n\nI. Guerini et al. BABREF39\n\nJ. Hassan et al. BABREF40\n\nK. Kannan et al. BABREF41\n\nL. Khare and Mohamed, BIBREF42\n\nM. Koo et al. BABREF43\n\nN. Lapata BABREF44\n\nO. Lee and Knight, BABREF45\n\nP. Lapata, BIBREF46\n\nQ. Liu et al. BABREF47\n\nR. Liu et al. BABREF48\n\nS. Mackenzie et al. BABREF49\n\nS. MacTavish et al. BABREF50\n\nS. MacTavish et al. BABREF51\n\nS. Mitchell et al. BABREF52\n\nS. Morel, BIBREF53\n\nS. Morel and Koehn, BABREF54\n\nT. Nikolinsk, BABREF55\n\nT. Palan and Haffari Fard BIBREF56\n\nU. Pham et al. BABREF57\n\nV. Pennington et al. BABREF58\n\nV. Petrov et al. BABREF59\n\nW. Phang et al. BABREF60\n\nW. Phang et al. BABREF61\n\nWikipedia, 2017. Statistics: English. Available at: https://en.wikipedia.org/wiki/Wikipedia:Statistics/English (accessed September 1, 2017).\n\nB. Alsace et al. BABREF26\n\nB. Ashburner et al. BABREF27\n\nB. Babu et al",
    "7e62a53823aba08bc26b2812db016f5ce6159565": " The pre-ordering approach should be further explored with a larger set of source-to-target Indian language pairs. Note that a more effective approach to pre-ordering for NMT would be building a Hindi grammar that can identify and re-order the sentences in the assisting language automatically. This is one of the future directions for this paper. In future, we would like to investigate whether pre-ordering can further benefit other NLP tasks like NER, NMT, Machine and Cross-lingual Reading Comprehension.\n\nAcknowledgements\nThis work has been funded by IBM Research India, Hyderabad, India. We would also like to thank Anurupma Chakravarthy for her insightful comments during the course of this work.\nAcknowledgments\n\nThis work has been partly supported by the Google AI Center for Excellence. Google India provides generous financial support for the AI center and other AI projects at IIT Bombay.\nIntroduction\n\nRecent advancements in Machine Translation for Indic languages has improved the translation quality across various Indian languages BIBREF20, BIBREF29, BIBREF31, BIBREF32, BIBREF33. However, the resource requirements associated with this task has been a significant bottleneck to its use in India. Translation between all major Indo-Aryan languages requires around 2.75-19.31 times more data BIBREF33 (on a word-by-word basis), than the available publicly available corpora BIBREF20, BIBREF34. There are approximately 1.28 billion Hindi speakers in India INBIBREF35, which corresponds to a 1.78 times demand in human resources if the current translation quality is to be preserved INLINEFORM0.\nWe have addressed this problem by studying the use of transfer learning for low-resource MTL (Morphological and Syntactic Learning) (MTL) NMT. MTL addresses the limited amount of available parallel data by jointly training multiple multilingual NMT frameworks with very similar languages. This paper presents an initial exploration of MTL in the context of Machine Translation (MT) for Indian languages and uses pre-ordering as an initial way to overcome word order divergence. MTL has been explored for cross-lingual tasks like crosslingual sentence similarity (CLSR) and crosslingual question answering (CQ). However, to the best of our knowledge, the use of MTL for MT has not",
    "9eabb54c2408dac24f00f92cf1061258c7ea2e1a": " Moreover, as a follow-on to the work presented in Section SECREF37, we plan to conduct a series of experiments on the automatic simplification of German texts for selected target groups using the data provided in this corpus.\nAcknowledgements\nWe acknowledge the support of the German Infrastructural Platform for Language Resources and Language Technologies (GIP), the National Research Data Infrastructure (NRDI), and the National Centre for Language Technology in the Humanities and Social Sciences (NeCLaHH) in the course of which this project was carried out.\n\n1. https://en.wikipedia.org/wiki/\n\nFlesch_Reading_Ease\n\n2. http://www.gutenberg-e.org/wiki/\n\nFlesch_Reading_Ease\n\n3. https://www.readingease.org\n\n4. https://euwebservices.universityofcalifornia.edu/\n\nindex-readability-and-wordcounts.html\n\n5. Dunning, B., A. S. Hayes, R. B. Hayes, and B. B. Ojha (1999). A new readability formula: a comparison with the Flesch. http://www.ncsl.nato.edu/pub/ncsu_e_dunb/documents/dunning-99.pdf. Accessed March 20,\n\n2006. Dunning, B., A. S. Hayes, R. B. Hayes, and G. D. Miller (2003). New metrics for readability: a comparison with the original Flesch. Language and Education, 16, 169\u2013175.\n\n6. T. Kauchak, T. L\u00f6ser, S. Mader, E. Steinberger, and M. Maia (2014).\n\nMeasuring Complexity: Machine Learning Versus Readability Formulas. The Computer Journal, 57, 2617\u20132638. 10.1109/TEC-CO.2014.1475.\n\n7. E. L. Lomax and T. Klinger (2018) German Text Simplification in the Year 2018. In Proceedings of WMT18, Workshop on Machine Translation, pp.\n\n2613\u20132615.\n\n8. S. P. Suter and K. O. Chamchamovit (2015). A",
    "3d013f15796ae7fed5272183a166c45f16e24e39": " Text simplification is useful for a wide range of applications, ranging from the improvement of information quality to cross-lingual accessibility to applications in the field of artificial intelligence. We will in the coming months work on extending the corpus with more parallel data and monolingual-only text to enrich the existing machine learning experiments.\nAcknowledgments\nWe thank the Centre for Digital Humanities and Hermeneutics in Switzerland for its support during the data collection phase. Additionally, we thank David Rizzo for his support during the data curation and the Centre for Research in Applied Natural Language Processing for its support in the machine learning experiments.\n::::: 1. http://www.fleschkincaid.com (accessed 23rd September 2019).\n::::: 2. http://readabilityformulas.com/ (accessed 23rd September 2019).\n::::: 3. https://www.sciencedirect.com/science/article/pii/S13871233130010056 (accessed 23rd September 2019)\n::::: 4. http://journal.i-semantics.org/ (accessed 23rd September 2019).\n::::: 5. https://zenodo.org/record/306493#citeas (accessed 23rd September 2019)\n::::: 6. http://www.cis.upenn.edu/\u02dcbmes (accessed 23rd September 2019)\n::::: 7. http://journal.i-semantics.org/ (accessed 23rd September 2019).\n::::: 8. http://www.gerts.ethz.ch/\u02dcgerts/simp.html#bib_list (accessed 23rd September 2019)\n::::: 9. https://papers.nips.cc/paper/6874-nmt-for-text-simplification-of-english-based-multilingual-corpus (accessed 16th January 2019)\n::::: 10. http://www.cis.upenn.edu/\u02dcbmes/cawmt2011/pdfs/cawmt.pdf (accessed 16th January 2019)\n::::: 11. http://www.cis.upenn.edu/\u02dcbmes/eurob_1-1.pdf (accessed 16th January 2019)\n::::: 12. https://arxiv.org/abs/1712",
    "9ee07edc371e014df686ced4fb0c3a7b9ce3d5dc": "\nAcknowledgments\n\nWe are grateful to our advisor Prof. Jason D. Hu for his valuable comments and suggestions. This research is supported by the National Science Foundation (award grant number CCF-1542107).\n\n[1]\n\nBender, C.; Agrawal, A. (2015) Unified Textual Query Understanding. Proc. International Joint Conference on Artificial Intelligence and the Web and the Joint Conference on Digital Libraries. pp. 1075\u20131078.\n\nBentivogli, F.; et al. (2015) WebQSP: A Multirelation question answering benchmark from Freebase. Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics.\n\nChen, C.; Chen, Y.; Zhang, H.; Li, Y.; Li, X.; Duan, L. (2012) Word2vec: Distributed representations of words and phrases 2.0. In Proceedings of the 21st Conference on Computational Natural Language Learning (re-visit), pp. 159\u2013168.\n\nDerivan, C.; et al. (2016) Exploring Knowledge Graph Learning with a Large-scale Question Answering Dataset. In Proceedings of International Conference on Web Search and Data Mining (2015).\n\nDu, J.; et al. (2017) DGCN: Deep neural relational graph CNNs for complex question answering. In Proc. of AAAI Conference on Artificial Intelligence.\n\nHu, J. and Mi, H. (2017) Relation detection using Bidirectional LSTMs. Arxiv, 1710.09424.\n\nJin, D.; et al. (2014) OpenNE: Open domain relation extraction via unsupervised mining of text corpora. In Proceedings of International Joint Conference on Artificial Intelligence and the Web (IJCAI-2015), pp. 2679\u20132786.\n\nKadlec, K.; et al. (2016) The SemEval 2016 Task 9: Relation extraction with multiple-choice labels. Arxiv, 1612.00783.\n\nMa, C.; et al. (2016) Relation extraction from sentences via bidirectional LSTM. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics.\n\nMohammed, H.; et al. (2016) Relation Detection and Ranking using Bidirectional LSTMs for Knowledge",
    "d3aa0449708cc861a51551b128d73e11d62207d2": "\n\nTable 3. KBQA Results\nImproving Semantic Parsing by Relation-Directed Spatial Attention\nYan et al., 2018\n\nThe purpose of this work is to improve semantic parsing by learning relation-aware representations. Specifically, we show that leveraging entity and context features, namely spatial attention and joint context features, helps to improve the semantic parsing task performance.\nIn this study we use an end-to-end neural model to tackle the semantic parsing problem. This model is based on a sequence-to-tree algorithm, where sequences of words are expanded, in turn generating a parse tree. To improve this model, we investigate how to learn good sequence representations from a sequence consisting of word and relation co-occurrence features. The key contribution is that we use a spatial attention mechanism in the encoder, in order to better capture entities and relations from question context.\nSpecifically, given a sentence and its possible parse tree, the decoder aims to generate a distribution over the parse trees.\n\nThe problem is to learn the function p to transform sequences of word-relation co-occurrences to a parse tree. First, the encoder computes joint context features $Cj$ for each word in question based on the information in its context, that is, all relations and entities associated to this word. Second, the decoder employs a spatial attention mechanism to select context vectors that best match entities and relations in the context. Third, using the context vectors and the joint context features, the decoder generates a parse tree (see Equation (8), and Figure 3 ).\n\nTo enable the attention mechanism to work at each word position in a sequence, we build a sentence-word attention model on joint context features:\n\nwhere $i(j) $ is the word position of $j$ in the sequence of words, $C_{j}^{\\cdot c} $ is the $j$th joint context feature vector in context $c$, and $patt\\cdot (c(t_x)_j^ $ is the corresponding tree pattern where each pattern corresponds to a child node in parse tree T, and $t_x$ is the node at position $x$ of context $c$. Each context vector can be seen as a sequence of word-relation pairs, which are considered as the features.\n\nSince context vectors $c$ are also words, we also embed word-relation pairs in them by computing the inner",
    "cfbec1ef032ac968560a7c76dec70faf1269b27c": " Finally, we will release the pre-trained relation models and data/code used in this paper.\nAcknowledgments\nWe would like to thank the anonymous reviewer and the assistant conference editors for their insightful feedback that significantly improved the quality of this paper. We thank the participants in the Google QA track at EMNLP 2017/ACL 2018, the organizers of the EMNLP 2017 relation detection shared task, and the organizers of the AAAI 2019 relation extraction shared task for the discussions that informed our work.\n\nWe would like to thank our collaborators in the KBQA community for the valuable discussions. We would also like thank the staff of the Microsoft Research Asia Lab (Shenzhen) for their help during the experiments.\n\nWe would like to acknowledge the support of Amazon Research, especially for the development of our KBQA system.\n\nLast, we are grateful for the support from the National Natural Science Foundation of the China (61551203, 61501132, 61501986), and NSFC University for Young Scientists Joint Fund (DUTOYS) for their support.\n\n1 https://ai.google/pubs/2012/GoogleQuestionAnswerSystem.pdf\n \n### \"I'm going to see the stars and the clouds and God. I don't care where I go, as long as I can get there.\" -Parker Posey, The Big Lebowski\n\n### From the book\n\n## The Greatest Cocktail Party in History\n\nThe Last Dinner\n\nFrom the memoir\n\nWhen the Saints Go Marching In\n\nBy Pat Conroy\n\n## Contents\n\n  1. Title Page\n  2. The Greatest Cocktail Party in History\n  3. When the Saints Go Marching In\n  4. Copyright\n\n## The Greatest Cocktail Party in History\n\n\"I'm going to see the stars and the clouds and God. I don't care where I go, as long as I can get there.\"  \nI'm going to see the stars and the clouds and God. I don't care where I go, as long as I can get there.\"  \nI'm going to see the stars and the clouds and God. I don't care where I go, as long as I can get there.\"  \nI'm going to see the stars and the clouds and God. I don't care where I go, as long",
    "c0e341c4d2253eb42c8840381b082aae274eddad": "\n\nAcknowledgments\n\nThis work is supported by Intel Labs, Microsoft Corp. and NSF. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of Intel Labs, Microsoft or the National Science Foundation.\n\n[1]\n\nhttp://www.openfdb.org/\n\n[2]\n\nhttps://openfdb.org/freebase/\n\n[3]\n\nhttps://togelius.us/data/freebase2m/\n\n[4]\n\nhttps://www.reddit.com/r/GameofThrones/\n\n[5]\n\nhttp://kbquestions.com/\n\n[6]\n\nhttp://gameofthrones.wikia.com/wiki/Mike_Kelley\n\n[7]\n\nhttp://dbpedia.org/resource/Mike_Kelley\n\n[8]\n\nhttps://dbpedia.org/resource/List_of_Game_of_Thrones_characters\n\n[9]\n\nhttp://dbpedia.org/resource/Episode_Writer\n\n[10]\n\nhttps://dbpedia.org/resource/TV_Series\n\n[11]\n\nhttp://freebase.cimpa.cs.cmu.edu\n\n[12]\n\nhttps://dbpedia.org/resource/Play_\n\n[13]\n\nhttp://dbpedia.org/resource/TV_Show\n\n[14]\n\nhttps://dbpedia.org/resource/TV_Appearance\n\n[15]\n\nhttp://en.wikipedia.\n\n[16]\n\n{Mike_Kelley, Episodes_Written_By, Writing_Credits_By, Writer, Writer, Writer}_1\n\n[17]\n\nhttp://freebase.cimpa.cs.cmu.edu/entity/Mike_Kelley\n\n[18]\n\nhttp://en.wikipedia.org/wiki/Mike_Kelley\n\n[19]\n\nhttp://www.imdb.\n\n[20]\n\nhttp://freebase.cimpa.cs.cmu.edu/entity/Writer\n\n[21]\n\nhttp://",
    "1ec152119cf756b16191b236c85522afeed11f59": " We also thank the members of the RUDi Labs reading group for their comments on the first draft of this manuscript.\n\nThe authors are aware that they took a somewhat conservative approach when deciding whether to include hyperlinked references in References. We decided to forgo hyperlinking in References to ensure that all referenced PDFs were actually readable by an end user. The source of each reference is provided in the list of PDFs in the References section.\n[BIBREF0] Bojanowski S. et al. (2010) Enriching word representations with subword information. in EMNLP, pp. 409-416. http://aclweb.org/anthology/P10-1041. pdf.\n\n[BIBREF1] Mikolov T., Chen CK., Corrado S., Dean J. (2013) Efficient estimation of word representations in vector space. in EMNLP, pp. 1734-1742. http://aclweb.org/anthology/D13-1144. pdf.\n\n[BIBREF2] Peters J., Chen C. D., Wang K. (2018) Deep contextualized word representations. in EMNLP, pp. 3432-3450. http://aclweb.org/anthology/D18-1778. pdf.\n\n[BIBREF3] Devlin J., Chang K., Lee K., Toutanova T. (2018) Bert: transforming text with deep bidirectional transformers. in EMNLP, pp. 2981-2991. http://aclweb.org/anthology/D18-1172. pdf.\n\n[BIBREF4] Liu K., Goyal N., Sridhar K., Iyer R. (2019) Improving text classification with dynamic word representations. in EMNLP, pp. 3031-3040. http://aclweb.org/anthology/D19-1001. pdf.\n\n[BIBREF5] Liu K., Goyal N., Sridhar K., Iyer R. (2019) Probing Language Representations from Transformers. in EMNLP, pp. 2469-2479. http://aclweb.org/anthology/D19-1088. pdf.\n\n[BIBREF6] Peters J., Belinkov M. V., van der Maaten L. J",
    "891c2001d6baaaf0da4e65b647402acac621a7d2": " We thank the University of Toronto for providing us with computing resources.\n\nReferences\n\n<div class=\"publication-refs ref-list entry\" id=\"BIBREF0\">BIBREF0.\n\nMikolov, T., Chen, C., Corrado, G., & Dean, J. (2013). Efficient Estimation of Word Representations in Vector Space. In International Conference on Web Search and Data Mining (ICWSDM), pp. 139\u2013147.\n\n[<a href=\"https://dl.acm.org/doi/10.1145/2440308.2440329\">[BIBREF0]\n\n<div class=\"publication-refs ref-list entry\" id=\"BIBREF1\">BIBREF1.\n\nChen, C., & Liu, S. (2014). Negative-Sampling Based Estimation of Word Representations in Vector Space. In 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 1778\u20131784.\n\n[<a href=\"https://dl.acm.org/doi/10.3115/v1/D14\u20131163.bib\">[BIBREF1]\n\n<div class=\"publication-refs ref-list entry\" id=\"BIBREF2\">BIBREF2.\n\nPeters, C., Chen, C., & Goodman, N. (2018). ELMo: Deep Linguistic Models. In Conference on Empirical Methods in Natural Language Processing (EMNLP).\n\n[<a href=\"https://dl.acm.org/doi/10.18653/v1/P18\u20132141\">[BIBREF2]\n\n<div class=\"publication-refs ref-list entry\" id=\"BIBREF3\">BIBREF3.\n\nPeters, C., Chen, C., & Goodman, N. (2018). Deep contextualized word representations. In Conference on Empirical Methods in Natural Language Processing (EMNLP).\n\n[<a href=\"https://dl.acm.org/doi/10.18653/v1/P18\u20131043\">[BIBREF3]\n\n<div class=\"publication-refs ref-list entry\" id=\"BIBREF4\">BIBREF4.\n\nChambers",
    "66c96c297c2cffdf5013bab5e95b59101cb38655": "\nReferences:\n\n[noitemsep]\n\nahemt2017automated.\n\n[noitemsep]\n\namodei2018neural.\n\n[noitemsep]\n\nbertsk2019data.\n\n[noitemsep]\n\nbhaisare2018deep.\n\n[noitemsep]\n\nbertwillis2013deep.\n\n[noitemsep]\n\ncarlini2018deep.\n\n[noitemsep]\n\ncheng2019bertiext.\n\n[noitemsep]\n\ncormode2009evaluation.\n\n[noitemsep]\n\ncormode2009learning.\n\n[noitemsep]\n\ncui2018naturalth.\n\n[noitemsep]\n\ndaniel2015hierarchical.\n\n[noitemsep]\n\ndong2016hierarchical.\n\n[noitemsep]\n\nfabbri2018generating.\n\n[noitemsep]\n\nfaresmith2018deep.\n\n[noitemsep]\n\ngarcia2018automating.\n\n[noitemsep]\n\ngoh2017learning.\n\n[noitemsep]\n\ngrelu2018detecting.\n\n[noitemsep]\n\ngulli2016learning.\n\n[noitemsep]\n\ngulli2017learning.\n\n[noitemsep]\n\ngulli2018predicting.\n\n[noitemsep]\n\ngulli2018semantic.\n\n[noitemsep]\n\nhassan2018anonimizacion.\n\n[noitemsep]\n\njacob2017identifying.\n\n[noitemsep]\n\nkalinin2017analyzing.\n\n[noitemsep]\n\nkomninos2011identifying.\n\n[noitemsep]\n\nkontokosta2017deep.\n\n[noitemsep]\n\nli2017improving.\n\n[noitemsep]\n\nmao2019hadoken.\n\n[noitemsep]\n\nmamede2016automated.\n\n[noitemsep]\n\nmei2017using.\n\n[noitemsep]\n\nnguyen2016deep.\n\n[noitemsep]\n\npeng2017deep.",
    "6b53e1f46ae4ba9b75117fc6e593abded89366be": "\nREFERENCES\n\n<http://www.deepreading.eu/> BIBREF7\n\n<http://www.deepreading.eu/> BIBREF8\n\n<http://www.deepreading.eu/> BIBREF9\n\n<http://www.deepreading.eu/> BIBREF10\n\n<http://www.deepreading.eu/> BIBREF11\n\n<http://www.deepreading.eu/> BIBREF12\n\n<http://www.deepreading.eu/> BIBREF13\n\n<http://www.deepreading.eu/> BIBREF14\n\n<http://www.deepreading.eu/>\n\n<http://www.deepreading.eu/> BIBREF15\n\n<https://pypi.org/project/python-sklearn/\n\nhttps://docs.scipy.org/doc/scipy/0.18.1/reference/generated/sklearn.externals.pandas.html#sklearn.externals.pandas.LabelBinarizer\n\n<http://www.deepreading.eu/>\n\n<http://www.deepreading.eu/>\n\n<http://www.deepreading.eu/> BIBREF16\n\n<http://www.deepreading.eu/> BIBREF17\n\n<http://www.deepreading.eu/> BIBREF18\n\n<https://pypi.org/project/python-scikit-learn/\n\nhttps://docs.scipy.org/doc/scipy/0.18.1/reference/generated/sklearn.externals.pandas.html#sklearn.externals.pandas.LabelBinarizer\n\n<https://pypi.org/project/python-sklearn/ BIBREF19\n\n<https://dl.fba.hut.fi/bitstream/100013/312839/3.pdf> BIBREF20\n\n<http://www.deepreading.eu/>\n\nwww.sciencedirect.com\n \n## JACK McDEVITT\n\n# ALIENS  \nTOUCH\n\n## Contents\n\nChapter 1 (The New Kids)\n\nChapter 2 (The New Kid)\n\nChapter 3",
    "c0bee6539eb6956a7347daa9d2419b367bd02064": "\n\nReferences\n\n[BERT]\n\ndevlin2018bert.\n\nDevlin, Jacob, et al.\n\n\"BERT: Pre-training of deep bidirectional transformers for language understanding.\"\n\nhttps://arxiv.org/abs/1810.04805\n\nAccessed: June 20, 2020.\n\n[Cormode _et al., 2009]\n\nCormode, G., Srivastava, A., and Koutra, F.\n\n(2009).\n\nAnonymizing clinical records using linguistic patterns.\n\nIn: ISMB/ECCB 2009 Workshop on Clinical Proteomics: Challenges in Data Mining and Machine Learning, 2009.\n\n[deronon _et al., 2016]\n\nDeron, Y., G\u00fcnel, S., and Tveit, A.\n\n(2016).\n\nDeep learning for document de-identification.\n\nPattern Recognition, 2016, 39(3), pp. 1239-1255.\n\n[garcia _et al., 2018]\n\nGarcia-Castro, A., Pujadas-Ruiz, D., and Lopez, J.-C.\n\n(2018).\n\nAutomating clinical record de-identification.\n\nIn: Proceedings of the 5th IberSECTECH Conference, 2018, pp. 4-15.\n\n[gil _et al., 2008]\n\nGil-Gonzalez, I., Pujadas-Ruiz, D., L\u00f3pez, J.-C., and Areny-Valldeperas, S.\n\n(2008)\n\nNes, a tool for de-identification of Spanish text.\n\nIn: ISMB/ECCB 2008 Workshop on Biomedical Informatics, Sep. 2008, 2008, pp. 17\u201321, Washington, D.C.\n\n[habi _et al., 2015]\n\nHabi, K., Abi, O., and Hekimov, O.\n\n(2015).\n\nBiom: a tool for de identification of Turkish text.\n\nIn: Second Workshop on Biomedical Informatics, 2015, London, United Kingdom.\n\n[karp _et al._, 2017]\n\nKarpukha, T., Kuznecov, A., Lachs",
    "3de0487276bb5961586acc6e9f82934ef8cb668c": " We would like to acknowledge the support from the organiser of the MEDDOCAN workshop, in particular for providing the challenge data. We also thank all the MEDDOCAN participants for making the challenge possible.\nReferences\n\n[1] BERT: Wikipedia pretraining for language understanding.\n\nDevlin, J. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.\n\nhttps://science.sciencemag.org/content/357/6434/2010.\n\n[2] Sastra, J. et al. Semeval-2019 task 5: Sentence-level anonymization of medical records (SemaMed-R).\n\nhttps://aclanthology.org/E19.723-2018\n\n[3] BIRN. A clinical narrative corpus of medical reports (NUBES). 2014\n\nhttp://www.birn.gr/nlp/NUBES\n\n[4] Cormode, M. et al. De-identification, anonymization, and patient identifier-scrubbing for research: recent developments in the NLP community.\n\nBIRN. 2015\n\nhttp://www.birn.gr/nlp/NUBES\n\n[5] Goyal, S. et al. The data/nlp research symposium 2013: open challenges, benchmarks, and evaluations for biomedical natural language processing.\n\nhttps://www.cl.cam.ac.uk/users/sh/home/publications/2013_GOLDMONI/goldmoni-2013_slides.pdf\n\n[6] Khashabi, A. et al. On the usage of pretraining for sequence labelling.\n\nhttp://arxiv.org/pdf/1901.03223v2.pdf\n\n[7] Vaswani, M. et al. Attention is all you need: Transformer models.\n\nhttps://openreview.net/pdf?id=Bkx3-I\n\n[8] Devlin, J. et al. Biological clinical term detection for open access text: cross-lingual transfer and task-level adaptation.\n\nhttps://aclanthology.org/R19-2017.1\n\n[9] Zeng, Y., Nawaz, R., & Caceres, R. Open AI's",
    "113d791df6fcfc9cecfb7b1bebaf32cc2e4402ab": "\nAcknowledgments\nThis research was funded by a National Science Foundation Graduate Research Fellowship and by the National Institute of Mental Health of the National Institutes of Health under award numbers 3T32 MH 07047-16 and MH 104843-02.\n\nWhile developing this system, we drew inspiration from and made use of many tools and architectures. We found our model architecture in [bahdanau2014neural]\n. For language-aware attention, we built upon [luong2015effective] and [bahdanau2015convolutional]. The language distance metric used to choose between wFSTs was inspired by [deri2016grapheme]\n\n. For g2p data cleaning, we used code provided by [suthori2002prosodic].\nThese are some of the libraries used:\n\n# Copyright\n\nThis work was done as part of our Ph.D. thesis, Carnegie Mellon University\n\n# Disclaimer\n\nThis work is licensed under a Creative Commons Attribution 4.0 International License. To view a copy of this license, visit <http://creativecommons.org/licenses/by/4.0/> or send a letter to <creativecommons@creativecommons.org>.\n\n# Acknowledgments\n\nMany thanks to our thesis adviser, John Deri, and all of the other faculty members who guided us while we worked on this project.\n\n# References\n\n#### References:\n\n[1] Abjad - Wikipedia. 2018. Retrieved from https://en.wikipedia.org/wiki/Abjad\n\n[2] Deri, J., and K. Knight. 2016. \"Learning a unified grapheme-to-phoneme model for low resource languages from high resource data.\" In Proceedings of the 52nd Annual Meeting\n\nof the Association for Computational Linguistics, pages 1214\u2013 1223\n\n[3] Firth. 1957. \"A note on the pronunciation of abcedary.\" In _Studies in Phonetics_, pp. 65\u2013 76.\n\n[4] International Phonetic Alphabet - Wikipedia. 2018. Retrieved from https://en.wikipedia.org/wiki/International_Phonetic_Alphabet\n\n[5] Jyothi, L. H., B. T. Knight, R. Hasegawa-Johnson",
    "0752d71a0a1f73b3482a888313622ce9e9870d6e": " This could be especially useful for foreign loanwords in English and German, which both have English-based orthographic systems. Given this, a second potential application would be monolingual g2p using English-based orthographies for low resource languages, such as Scottish Gaelic and Scottish English.\nAcknowledgments\nWe thank our many reviewers, including Christopher D. Manning, Scott A. Johnson, Kostas Schlie, Anoop Cherian, and Kostas Ortega, for their many helpful comments and suggestions. We would especially like to thank Christopher D. Manning for bringing this work to our attention. Many of our ideas were based on discussions at the Isolectics 2017 workshop.\nThis project was supported by the Natural Sciences and Engineering Research Council Canada. We are also grateful to NVIDIA for their generous donation of CPUs for code optimization and cloud compute resources.\nReferences\nBIBREF1.\n\nhuyck2016phonetisaurus,\n\nhuyck2016new,\n\nsudhakar2013phoneme,\n\njohnson2016google,\nbakker2016multilingual,\nderi2016grapheme\n\nBIBREF2.\n\nlau2018learning,\nzhang2017phonemize,\nbahm2015phoneme,\n\npeng2016learning\n\nBIBREF3.\n\njohnson2015learning,\njohnson2016zero,\nbostrom1988phonological\n\nBIBREF4.\n\ndabre2017model,\ntrompf2018phonemization\n\nBIBREF5.\n\nkuhn2016phonemes,\nkuhn2013universal,\n\nkim2012universal\n\nBIBREF6.\n\nhoffmann2015wals\n\nBIBREF7.\n\njohnson2016google,\nhu2017neural,\nhu2017language\n\n[1]\n\n[1]: Huyck, Sven and Deri, Aditya and Knight, Alex and Knight, Christopher P, 2016, \"Multilingual Grapheme-to-Phoneme Conversion Using Bidirectional Sequence-to-Sequence Models\"\n[1]\"A unified sequence-to-sequence learning approach to multilingual grapheme-to-phoneme conversion and transcription\"\nBIBREF8.\n\nhixon2011phonemic,\n\nk",
    "55c8f7acbfd4f5cde634aaecd775b3bb32e9ffa3": " Such etymological information would be useful in other NLP systems as well.\nAn important extension to the models presented here is to learn an orthography model and then to use it to generate the necessary phoneme sequences. For example, the model could encode the orthographic sequences of a language's words in a fixed-length vector, and then could be used for phoneme prediction within that language's phonotactic context, such as within a word.\n\nData-driven approaches to grapheme-to-phoneme conversion are most effective for languages with ambiguous orthographies. g2p for languages with unambiguous orthographies is difficult because there are usually many possible phoneme sequences that could be used to write the word, such as English. It is an interesting challenge for future work to create a network that is able to predict an arbitrary word from its orthography in English. Deri and Knight's system used a different neural network architecture with this goal in mind. Using neural networks may also prove useful for creating orthographic rules for languages in which there is no standard orthography.\n\nAcknowledgments\nWe would like to thank Lacey Baldwin for her generous help with data cleaning, and the anonymous PronunList server for providing the Penn/CED and Penn/UniEmo corpora.\nReferences\n\n* BIBREF1. Knight, R.E., & Deri, S. (2016). Phonetisaurus: A multilingual tool for phonetisaurus pronunciation mapping. In Proceedings of Interspeech 2016 (pp. 1705\u20131708), Gothenburg, Sweden. <https://per-d.eu/publications/16-S3-Phonetisaurus/>\n\n* BIBREF2. Knight, R.E., & Deri, S. (2016). Combining data-driven and linguistic modelling to improve grapheme-to-phoneme conversion for low-resource language pairs. Language Resources and Evaluation, 50(5), 1511\u20131528.\n\n* BIBREF3. Knight, R., Wass, J., Deri, S., & Brugman, A. (2017). Phonetisaurus-based phoneme mapping in low-resource language pairs. In Interspeech 2017, Workshop on Language Resources and Technology Development for Under-resourced Languages (pp. 11\u201313).\n\n* BIBREF4. Der",
    "4eaf9787f51cd7cdc45eb85cf223d752328c6ee4": "\nAcknowledgements\nThis work was funded by a U.S. National Science Foundation Research Initiation Grant\nD. Mellinger: This research was conducted in the Sensory Computing Lab at the Rochester Institute of Technology. Thank you to the members of my thesis committee for all of your help and guidance.\nD. Mellinger, K. U. Feser, A. D. Walker: This research was supported in part by U.S. National Science Foundation Grant IIS-1503234, in part by the Air Force Research Laboratory, and in part by the Intel Corporation under Contract No. HH-6047-102-P-2116.\nJ. Knight: All of the code used for this paper is freely available at https://git.io/vXqW/g2p-evaluation\nReferences\n\n[1]\n\nBIBREF1\n\nPhonetisaurus: A hybrid system for phoneme-level phonetic transcription.\n\nPhonetisaurus. BIBREF1. http://phonetisaurus.eu/.\n\nAvailable: http://phonetisaurus.eu/\n\n[2]\n\nBIBREF2\n\nEmeka-jung: A grapheme-to-phoneme system for low-resource languages.\n\nEmeka-jung. BIBREF2. http://elmo.lingph.illinois.edu/g2p/.\n\nAvailable: https://elmo.lingph.illinois.edu/g2p/\n\n[3]\n\nBIBREF3\n\nDeri, D., and R. Knight. Automatically adapting grapheme-to-phoneme systems trained on high resource languages to low resource ones. In EMNLP 2016.\n\nDeri, D., and R. Knight. Automatically adapting grapheme-to-phoneme systems trained on high resource languages to low resource ones. BIBREF3. arXiv:1803.07123. http://arxiv.org/abs/1803.07123.\n\n[4]\n\nBIBREF4\n\nDeri, D., R. De Melo, M. Lever, and R. Knight. A comprehensive lexical-phonological corpus of South African English. In Proceedings of INTERSPEECH 2015.\n\nDeri, D.,",
    "fb2b536dc8e442dffab408db992b971e86548158": ".\n\nREFERENCES\n\n[1] Adil, M. O., J. Heim, G. Pasternak, and Y. Bengio.\n. 2017. Efficiently training encoder-attention-decoder for abstractive summarization of long documents.\n\nECCV.\n\n[2] Adil, M. O., G. Pasternak, J. Heim, and Y. Bengio.\n\n2018. A neural attentional summary generation network with word-based coverage.\n\nECCV.\n\n[3] Armentrout, C. A., J. Heim, G. Pasternak, and Y. Bengio.\n\n2018. Data augmentation by data generation.\n\nTACL.\n\n[4] Armentrout, C. A., J. Heim, and C. S. Chen.\n\n2017. Tune-n-Summarize: Deep summarization with domain transfer.\n\nTACL.\n\n[5] Armentrout, C. A., K. Chen, M.-K. Tan, and J. Heim.\n\n2017. Improving extractive abstractive summarization by using large quantities of out-of-domain data.\n\nEMNLP.\n\n[6] Armentrout, C. A., C. S. Chen, H. H. Wang, and J. Heim.\n\n2018. Summariztion and knowledge distillation using deep neural networks trained on large quantities of out-of-domain data.\n\nEACL.\n\n[7] Armentrout, C. A., K. Chen, M.-K. Tan, and J. Heim.\n\n2018. Exploring knowledge representation and inference in abstractive summary generation.\n\nTACL.\n\n[8] BANSAL, E., and R. K. S. Jain. 1997. Learning latent topics for text summarization.\n\nKDD.\n\n[9] BIBREF0. A. Kalchbrenner and C. S. Lee. 2018. Neural seq2seq summarization with attention: a system description. ACM Trans.\n\nComput.-Commun.\n\n33:37\u201347.\n\n[10] BIBREF1. Armentrout, C. A., and",
    "31735ec3d83c40b79d11df5c34154849aeb3fb47": ".\nReferences\nAgarwal, H., and A. Chopra. 2015. Generative Story Summarization with Reinforcement Learning. ACL.\n\nAgarwal, H., A. Chopra, P. Liu, and R. R. Salakhutdinov. 2015. Automatic Keyword Identification for Topic-Oriented Summarization. In Proceedings of the Twenty-Second Workshop on the Evaluation of Information Access (CLEF). Pages 10\u201318.\n\nBengio, S., and S. D. Louis. 1993. Learning to Summarize through Templates. In Proceedings of the Thirty-Fourth Annual Meeting on Association for Computational Linguistics. Volume 2. Washington, DC.\n\nBengio, S., R. Larochelle, A. K. Deoras, K. Simard, M. J. Plunkett, and A. F. C. Smith. 2005. Learning to summarize through templates and language models. Computational Linguistics Journal 31(3\u20134): 347\u2013385.\n\nBIBREF0.\n\nSee http://www.cs.cuhk.edu.cn/\u223cwuc/works/docs/SummarizationSurveyAndExperiments.pdf.\n\nBIBREF1.\n\nSee http://citeseerx.ist.psu.edu/10.1.1.195.8356.pdf.\n\nBIBREF2.\n\nSee https://aclweb.org/anthology/C/C15/papers/C15-1835.pdf.\n\nBIBREF3.\n\nSee http://data.cnn.com/ds/summarization.pdf.\n\nBIBREF4.\n\nSee https://www.aclweb.org/anthology/P16-1010.pdf.\n\nBIBREF5.\n\nSee https://pdfs.semanticscholar.org/4e22.pdf.\n\nBIBREF6.\n\nSee http://citeseerx.ist.psu.edu/10.1.1.18.5075.pdf.\n\nBIBREF7.\n\nSee http://citeseerx.ist.psu.edu/10.1.1.7.5756.pdf.\n\n",
    "10d450960907091f13e0be55f40bcb96f44dd074": ".\nReferences\n\n[1] T. Abraham and D. Meurers, \"SummEval: An End-User-Friendly Tool for Automatic Evaluation of Summary Quality and Readability,\" in Proceedings of the 57th Annual Meeting of the Association of Computational Linguistics, pp. 2127\u20132132, 2016.\n\n[2] R. Adams, R. Barzilay, G. Das, L. Gimpel, and J. Callaghan, \"Fast-RL: a New Approximate Bayes Approach to Reinforcement Learning,\" in Proceedings of EMNLP, 2014.\n\n[3] D. Allen, J. Gimpel, and K. Doshi-Velez, \"ReSum: Automatic Extractive Summarization via Generative RNN Encoder-Decoders,\" in Proceedings of the 55th Annual Meeting of the Association of Computational Linguistics, pp. 1268\u20131277, 2015.\n\n[4] J. Ang and D. McAllester, \"Attention-Based Neural Abstractive Summarization,\" in Proceedings of Empirical Methods Research in NLP, 2015.\n\n[5] Y-Y. Ash, F. Liu, and R. McCallum, \"Improving Summaries Using SummBank,\" in Proceedings EMNLP, 2017.\n\n[6] D. Attardi, T. Kulkarni, and R. Barzilay, \"Multi-Doc Summarization with Parallel Attention,\" in Proceedings of EMNLP, 2016.\n\n[7] A. Bachev, Y. Yang, and D. Meurers, \"Using Templates to Improve Extractive Text Summarization,\" in Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, pp. 2172\u20132179, 2015.\n\n[8] M. Ballesteros, A. Bies, S. Dua, B. S. Jones, X. Lin, and G. Neubig, \"Abstractive Summarization with Multi-Doc Capsules,\" in Proceedings of EMNLP, 2018.\n\n[9] M. Ballesteros, X. Lin, S. Choi, R. Barzilay, N. P. Kwatra, D. Meurers, and J. Callaghan,",
    "b5608076d91450b0d295ad14c3e3a90d7e168d0e": ".\n\nNotes and References\n\n1 BIBREF0 J. Yuan et al. (2020) PG-net: a pointer-guided neural abstractive summarization model with coverage. Journal of Artificial Intelligence Research. 61: 1661\u20131684.\n\nhttps://www.jair.org/index.php/ jair/article/view/11131/\n\n2 BIBREF1 L. Xiao et al. (2017) Domain-transfer learning improves abstractive summarization. International Joint Conferences on Neural Networks: Workshop on Large Language Models.\n\n3 BIBREF2 K. L. Choi et al. (2018) Abstractive story summarization with pointer-guided neural network. Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: A Conference on Emmerpimental Method in Natural Language Processing, EMNLP 2018., pp. 1663\u20131671.\n\n4 BIBREF3 D. Liu et al. (2017) CNN/daily mail: a large-scale abstractive news summarization benchmark corpus. International Journal of Language and Computation. 2(2): 24.\n\n5 BIBREF4 D. Liu et al. (2019) Domain shift in neural abstractive summarization. International Joint Conferences on Neural Networks.\n\n6 BIBREF5 K. L. Choi, P. Lin, and R. B. Klein (2019) Summarization as abstractive machine translation. AI Magazine.\n\n7 BIBREF6 K. L. Choi et al. (2020) Understanding student reflections through abstractive summarization. Journal of Computational Linguistics.\n\nhttp(//ling.upenn.edu/\u223cjchoo1/summarization.pdf)\n\n8 BIBREF7 J. Xu, H. Guo, and M. Li (2019) Exploring abstractive summarization of student reflections. International Joint Conferences on Neural Networks.\n\n9 BIBREF8 T. N. Kober et al. (2017) Show, attend and tell: Sequence-to-sequence learning with attention and coverage layers. International Joint Conferences on Neural Networks.\n\n10 BIBREF9 K. L. Choi and H. Guo (2018) Pointer networks for abstractive text summarization. International Joint Conferences on Neural Networks.\n\n11 BIBREF",
    "c21b87c97d1afac85ece2450ee76d01c946de668": ".\n## 2.3 Introduction\n\nIn this chapter, we will first review the state-of-the-art for text summaries (Section 3), as well as the related area of abstractive summarization (Section 2) before we discuss our contributions in detail (Section 11). Then, we will outline our data-set (Sections 5\u201310) for the task of reflecting abstractive summarization and present the related tasks of keyphrase extraction, document ranking, and question generation.\n\nA. Text Summarizer\n\nTable 2.3\n\nTable of text summaries\n\nTable 2.3 presents the summarized texts from TREC documents as an example of the TREC summary task. In addition, Figure 2.4 shows the three reference summaries from the TREC conference documents.\n\nTable 2.3 is an abridged version in terms of the number of sentences of the full table given in [1], for a clear presentation. TREC is an organization that sets up yearly evaluation tasks on information retrieval topics based on some actual real-world topic, which are then passed to participating organizations for completion. The TREC task is to summarize the given TREC document into a single summary containing no more than 10 sentences. Each one of the participating organizations chooses to approach the task using a different method, as long as it is an automatic summarization model. As a result, the different TREC summaries could be diverse and vary in size as well as style. The TREC summaries are usually short in size and may have completely different styles, so TREC summaries are more suitable in evaluating summarization systems than abstractive systems.\n\nTo further demonstrate an example of various approaches, we also include the two summaries produced by the NIST system in the table. The NIST method involves extracting a summary containing 5 to 15 sentences from the TREC document, summarizing by generating a summary which contains some of the words in the query, that were present in the original TREC document. The rest of the vocabulary is generated using a simple template approach. Such summarizer produces a very short summary (only a single paragraph long) and has little lexical overlap with the original document despite being generated from the same document. However, as TREC only involves a single document, the language diversity and style are limited, and therefore the NIST method is not able to produce a good summary. As mentioned in [1], many",
    "d087539e6a38c42f0a521ff2173ef42c0733878e": " We also see potential in applying our idea to other family of language models such as XLNet, which utilizes an even longer sequence length, up to 1280 tokens.\n\nAcknowledgements\nWe would like to thank our reviewers, as well as other experts in deep learning models, who made insightful discussions in helping us to better understand the limitations of knowledge distillation.\n\nAppendix A: BERT-Related Terms\nIn order to avoid burdening the reader with the technical details of BERT as well as the NLP field, we include the following short glossary of commonly encountered terms.\n\nHidden State Size: The dimension size of BERT's hidden states, denoting the length of the contextualized vector.\n\nMasked Language Modeling: In the masked language modeling task, the task is to predict the missing words given context. We apply this task to the context itself, which would be a sequence of words to be masked out.\n\nWordPiece Tokens: WordPiece segments are sub-word units obtained by segmenting the training corpus text with a greedy algorithm with a desired number of segments; the number of words in a WordPiece is between 1-5.\n\nWordPiece Vocabulary: A vocabulary containing all the WordPiece tokens. Here the vocabulary for the teacher model is considered $D=30K$, while the vocabulary for the student model is 4928 (for our experiments)\n\nKnowledge Distillation: The process of distilling a small-footprint student model from a large teacher model by mimicking its soft label distribution.\n\nReference\n\n[BIBREF1] Guo et al., \"XLNet: An Efficient Multi-task Neural Network for Language Understanding\", CoRR abs/1803.04175, 2018\n\n[BIBREF2] Liu et al., \"XLM: Extremely Lightweight Machine Reading and Reasoning\", CoRR abs/1802.02546, 2018\n\n[BIBREF3] Conneau et al., \"XLMrb: A Robustly Fast and Distributed BERT Pretraining Model\", CoRR abs/1804.07461, 2018\n\n[BIBREF4] Mikolov et al., \"Contextual Word Embeddings\", 2013, Trends in Language Processing, pages 15-21, 2018\n\n[BIBREF5] Bojanowski et al., \"Enriching",
    "efe9bad55107a6be7704ed97ecce948a8ca7b1d2": " For example, the embedding dimensionality of a BERT model may be tuned by tuning the highest percentage of WordPiece tokens, since the majority of vocabulary tokens occur fewer than once in the training corpus.\nAcknowledgments\n\nWe use Google Cloud TPUs for training for our experiments in this work. As mentioned in this work, some hardware support for low-precision arithmetic, especially for deep learning. Some earlier portions of this work were carried out at the University of Chicago.\nReferences\n[1]\n\nBeltagy Ozan I. et al.\n\nWordBERT: A large contextualized word repository extracted from booksCorpus.\n\nhttps://www.aclweb.org/anthology/D19-1461.pdf\n\n[2]\n\nDevlin, James et al.\n\nBERT: Pre-training of deep bidirectional Transformers for language understanding.\n\nhttps://www.aclweb.org/anthology/D19-1494.pdf\n\n[3]\n\nChen, Kelvin et al.\n\nT5: A lightweight Transformer for text generation, comprehension and tasks.\n\nhttps://www.aclweb.org/anthology/D19-1180.pdf\n\n[4]\n\nClark, Matthew A., et al.\n\nGPT-3: Language models are unsupervised multitask learners.\n\nhttps://www.aclweb.org/anthology/D19-1187.pdf\n\n[5]\n\nHenderson, Edward et al.\n\nXLNet: Generalized language modeling with cross-attention.\n\nhttps://www.aclweb.org/anthology/D19-1176.pdf\n\n[6]\n\nDevlin, James et al.\n\nBERT: Pre-training of deep bidirectional Transformers for language understanding.\n\nhttps://www.aclweb.org/anthology/D19-1494.pdf\n\n[7]\n\nZhou, Qian, et al.\n\nXLNet: Generalized language modeling with cross-attention.\n\nhttps://www.aclweb.org/anthology/D19-1176.pdf\n\n[8]\n\nRaffel, Colin et al.\n\nAttention is all you need: A neural visual-question answerer.",
    "71e4ba4e87e6596aeca187127c0d088df6570c57": "\nReferences\n\n[a1]\n\nBIBREF0\n\nSch\u00fctt, M., S. M. Daniell, V. Vasilyev, M. Rashtchian, and L. Jutzi.\n\n2012.\nFlickr8K Corpus: Images and Descriptions\n\nImage and Vision Computing 30, 37-41\n\n[a2]\n\nBIBREF1\n\nSch\u00fctt, M., S. M. Daniell, V. Vasilyev, M. Rashtchian, and L. Jutzi.\n\n2013.\nFlickr8K Entities: Extending Flickr8K to Images\n\nAdvances in Neural Information Processing Systems 26, 3141-3152\n\n[a3]\n\nBIBREF2\n\nrashtchian2010collecting\n\n2013.\nCollecting Human Language Data in Large Corpora\n\nProceedings of the Workshop on Statistical Approaches to Natural Language Generation\n\nin Association with ACL 2013\n\n[a4]\n\nBIBREF5a\n\nSleijpen, T., S. Mengis, H. de Vos, H. Versteeg, and J. Pautasso.\n\n2014.\n\nStereotypes, Prejudice, and Language: The Impact of Language Models on Discourse Analogy Generation\n\nProceedings of the 6th International Joint Conference on Artificial Intelligence, 2287\u20132295\n\n[a5]\n\nBIBREF5b\n\nCottle, P., E. Kearns, P. Smyth, M. Rashtchian, L. Jutzi, and S. M. Daniell.\n\nBIBREF5c\n\nCottle, P., H. de Vos, H. Versteeg, and L. Jutzi.\n\nBIBREF5d\n\nCottle, P., J. Pautasso, and L. Jutzi.\n\nBIBREF5e\n\nvan der Wegen, J., S. Mengis, E. Kearns, and L. Jutzi.\n\n2017\n\nMinecrafting Language: The Effect of Modding on Word Choice\n\nComputational Linguistics 43(2), 287\u2013301\n",
    "7561a968470a8936d10e1ba722d2f38b5a9a4d38": " A large portion of the data and examples was also used in a project on linguistic biases: https://www.sns.nl/research/publications/project-human-language-biases-in-an-open-source-data-set-for-language-models/ (2014-2018).\n\n[leftmargin=0cm]\n\nReferences\n[al2017stereotyped]al, anna, and elena velk. 2017. \"Gender stereotyping in linguistic and statistical language models.\" bioRxiv, no. 696111.\n\n[beukeboom2014mechanisms]beukeboom, ewout, jeroen van der leij, kirsten t. kaltenborn, and joost velzen. 2014. \"The language of stereotyping-driven descriptions.\" Proceedings of the 13th International Conference on Language Resources and Evaluation (LREC 2014), 1033\u20131040.\n\n[fokkens2016linguistic]fokkens, antske, and anna alexander. 2016. \"Linguistic biases.\" Nijmegen Working Paper 2016-04:1-32.\n\n[he2016gender]he, linlin, and anna alexander. 2016. \"Gender-marked language bias in language modeling.\" Proceedings of the 10th Conference on Natural Language Understanding (In Proceedings of The 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Volume 1: Demonstrations and Posters, pages 1411\u20131419).\n\n[lin2016detecting]lin, li, and anna alexander. 2016. \"Detecting unconscious gender bias in pre-trained neural machine translation models.\" Proceedings of the 10th Conference on Natural Language Understanding (In Proceedings of The 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Volume 1: Demonstrations and Posters, pages 1420\u20131429).\n\n[li2017gender]lin, li, shayan liu, and anna alexander. 2017. \"The effect of gender bias in training data on a gender-fair machine translation system.\" In Proceedings of the 2017 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), pages 1007\u20131021",
    "6d4400f45bd97b812e946b8a682b018826e841f1": "\nREF1\nBIBREF1\nBeukeboom, Paul, Paul Veron, and Luc Steels. 2014. A Collecting the World: Analyzing Collective Language. In In Proceedings of the Eighth International Conference on Webscraping and Data Mining, NOSDM 2014, pages 19\u201326. ACM. http://dx.doi.org/10.1145/2609673.2609711.\nBIBREF2\nBeukeboom, Paul, Paul Veron, and Luc Steels. 2015. Collecting the World: A New Task for Neural Text Summarization Models. In Proceedings of the 15th International Workshop on Speech and Language Technology for a Multi-cultural World, IWSLT 2015, pages 37\u201340.\nBIBREF3\nbeukeboom2014mechanisms, Beukeboom, P., W. J. van der Heijden, T. J. Schuurman, P. Steels, G. Steen, and P. Veron. 2014.\nBeukeboom, P., B. L. Nespor, and S. van der Leeuw. 1999. Gender Stereotypes and Cognitive Mapping in the Dutch Language. Language and Linguistics Compass 2, no. 6:1266\u20131277. http://dx.doi.org/10.1111/j.1745-3913.1999.00187.x\nBIBREF4\nBIBREF5, Beukeboom, P., B. L. Nespor, and S. van der Leeuw. 1999. Gender-Specific Language Use: The Negation of Feminine Professions. Journal of Pragmatics 31:791\u2013814. http://dx.doi.org/10.1017/S0143685599004928X.\nBIBREF6\nLanigan, Margaret, and Cai Li. 2015. Stereotypic Explanatory Bias in Word Choice: Evidence from Word Use in the Dutch Language. Language and Linguistics Compass 9, no. 1:25\u201344. http://dx.doi.org/10.1111/1745-3913.12051.\nBIBREF7, Beukeboom, P., J. O'Donnell, and T. J. Schuurman. 2005. The Ste",
    "26c2e1eb12143d985e4fb50543cf0d1eb4395e67": "\n\nReferences\n\n1) A. BIBREF1.\n\n2) A. BIBREF2.\n\n3) M. BIBREF3.\n\n4) D. BIBREF4.\n\n5) J. BIBREF5.\n\n6) M. BIBREF6.\n\n7) A. BIBREF7.\n\n8) R. BIBREF8.\n\n9) M. BIBREF9.\n\n10) K. BIBREF10.\n\n11) T. BIBREF11.\n\n12) J. BIBREF12.\n\n13) R. BIBREF13.\n\n14)\n\n\nR. BIBREF14.\n\n15) \nR. BIBREF15.\n\n16)\n\nT. BIBREF16.\n\n17)\nM. BIBREF17.\n\n18)\nR. BIBREF18.\nTable 1\n\nA table of example descriptions (first row: image; second row: description; third row: coreference annotations)\n\nFigure 1\n\nA random selection of images (incl. links) in the Flickr30K dataset\n\nFigure 2\n\nA sample of example words annotated without a coreference link (with a link to the images)\n\nFigure 3\n\nA sample of example words tagged in a stereotype-driven way (with a link to the images)\n\nTable 2\n\nA table that summarizes all coreference clusters found in the English part of the Flickr30K data excluding the word `black', which is a separate cluster\n\nFigure 4\n\nA flowchart of the methodology applied to detect ethnicity bias (for black, white and asian)\n\nTable 3\n\nA table that summarizes the clusters found in Flickr30K Entities\n\nFigure 5\n\nA flowchart of the methodology applied to detect status/occupations/roles bias (for manager, worker, and boss)\n\nTable 4\n\nA table that summarizes the clusters found in Flickr30K Entities\n\nFigure 6\n\nA flowchart of the methodology applied to detect baby/children/parent bias\n\nTable 5\n\nA table that summarizes the clusters found in Flickr30K Entities\n\nFigure 7\n\nA table that summarizes",
    "f17ca24b135f9fe6bb25dc5084b13e1637ec7744": " We thank Prof. Michael J. Twidale and all the PDTB contributors for releasing the PDTB corpus. We thank the PNNL High Performance Computing system for the extensive computational resources.\nAppendix A\n\nAdditional Evaluation Results\nIn addition to the results of the previous works, we also present the full evaluation results of our new experimental setting (i.e., multi-way classification). This will provide details of our proposed models as well as baselines across most of all 4 relation types in the PDTB v2.0 corpus.\nMulti-way Classification\n\nA. Baselines\n\n1. BIBREF19: the previous best non-neural baseline with explicit and implicit relation models learned in a multi-task joint learning model.\n\n2. BIBREF18: a neural tensor (SWIM) model that has a tensor-based attention mechanism.\n\n3. BIBREF14: a neural tensor model with tensor-based soft-attention and tensor-based hard-attention mechanisms.\n\n4. BIBREF6: a multi-level attention-over-attention model with tensors to capture soft- and hard-attention patterns.\n\n5. BIBREF5: a gated relevance net (GRN) model with tensors to capture interactions between words from two discourse units.\n\n6. BIBREF9: a convolutional neural network model that leverages relations between different styles of discourse relations annotations (PDTB and RST-style BIBREF24 ).\n\n7. BIBREF8: a neural tensor model that leverages relations between explicit discourse relations in PDTB and implicit/explicit discourse relations in unlabeled data.\n\n8. BIBREF17: a tensor-based attention mechanism model that exploits tensor interactions between words from two discourse units.\n\n9. BIBREF11: a neural tensor model that applies tensor-based soft-attention and tensor-based hard-attention mechanisms together for capturing soft- and hard-attention patterns.\n\n10. BIBREF1: a logistic-regression-based system that only identifies explicit discourse relations.\n\n11. BIBREF2: a bag-of-features-based system that only identifies discourse relations between two discourse units.\n\n12. BIBREF19 : our full paragraph-level neural network system.\n\nA. F1-Scores and Accuracies on PDTB Multi",
    "bd5bd1765362c2d972a762ca12675108754aa437": " Author thank the support of AHRC (Award: AH/T010061/1) and the start-up funding from The University of Nottingham for the support of this research.\nBIBREF0 T. K\u00f6hler and S. Sch\u00fctze, \"Discourse Connective Analysis and Sentence Fusion,\" in Proceedings of the 10th Conference of the European Chapter of the Association for Computational Linguistics, Association for Computational Linguistics, Berlin, Germany, 2003a.\n\nBIBREF1 B. Heyer and M. Strube, \"How to Recognize Implicitations in Discourse Relations,\" in Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics, Association for Computational Linguistics, Berlin, Germany, 2003b.\n\nBIBREF2 Y. Huang, Y. Jiao, and J. Cheng, \"Implicit Discourse Connective Analysis based on Neural Tensors,\" in Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL-08), 2007.\n\nBIBREF3 Y. Huang, J. Cheng, and Y. Jiao, \"Learning Implicit Discourse Relations from Paragraphs using Neural Tensors and Word Interactions,\" in Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics (EACL-2010), 2010.\n\nBIBREF4 C. Lin and R. N. C. H. Ng, \"Implicit Discourse Relation Recognition using Neural Paragraph Models,\" in Proceedings of the 14th International Joint Conference on Neuro-Linguistic Programming and Virtual Environments (Neuroling 2010), 2010.\n\nBIBREF5 L. Li, D. Zhang, and Y. Guo, \"Identifying and Reasoning About Discourse Relations of Paragraph-Level Documents: A Hierarchical gated Neural Tensor Network Approach,\" in Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP 2014), 2014.\n\nBIBREF6 L. Li, C. Lin, Y. Guo, and Z. M. Feng, \"Discourse-Aware Joint Learning of Implicit and Explicit Discourse Relations over Paragraphs with Attention and Word Interaction,\" in Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EM",
    "d9b6c61fc6d29ad399d27b931b6cb7b1117b314a": "\nAcknowledgements\n\nThis work is supported in part by Google AI Singapore Ltd., and in part by the National Research Foundation under Grant number 104612-AI. The author would like to thank all team members in the Google-NRL Team for the fruitful discussions in the project.\nReferences\n\n[1] R. Bowman, Z. L. Chen, K. Q. Tan, H. Liang, and Q. Ying. Deep learning for machine comprehension. CoRR, abs/1708.08050, 2017.\n\n[2] J. Clark, D. Keshet, C. Smith, G. Garg, and B. D. Wills. Learning an end-to-end sequence-to-sequence model for question answering. CoRR, abs/1607.02339, 2016.\n\n[3] D. G. Chiu, W. N., Chiu, and S. Rambow. Deeplearning with knowledge. In AAAI, pages 875\u2013882, 2016.\n\n[4] D. D. Dabre, D. C. Dyer, and T. S. Favela. Adversarial test sets for evaluating machine reading comprehension. In ACL, 2016.\n\n[5] J. DeYoung, T. Chen, and I. Reid. Adversarial questions for machine reading comprehension. CoRR, abs/1710.03853, 2017.\n\n[6] T. E. Deng, R. T. Li, A. Daly, and P. Li. The CNN/DailyMail dataset and baseline systems for machine reading comprehension. In NLPCC, 2016.\n\n[7] P. Farkas, N. S. Goyal, F. D. T. Sanjoy, E. D. Hovy, J. P. Liang, D. G. Chiu, A. D. Roy, and S. N. Koh. Fact-level question answering. In AAAI, pages 4381\u20134387, 2017.\n\n[8] P. Fodor, K. K. Asher, B. H. Lim, J. K. Li, and E. J. Huang. Explainable question answering. In AAAI, pages 767\u2013773, 2017.\n\n[9] J. Fisch, T. McAul",
    "d27438b11bc70e706431dda0af2b1c0b0d209f96": "\n\nThe BIBREF0 model performs the best on all the conditions, while the RNN-based BIBREF4 model (a version of LSTM) performs the worst. This trend is consistent with prior work.\nI am puzzled by the out performance on the NPI tasks. Despite similar evaluation setups, I find that BERT (and especially the BERT-large versions) performs better than the BIBREF3 results.\n\nOne explanation for these results could be that the NPI tasks are harder (simply because they have fewer stimuli). This seems unlikely, since the BERT large version, which includes more capacity in general, is still outperforming the smaller BIBREF3 model when evaluated on the BIBREF1 stimulus (which is composed of only 10,000 tokens vs 8,600 in the BIBREF3 data). Another question is whether this difference can be explained by the difference in context: in the first setups the inflectional context around the inflection (such as a plural noun between the verb and subject) is not too different to the word (such as plural or singular inflection following the subject). In the BIBREF3 paradigm the inflectional context is very different from the word context due to the use of OOV items.\n\nFinally, I also explore a similar experiment in the other direction. In this evaluation, the bi-directional model is trained on the BIBREF0 setups and evaluated on BIBREF1 and BIBREF2 stimuli. Surprisingly, there is a larger bias in performance for BERT-Large than for BERT-Base when evaluating on BIBREF1 stimuli, but only in a slight bias towards BERT-Base than BERT-Large (compared to BIBREF3 and earlier work). I discuss possible explanations in the discussion.\nFinally, I also investigate the case in which BERT is trained on BIBREF0 and evaluated on BIBREF3 and BIBREF1 stimuli, and find that the performance on BIBREF3 stimuli goes up, but the performance on BIBREF1 is down. This makes little sense to me.\nThis research is based on the pre-print\nWijaya, Y., & Levy, E. 2018. When Syntax is Enough: Measuring the Synthness of LSTM Representations. In Proceedings of ACL-2018, Volume 1: Long Papers.",
    "8d4ac4afbf5b14f412171729ceb5e822afcfa3f4": "\nAuthor Key\nLi, Yanyan. School of Information, University of Michigan - Ann Arbor\nLi, Yanyan.\nZhang, Jiatao.\nZhang, Jiatao.\nGolovchik, Daniel.\nGolovchik, Daniel.\nZhao, Xinghai.\nZhao, Xinghai............\nThe authors acknowledge the support of the National Science Foundation (#1344039); the MIT Office of Digital Learning; NSF DII Grant #1136756; the International Conference on Computational Linguistics, LRE, Sydney, Australia.\nAuthor Key\nShin, Sung Jin. School of Computing, Korea University\nShin, Sung Jin.\nLee, Sung Jin............\nThis document is in the public domain. Feel free to copy, reproduce, use, and adapt it. We believe in universal access to published content and thus do not place any restrictions on its use.\nAuthor Key\nXue, Dacheng. School of Informatics, Indiana University Bloomington\nXue, Dacheng.\nZhang, Qichao.........\nThis work was partially supported by NSF grant DMI-1152689 and by the National Natural Science Foundation of China.\nAuthor Key\n\nLazaridou, Maria. School of Information, University of Michigan-Ann Arbor\nLazaridou, Maria.\nLi, Mingliang.\nLi, Mingliang...............\nThe authors gratefully acknowledge the support of a generous gift by the John W. Pope, Jr. Endowment for the Study of Ethics and the Ethical Life, Indiana University.\nAuthor Key\n\nNastasa, John. School of Information, University of Michigan - Ann Arbor\nNastasa, John..................\nThe authors would like to express thanks to the National Science Foundation for support under grant #1264198 \"Language Variation in Social Media\".\nAuthor Key\n\nNastasa, John. School of Information, University of Michigan - Ann Arbor\nNastasa, John..............",
    "3c93894c4baf49deacc6ed2a14ef5e0f13b7d96f": " We further thank our coauthor David Kieras for his help with the final revisions, and our anonymous reviewers for suggestions.\n[ ] The authors would like to thank the blog.com team for providing useful access through their profile finder and for facilitating the data collection for this project.\n\nReferences\n\nBIBREF0\n\nAlimova, A. (2016). Blogging and Its Impact: A Survey of the Literature. Journal of Communication 72(4): 714\u2013733.\n\nBIBREF1\n\nBaker, N. (2013, March 5). An Introduction to Linguistic Geography. Language Variation and Change 25: 1\u201328.\n\nBIBREF2\n\nLee, D. L., Foss, K., and Jaffe, N., 2010. Toward a Geographic Theory of Personality. Culture and Psychology 15: 203\u2013227.\n\nBIBREF3\n\nSanchez-Gonzalez, P., Wang, H. H., Wang, H. J., Kieras, D., Kovaliova, L., and Fan, J., 2015. Building a Knowledge-Consumption Map of the U.S. Language Science and Computational Linguistics 4(3): 698\u2013716.\n\nBIBREF4\n\nShapiro, D. (2004). Language in Maps. Nature 431: 697\u2013699.\n\nBIBREF5\n\nMugan, G., Jansen, P. B., N. J. J., & Shanks, J. R. (2005). The Linguistic Geography of Twitter. Cognition and Emotion, 19(2-3): 191\u2013208.\n\nBIBREF6\n\nKatz, D., L. C., & M. (2013). Building a Demographic Map of Blogging in the United States Using User Information. Proceedings of the 2012 Conference on Empirical Methods in Natural Language Processing, (EMNLP 2012), Austin, TX.\n\nBIBREF7\n\nBaker, N. S., 2013. Language Variation and Change 27(1): 17\u201341.\n\nBIBREF8\n\nShapiro, D., Lee, Y., & M. (2014). The Geography of Personality: Language and Personality in Spatial Context. PloS One 9(12): 90417.",
    "07d15501a599bae7eb4a9ead63e9df3d55b3dc35": " \nReferences\n\nBaldwin, M., Kiesecker, S., et al. (1995) Geometric and semantic properties of regional personality. Psychol Rev. 102, 63-81.\n\nBarthes, R. (1997) A linguist considers the elephant. In: S. Derrida, J. Culler, C. Seely, D. Wood, and G. Harner, eds., Writing Degree Zero: Barthes and the Philosophical Discourse of Literature, pp. 69-76. Durham: Duke University Press.\n\nBIBREF0\n\nDiaz, F., L. Zhang, and L. Ma (2014). Blogging: A brief history and analysis. In: A. Karahoda, Z. Cveji\u0107, J. Lai, and H. Nakadate, eds., Proceedings of the 6th International Symposium on Blogging and Social Media: Blogs and Beyond, Athens. New York: ACM.\n\nBIBREF1\n\nLin, Z. and Halavais, C. (2008). Linguistic mapping of the blogosphere. J Word Stud., 47, 761-776.\n\nBIBREF2\n\nWard, K. (2011). Do the British write differently because of the weather. In: M. A. K. Hall, ed., Blogging and the Social Media Landscape. Cambridge: Cambridge University Press.\n\nBIBREF3\n\nWard, K. (2011). Word frequency and regional personality. Linguist. Compass. 5, 935-948.\n\nBIBREF4\n\nGonz\u00e1lez-Benito, J. L., J. A. Zampolli, J. Choi, J., J. B. C. Lippi, L. Ma, and M. W. O'Donnell (2013). Spatial variation of semantic characteristics of linguistic constructs in the blogosphere. Corpus Linguist. Stud., 1, 55-81.\n\nBIBREF5\n\nFrymier, D. K., S., P. H. Brown, E. R. Berthelsen, J. W. Hancock, and M. T. DeDecker (2013). The spatial distribution of language use, personality, and well-being in the United States. Psychol.",
    "99e78c390932594bd833be0f5c890af5c605d808": "\nReferences\n\n<span id=\"BIBREF0\" class=\"anchor\" data-reference=\"\n\n[REF] Sharma, D., & Hsiao, P. (2020) Physician burnout in the United States: A survey of physicians in the Massachusetts General Physicians Organization. Health Affairs, published online first. https://www.healthaffairs.org/do/10.1377/haff2020.0135\n\n[REF] Sharma, D., et al. (2014) How much does EHR documentation interfere with patient care? A cross-specialty survey of Massachusetts General Physicians Organization. Medical Care. 52, 938-944. https://pubmed.ncbi.nlm.nih.gov/24343452/\n\n[REF] Purohit, A. A., et al. (2017) Answers to the questions doctors ask patients after consultations: An observational study. Nature. 551, 772. https://pubmed.ncbi.nlm.nih.gov/27517138/\n\n[REF] Choudhury, S. H., et al. (2018) The effect of patient recall on shared decision making and adherence with the decision: A study of encounters recorded by physicians in Kenya. International Journal of Pediatrics. 2018, pp. e20180066. https://www.sciencedirect.com/science/article/pii/S246915221831734/\n\n[REF] Jha, A., et al. (2018) How much is spent on collecting and re-entering information into EHRs for each outpatient clinic visit? Perspective from a multicountry sample of practicing physicians in LMICs. The Journal of the American Medical Association Open. 3, 913-919. https://pubmed.ncbi.nlm.nih.gov/30075121/\n\n<span id=\"BIBREF1\" class=\"anchor\" data-reference=\"\n\n[REF] Sharma, D., et al. (2017) Physician burnout: A systematic review and meta-analysis of its associations among specialty and practice type. JAMA Internal Medicine. Published online October 13, 2017.  \n10.1001/jamainternmed.2017.7065\n\n  http://doi.org/10.1001/jamainternmed.2017.7065\n\n  http://",
    "861187338c5ad445b9acddba8f2c7688785667b1": " Funding for the this study was provided by UPMC through a grant awarded in the form of faculty development time to Dr. Amitabh Vashisth.\n\n\nCopyright \u00a9 2016 by Daniel Wallace  \nAll rights reserved.  \nPublished in the United States by Crown Books for Young Readers, an imprint of  \nPenguin Random House LLC, New York.  \nCrown and the Crown colophon are registered trademarks of Penguin Random House LLC.\n\nLibrary of Congress Cataloging-in-Publication Data\n\nWallace, Daniel, 1960\u2013\n\nPure poison / Daniel Wallace.\n\np. cm.\u2014(Novels of the Otherkin ; 6)\n\nSummary: Lena, a young Otherkin, who is one of the very rare beings whose powers lie on the border between magic and science, is pulled into the world of the Otherkin, where the Otherkin live, to learn of the origins of her powers and to find help against her enemies and save her love.\n\nISBN 978-1-101-96022-0 (hardback)\u2014ISBN 978-1-101-96023-7 (pbk.)\n\n[1. Fantasy] I. Title.\n\nPZ7.W186P97 2016 [Fic]\u2014dc23 2015017326\n\nISBN 978-0-553-48247-2 (eBook)\n\nThe characters and events in this book are fictitious. Any similarity to real persons, living or dead, is coincidental and not intended by the author.\n\nVersion_2\nTable of Contents\n\nTitle Page\n\nCopyright Page\n\nDedication\n\nAcknowledgments\n\nExcerpt from Poison Prince\nA CATCH OF THE OTHERKIN\nTHE SOURCE OF MISCHIEF\nA BATTLE FOULLED OF TROUBLE\n\nUNDER THE SKIN\n\nNO MERCY\n\nCHANCES OF DEATH\n\nMURK'S INVENTION\n\nLITTLE DEATHS\n\nCAGE OF DUSK\n\nA RIVER OF DARK\n\nGOD'S MISTRESS\n\nSILENT FEAR\n\nVETO THE LESSER\n\nA BEAUTY AFFLICTED\n\nTHE TERROR OF WATER\n\nTHE CHURCE'S RE",
    "f161e6d5aecf8fae3a26374dcb3e4e1b40530c95": "\n\n\n### References\n\n1. T.M. O'Malley, J.D. O'Malley, M.D, M.S, et al., *Burnout and Depression in Health Care*, Massachusetts General Physicians Organization (2015).\n\n2. P. Bajic\u2020, J.T. Bajic\u2021, M.D, M.B.A., et al., *Administrative Tasks Impede Physicians' Clinical Facetime, Study Finds*, Becker's Hospital Review (2018).\n\n3. N.J. Ting,*The impact of EHR system demands and documentation on U.S. physicians' work, Journal of the American Medical Informatics Association (2018).\n\n4. P. T. R. S. Bajic\u2020, L. G. Kothare, M.D., et al., *Using Deep Learning for Automatic Extraction of Local Clinical Information in Doctor-Patient Conversations*, Proceedings of the Thirty-Fourth Conference on Association for the Advancement of Artificial Intelligence (2019).\n\n5. L. G. Kothare\u2020, I. D. Sharma\u00a7, et al., *Understanding Doctor-Patient Conversation Using Attention in Conversation Recognition*, Proceedings of the Twenty-First Workshop on Automatic Speech Recognition and Understanding (2016).\n\n6. G. G. G. Kaushal\u2020, T. F. R. Shah, M.B.S.S., et al., *A Review of Medication-Related Interventions in Burnout and Depression among US Internal Medicine Physicians*, Mayo Clinic Proceedings (2020).\n\n7. Q. Zong, J. Chen\u2021, K. R. Bhatt\u2021, et al., *Advancing Conversational Speech Recognition with Pointer-generator Models*, Proceedings of the Thirty-Fourth Conference on Association for the Advancement of Artificial Intelligence (2019).\n\n8. A. Wang\u2020, J. Chen\u2021, D. G. Lowe\u2021, et al., *Efficient and Expressive Information Extraction for Question Answering*, Proceedings of the Thirty-Fourth Conference on Association for the Advancement of Artificial Intelligence (2019).\n\n9. T. Kim\u2020, C. Chen\u2020, G. Chen\u2021, et al., *Attention-based Question Answering for Natural Language Summar",
    "12c50dea84f9a8845795fa8b8c1679328bd66246": "\n\nFig. FIGURE8: BERT model for classification of long sequences.\na) shows to be a BERT-Base configuration obtained from https://huggingface.co/sentence-transformers/ b) Shows fine-tuning of a BERT model for predicting customer satisfaction from a conversation transcript. Fig. FIGURE22 shows to be a BERT-Large configuration obtained from https://huggingface.co/sentence-transformers/ c) Shows RoBERT architecture (as used is ToBERT)\nFig. FIGURE21: Distribution of documents lengths : Fisher Dataset.\nFig. FIGURE22: Distribution of documents lengths : 20 Newsgroups Dataset.\nFig. FIGURE23: Distribution of documents lengths : CSAT Dataset.\nFig. FIGURE24: Distribution of documents lengths : Fisher Dataset.\nFig. FIGURE25: Distribution of documents lengths : CSAT Dataset.\nFig. FIGURE31: Average voting vs. ToBERT results for Fisher Dataset : Comparison of accuracy for various token lengths.\nFig. FIGURE26: Distribution of documents lengths : 20 Newsgroups Dataset.\nFig. FIGURE27: Distribution of documents lengths : CSAT Dataset.\nFig. FIGURE28: Distribution of documents lengths : Fisher Dataset.\nFig. FIGURE29: Distribution of documents lengths : CSAT Dataset.\nTable TABREF22: Dataset statistics (Fisher Dataset).\nTable TABREF23: Dataset statistics (20 Newsgroups Dataset).\nTable TABREF25: RoBERT BERT performance(using pre-trained BERT features) on Fisher, CSAT, 20newsgroups (for 30 runs)\nTable TABREF26: RoBERT BERT performance (using fine-tuned BERT features) on Fisher, CSAT, 20newsgroups (for 30 runs)\nTable TABREF27: ToBERT BERT performance (using fine-tuned BERT features) on Fisher, CSAT, 20newsgroups (for 30 runs)\nTable TABREF28: RoBERT LSTM performance (using pre-trained BERT features) on Fisher, CSAT, 20newsgroups (for 30 runs)\nTable TABREF29: ToBERT LSTM performance (using fine-tuned BERT features) on Fisher, CSAT, 20newsgroups (for 30 runs",
    "0810b43404686ddfe4ca84783477ae300fdd2ea4": "\n\nReferences\n\n[1] \"Bidirectional Encoder Representations from Transformers\", J. D.-Y. Wang, J.-Y. Zhao, J. Pennington, S. Hinton, B. Weston, Z. Yang, A. Prabhavat, and M. Natukuntha. \"Transformers\" - Efficient Deep Learning for Language Understanding, 2017. <https://www.aclweb.org/anthology/N17-1403/>.\n\n[2] \"TransformerXL: Attentive, Multitask, Adaptive Transformers as Large Language Models\", Kaiming He, Yuke Zhang, Di He, and Chenxue Pan. A Tutorial on Transformers, 2017. <https://nlp.nju.edu.cn/publications/transformerXL.pdf>.\n\n[3] \"Mikolov: Distributed Representation Learning\", Tomas Mikolov, Ilya Sutskever, Kai Chen, Gregory S. Corrado, and Jeffrey Dean. Advances in Neural Information Processing Systems, 2014. <https://www.aclweb.org/anthology/D14-1166/>.\n\n[4] \"Autoencoder\" - Compression for Language Representations, R. Caruana, S. Bengio, D. Collobert, D. Weston. Advances in Neural Information Processing Systems, 2014. <https://www.aclweb.org/anthology/D14-1165/>.\n\n[5] \"Subspace Support Vector Machines for Topic Classification on Speech Transcripts\", Z. Rastogi, C. L. Callaghan, D. Metaxas, and B. Schlangen. International Conference on Machine Learning, 2007. <https://www.aclweb.org/anthology/D07-1054/>.\n\n[6] \"Learning Caller Behavior in Call-Centers\", U. C. Singh, T. S. Katti, R. D. Lee, and Y. Shu. Proceedings of the 20th ACM International on Conference on Information and Knowledge Management, 2009. <https://dl.acm.org/doi/10.1145/1562970.1562976>.\n\n[7] \"Learning Speech Topics with AutoEncoders\", R. C. F.",
    "455d4ef8611f62b1361be4f6387b222858bb5e56": " We thank anonymous expert annotators and users who took part in data collection process. We also thank Peter Pa\u0161tik for initial idea of the presented work.\nREFERENCE_ABBRv1\n\nAbdar S, N. T., T. H., and M. A. (2017). Towards Multidomain Question AnsweR (Multidora): Exploring Interactive Learning using Knowledge Base-Guided Conversations. In Proceedings of Interspeech 2017, Sapporo.\n\nBengtsson M. and H. J. (2012). User modeling for effective dialog policy selection in a conversational user interface. Comput. Speech Lang. 24: 25\u201342. https://doi: 10.1007/s10587-012-9126-1.\n\nBharadwaj M. and M. Z. (2016). Learning dialog policies for open domain question answering. arXiv: 1606.02759, arXiv: 1610.02756, https://ieeexplore.ieee.org/document/7862604/.\n\nBollegala S, A., I. E. D., and R. G. R. (2017). Efficient, Scalable, and Adaptive Semantic Question Answering via Information Retrieval and User Model Augmented Interaction Learning. In Proceedings of Interspeech 2017, Sapporo.\n\nBrookes V, C., D. W., H. L., and R. B. (2014). How do people use Wikipedia? Comput. Linguist. 38: 1\u201313.\n\nCabriolet D. P., E. D., T. C. R., B. P., J. D., et al. (2016). Chit-chat for open domain question answering on Wikipedia. In Proceedings of the 2017 Conference of the European Chapter of the Association for Computational Linguistics (EACL), Valletta.\n\nCai Y, P. W., N. E., W. S., J. H. M., et, al. (2018). DIALOGS: Deep Interactive Learning Over Language Subspaces. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, Melbourne.\n\nDaum\u00e9 IV, P., M. A., V. M. J., A. B., D. K.",
    "bc16ce6e9c61ae13d46970ebe6c4728a47f8f425": " The paper also contains quotes from the Wikipedia (Wikimedia foundation).\nReferences\n\n1.\n\nBergsma, E., de Rijke, T., Hovy, D., Schlangen, A., Storrer, D. (2019) Knowledge graph representation for dialog learning and evaluation. In: Proceedings of the First Workshop on the Challenges and Opportunities of Spoken Dialogue at Conference of the European Chapter of Association for Computational Linguistics (EACL 2019).\n\nhttps://aclweb.org/anthology/E19-5047.\n\n2.\n\nBergsma, E., Schlangen, A., Koutney, A., Hovy, D. (2019) Probabilistic belief tracking for spoken dialogue in natural language. In: Proceedings of the First Workshop on the Challenges and Opportunities of Spoken Dialogue at Conference of the European Chapter of Association for Computational Linguistics (EACL 2019).\n\n3.\n\nBergsma, E., Schlangen, A., Bek, S., Hovy, D., Storrer, D. (2020) Evaluating interactive learning for open domain dialog systems in crowdsourced data. In: Proceedings of the 10th International Workshop on Computational Semantics, CoSAf 2021.\n\n4.\n\nBergsma, E., Koutney, A., Hovy, D., Storrer, D. (2020) Automatic generation of knowledge graph-backed dialog system policies: A case study from Wikipedia. In: Proceedings of the 19th Conference of International Language Resources and Evaluation Conference (LREC 2020).\n\n5.\n\nChang, T.-H., Kemp, A., Lin, H.-L., Liang, L., Peeples, J. (2020) Open-domain dialogue systems: Challenges and opportunities. In: Proceedings of the 19th Conference of International Language Resources and Evaluation Conference (LREC 2020).\n\n6.\n\nElsayed, A., Poria, A., Ramisch, T., Baral, R., Liu, M., Stork, N., Yu, D., Zheng, E. (2019, February). Retrieved from\n\nhttps://aclweb.org/anthology/P19-2011.\n\n7.\n\nChang",
    "1ff0fccf0dca95a6630380c84b0422bed854269a": "\n\n## 1.\n\n## Introduction\n\nAutomatic Text Summarization (ATS), also called Text Summarization, is a process where we identify main ideas of a document without consulting the full copy. For example, if a user wants a summary of Barack Obama's life, we may generate a few phrases such as \"His life was a struggle to succeed in politics in America\", which does not mention the name of a person or the exact date of a lifetime event.\n\nOver decades, researchers have proposed various techniques to achieve ATS, ranging from simple (e.g., \"bag\") to complex (e.g., machine learning). The main goal of ATS is to summarize a document into a few sentences that contain important ideas. However, as many ATS techniques extract sentences from a copy in an ad hoc manner, the sentences they extract may not contain critical keypoints for understanding the document. Consequently, we can end up with summaries whose quality can be affected by superficial factors (e.g., number of sentences) as well as the underlying text.\n\nWe ask if there exists a more principled way of extracting summarizing sentences. For example, if a document contains references to a number of locations, are there any rules of thumb for choosing which sentence(s) to keep/drop from the copy? In this work, we study an efficient heuristic that achieves high accuracy of summarization (e.g., the top-ranked sentences by a baseline extraction model). The heuristic is that sentences contain a high number of mentions of the locations to be kept are more likely to be keypoints. To make sure the heuristic is not biased to locations only, we also consider mention-counts of other concepts (e.g., \"America\", \"women\", \"young\") as features of sentences. Inspired by human-provided summarization guidelines such as \"write for lay audience\", we also measure the diversity of retained sentences (e.g., the number of unique topics in retained sentences).\n\nWe introduce a novel metric for automatic summarization, which we call the LocMention diversity score. For a given document, we calculate the LocMention diversity score by\n$$ \\mathrm {loc\\_mnt\\_div} \\ = \\frac1{N_d} \\sum\\ _{i=1}^d \\frac{\\mathrm {reln}_i - \\mathrm {reln}_c}_j}{\\mathrm",
    "3d7d865e905295d11f1e85af5fa89b210e3e9fdf": "\nApproach\n\n# Displaying Figures and Tables\nFor best results, Figures should be presented in color. If possible, please use the official color map for your journal (also provided on the LaTeX page). Figures should be formatted using the standard 2-column landscape figure format. This is described in detail in the instructions for the author kit. For full-color plots, use the colors in Figures.pdf.\n\nFor high-quality text, use fonts with vertical metrics such as Times or Computer Modern fonts. A good way to identify such fonts is to examine math symbols on each font. We prefer typesetters not to use any other font families. Note also that when you use symbols in a font other than Computer Modern, the text may end up looking unusual.\n\nPlease include figures as separate files. Use a clear and descriptive name for each figure. Use both the author-first and surname-last conventions. Note that authors on the program committee will see the first two authors in the figure captions and footnotes and will not see the others in the caption and footnote lists. Note that abbreviations should be used only in the body of the paper, not in the figure legends and titles.\n\nYou should use the figures package within LaTeX to control the way figures look within the paper.\n\nDisplaying Tables\n\nFor best results, Tables should be formatted as Latex tables using the longtable package. Tables should follow some general formatting rules:\n\nTable Table should be centered\n\nTable Table should be justified\n\nTable Table should have a white background, not a gray background\n\nTable Table should have a minimum width of 1.5 inches; columns should have a width of 0.25 inches\n\nTable Table should have a minimum height of 1 inch\n\nTable Spacing should be 1 inch between table rows\n\nTable Table should have at least 0.5 inch spacing between column cells\n\nTable Table numbers should appear in the upper left hand corner of the first cell\n\nTable Table should be formatted in bold\n\nTable Each table should have a clear figure title that is larger and in boldface than all other text\n\nTable Table numbers should appear in the lower right hand corner of the table\n\nTable Please use the following convention for table indentation:\n\nTable Table numbers should be left justified\n\nTable Table numbers should be flush with left-hand table edge\n\nTable Table cells should be",
    "2ad4d3d222f5237ed97923640bc8e199409cbe52": "\nAppendix\nThe proposed autocomplete model was trained on randomly sampled sentences from Yelp reviews. We use the same training, validation and test subsets (see Appendix for details) as in BIBREF1. We use the official autocomplete task competition training and validation split.\nWe observe that the constrained objective (EPOCHS=400, BEAMSIZE=5, WARMUP=0.07) achieves slightly better performance than the weighted objective (EPOCHS=400, BEAMSIZE=5). More importantly, the constrained objective shows better stability with respect to the tradeoff parameter (EPOCHS=400, BEAMSIZE=5).\nAppendix ::: Acknowledgments\nWe thank the reviewers and Yunseok Jang for their helpful remarks. This work was supported by the National Science Foundation under Grant No. IIS-1552635, Grant No. IIS-1520446, an Intuit Research Award, and an Amazon Faculty Fellowship.\nAppendix ::: Reproducibility\n\nTable TABREF13 shows two examples of autocompletion task and actual user keywords. Each column contains a set of keywords and its corresponding top three suggestions generated by the autocomplete system with beam search. We observe that the autocompletion system achieved high accuracy of reconstruction when provided enough keywords (left column) and almost the same sentences for well-specified keywords (right column). For under-specified keyword (middle column), the autocompletion system completed sentences accordingly by adding a verb, adjective, adverb, preposition, capitalization, and punctuation (see Appendix for examples). Lastly, the autocompliation model achieved highly-efficient results, as users spent 3.86 seconds typing the keywords compared to 5.76 seconds for full sentences on average. The variance of the typing time was 0.08 seconds for the keywords and 0.12 seconds for full sentences, indicating that choosing and typing autocompletion system for the system did not incur much overhead.\n\nAppendix ::: Experiments\nWe evaluate our approach by training an autocompletion system on randomly sampled sentences from Yelp reviews. We use the same training, validation and test subsets (see Appendix for details) as in BIBREF0, BIBREF9. We used the official autocompletion task competition training and validation split. For the constrained objective, we minimize the constrained loss for 100 epochs and update parameters (EPOCHS=100, BEAMSIZE",
    "3fad42be0fb2052bb404b989cc7d58b440cd23a0": "\nExperiments ::: Details\n\n::: Data-generation algorithm for experiments.\n\nWe use a simple algorithm to generate the data for our experiments (see Appendix for details). For a given source sentence $x$ and target sentence $y$, the output of our algorithm is a sequence of encoded keywords $z_1$ and $z_2$ by our stochastic encoder $q_c$, and also the probability of each keyword remaining in the sequence $z$ which we call the retention rate of each token. For example, for the source sentence \"The pizza is delicious\", the algorithm will output the encoded words ($z_1 = pizza$ and $z_2 = delicious$) and the retention rate of each ($retention_1 = 0.75, retention_2=0.95, \\ldots, retention_7 = 0.95, retention_8 = 0.96$) and then generate the target sentence $y = x$ using the autdecoder.\nApproach ::: Data preprocessing.\n\n::: Datasets and training details.\n\nWe use the Yelp reviews dataset (BIBREF6) to train our models. We preprocess the data for training by discarding all sentences with less than three tokens and all stop-words (e.g. `:', `is', `a', `the', `are') (see Appendix for details). We use a single decoder (BERT) to replace all keyword encoders. We discard samples without tokens and with average decoding loss of more than twice the maximum loss across all of the training set (see Appendix for a detailed description of these steps). The total number of samples used in training is 500K.\nExperiments ::: Qualitative visualization.\n\nFigure FIGREF13 illustrates the correspondence between the user typing and our learned communication schemes, which allow us to reconstruct the target sentence directly by decoding the keywords.\nAcknowledgements\n\n::: References.\n\n \nROBIN HOBB\n\nJinx\n\nG. P. PUTNAM'S SONS\n\nPublishers Since 1838\nFor my father\n\nI know this\n\nisn't\n\nexactly your style,\n\nbut\n\nI couldn't\n\nlet this go\n\nunless\n\nyou got in\n\nthe way\n\nand did\n\nthe\n\nnasty\n\nthing\n\nI needed of",
    "ee417fea65f9b1029455797671da0840c8c1abbe": " The dialogue manager picks a system action according to the state of the ID. All the information is shown to the user in the second phase, and the user is asked to confirm the correctness of the message.\n\nA) No previous question on sub-topic and topic:\n\nB) Correct sub-topic but missed previous question number:\n\nC) Wrong question number:\n\nD) No previous sub-topic and topic:\n\nE) Error in question number:\nReferences\n\n\\html<https://ombplus.de/>.\nPfeuffer, Thomas (2014). \"Wie lernt man anhand von Vektoren eine Mathematik in einem Online-Kurs?\" [in German]. https://ombplus.de/lernforum/beitraege/wie-lernt-man-anhand-von-vektoren-eine-mathematik-im-online-kurs/.\n\nBIBREF0 B\u00fcscher, Daniel, Andreas R\u00fccking, and J\u00fcrgen Gr\u00e9uler (2012). \"Automated RPA: A Robot Solution for Automating Repetitive Routine Tasks in a Banking Organization\". https://www.researchgate.net/publication/267813889_Automated_RPA_A_Robot_Solution_for_Automating_Repetitive_Routine_Tasks_in_a_Banking_Organization/file/265279084?origin=publication_download&rid=267813889.\n\nBIBREF1 Gebhard, Philipp & Janosch Kollmeier & Andreas Schmitz & Christian H. Becker & Markus Wachtenbauer & Jannik M\u00fcller (2019). \"Machine Learning for Dialogue Generation: An Approach Using Machine and Deep Learning\". arXiv :1911.04213v1 [cs.CL] [cs.CL/papers/1911.04213].\n\nBIBREF1 Yee-Joo Shun, Le, Han-Yi Wang & Jian-Ping Zheng & Yannan Zhou & Yi-Jing Nie & Chih-Hung Leu (2019). \"On Transferring Knowledge across Domains: Topic-Aware Word-Aligned Sequence-to-Sequence Training\". Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing",
    "ca5a82b54cb707c9b947aa8445aac51ea218b23a": " For each, it is shown the user utterance and the system's response. For each turn in the conversation, it is marked by the unique dialogue- and turn-indexes.\n\nDiscussion\n\n## SECTION: Dialogue Manager\nFigure 3. Dialogue Manager System Architecture\n\n## SECTION: Next Action Prediction\n## SECTION: Named Entity Recognition\n\nFigure 4. German BERT Model Architecture\n\n## SECTION: Next Action Prediction\n\n\n# Copyright\n\nDiversion Books\n\n610 Parker Street\n\nSan Francisco, CA 94102\n\nCopyright \u00a9 2017 by Andrew Smith. All rights reserved. No part of this book may be used or reproduced in any manner whatsoever without written permission except in the case of brief quotations embodied in critical articles or reviews. For information, contact Diversion Books.\n\nThe illustrations were designed by Elsie Lyons.\n\nElsie Lyons has asserted her right under  \nthe Copyright Act, 1976, to be identified  \nas the author of this work.\n\nISBN 978-1-62416-926-3\n\nThis is a work of fiction. All characters, organizations,   \nevents, and locales portrayed in this novel either are products of the imagination   \nor are used fictitiously.\n\nPartly based on _Anarchy: A Short History of an Idea,_ by Doug Saunders\n\n# Contents\n\nCopyright\n\nPrologue\n\nChapter 1\n\nChapter 2\n\nChapter 3\n\nChapter 4\n\nChapter 5\n\nChapter 6\n\nChapter 7\n\nChapter 8\n\nChapter 9\n\nChapter 10\n\nChapter 11\n\nChapter 12\n\nChapter 13\n\nChapter 14\n\nChapter 15\n\nChapter 16\n\nChapter 17\n\nChapter 18\n\nChapter 19\n\nChapter 20\n\nChapter 21\n\nChapter 22\n\nChapter 23\n\nChapter 24\n\nChapter 25\n\nChapter 26\n\nChapter 27\n\nChapter 28\n\nChapter 29\n\nChapter 30\n\nChapter 31\n\nChapter 32\n\nChapter 33\n\nChapter 34\n\nChapter 35\n\nChapter 36\n\nChapter 37\n\nChapter 38\n\nChapter 39\n\nChapter 40\n\nChapter 41\n\nChapter 42\n\nChapter 43\n\nChapter 44\n\nChapter 45\n\nChapter 46\n\nChapter 47\n\n## **",
    "da55bd769721b878dd17f07f124a37a0a165db02": " First, we show how our system gathers information on topic, subtopic, exam mode and level, question number and problem formulation. The first dialogue presents the case when user provides information on topic, exam mode and level in the first dialogue step. In the second example, in the first dialogue step, a student provides the information only on exam mode. Here, the model requests the subtopic. The third example demonstrates three consecutive interactions with the same student where it gathers several pieces of information and subsequently gives the correct answer regarding problem formulation. In the fourth dialogue we have a case where the system requires to ask the sub-topic and level twice before it extracts correct question number. In the sixth dialogue, we show a case where the next action cannot be extracted from valid dialogue states, thus the dialogue is handed over to a human tutor.\n1.a. Exercise 1.b. Chapter 4.2.4.b\n\n1.e. Chapter 3.3.2.f. Quiz\n\n4.11. Section 1.a. Problem 5.c + $x = $b + $c\n\n4.15. Exercise 3.a. Question 5.c. Chapter 3.3\n\n3.15. Chapter 5.1.a. Problem 9.a\n\n[Topic, Sub-topic, Exam Mode, Question Number]\n\n4.19. Course work certificate + final exam + $y = $x + $c + $d \\+ $e\n\n4.22. Exercise 1.d. Question 5.c + $z = $xy \\+ $ef\n::: Reference Model of the NAP Task\n\nFigure\n\nConventional pipeline for dialogue generation consists of handcrafted modules: (1) Natural Language Understanding (NLU), (2) Dialog State Tracker (DST), (3) Policy Learner (PL), and (4) Response Generation (RL).\n\nFigure illustrates the architecture of a generic IPA conversational assistant. This architecture consists of a dialog state tracker (DST), a policy learner (PL) and a response generator.\n\nFigure\n\nReference model of the NAP task: Each unit takes the previous system input and predicts the next system action. Each step can be implemented using conventional rules or deep learning methods.\n\n::: Acknowledgments.\nWe gratefully acknowledge the OMB+ team for the collaboration and especially thank",
    "feb448860918ef5b905bb25d7b855ba389117c1f": " In the future work we plan to improve this approach by using pre-trained ResNet neural network for feature extraction.\n\nAcknowledgement\nThe authors are grateful to IIT Bhubaneswar for the resources provided for this research. We would also like to thank Prof. Aniket Dasgupta for his support on this paper.\n\nReferences\n\n[1] [1] P. Matejska, N. Dahek, S. Yannitsar, S. Vajjhala and A. Vougioudakis (2010) Language identification with i-vectors, Proc. Interspeech, pp. 1623\u20131627.\n\n[2] [2] S. Pavel, M. Hsuan, T. Huang, Z-L. Hsieh, K. Xiang and D. Snyder (2016) Deep learning for language identification, Proc. Interspeech, pp. 1789\u20131792.\n\n[3] [3] S. I\u00f1iguez Lopez, F. Pepe, U. Fonollosa, L. T. Alvarez and K. G. Jones (2017) Speaker-specific modeling of spoken language via deep learning, IEEE Signal Process. Lett., PP, 16(2):478\u2013482.\n\n[4] [4] E. H. G. M. Gonzalez-Dominguez, M. P. Povey, O. Guez-Herranz Bermejo and J. Rozemberczuk (2017) Improving the language identification task within neural networks, Proc. Interspeech, pp. 2750\u20132754.\n\n[5] [5] A. D. Alicia, J. Gonzalez-Dominguez, M. Peete and D. Garcia-Romero (2018) X-vectors: Deep neural networks for speaker identification and language recognition, Proc. Interspeech, pp. 2760\u20132764.\n\n[6] [6] E. H. G. M. Gonzalez-Dominguez, M. P. Povey, O. Guez-Herranz Bermejo, J. Rosemberczuk, E. J. Sanfeliu and M. A. Villar (2019) Language identification for deep neural network model in the x-vector framework, Proc. In",
    "4bc2784be43d599000cb71d31928908250d4cef3": " Our code and audio data is available at [13]. This work is published as part of The Numenta India AI for Good program.\nReferences\n1.\nN. Dahek, A. Kozareva, M. Kruszynski, and T. Palaskov, \"Deep learning for language Identification,\" in Proceedings of the 2014 International Conference on Acoustics, Speech and Signal Processing (ICASSP 2014), San Diego, California, USA (May 2014), pp. 659-662 vol., no. 739 of ICASSP.\n2.\nP. Matejka, F. G\u00f3mez-Robles, F. Pardo, and V. Romero, \"Acoustic modeling and deep learning for multilingual language identification,\" in Proceedings of the 2014 Annual Conference of the International Speech Communication Association, San Francisco, CA, USA (August 2014), 873-876 vol.\n3.\nI. Lopez-Moreno, H. S. Romano, and J. M. Lopez-Rios, \"Convolutional neural networks for language identification,\" in Proceedings of the 2016 Amazonas Workshop on Acoustics, Speech and Language, Manaus, Brazil (June 2016), vol.\n\n4.\nJ. Gonzalez-Dominguez, H. S. Romano, J. M. Lopez-Rios, and B. C. Hough, \"Using convolutional neural networks for language identification,\" in Proceedings of the Amazonas Workshop on Acoustics, Speech and Language Workshop, Manaus, Brazil (June 2016), vol.\n\n5.\n\nJ. Gonzalez-Dominguez, H. S. Romano, A.-C. Chaney, B. C. Hough, P. Jain, X. Rong, and K. S. Doshi, \"Cross-layer feature extraction and deep Convolutional neural networks for language identification,\" in Proceedings of the 2018 International Conference on Acoustic, Speech and Language Processing, Melbourne, Australia (March 2018), pp. 2380-2384 vol. 9256 of ASP-SLP.\n\n6.\n\nD. O. Garc\u00eda-Romero, A. Castells, H. S. Romano, G. S\u00e1nchez-Vela, and L. A. R. Ibarz, \"A Convolutional network trained using stacked bottleneck",
    "75df70ce7aa714ec4c6456d0c51f82a16227f2cb": " We plan to make all the code, model, and the data publicly available.\nACKNOWLEDGEMENTS\nIn this article, the authors expresses their gratitude to Mr. Harsh Man Singh Chhibber, Research Director at IIIT, Allahabad, India for providing the language database required for conducting this work and for introducing them to the Ghost-VLAD technology. They are also grateful to Dr. M. Srinivasa Chilamkuri, Group Leader at IIITH, India for providing expertise to the experiments conducted in this work.\nREFERENCES\n[1] D. Niehues and A. S. G. Haffner. 2015. Deep speaker diarization. In: 2015 Conference on Computer Vision, Imaging and Computer\n\nEnhanced (ICCV), pp. 1\u20138.\n\n[2] P. Matejka, P. Hajdunoev, Y. LeCun. 2012. Deep learning for speech recognition. In: 2012 International\n\nConference on Computer Vision, pp. 3231\u20133243.\n\n[3] I. Lopez-Moreno et al. 2017. Deep neural networks for automatic speaker identification. In: 2017 IEEE/ACM International Joint Conference on\n\nComputer Vision, Computational Imaging, and Multimedia (ICCVIM), pp. 17\u201324.\n\n[4] J. G. Gonzalez-Dominguez et al. 2017. Deep learning for language identification. In: 2017\n\nACL-IJCNLP, Vol. 54, pp. 1439\u20131447.\n\n[5] N. Liu et al. 2018. Acoustic modeling for deep learning. In: 2018 Signal Processing\n\nWorkshop (ICASSP), pp. 1\u20136.\n\n[6] D. Garcia-Romero et al. 2018. Improving language identification accuracy with speech recognition\n\nacoustic models and time-delay neural networks. In: 2018 International Conference\n\non Audio, Speech, and Language Processing (InterSpeech), pp. 3467\u20133474.\n\n[7] D. Snyder et al. 2017. Speaker x: vector-based speaker diarization. In: 2017\n\nACL-IJCNLP, Vol. 54, pp. 1270\u20131275.\n\n[8] D. Snyder et al. 2018. X-",
    "6424e442b34a576f904d9649d63acf1e4fdefdfc": " It would be also interesting to compare our results with other generative approaches, including recent HMM-based ones, such as BIBREF50, BIBREF51, BIBREF52, BIBREF53.\nWe thank Christopher Manning and everyone at the WMT working group for valuable discussions. Finally, any mistakes are our own.\n\n## Acknowledgements\nAcknowledgments\n\nThis work is supported by Amazon.\n\n\nBegin Reading\n\nTable of Contents\n\nAbout the Author\n\nCopyright Page\n\nThank you for buying this\n\nSt. Martin's Press ebook.\n\nTo receive special offers, bonus content,\n\nand info on new releases and other great reads,\n\nsign up for our newsletters.\n\nOr visit us online at\n\nus.macmillan.com/newslettersignup\n\nFor email updates on the author, click here.\nThe author and publisher have provided this e-book to you for your personal use only. You may not make this e-book publicly available in any way. Copyright infringement is against the law. If you believe the copy of this e-book you are reading infringes on the author's copyright, please notify the publisher at: us.macmillanusa.com/piracy.\nFor Peter\nI got up before the alarm went off and I dressed as quickly as I could without waking Anna. When I got to my bedroom, I changed my clothes, put my shoes on, and carried a few items of clothing to the living room without waking her again, and after that I went out to the front door and pulled my keys from my dresser. I closed the door behind me, locked and double-locked it while my eyes adjusted to the early morning light, and walked out onto the front porch and down the steps and out into the driveway where the first person I saw walking in my direction was a policewoman who was wearing a dark blue uniform and carrying a notepad and a notebook. She looked up at me then at my daughter and then she spoke, \"Good morning, Mr. Taylor. How's everything this lovely morning?\"\n\nI took off my cap and I said, \"I've gone ahead and put her in the car.\" I felt stupid because I didn't know what else I could possibly have said and then I said, \"I'm sorry to bother you, but I've been sleeping at the hospital",
    "5eabfc6cc8aa8a99e6e42514ef9584569cb75dec": "\nAcknowledgments\nThanks to Duy-Hai Nguyen and Yi-Ting Gao for discussions on continuous word representations, and Lillian Chuin-Wey Wang for her comments on syntax modeling. This research was funded in part by a Faculty Research Grant and the Office of the Vice Chancellor for Research at Stanford University.\n\nReferences\n\n1.  Lample, Guillaume, Alexander Rush, David Yarowsky, Alexander J. Radulescu, et al. \"The unsupervised learning of word representations\". In EMNLP, 18:1611\u20131625, 2014.\n2.  Bilmes, David, Alexei A. Efros, and Jitendra Malik. \"Covariant neural encoder-decomposers for object detection, pose estimation, and semantic parsing\". In SIGGRAPH Asia, 2015.\n3.  Liu, Dan and Joshua Tenenbaum. \"Discrete word representations improve gated recurrent neural network performance on both machine translation and language modeling\". In NIPS, 2016.\n4.  Shen, Rujian, Chiranjit Jain, and David V. Fox. \"Structured neural language models with learned hierarchical syntax\". In ICLR, 2017.\n\n5.  Le and Samy Bengio. \"Character-aware neural language models\". In In ICLR, 2015.\n6.  Chiang, Yichen, Peter Kwong, and Noah A. Smith. \"Unsupervised word representation learning using deep neural networks\". In NIPS, 2016.\n\n7.  Mikolov, Tomas, Kai Chen, and Ting Zhao. \"Distributed representations of words and phrases and their compositional semantics\". In ACL, 2013.\n\n8.  Pilehvar, Dani Y., Yann LeCun, S. V. N. Vishwanathan, et al. \"GloVe: Globally scalable representations for word similarity discovery\". In EMNLP, 2013.\n\n9.  Pilehvar, Dani Y., Somesh Gowda, Ting Zhao, et al. \"Deep semantic models for the wikipedia 10k most common English words\". In AAAI, 2016.\n\n10.  Pilehvar, Dani Y., Somesh Gowda, and David Clarkson. \"",
    "887c6727e9f25ade61b4853a869fe712fe0b703d": " An alternative possibility is to use GANs 49 directly for modeling hidden states. Lastly, a more general approach to model latent syntactic structures is to consider extending the DMV-based approaches with neural language models. These ideas will be investigated in future work.\nWe thank Xucheng Zhang for helpful discussions.\nAcknowledgements\nThis research is supported by the U.S. Office of Naval Research (ONR) and Google. Any opinions, findings, and conclusions or recommendations expressed herein are those of the authors and do not necessarily reflect the views of the United States Navy or the Office of Naval Research.\n\n1 https://www.tensorflow.org/tutorials/inference/inference_gbm.\n\n2 https://www.tensorflow.org/api_docs/python/tf/nn/rnn.dnn_bidi_rnn.\n\n3 https://deeplearning4j.org/text-classification.html.\n\n4 https://stanfordnlp.github.io/models/seq-model.html.\n\n5 https://lilt.stanford.edu/en-nlp-models/.\n\n6 https://cogcomp.stanford.edu/lilt-tools.\n\n7 https://en.wikipedia.org/wiki/Penn_Treebank.\n\n8 https://www.iata.org/content/english-pos-tags/.\n\n9 https://ruder.io/2019/09/18/how-to-train-a-skip-gram-model-for-word-embeddings/.\n\n10 https://ruder.io/2022/04/04/word-embeddings-tutorials/.\n\n11 https://ruder.io/2022/04/05/word-embeddings-tutorials/#unsupervised-pos-tagging.\n\n12 https://ruder.io/2020/02/04/word-embeddings-tutorials/.\n\n13 https://www.aclweb.org/anthology/P15-1018.pdf.\n\n14 https://www.aclweb.org/anthology/P15-1019.pdf.\n\n15 https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.00203",
    "6236762b5631d9e395f81e1ebccc4bf3ab9b24ac": " Also, investigating methods that can use this conflict mechanism to improve results for NLP tasks involving long sequences.\n\nAcknowledgments\nThe work was done during my fellowship here and the kind support of Prof. Siddharth Batra and mentorship of Dr. Suneh Jain was immensely helpful in performing this work.\n\nREFERENCES\n\nBahdanau, D., Cho, K. and Gulcehre, B. (2014). Neural Machine Translation by Jointly Learning to Align and Translate. In ACL, 1473\u20131479. http://www.cs.cmu.edu/~lingju/papers/ACL2014.pdf.\n\nBIBREF0\n\nHabash, A. and Sap, O. (2018). A Neural NLI Model for Argument Generation Task: Evaluation and Analysis. CoRR abs/1808.00887. https://arxiv.org/abs/1808.00887.\n\nHabash, A. and Sap, O. (2019). A Neural NLI Model for Argument Generation Task. ACM Transactions on Asian Language Information Processing, 19(1), Article 15. https://dl.acm.org/doi/10.1145/3338145.\n\nHochreiter, S. and Schmidhuber, J. (1997). Long Short-term Memory. Neural Computation, 9(2), 347\u2013356.\n\nLiu, Y., Chang, C. and Lou, P. (2017). SAN for Lattice Path-Tracing NLI. In EACL-IJCNLP 17, 1\u20138. http://www.aclweb.org/anthology/P17\u20131211.pdf.\n\nShen, M., Chen, L., Wang, Y., Liu, Q., Zhang, S. and Li, X. (2019). Word-Level NLI with Attention-Aware Confusion Matrix Prediction in Transformer Models. CoRR abs/1911.11218. http://arxiv.org/abs/1911.11218.\n\nBIBREF1\n\nBIBREF2\n\nBauis, A., Chen, L. and Wu, S. (2013). WordAligner: Fast Neural Alignment of Very Long Text Sequences. In Proceedings of the Association for Computational Linguistics: 53rd",
    "31d695ba855d821d3e5cdb7bea638c7dbb7c87c7": " Also, we would like to explore what is optimum ratio of attention weight and conflict weight for better performance.\n\n\nAcknowledgements\nThis work would not have been possible without the generous help of professors of INSA Lyon, especially Dr. Fabien Jurgenson and Dr. Matheswaran Joty. We also thank them both for giving us an opportunity to work on this project in our free time for the duration of the summer.\n\nReferences\n\nBahdanau, D., Chopra, S., and Khudanpur, B. (2014) Neural machine translation by jointly learning to align and transduce. CoRR abs/1405.4157.\nBeltagy, R., Poon, G., and He, K.-S. (2015) Sequence-level attention for structured neural network. In ICMR, pp. 967-976.\n\nBelles, M., Kim, J., and Chen, W. (2017) Exploring the trade-off between query-based language model and context-based language model for answering. In ACL, pp. 2263-2272.\n\nBermudez, X., Heit, J., and Bletz, C. (2009) A unified framework for neural semantic alignment and word alignment. In EMNLP, pp. 993-1002.\n\nBIBERNERG, A. R., and Roy, A. K. (2017) Sentence similarity based language model for question answering. In ACL.\n\nBIBERNERG, A., and Ranzato, M. A. (2018) Towards neural sentence similarity models for question answering. In EMNLP, pp. 2286-2297.\n\nBIBERNERG, A., and Roy, A. K. (2018) Unsupervised cross-sequence attention for ranking. In EMNLP.\n\nCheng, X., Zheng, H., and Liu, S. (2015) On the representation of long sentence pairs for neural semantic similarity. In ACL, pp. 13-23.\n\nCheng, X., Zheng, H., and Liu, S. (2018) Semantic similarity for question answering. In ACL.\n\nDong, J., Chen, Y., and Zhou, B.",
    "b14217978ad9c3c9b6b1ce393b1b5c6e7f49ecab": " Further, we believe that there is still significant scope in tuning the parameters of conflict mechanism to improve the performance further.\nAcknowledgments\nWe would like to thank our project advisor Mohit Anand for his supervision and valuable comments.\nDisclosure: None.\n\n1. M. Akin, and A. Goldberg.\n\n2. Y. Bahdanau, Kyunghyun Cho, and Yoshua Bengio.\n\n3. Y. Bahdanau, Kyunghyun Cho, and Yoshua Bengio.\n\n4. S. Bahdanau, Yoshua Bengio, and Yoon Kim.\n\n5. J. Wang, Q. Jiang, X. Wei, and T. Zhang.\n\n6. H. Liu, B. Yoo, and A. Lazaridou.\n\n7. G. Zhu, Q. Jiang, K. Cho, Y. Wang, and T. Zhang.\n\n8. J. Wang, P. Shen, and L. Zou.\n\n9. R. J. Thonhauser, T. Schalk, K. Cho, and M. E. Kearnes.\n\n10. S. Levy, J. Wang, N. V. Parameswaran, and Y. Bengio.\n\n11. G. Zhu, Q. Jiang, K. Cho, Y. Wang, and T. Zhang.\n\nRecommended Reading\n\n[1] Guo, Fang, and Jie Tang. 2018. \"Efficient Attention Mechanisms for Sequence Models.\" arXiv preprint arXiv:1802.08782.\n\n[2] J. Wang, P. Shen, and L. Zou. Attn: Efficient Attention Mechanism with Scaled Dot-Product for Sequence-to-Sequence Learning. In SIGIR. 2018, 2628\u20132636.\n\n[3] J. Wang, Q. Jiang, X. Wei, and T. Zhang. Fast and Effective Attention for Computational Modeling of Nonparallel Interactions. In SIGIR. 2020, 592\u2013600.\n\n[4] R. S. Radhakrishnan, and D. Anguelov.\n\n[5] Zhu et al. Attentive Semantic Alignment over Sequence Embeddings. In CIKM. 2017, 1\u20139.\n\n",
    "a99fdd34422f4231442c220c97eafc26c76508dd": "\nReferences\n\n[1] Agarwal, P., 2006. News Clustering: A Framework for Automatic Hierarchical Clustering of Narrative Events from Large-Scale Streams.\n\n[2] Amar, E., Ritter, C., Shu, F., and Mihalcea, R. 2006. An Introduction to Online Clustering of Documents and Its Applications in Media Monitoring.\n\n[3] Amar, E., 2008. Stacked Clustering and Related Text Representation Methods for Time-Dependent, Multi-document Stream Clustering.\n\n[4] Amram, A. and Goldfarb, A., 2007. Clustering Multilingual Documents from Large-Scale Streams of Articles. Proceedings of the 8th International Conference on Multimodal Interaction.\n\n[5] Belz, M., and Doshi, V., 2016. The Event Registry: A Distributed Multilingual Event Database. Proceedings of the 9th ACM Workshop on Multimedia Information Retrieval.\n\n[6] Bollmann, T., Buntine, C., and Mihalcea, R., 2017. Deep Representations from Language Models for Event Clustering.\n\n[7] Brodersen, J., Kloedtke, O., and Neumann, I., 2015. Improving Cross-Document Similarity Approximation Using Word Co-occurrences. Proceedings of the 2015 Conference on Computational Linguistics.\n\n[8] Choubey, S., Yadlowsky, Z., and Zuehlsdorf, S.-H., 2017. Online clustering of streaming event data with topic detection and story clustering. Proceedings of the 22nd International Conference on Computational Linguistics.\n\n[9] Dai, X., Xiang, B. and Liu, W., 2013. Neural Sequence-to-Sequence Learning for Machine Translation. Proceedings of the 34 th International Conference on Neural Networks.\n\n[10] Dai, X., Wang, B., Li, Q., and Zong, F., 2015. Neural Machine Translation by Adaptive Cluster Expansion. Proceedings of the 35 th International Conference on Machine Learning.\n\n[11] Dehnelt, V., 2017. A Tutorial on Multilingual Cluster Extraction: Problems and Solutions. Proceedings of the 9th Language Resources and Evaluation Conference.\n\n[12] Eger,",
    "2c78993524ca62bf1f525b60f2220a374d0e3535": " Both the SUMMA project and this paper have benefited from the work of Esma Balk\u0131r on the crosslingual similarity metrics, as well as that of Adham El-Ansary on how to learn when to open new clusters.\n\nTable TABREF30\n\nStatistics about the dataset used for the experiments on Table TABREF35 and Table TABREF39 from \u00a7 SECREF12. Note that the statistics for English differ from the one reported in \u00a7 SECREF18 in their final manuscript, as they include the three additional crosslingual features for each cluster. We also include statistics for the text benchmark from \u00a7 SECREF5 and details on how to process the German, French and Turkish clusters from \u00a7 SECREF5.\nTable TABREF31\n\nWe report statistics about the final clustering test sets for each dataset, as well as statistics for the monolingual and crosslingual embedding vectors used on the monolingual text benchmark from \u00a7 SECREF5, the test set for the multilingual benchmark from \u00a7 SECREF5 (in which the labels are given in the crosslingual space), and statistics on the training set used for the crosslingual embedding vectors from \u00a7 SECREF5.\nTable TABREF32\n\nTable of contents, for easy navigation and quick reference to \u00a7 SECREF3, \u00a7 SECREF4, \u00a7 SECREF5, \u00a7 SECREF6, \u00a7 SECREF7, \u00a7 SECREF8, \u00a7 SECREF9, \u00a7 SECREF10, \u00a7 SECREF11, \u00a7 SECREF12 and \u00a7 SECREF17.\nTable TABREF33\n\nThe time-adjusted news corpus used for the experiments on Table TABREF35 and Table TABREF39 from \u00a7 SECREF12.\nTable TABREF34\n\nHyper-parameters used on the multilingual news article embedding vectors and on the training set used for building the monolingual clustering model vectors.\nTable TABREF35\n\nExperimental results on Table TABREF32. Given the nature of our experimental set up, we could not report scores achieved with an unsupervised baseline (such as CluStream BIBREF12, ahmed2011unified, rupnik2016news), which is the baseline used as a target by our learning process. Instead, we report the scores achieved by training our model and comparing those to the baseline.\nTable TABREF36\n\nAcc",
    "d604f5fb114169f75f9a38fab18c1e866c5ac28b": "\n\nBibliography\n[aggarwal2019using] aggarwal, n., zhao, h., jain, s., rajpurkar, p., kim, s. y., gavves, t. (2019), Using a Convolutional Word Embedding to Extract Crosslingual Information from a Stream of Articles, in Proceedings of the 56th Annual Conference of the Association for Computational Linguistics (ACL 2019), pages 3789\u20133799, Singapore, Singapore.\n[ahmed2011unified] ahmed, o., atwell, j., raihani, m., kim, s., magee, d. (2011), Unified Representation of Semantic Relations for News Event Detection, in Proceedings of the 13th ACM Conference on Information and Knowledge Management (CIKM), pages 1344\u20131353, Toronto, Canada.\n\n[ammar2016massively] ammar, w., salas, a., lvov, m. (2016), Massive Cross-lingual Word Embeddings for News Clustering, in Proceedings of the 32nd Annual International ACM SIGIR Conference on Research & Development in Information Retrieval, pages 5, Budapest, Hungary.\n\n[aviv2016newsflow] aviv, s., buechi, d., perez, f., kim, s. (2016), NewsFlow : A Multilingual Stream Clustering System, in Proceedings of the 12th International Conference on Semantic and Social Media Adaptation (ICSSAM), pages 87\u201394, Chicago, Illinois.\n\n[chen1991use] chen, w., hans-p\u00e4ter, j., andres, d. (1991), Using word-list frequencies in document-term matrices to build keyword lexicons, in Proceedings of the 18th International Conference on Computational Linguistics (COLING), pages 1140\u20131147, Washington, D.C.\n\n[chen1994use] chen, w., thompson, f., chayes, a., andres, d. (1994), Using Word-List Frequencies to Build Word-list Lexicons, in Proceedings of the 30th Annual Meeting of the Association for Computational Linguistics (ACL), pages 84\u201389, Baltimore, Maryland.\n\n[cherry2019ngram] cherry, s., jain,",
    "1d3e914d0890fc09311a70de0b20974bf7f0c9fe": "\nAcknowledgments\n\nWe are grateful to the SQuAD authors, Amazon Research and Deepset.ai for making their datasets open access. We also thank the authors and developers of BERT, Word2Vec and BioBERT. We thank the organizers and participants of the BioNLP2020 shared task for useful discussions on BioBERT evaluation metrics. We thank Sarah Dai and Peter Clokie for reading drafts. Finally, we are grateful to our collaborators, especially David Schatz and Peter Clokie.\nAppendix\nAppendix.1: Training Details\nThis appendix discusses pretraining details for the GreenBioBERT and GreenCovidSQuADBERT models.\nAppendix.1.1.: BioBERTv1.1\n\nWe finetune BioBERTv1.1 on the NER tasks described in Section SECREF1. We start with the same model as in BIBREF2 (https://storage.googleapis.com/bert_models/2018_10_18/cased_L-12_H-768_A-12.zip), pretrained on a subset of NER-LMDB. We then adapt it to BioBERTv1.1. In particular, we remove the final Feed-Forward Net, initialize it with random parameters and randomly drop 50% of edges. We then free-train it on PubMed + PMC with a mini-batch size of 64 and a learning rate of $1 \\cdot 10^{-6}$; the dropout rate is 0.5 with a hidden size of 768, i.e., all layers except the last layer have a hidden size of 768. The learning rate is reduced by a factor of 10 every other epoch and the final finetuning ends at 100 epochs. We then fine-tune the final Transformer layer using the standard SGD for ten epochs with momentum 0.9.\nAppendix.1.2: BioBERTv1.0\n\nSimilar to BioBERTv1.1, we finetune BioBERTv1.0 on NER-LMDB. We start with the same model as in BIBREF2 (https://storage.googleapis.com/bert_models/2018_10_18/cased_L-12_H-768_A-12.zip), pretrained on a subset of NER-LMDB. We then adapt",
    "16535db1d73a9373ffe9d6eedaa2369cefd91ac4": "\nInexpensive Domain Adaptation of Pretrained Language Models (Appendix) ::: Experiment 2: Covid-19 QA ::: Hyperparameters\nWe fine-tune SQuADBERT with default parameters, including batch size of 32, peak learning rate of $1 \\cdot 10^{-5}$, and 100 epochs. In practice, we found it more useful to use a smaller learning rate for the task-specific layer (i.e., $1 \\cdot 10^{-6}$) and a larger learning rate for all other layers (i.e., 20 $ \\cdot 10^{-5}$). At inference time, for every question-context pair we gather the start and end logits and decode using 50/50 tokenization.\nAcknowledgements\nWe thank the organizers of the SemEval 2019 Text Annotation Evaluation for providing BioBERTv1.0's NER tasks and data. Additionally, we are grateful to the team of authors of BioBERT (especially Peter Henderson-Wallace and David Lo) for sharing their work.\nReferences\n\n[1] BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In: Proceedings of the 2019 Conference on Neural Information Processing Systems (NeurIPS 2019), Honolulu, HI.\n\n[2] BioBERT: A robustly updated biomedical language representation for efficient question answering. BioRxiv, 2019.\n\n[3] Difference between Word2Vec and GloVe?\n\n[4] Distilling a state-of-the-art language representation model for few-shot question answering. In: Empirical Methods in Natural Language Processing (EMNLP 2018), Brussels, Belgium.\n\n[5] SciBERT: Pretraining SciSpark on a large-scale corpus to improve biomedical question answering. BioRxiv, 2019.\n\n[6] ClinicalBERT: Integrating clinical knowledge to improve biomedical NER. In: Proceedings of the BioNLP 2018 Shared Task Series (BioNLP 2018), Dublin, Ireland.\n\n[7] ClinicalBERT: Fine-grained, task-aware clinical named entity recognition using domain-specific language features. In: Proceeding of the 10th Conference on BioNLP (BioNLP 2018), Dublin, Ireland.\n\n[8] ClinicalXLNet: A multilingual, cross-task, cross-domain, cross-framework NLP knowledge graph.",
    "de0b650022ad8693465242ded169313419eed7d9": " In the future work, we will put these problems on our concern list.\n1:\n\nhttps://t2t.ai/post/translation-evaluation-for-low-resource-language-pairs-with-neural-machine-translations/\n\n2:\n\nhttp://www.sigtra.lirmm.fr/home/lindsay/files/icassp-2017-mcdonald_slides.pdf\n\n3:\n\nhttp://aclweb.org/Workshops/AttentionAndLstms/index.html\n\n4:\n\nhttps://www.aclweb.org/upload/assets/program/abstracts/1770.html\n\n5:\n\nhttp://aclweb.org/upload/assets/program/abstracts/1858.html\n\n6:\n\nhttps://aclweb.org/upload/assets/program/abstracts/2208.html\n\n7:\n\nhttp://aclweb.org/upload/assets/program/abstracts/2870.html\n\n8:\n\nhttp://aclweb.org/upload/assets/program/abstracts/2137.html\n\n9:\n\nhttp://aclweb.org/upload/assets/program/abstracts/2198.html\n\n10:\n\nhttp://aclweb.org/upload/assets/program/abstracts/2157.html\n\n11:\n\nhttp://www.aclweb.org/upload/assets/program/abstracts/2927.html\n\n12:\n\nhttp://www.aclweb.org/Upload/assets/program/abstracts/3946.html\n\n13:\n\nhttp://proceedings.mlr.press/v48/Sennrich15.pdf\n\n14:\n\nhttp://www.aclweb.org/Upload/assets/pdf/2015-Miller.pdf\n\n15:\n\nhttp://proceedings.mlr.press/v32/Bahdanau14.pdf\n\n16:\n\nhttp://www.aclweb.org/Upload/assets/2016.06/Sennrich16.pdf\n\n17:\n\nwww.aclweb.org/media/Files/2016-Sennrich-Berkeley.pdf\n\n18",
    "2b3cac7af10d358d4081083962d03ea2798cf622": " In the meantime, we introduce an idea of fine-tuning our NMT network to focus its attention to the right number of sentences in target language for a particular language pair at training time while avoiding overfitting to large monolingual texts without losing the common language features across all source languages.\n\nOur project is open to public access at https://nematus.cc/projects/multilingual-nmt/.\nWe gratefully acknowledge the helpful discussions with our reviewers and thanks to the editors for giving us a chance to publish the paper.\nAcknowledgments\nPart of this work was conducted while Kyeongho was an intern in The Korea Institute of Science and Technology Information. This work was supported by Korea Ministry of Science, ICT Accelerator Program through The Korean Institute of Science and Technology Information, and partially funded by a grant in The Korean Basic Science Institute Support Program through The National Research Foundation of Korea under Grant of the Ministry of Education, Science and Technology (No. 2018R1D1A1-B0100650).\n\n[1]\nBahdanau, Daan, et al. 2014.\nNeural machine translation by jointly learning to align and translate.\nBIBREF0\n\nLuong, Minh-Thang, et al. 2015.\nUnsupervised multilingual sentiment lexicon induction. Proceedings of Coling 2015, p. 1138\u20131148.\nBIBREF1\n\nMa, Xingyu, et al. 2016.\nA neural machine translation system trained on raw text.\nBIBREF2\n\nLuong, Minh-Thang, et al. 2015.\nAttention is all you need.\nBIBREF3\n\nHochreiter, S. and Schmidhuber, J. 2015.\nLong short-term memory.\n\nBIBREF4\n\nGraves, Andy, et al. 2018.\nGenerating quality character-level translations with very few resources. arXiv preprint arXiv:1802.02920.\n\nBIBREF5\n\nBahdanau, Daan, et al. 2015.\nNeural machine translation by jointly learning to align and translate. International Conference on Machine Learning.\n\nBIBREF6\n\nLuong, S., et al. 2016.\nZero-resource translation with subword units. CoNLL Workshop and Shared Task, 2016.\nB",
    "897ba53ef44f658c128125edd26abf605060fb13": "\nAppendix A NER Examples\n@en@Kapitalismus\n@de@die@Projektion\n\n@en@demokratie@Konflikt\n\n@de@den@Konsum.\n\n@en@dem.\n\n@de@geht@im@Vortrag\n\n@en@car@automobile\n\n@de@Flussufer@bank\n\n@en@kleine@Zahlen\n\n@de@Vortrag@car\n\n@en@darum@Kapitalismus@Konflikt@gibt @en@car@automobile@\n\n@de@Flussufer@Vortrag@bank@professor @en@car@bank@professor@vortrag@Kapitalismus@Konflikt@gibt\n\n@en@gibt @en@Vortrag@car@bank@professor@Vortrug@Kapitalismus@Konflikt@gibt\n\n@de@Projektion@Gegenteiler@Kapitalismus@Konflikt@gibt @en@car@bank@professor@Vortrug@Kapitalismus@Konflikt@gibt\n\n@en@geht@im@Vortrag\n\n@de@Projektion@Gegenteiler@Kapitalismus@Konflikt@Gegenteiler@Konflikt@darum@Kapitalismus|@en@car@Vortrag@Vortrag@gibt @en@Flussufer@bank@professor@Vortrug@Kapitalismus|@en@Vortrag@car|@de@flussufer@bank@professor@Vortrug|\n\n@en@darum@Kapitalismus|@de@Vortrag@Kapitalismus|@de@Flussufer|@de@Vortrag|@en@car|@de@CarProjektion@bank@Projektion|@en@Bankcar@BankProjektion)\n\n@en@kleine@Zahlen@zahlen @en@de@Projektion@Pro",
    "41ac23e32bf208b69414f4b687c4f324c6132464": "\nIn conclusion, we hope that the proposed framework can serve as a solid ground for future work about the multilingual attention-based NMT.\n\nAcknowledgement\nThis research was supported in part by a grant from RIKEN and in part by H2020-ICT-3 project HMT-4EU-IDI, grant agreement 644422, with support from the European Union's Horizon 2020 research and innovation programme, a large scale European research and innovation programme under Horizon 2020, the Framework Programme for Research and Technological Development and the national research and\nA. Cires\u00e1n and Y. Tsvetkov. End-to-end neural machine translation system using a new joint loss function. ArXiv e-prints ArXiV-2010\u20130788. ArXiv: arXiv:1005.1140 [stat.ML: cs.LG]\n\nA. Ciresan, P. Toutanova, and Y. Tsvetkov.\n\nNeural machine translation for statistical machine translation.\n\nEURASIP J. Adv. Signal Process. 2016; 3, 20. ArXiv: 1609.08701. ArXiv: 1609.08701 [cs.CL]\n\nS. Edunov and I. Loukos.\n\nZero-shot word sense disambiguation with a multilingual deep neural network.\n\nArXiv e-prints ArXiV-1608.0588. ArXiv: 1608.0588 [stat.ML]\n\nM. Federico and G. Mart\u00edn Alvarado.\n\nNeural machine translation with multilingual data using sequence-to-sequence models.\n\nArXiv e-prints ArXiV-1503.01123. ArXiv: 1503.01123 [stat.CL]\n\nS. Gonzalez-Dominguez.\n\nA neural machine translation system for low-resourced language pairs: a comparison of bilingual and multilingual approaches with English as a pivot language. \nArXiv e-prints ArXiV \u2013cs.CL/1511.01936. ArXiv: cs.CL / arxiv:1511.01936 [cs.CL]\n\nB. Giraffa, A. Ciresan, M. Cacciari, R. Gatti, F. Rossi, M. Mecagni, and L. Strube.\n\n",
    "e97186c51d4af490dba6faaf833d269c8256426c": " For the moment, we suggest having several alternative evaluation sets, all of which can be used to provide consistent estimates of model competence.\n\nFor our preliminary testing of the automatic generation of probe data, we made a few efforts to inspect the quality of our generated data via crowd-sourcing and cluster-based metrics. While we find generally high quality in our automatic generation of probes, we do not believe it is possible to construct a comprehensive set of such metrics at present. As a promising direction, we leave future work in creating methods for conducting such validations as well as automatically identifying systematic biases using a variant of the methods previously used to detect adversarial attacks on language models BIBREF43 and recent work on word sense disambiguation BIBREF57.\nAcknowledgments\nThis work was done in collaboration with Oli Yankam and Kailash Sastry at AllenNLP. We thank the people at the Allen Institute for the support over the years that made this possible, and especially for their longstanding encouragement of open-source research tools.\nWe thank the reviewers for a careful review of our work, which greatly helped shape the final form of the submission.\nWe gratefully acknowledge the support of NSF Grants 1647177, 1633357, 1724105, 2011700, and 1634532, and a gift grant from Facebook.\n\n[1] G. Abend, M. Chen, S. P. Loparo, and C. Klinger, eds. WordNet Consortium. 2013. http://wordnet.princeton.edu\n\n[2] Jiaqi Zhou, Yajie Chen, Daniel M. Roth, and Dushan Shah. Open-Domain Question Answering. In: EMNLP. 2016.\n\n[3] A. Alyabova, A. Agarwal, and N. Roy Choudhury. An Empirical Study of Querying Multiple Knowledge Sources Using a Single QA Model Training. In: SemEval-2018. pp. 1039\u20131045.\n\n[3] T. Ashwini, C. B. E., J. S. Breck, H. J. Huang, L. Prabhakar, T. K. Lewis, M. C. Lin, R. M. Mishra, K. Saidi, and H. Y. Wang. SciQ. In: ACL. 2020.\n",
    "5bb3c27606c59d73fd6944ba7382096de4fa58d8": "\nIn addition to probing knowledge from large-scale lexical resources (e.g., WordNet and the GCIDE), we also explored the use of other sources such as ConceptNet and SRLBANK datasets BIBREF7, BIBREF38. While we found that such probes lead to more varied results, and some of our probes do have interesting characteristics, more systematic, controlled experiments are required to confirm the full implications.\nWhile naturalistic probes tend to have more nuanced error statistics, we also leave open the possibility of combining different types of benchmarks as an alternative to studying only expert knowledge. As an example, we have found that the performance of models on probes based on ConceptNet is more diverse than in our WordNet (or even Dictionary) probes. While results for specific models still seem consistent with the findings above, further controlled experiments are required to resolve any possible bias issues.\n\nFinally, we note several technical details related to the general feasibility and application of our methodology. One issue is that data generation can be an expensive and time-consuming process (e.g., using WordNet or the GCIDE, which took several weeks per probe). Future work should look into making this process faster and cheaper by exploiting the work of others BIBREF57 (e.g., BIBREF58) in making available a variety of expert knowledge resources, as well as through the use of neural language models in pre-processing to boost synthesis output. Another issue, which is not immediately relevant to creating novel probes, is ensuring that the model being trained on benchmark tasks can perform reasonably well on our synthetic probes, a topic which we leave for future work.\n\nWe hope that our work will lead to stronger, more competent transformer models for science QA, and encourage others to look at our new methodology for systematic probing in other domains. The ultimate merit of a large-scale probing study such as this one might not be the direct knowledge obtained about models themselves, but rather serve as a source of motivation to bring out even more knowledge implicitly contained inside of pre-trained models. One such potential direction of inquiry would be to incorporate the idea of inoculation into more general model pre-training processes by training on a variety of different probes, as described by BIBREF59. We further look forward to future work that further explores model consistency and robustness in more controlled experiments.\nAppendices\n\n## Table of Contents\n\nAppendices   :\n\n\n## A",
    "8de9f14c7c4f37ab103bc8a639d6d80ade1bc27b": "\nAcknowledgments\nM.N. acknowledges support from NSF awards IIS1901137, IIS1914191, BOS #1854998; DARPA; AFOSR #FA95-19-1-0072; GSA #JFA-P-0057; Amazon; Google; Microsoft; NSF S2S #1634955; NSF S2S #1700133; AFOSR #2032104, 1815018, #FA9550B002; NASA; AFOSR #FA9550-19-1-0077\nThis open source research was made possible through the support of the National Science Foundation under Grants NSF-AIS-1754094, DARPA XData #FA9550-20-1-0156, and DARPA.\nThis work is supported in part by the Defense Advanced Research Projects Agency (DARPA) under contract number FA9550-19-1-0077. The views, opinions, and/or findings expressed are those of the authors and should not be interpreted as representing the official views or policies of the United States government, the Department of Defense, or the U.S. Army Research Laboratory.\n\nThe authors would like to acknowledge the valuable feedback of all members of the NSF Center for Robust Speech Technologies.\n\nAuthor Summary\nWe showed how to automatically create challenge datasets drawn from a wide variety of expert sources by proposing a novel methodology for synthesizing naturalistic questions based off of information in lexical knowledge bases. Our methodology makes use of existing tools for constructing scientific benchmarks, including Huggingface. We further showed that state-of-the-art QA models, as well as a variant of fine-tuning for inoculation, have a surprising ability to recognize the knowledge contained in synthetic data based on such knowledge.\n\nFigure 1: High-level view of our probing methodology (left side) and examples of the resulting probes (middle).\n\nTable 1: Datasets used for probing study.\n\nTable 2: Number of example questions and answers in each probe.\n\nTable 3: Number of clusters created by dividing targets (concepts), based on WordNet and GCIDE and on different types of question patterns.\n\nTable 4: Overview of WordNet and GCIDE triples used to construct probes for different semantic types.\n\nTable 5: Details of how the WordNet synsets is mapped to the",
    "85590bb26fed01a802241bc537d85ba5ef1c6dc2": "\nWe also emphasize that models should not be seen as being able to handle complex knowledge implicitly. Instead, probe questions should be understood as a kind of knowledge bottleneck; even if a model can answer several probing questions correctly, this does not guarantee knowledge acquisition or reasoning abilities. Instead, we note the interesting fact that some models are consistently better at some probe types than others and that model choice might be critical in this regard, as was also observed in recent QA studies BIBREF50, BIBREF51. For example, BERT and RoBERTa are stronger than ESIM on most types of probe questions, even with models that are very different in terms of their training, architecture, and hyper parameters; such consistency in performance on different tasks is suggestive that fundamental knowledge/cognitive abilities might be involved (such as a model's ability to use available reasoning resources). We leave the study of domain-specific knowledge and its relationship to cognitive capabilities, such as ISA and taxonomic reasoning, to future work.\nIn addition, we highlight how the choice of generation templates can have a significant effect on model competence. Models trained on different task-specific benchmarks consistently learn different templates leading to different distributions over their internal parameters and hence model competence across different queries, which shows that these models do bring with them domain-specific knowledge (i.e., knowledge of different ways to encode questions and answers). We leave open the question how much of this knowledge is available prior to training on benchmarks, and how much it can be explicitly engineered in.\nFinally, despite strong performance on many probes, we see considerable room for improvement especially in terms of definitional and taxonomic reasoning. Models fail to excel on more complex distractor patterns, and some models are consistently better at answering individual probes than other models. This suggests avenues for future work in engineering more complex benchmarks for pre-training of open-domain models, e.g., that focus more on definitions, taxonomic relations, and word senses rather than only on facts (or at the very least, on making the distribution of probe categories more uniform).\nAcknowledgements\nWe thank all the members of the Allen Institute for AI for their guidance, help, and many insightful discussions over the years. We are also deeply indebted to all the collaborators in the OpenCQGen initiative, especially for their work on the OpenBookQA BIBREF10. We would also like to thank the Google AI Research team, especially Sam Bowman, Yonatan K",
    "75ff6e425ce304a35f18c0230c0d13d3913a31a9": "\nWe also note that, while the general methods presented here might have some value for probing any MCQA domain, specific application for any given task is still primarily guided by domain knowledge and specific models/architectures under interrogation. More in-depth evaluations across other tasks and architectures would be needed to confirm that our methodology is broadly useful for modeling competence.\nWe would especially like to perform similar experiments probing other natural language processing (NLP) tasks, e.g., natural language understanding (NLU) and generation, as well as other general tasks such as question answering. A broader framework for generating probe data for QA data and other domains would be desirable and would be helpful for allowing a holistic cross-examination of language models' ability to handle diverse types of knowledge.\n\nOne possible direction is to extend our WordNet probe approach to include probing knowledge graph networks, e.g., using links based on more complicated semantic predicates such as hypernymy, or by targeting specific types of relations. In contrast, in the area of NLI the adversarial paradigm BIBREF14, BIBREF45, BIBREF47 has proven to be of particular use for discovering interesting cases of reasoning. In some cases, these new probe constructions have given rise to much better models BIBREF54, BIBREF17, BIBREF57; it will be interesting to see whether equivalent probes for NLP tasks are similarly successful. We also encourage further work on investigating the exact nature of the background knowledge contained in today's language models, as well as in exploring alternative probes for probing relational knowledge that might be more amenable to automatic generation or involve knowledge graph networks.\n\nNote that there is considerable interest in finding ways to make models more consistent and robust, which could lead to improved QA and other end-use areas, where more robust models can also become more valuable. As we describe earlier in Section SECREF1, in this manuscript we concentrate on evaluating certain types of background information, whether through a more systematic manipulation of probe questions or through a more comprehensive set of cluster-based metrics that measure robustness to more diverse sources of errors. In addition, as we describe in Section SECREF1 and Section SECREF2, we can use this methodology to interrogate how models are vulnerable to certain types of adversaries, where this vulnerability can come both in the form of a lack of robustness or a failure to recognize patterns that may indicate adversarial effects.\nAcknowledgments",
    "5cb610d3d5d7d447b4cd5736d6a7d8262140af58": " Thanks to our coauthors Anastasia Athanasiou and Nathana\u00ebl Vibergua for help with the research.\nReferences\n\n. Blevins, R. (2016). Learning to rewire: An introduction to multi-task learning in neural networks. _Transactions of the Association for Computational Linguistics_, 7(1).\n\n. Borth, A., Lass, R., and Ehrlich, C. (2017). Learning morphological rules from a single example in a multilingual setting. _Arxiv:1707.05492_.\n\n. Chen, C. (2017). Universal morphological reinflection in context. Ph.D. thesis, University of Texas at Austin.\n\n. Demner-Fushman, D., Gurevych, D., and Koehn, P. (2017). Neural sequence-to-tree conversion with shared parameters and task-aware learning. _Arxiv:1703.10555_.\n\n. Finkel, C., Khot, J., and Manning, C. (2016). Using MSD tags to generate inflected word forms. Proceedings of the Thirty-first Conference on Association for Computational Linguistics, pages 1037\u20131045, Washington, DC, June 2016.\n\n. Khot, J., Finkel, C., Meng, B., and Manning, C. (2017). Multitask learning for universal morphological reinflection. _Arxiv:1712.09364_.\n\n. Kozminskii, O. (2016). BIBREF: A multilingual benchmark for reference-based universal morphological inflection tasks. _Proceedings of the 2017 Conference on Empirical methods in Natural Language Processing, EMNLP 2017, Vancouver, BC, Canada, November 2017_, pages 25\u201334.\n\n. Kulick, K. and Ngai, R. (2015). A neural network reinflection system for morphologically rich languages. _In Proceedings of the First Workshop on Neural Networks for Morphologically Rich Languages, EMNLP 2015, Denver, Colorado, September 2015_.\n\n. Pires Maia, E., and Verga, F. R. (2017). Automatically Induced Universal Mappings: an Empirical Evaluation of Morphological Reinflection Tasks. _Arxiv:1702.02890_.\n\n",
    "c32adef59efcb9d1a5b10e1d7c999a825c9e6d9a": "\nAll the models were trained on the High Resource setting of Task 2, i.e. a total of 70K training instances, and so the presented results are valid only for this setting.\nTable TABREF1.\nAn example multi-lingual input sentence for the high-resource setting of Track 1.\nTable TABREF17.\nThe test results of our submission to the CoNLL\u2013SIGMORPHON 2018 shared task on Universal Morphological Reinflection, Task 2, on the English, Russian, German and Spanish test sets.\nTable TABREF2.\n\nThe test results of our submission to the CoNLL\u2013SIGMORPHON 2018 shared task on Universal Morphological Reinflection, Task 2, on the Croatian, Estonian, Swedish, Norwegian, Arabic and Finnish test sets.\nTable TABREF23.\n\nA comparison between our system and the winning baseline system in Track 1 (Mikolov et al., 2018) for languages that are also covered in High Resource (HR) track. The baseline only receives context word forms, lemmas and MSDs as input, while the system receives all three sources of information. High Resource denotes settings with 70K instances per language. Note that we do not train on the Norwegian NORM dataset (50K instances), as it lacks MSD annotations for the target form.\nTable TABREF24.\n\nThe test results of our submission to the CoNLL\u2013SIGMORPHON 2018 shared task on Universal Morphological Reinflection, Task 2, on the low-resource setting data. All data is in Track 1 and is split in three languages. For each language, the leftmost value corresponds to the baseline while the rightmost one to our multi-lingual multi-tasking system. All data comes from Track 2 and is split in two languages.\nTable TABREF25.\n\nAccuracy for the five best models for each language and architecture, as described in sections 4.1 and 4.2. All data is in Track 1 and is split in two languages. The values for the best models were selected from the top-n model by a majority vote.\nTable TABREF26.\n\nAccuracy for the multi-lingual multi-tasking system on each language and architecture, including English, German, Spanish, Russian, Norwegian, Arabic, Finnish, and Swedish.\nTable TABREF27.\n\n",
    "b9d168da5321a7d7b812c52bb102a05210fe45bd": "\nReferences\n\n[BIBREF0 ] K. Bontcheva, M. Chander, X. Feng, R. Ganchev, D. Helmroul, T. Kottur, N. P. Manning, J. Sch\u00fctze, R. Soze, D. Tenenbaum, J. Zollmann, K. Toutanova, A. Klamt, T. Hofmann, J. Alshumaimer, P. Ginter, J. Klein, K. Lamprecht; Universal Morphological Reinflection: CoNLL 2018 Shared Task, In Proceedings of the CoNLL 2018 Shared Task on Morphological Parsing, Association for Computational Linguistics, to appear.\n\n[BIBREF1 ] J. Pereyra, S. Zhang, R. Soze, J. Ginter, A. Klamt, C.-Y. Liu, P. Ginter, J. Alshumaimer, K. Toutanova; A Seq2seq Model with Attention for Morphological Reinflection. In Proceedings of the CoNLL 2016 Shared Task on Morphological Segmentation and Dependency Parsing Shared Task, Association for Computational Ling-  uistics, to appear.\n\n[BIBREF2 ] T. Hofmann, J. Ginter, K. Lamprecht; End-to-end Morpher. In Proceedings of the Sixth Workshop on the Semantics and Pragmatics of Morphosyntactic Structure, Association for Computational Linguistics, 2017.\n\n[BIBREF3 ]  \nThis list is not exhaustive: see, e.g., T. Hofmann and J. Ginter, Multilingual Encoders for Morphogrammar Learning, International Workshop on Treebanks and Linguistic Theories (TALS 2016). (http://hal.inria.fr/ 00086038)\n\n[BIBREF4 ]  \nThe task of universal morphological reinflection is to generate from a given word form a target-language word form that inflects the same underlying structure. Here the number of input and output lemmas is typically significantly smaller than the number of possible target languages, however; so the number of input sentences that cover several variants of a word form and its context (e.g., to cover all forms of a verb in a language)",
    "0c234db3b380c27c4c70579a5d6948e1e3b24ff1": " We thank David Chavarr\u00eda for answering questions regarding Swedish syntax and grammatical cases, and we thank the anonymous reviewers for their valuable input on our work.\nReferences\n1. Gimenez, E., Haffard, G., Deorowicz, J., and Toutanova, T. (2016). Learning to infer Word Senses from Context and Paragraphs using Neural Networks. In CoNLL 2016: Eighth Workshop on Computational Natural Language Learning, Proceedings of the Conference of the Colorado\n2. Nallapati, G., Dyer, C., Neff, N., Wittenburg, P., Hancock, P., and J\u00e4rvle, P. (2016). Subword units for effective context-based morphosyntactic transfer. In EMNLP 2016: Proceedings of the 2016 Conference of the European\n3. Nallapati, G., Chavarr\u00eda, D., and Das, S. (2018). Multitask Learning for Morphological Reinflection. In COLING 2018: Proceedings of the 27th International Conference on Computational Linguistics, Associ-\n4. Dyer, C., Neff, N., and Aharon, W. (2016). Subword features for robust morphological reinflection. In COLING 2016: 2016 Joint Conference on Cognitive Linguistics, Abstract Book. Association\n5. Das, S., Chavarr\u00eda, D., Nallapati, G., and Lipton, D. (2016). Multitask learning for morphological mapping. In CoNLL 2016: Sixth Workshop on Computational Natural Language Learning, Association\n6. Hosseini, M. A., Jawahar, N., and Lipton, D. (2017). Multi-task sequence-to-sequence learning for morphological mapping with limited data. In ColingEACL 2017: Proceedings of the 26th International Conference on Computational Linguistics: Shared Task Papers, 3\u201324.\n7. Hosseini, M. A., and Houlsby, M. J. (2016). Multitask sequence-to-sequence learning for morphological tagging with limited data. In CoNLL 2016: Fifth Workshop on Computational\n8. Ma, H., Chavarr\u00eda, D., and Das, S. (2018). Multilingual multitask learning for neural dependency parsing with limited training data. In Co",
    "fa527becb8e2551f4fd2ae840dbd4a68971349e0": "\nReferences\n\nBIBREF0\n\nCoNLL, 2012.\n\nCoNLL-SIGMORPHON, 2018. Task 1 and Task 2: Universal Morphological Reinflection. Available at <https://www.conll.org/>.\n\nBIBREF1\n\nBohnet and Birns, 2016. CoNLL-SIGMORPHON 2016: Shared Tasks for Computational Linguistics. International Conference on Computational Linguistics, July 2016, Santa Fe, New Mexico.\n\nBIBREF10\n\nOflazer et al., 2016. Sharing Syntactic and Semantic Representations Between Relatively Close Languages: Results on Dependency Parsing. In Proceedings of the 22nd International Conference on Computational Linguistics, pages 1181\u20131190. IOS Press.\n\nBIBREF11\n\nDeMarco and Sch\u00fctze, 2017. Paradaigma: A Tool for Creating Linguistically-Grounded Multilingual Corpora from the Web. In Tenth Annual Meeting of the Association for Computational Linguistics, pages 1675\u20131684.\n\nBIBREF12\n\nHuang and Huang, 2017. Morphological Induction: An Example of Weak Supervision for Learning a Neural Network. In Proceedings of International Conference on Cognitive Modeling and Its Applications, pages 1\u20136. IICSA Press.\n\nBIBREF13\n\nNastase et al., 2013b. Reinflection of Complex Words in Sketch Engine: Results. In Third Workshop on Technologies Supporting Morphological Processing (TechMorpho 2013). http://aclweb.org/resources/.\n\nBIBREF14\n\nNastase et al., 2013a. Reinflection of Complex Words in Sketch Engine: A Tool for Building Datasets of Inflected Words. In Proceedings of the 22nd International Conference on Computational Linguistics. IOS Press.\n\nBIBREF15\n\nPopescu-Belis and Sch\u00fctze, 2017. A Multilingual Perspective on Universal Dependency Parsing. In Proceedings of the 23rd Conference of the Association for Computational Languages 2019, pages 118\u2013128. Association for Computational Linguistics.\n\nBIBREF16\n\nPopescu-Belis and Sch\u00fctze, 2018. Universal Morphological Reinflection with Multiple",
    "32a3c248b928d4066ce00bbb0053534ee62596e7": "\n[CoNLL\u2013SIGMORPHON 2018 Shared Task] CoNLL\u2013SIGMORPHON: International Workshop on Computational Approaches to Morphological Analysis. CoNLL\u2013SIGMORPHON Shared Task: Universal Morphological Reinflection. CoNLL. 2018, 2018.\n[CoNLL\u2013SIGMORPHON 2016 Shared Task] CoNLL\u2013SIGMORPHON: International Workshop on Computational Approaches to Morphological Analysis. CoNLL\u2013SIGMORPHON Shared Task: Universal Morphological Reinflection. CoNLL\u2013SIGMORPHON. 2016, 2016.\n[B\u00f6hme, B. and Hajic, S.] Towards End-to-End Morphological Reinflection: A Multitask Learning Approach with Contextualized Attention. CoNLL\u2013SIGMORPHON 2016 Shared Task: Universal Morphological Reinflection. CoNLL\u2013SIGMORPHON. 2016, 2016.\n[Bohnet, F., T. Grahl, G. F\u00e9ron and L. Lample] Morphological Reinflection with Multitask Learning. CoNLL\u2013SIGMORPHON 2016 Shared Task: Universal Morphological Reinflection. CoNLL\u2013SIGMORPHON. 2016, 2016.\n[Bohnet, F., G. F\u00e9ron and L. Lample] Context-Directed Morphological Reinflection with Multilingual Training. CoNLL\u2013SIGMORPHON 2017 Shared Task: Universal Morphological Reinflection. CoNLL\u2013SIGMORPHON. 2017, 2017.\n[Chollet, F., I. Goodfellow and L. Bengio] Deep Learning. MIT Press, 2015.\n[Graves, A. & Schmidhuber, J.] Super-resolution Neural Networks. NIPS 2014. 2014.\n[Hjelm, J., J. W. Moore, J. Eisner, C. C. Clark, and R. Riedel] Learning to Transduce Morpho-syntactic Features with Neural Turing Machines. TACL 2013. AOSP. 2013.\n[Hochreiter, S. and Schmidhuber, J.] Long Short-Term Memory. NEURIP 2005. 2007.\n[Lample, L., A",
    "c9b8d3858c112859eabee54248b874331c48f71b": " The views expressed are those of the authors, and neither the NVIDIA Corporation nor the grant agency had any role in the design of the submitted work.\nNotes & Definitions\n[1] Bauer, J., Kuhlmann, H., Riedel, S., Sennrich, R. BIBEF2 A neural-network-based grammar for agglutinative morphology. Proceedings of the Conference on Empirical Methods in Natural Language Processing, 2015.   \n[2] Bhatt, S., Cho, S., Zhang, H., et al. BIBREF3 MTL for NLP: Multilingual Learning for All. In Proceedings of the EMNLP 2018, 2018.   \n[3] Hosp, E. J., Lafferty, K. L., Raganato, B., et al. BIBREF5 A new paradigm for multitask learning from human examples. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, 2017.   \n[4] Howard, A., Ruder, S., Schmitt, B., et al. BIBREF6 Multi-task learning: learning multiple tasks from limited data with neural networks. arXiv preprint arXiv:1506.01497, 2015.   \n[5] Artetxe, P., Cuci, S., Navigli, C. BIBREF6.1. Morphologically annotated treebanks for universal morphological inference. Proceedings of the Conference on Empirical Methods in Natural Language Processing, 2018.   \n[6] Clark, P., Gildea, T., Klein, Y. MTL. Journal of Machine Learning Research, 6:37\u201357, 2015.   \n[7] Artetxe, P., Heesen, M., Navigli, C. BIBREF7.1. Multitask deep learning and universal morphological inference: the case of German and Dutch: a case study. Proceedings of the Conference on Empirical Methods in Natural Language Processing, 2018.   \n[8] Bordes, R., Weston, J., Chomer, M., et al. BIBREF8.1. Multi-task multi-lingual deep learning for natural language processing. arXiv preprint arXiv:1506.07123, 2015.   \n[9] Hwang, T., Dyer, C., Lee, D., et al. BIB",
    "45e9533586199bde19313cd43b3d0ecadcaf7a33": " This work was supported partly by National Science Foundation of China (Grant Number: 61673078).\n\nThe authors would also like to thank their friends, family and colleagues for their encouragement.\nReferences\n\n[BIBREF1] Qiu et al. (2018) Joint learning for machine reading comprehension. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing (EMNLP).\n\n[BIBREF2] Lin et al. (2018) Learning to reason and discover useful information from the reading passage. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing (EMNLP).\n\n[BIBREF3] Choi et al. (2017) Document-level knowledge induction: a neural attention-over-attentive model for text comprehension. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing (EMNLP).\n\n[BIBREF4] Gu et al. (2017) A survey on machine reading comprehension for open-domain question answering. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing (EMNLP).\n\n[BIBREF5] Jia et al. (2018) Multi-task learning for open-domain question answering: an empirical study on neural architectures and task combinations. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pp. 1295\u20131298. Association for Computational Linguistics. https://doi.org/10.18653/v1/C18-1104.\n\n[BIBREF6] Qiu et al. (2018) Unanswerable questions in machine reading comprehension. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Annual Meeting 2018 (NAACL-HLT).\n\n[BIBREF7] Pennington et al. (2015) Glove: global vectors for word representation. In Proceedings of 2014 Conference on Empirical Methods in Natural Language Processing, pp. 1724\u20131731. ACL. https://dx.doi.org/10.18653/LL-15-2115.\n\n[BIBREF8] S\u00f8gaard et al. (2018) Joint attention for machine reading comprehension. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pp. 1609\u20131619. Association for Comput",
    "d3dbb5c22ef204d85707d2d24284cc77fa816b6c": " This work is supported in part by the National Natural Science Foundation of China under Grant Nos. 61403272, 61703210 and 61832011.\n\nReferences\n\n[1] Zhu, L., Li, N., Yu, J. & Ji, B. Joint Attention Multi-Turn Model for Machine Reading Comprehension. arXiv:1910.09450v3 (2019).\n\n[2] Yang, G., Zhang, H. & Fan, J. The Reading Comprehension of Chinese Passages Based on Neural Network Model. Tsinghua Sci. J., 32(4): 1555-1563, EISSN 1008-6236, (2017).\n\n[3] Xiang, C., Sun, J. & Li, Y. Reading Understanding: A New Approach to Question Answering for Natural Language Processing. In: Proceedings of the 33rd Annual Conference of the American Association for Artificial Intelligence, AAAI 2016, Vancouver, Canada, 2016, pp. 2310-2316.\n\n[4] Zheng, L., Jiang, K., Zhang, Z. & Huang, Y. Reading Comprehension of Paragraphs and Documents with an Attention-based Deep Neural Model. J. Web Sem. Netw., 9(3): 135-150, EISSN 1874-6953, (2018).\n\n[5] Ji, B., Wang, T., Fan, J. & Qian, X. Joint Modeling for Multi-Turn Machine Reading Comprehension. In: Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing, EMNLP, Singapore, 2019, pp. 1599-1610.\n\n[6] Jiao, C., Zhou, H. & Zhang, H. Jointly Matching Text Spans and Predicting Unanswerable Questions in Machine Reading Comprehension. In: Proceedings of the 2020 International Conference on Artificial Intelligence and Statistics, AISTATS, Melbourne, Australia, 2020, pp. 879-892.\n\n[7] Ji, B., Zhang, H. & Sun, J. CoAtt: Coupled Reading Comprehension with Complemental Convergence for Neural Web Search. WWW 2019.\n\n[8] Wang, T., Wu, M., Fan, J. & Qian, X. Multi-Task Learning for Machine Reading",
    "a5e49cdb91d9fd0ca625cc1ede236d3d4672403c": "\n\nReferences\n\n[\n\n] Zhou, C., Huang, Q., and Zhang, S. (2017). SENet: Towards a semantic-aware neural network for reading comprehension. In Proceedings of the Fifty-Third Annual Meeting of the Association for Computational Linguistics (ACL), pp. 2476-2485.\n\n] Rennie, M. H., Lotsteiner, I., S\u00f8gaard, P., Demberg, Z., et al. (2017). Distantly supervised sentence compression and retrieval with fast-match. In Proceedings of the 2017 Conference of the North American Annual Meeting of the Association for Computational Linguistics (NAACL), pp. 1498-1507.\n\n] Yu, J., Lin, H., and Cucerzan, R. (2016). The Stanford Question Answering Dataset. In Proceedings of the 2016 Conference in Boston, Massachusetts on Advances in Neural Information Processing Systems (NIPS), pp. 1609-1618.\n\n] Karpukhin, K., et al. (2016). Stanford CoreNLP. http://nlp.stanford.edu/software/corenlp.shtml: Stanford University, https://git.stanford.edu/stanfordnlp/stanfordnlp/tree/dev/.\n\n] Liang, B., et.al. (2017). BIBREF: A benchmark for unanswerable questions. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL), pp. 3513-3523.\n\n] Chen, Z., and Manning, Chris D. (2014). Stanford Question Answering Dataset version1.0. In Proceedings of EMNLP, 2014, pp. 1014-1021.\n\n] Lin, C.-C., C. Zhang, and D. A. Dennison. (2016). Jointly Learning Answer Spans and Text Representations for Question Answering over Long Paragraphs. In Proceedings of NAACL, 2016, pp. 656-662.\n\n] NIPS-17-paper-0637-final.pdf.pdf\n\n] Dai, Z., Li, W., Shen, J., et al. (2017). Improving reading comprehension with external memory system. In Proceedings of the 53rd Annual Meeting of the Association",
    "aefa333b2cf0a4000cd40566149816f5b36135e7": "\n\nTable 1\n\nTransformation accuracy for different sets of parameters\n\nNoun Pair\n\nDamerau-Levenshtein\n\n50,000\n\nTransformation\n\nTest Set\n\nTrain Set\n\nTest Set\n\n50,000\n\nNoun Pair\n\nDamerau-Levenshtein\n\n50,000\n\nTransformation\n\nTest Set\n\nTrain Set\n\nTest Set\n\nTest Set\n\n50,000\n\nNoun Pair\n\nDamerau-Levenshtein\n\n50,000\n\nTransformation\n\nTest Set\n\nTrain Set\n\nTest Set\n\nTest Set\n\n50,000\n\nNoun Pair\n\nDamerau-Levenshtein\n\n50,000\n\nTransformation\n\nTest Set\n\nTrain Set\n\nRussian and Ukrainian Semantic Clustering\nOnce we obtained the linear transformation matrices for the two languages, we simply applied them to each of our test documents. For that, the text was split into words; then for each word one of the 300 dimensions (corresponding to a particular vector in a vector space) was found (that one which was the most different from the rest). The new vector was calculated as the mean of the 300 values. We then compared the resulting word representations in the Ukrainian vector space and the corresponding Russian vector space. As we described earlier, word distances in vector space roughly correspond to their semantic similarity, so the document vectors which are closer should be linked into different clusters. This is the main intuition behind clustering (see the next section for details).\n\nFor this analysis we restricted the set of documents to those with high similarity to our bilingual test set (for example, for economics, all texts describing economics classes in different languages get into one cluster, and so on). The corpus of Ukrainian documents was reduced from about 600 documents to around 200 documents for each topic. After that, we split the documents into 5 clusters.\nTo cluster the documents we used Affinity Propagation Classifier BIBREF10. This is a shallow clustering algorithm, which finds clusters via so called affinity propagation equations. It should be stressed that it does not train on actual labels of the classes, and that it only finds them based on word vectors in the semantic space as the only input. One of the main advantages of shallow clustering like this is that it requires very little preprocessing of data,",
    "c5abe97625b9e1c8de8208e15d59c704a597b88c": "\nAppendix ::: Results and Ablation Study\nResults and Ablation Study\nWe compare the two methods we introduce in Section SECREF2. This experiment evaluates A2C, KG-A2C-chained, KG-A2C-Explore, and an ablated version of KG-A2C-chained with no policy chaining. We choose A2C as it is a widely popular reinforcement learning method and also as it is the state-of-the-art on many text games. A2C's ability to do partial credit assignment allows it to scale up better than KG-A2C for larger action spaces than used in this work.\nWe evaluate the following strategies and their ablations:\n\nKG-A2C-chained A2C-chained\nKG-A2C-chained-ablate.  \nA2C-chained.  \nA2C-Explore.  \nA2C-Explore-ablate.\n\nFigure FIGREF19 shows that A2C-chained and KG-A2C-chained-ablate outperform the baseline A2C by a wide margin. KG-A2C-chained-ablate and KG-A2C-Explore surpass the bottleneck with a difference of over 100, whereas the A2C-Explore ablated method only gets to the bottleneck. The A2C-Explore-ablate agent uses the knowledge graph state representation as well. Figure FIGREF19.2 shows the performance of agents that utilize exploration methods with backtracking based on a patience setting, where the number of steps before the backtracking is triggered is dictated by this number. This setting is particularly suited to situations with high precision, where a large number of backtracking steps can lead to a near-optimal solution. On the other hand the KG-A2C and KG-A2C-Explore do better when we set a small patience setting. We thus see that while KG-A2C is much more sample efficient, it is not more efficient when it comes to backtracking. This can be explained by the fact that there is significant overlap in the sets of cell states that are explored after backtracking from a bottleneck, and so the backtracking step is more likely to find a locally optimal policy,",
    "eb2d5edcdfe18bd708348283f92a32294bb193a5": " Hyperparameters for both Go-Explore and KG-A2C are used in A2C-chained and the agents are also identical for A2C Explore and A2C.\nAppendix ::: Further Implement Details\nAs mentioned at the start of this work, we are developing a unified framework for tackling the challenges of partial observability, commonsense information, and large action spaces present in text-based games. Instead of using a set of specialized algorithms each built to tackle a challenge (e.g. A2C-chained for small combinatorial action spaces, Go Explore for large action spaces) we developed Jericho-Interact\u2014a game playing framework that can incorporate any set of specialized models (including A2C) we are experimenting with. The model architecture itself consists of first transforming the observation into a state using a language understanding system which will then be fed to a reinforcement learning policy network. The policy network is a 3-layer feed forward neural network with ReLU activation functions. The reward architecture is a single linear layer. The value network is a single linear layer with Tanh activation functions. We follow the standard setting of 10 times faster learning using exponential moving average updating. All models are implemented in PyTorch 1.5.0 and trained using a mixture of batch updates and experience replay using a batch size of 128. Each instance consists of 8 environments, each with its own random seed. The agent uses a fixed seed to generate its own game episodes over the course of 10-episode runs. Training episodes were carried out for 400k steps total with a patience of 1000 steps and a random starting point around episode 200.\nAppendix ::: OpenICE\n\nOpenICE is a semi-supervised entity discovery and tagging system that leverages a rich collection of domain-specific rules to extract triplets of the form $subject, relation, object$ from observations. OpenICE leverages simple rules as well as an ensemble of advanced machine learning models to extract this structured data as well as detect and classify entities using a rule-based approach BIBREF2, BIBREF5. OpenICE can extract information including $entity types$ such as $rock, stone, torch$, and $physical attributes$ such as $water, metal$ and $affordances$ such as $torch, wall, lamp$. In Figure FIGREF11 we show an example of the output of OpenIE for a state observation from Z",
    "88ab7811662157680144ed3fdd00939e36552672": " Note that we use the same cell step size for all our experiments (see Figure FIGREF1 for a visual example of different cell steps).\nFigure FIGREF15 and Figure FIGREF1 present examples of map structures, where the corresponding locations are labeled inside these figures.\nFigure FIGREF1: Example of textual observations generated by Zork at different steps of a game. Zork1 also has a limited range of words, with all nouns being properly nouns and pronouns being proper nouns to simplify the problem.\nAppendix ::: Knowledge\n\nKG-A2C is used to build a set of knowledge graph rules and is only applied to the game's textual observations BIBREF6\nAppendix ::: Additional Evaluation Results\nFigures FIGREF16, FIGREF17, & FIGREF18 show the learning curves for the first two steps of the four separate games used to generate the benchmarks and Figure FIGREF19 shows the learning curves for the first ten steps of all three games with the best policies from all the agent's approaches.\nWe find that the policy chaining method is effective at detecting bottleneck states to speed up exploration especially in the case of Zork1, which does not feature sparse rewards, unlike other games we considered for our evaluation. That is, the bottleneck is very high in this game. This bottleneck may be more generalizable than Zork1 where other games have higher bottleneck scores (e.g. Fig\n\n. FIGREF23: Examples of agent exploration in TextWorld.\nFigure FIGREF16: Exploration curves, average reward trajectory when taking the first step in a game.\nFigure FIGREF17: Exploration curves, average reward trajectory when taking the first five steps in a game.\nFigure FIGREF18: Exploration curves, average reward trajectory when taking the first ten steps in a game.\nAppendix ::: Additional Experiment Details\n\nWhen training the KG-A2C model, we use a base learning rate, \u03b1 = 0.001, and use a learning rate annealing method where the learning rate is multiplied by a factor of $0.95$ after every 10,000 episodes. We increase the temperature parameter, \u03b3 from T=0.01 to T=0.99 after every 25,000 episodes. The KG-A2C uses an initial value of the patience counter T = 25 and if the patience timer is exceeded, the agent assumes a bottleneck has been",
    "cb196725edc9cdb2c54b72364f3bbf7c76471490": "\nTABLE 4. Stats of Knowledge Base (KB).\nTABLE 5. Query Inference Strategies Formulated by LiLi.\nTABLE 6. Predictive Performances of LiLi and Baselines on WordNet.\nTABLE 7. Queries Answered by LiLi with Different Number of Clues Acquired from User.\nTABLE 8. F-one vs. w/o PTS vs. BG w/o PTS.\nReferences\n[1] M. B. P. C. M. Rauthe, C. M. Doherty, J. E. G. Conroy, R. M. K. S. Radovanovic, H. G. Jauhoux, B. I. D. Geman, and J. T. F. Stronge. \"Combining machine and human inference in knowledge graph completion.\" Machine Learning 106 (2016): 51-65.\n\n[2] A. Derycke, G. Lester, W. Tebald, H. N. Mwenda, M. Nahon, and N. Iyyer. \"Open-World Knowledge Base Completion with Closed-World Subsets.\" In ECAI2018, 2018, pp. 1275-1280.\n\n[3] V. Kumar, B. Sarkar, R. Hovy, and A. Yates. \"Learning from Examples with Open-World Knowledge Graphs.\" In WWW2014, 2014, pp. 2955-2966.\n\n[4] A. Yates, H. G. Jauhoux, D. Bansal, M. Bock, Y. Shu, V. Kumar, M. M. Dang, and J. G. Noyes. \"An open-world approach for knowledge base completion.\" In AAAI 2013 (2013): 661-668.\n\n[5] R. M. K. S. Radovanovic, H. G. Jauhoux, M. Bock, and Y. Shu. \"A simple open-world approach to zero-shot knowledge base completion.\" In ACL (2014).\n\n[6] G. Lester and G. M. Mina. \"Learning to link open-world triples.\" In ECAI, 2014, pp. 1177-1185.\n\n[7] A",
    "286078813136943dfafb5155ee15d2429e7601d9": "\nS. N. Jain is with Nanyang Technological University, Singapore.\nSriram Sankaranarayanan is with Cognitects LLC (India).\n\nJohannes Ritter is with Max Planck Institute for Informatics, Germany.\n\nAcknowledgments\n\nWe thank the anonymous reviewers and Area Chair for the ECAI 2017 Workshop on Machine Learning for Dialogue and Conversation for their valuable comments.\n\nNotes and Cautions\n\nREFERENCE 1: D. Turney. How many people speak English in the United States? A case study in building a large statistical language model. Speech & Language Technologies, 7:37\u201344, 1999.\n\nREFERENCE 2: Y. Chen, K. Bansal, R. Gopi Krishnan, Y. Wu, and C. Feng. Question answering using semantic matching and inference. In EACL, pp. 742\u2013746. ACL, 2010.\n\nREFERENCE 3: Y. Wu, L. S. Chodorowski, and L. Wang. Question Answering over an Open Domain Knowledge Base. In SIGKDD, pp. 598\u2013606. ACM, 2011.\n\nREFERENCE 4: D. Cohan and I. Titov. Chunk-based dialogues and dialog state tracking. In SIGdial, pp. 135\u2013142. ACM, 2012.\n\nREFERENCE 5: L. C. Dan, M. Goyal, E. Stent, G. S. Smyth, J. Crammer, and D. Jurafsky. Rethinking question answering using knowledge bases. In AAAI, 2013.\n\nREFERENCE 6: Y. Wu, Y. Huang, and H. Jiang. Neural chat: Conversational question answering over an open domain-specific knowledge base. In SIGKDD, pp. 741\u2013748. ACM, 2015.\n\nREFERENCE 7: D. M. Ranzato and A. Ghahraman. The compositional vector-space model. In NIPS, 2015.\n\nREFERENCE 8: J. Dong, X. He, S. G. Khaprajaya (editors). Proceedings of the first International Joint Conference on Computational Linguistics: Volume I: Speech and Natural Language Processing (IJC-",
    "8f16dc7d7be0d284069841e456ebb2c69575b32b": "\n\nBIBREF0\n\nB. Agarwal and E. Grau-Baker (1999), AIML, the Artificial Intelligence Markup Language, at http://www.cse.washington.edu/cogsci/aiml.\n\nBIBREF1\n\nH. Amini-Kiakhei, D. W. Kleinberg, and D. C. Smith (2009), Density-based rank metrics for evaluating open-domain question answering. In: Proceedings of the 27th Workshop on Natural Language Generation, Association for Computational Linguistics (ACL), 2.\n\nBIBREF2\n\nW. L. Backhouse, B. L. Lally, and J. O. Schuman (1999), Evaluating conversational systems. In: Proceedings of the Third European Conference on IR Applied to Language Resources, Association for Computational Linguistics (ACL), Association for Computational Linguistics, pp. 1\u20138.\n\nBIBREF3\n\nB. Agarwal, R. Zellers, J. Wiebe, W. A. Harman, and C. Kozlowski (2015), Building a large-scale dialog knowledge base. In: Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP), Association for Computational Linguistics (ACL), Association for Computational Linguistics, pp. 686\u2013696.\n\nBIBREF4\n\nQ. Zhang and K. Cho (2016), Neural response-generation systems for openended dialog. In: Proceedings of the International Joint Conference on Natural Language Processing, Association for Computational Linguistics (ACL), Association for Computational Linguistics, pp. 2141\u20132149.\n\nBIBREF5\n\nR. Lui, R. Nishio, and K. Watanabe (2017), Scalability of neural open-ended conversation models: A case study on knowledge-grounded large-scale dialog systems. In: Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (ACL), Association for Computational Linguistics, pp. 1079\u20131087.\n\nBIBREF6\n\nQ. Zhang, Z. Wang, C. J. Ely, and D. Chen (2018), A neural ranking approach for high-performance",
    "a7d020120a45c39bee624f65443e09b895c10533": " We thank Sourabh Gupta and Weicai Yan for their ideas that enabled us to improve LiLi with better guessing mechanism. We also thank the anonymous reviewers for providing valuable comments that helped improve the paper.\n\nReferences\n\nBIBREF0\n\nChaudhuri, N., etal. (2018). AIML, A General Markup Language for Creating Chatbots. Technical Report, AIES.\n\nBIBREF1\n\nSchank, R. (1975). Making Plans: The New Commonsense Reasoning. International Journal of Man-Machinery Studies, 1(1), 13\u201338.\n\nBIBREF2\n\nChaudhuri, N., etal. (2014). Why do people believe chatbots? Talking to and about chatbots over years. In Proceedings of the ACM INTERACT conference, 14\u201326. ACM.\n\nBIBREF3\n\nRojas, D. (1999). A Knowledge Base for an Informational Dialog System. AI Magazine, 20(4), 41\u201347.\n\nBIBREF4\n\nRojas, D., etal. (2015). Deep Reinforcement Learning Agents for Short-Term User-Intent Prediction, Conversational Question Answering and Task Prioritization. In Proceedings of the AAAI conference (2015 annual conference on artificial intelligence).\n\nBIBREF5\n\nTan, S., etal. (2016). Deep Question Answering with Incomplete Knowledge Bases: An Empirical Study of Open-Ended Question-Answering with Neural Networks. In Proceedings of SemEval-2016 (Demonstrative Speech and Multimodal Communication Workshop), page 9\u201314.\n\nBIBREF6\n\nTan, S., etal. (2017). Open-Ended Multi-Turn Dialogue Systems using Knowledge Bases with Compositional Vector-Based Embeddings of Entities, Relations and Spans. In Proceedings of the EMNLP conference.\n\nBIBREF7\n\nHermann, C., etal. (2015). The Chitchat Agent: Question-Answering and Story Generating Chatbots. In Proceedings of the EMNLP conference, page 1227\u20131236.\n\nBIBREF8\n\nSordoni, T., etal. (2016). A Large",
    "585626d18a20d304ae7df228c2128da542d248ff": " The authors express their grateful thanks to LiXin, Ting, Jiawen, Haomin, Wuxi, and Yuwen.\nFor references not found in the main text, we include the link to their citations in AAN.\nAbu-El-Hadi, Q et al. (2018) Extracting new facts from a knowledge base of millions. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 683\u2013692.\n\nAbu-El-Hadi, Q et al. (2017) Towards open-world question answering: Incorporating large-scale, real-time, and online knowledge sources. In European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases, Proceedings of KDD (ECML), 11\u201315.\n\nBaldock, R et al. (2016) Conceptnet: A database of common-sense knowledge. In International AAAI Conference on Web and Social Media Mining, Proceedings of the Conference Companion (ICWSM), 857\u2013864.\n\nBaroni, G, Caravana, G, and Giordano, C (2019) Modeling lifelong interactive learning and reasoning in a large-scale question answering system. In AAAI, 1\u20136.\n\nBIBREF01\n\nZhang, H et al. (2015) AIML: Artificial intelligent markup language for AIs and humans. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 1087\u20131094.\n\nBIBREF02\n\nLee, Y, Rambow, C, and Heindel, J (2015) Ranking and scoring to help building QAnDAs using knowledge bases. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 1585\u20131594.\n\nBIBREF03\n\nAbu-El-Hadi, Q et al. (2015) Towards open-world question answering. In Proceedings of the 21st ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2317\u20132326.\n\nBIBREF04\n\nDas, V and Zhang, H (2016) End-to-end dialogue agents: Reinforcement learning approaches for non-goal-oriented dialog. In Conference on Empirical Methods",
    "bfc2dc913e7b78f3bd45e5449d71383d0aa4a890": " and in part by the Office of Naval Research (ONR) and the US Air Force Research Laboratory under award number FA8450-15-1-3001.\n\nWe thank the editor, the anonymous reviewers, and the participants in Affective Turing workshop for their thoughtful feedback. We thank Zheng Wang, Yihong Gao and Ruo Zhang for their support.\nConflict of Interest: The authors declare that they have no conflict of interest.\nAuthors' Contributions: We equalize the contribution of authors equally.\n\nAbdul, Y., C. Chellandai, H. Giles, F. Ding, T. J. Darrell, H. Li, M. H. Levy, S. Choudhury, S. Agarwal, E. Darrell, F. J. Koehler, S. Kitsuregawa, H. Lee and S. Das,\nA. Amo et al.,\n\"An Overview of Dialogue Systems Technologies for the Year 2000,\"\nin Workshop on Applications of Dialog Technologies to Multimodal User Interfaces, Proceedings of the Tenth Annual SIGCHI Conference on Human Factors in Computing Systems, Vancouver, Canada, 2002, pp. 101\u2013113.\n\nAnderson, M., and R. C. Berat,\n\"The AIML Vocabulary: Introductory Documentation,\"\nin AIML, http://world.aiml.org/ai.html.\n\nBabu, B. K., V. Dvivedi, S. H. L. Kulkarni and R. C. Berat,\n\"A framework and an analysis of different methods for relation path extraction in knowledge base completion,\"\nin Proceedings of the Fourth International Joint Conference on Artificial Intelligence and Natural Language, Acapulco, Mexico, 2010, pp. 769\u2013778.\n\nBagga, O., and D. D. Tsatsaronis,\n\"Incentive based dialogue generation: A machine learning approach,\"\nin AI for Humanity Journal: 3rd World Conference, AAAI Press, 2017.\n\nBapna, C. K., C. K. Bagga, D. Sharma and R. C. S. J.\n\nBerat,\n\"Relation extraction for knowledge base completion: The LORE framework.\"\nin Proceedings of the 10",
    "6aa2a1e2e3666f2b2a1f282d4cbdd1ca325eb9de": "\n\nDiscussion\nCross-Domain Sentiment Classification\n\nDeep Learning for Natural Language Processing\n\nDeep Learning for Semantic Parsing and Text Summarization\n\nDeep Learning for Emotion and Sentiment Analysis\n\nDeep Learning for Knowledge Base Completion and Question Answering\n\nDeep Learning for Named Entity Recognition and Relation Extraction\n\nDeep Learning for Semantic Textual Entailment\n\nDeep Learning for Question Answering\n\nDeep Learning for Reading Comprehension\n\nDeep Learning for Paraphrase Identification and Question Paraphrase Generation\n\nDeep Learning for Topic, Sentence and Document Similarity, and Text Ranking\n\nDeep Learning for Summarization\n\nDeep Learning for Text Generation and Summarization\n\nDeep Learning for Sentiment Analysis\n\nDeep Learning for NLP for Medical Professionals\n\nDeep Learning for Information Retrieval\n\nDeep Learning for NLP for Non Professionals\n\nDeep Learning for NLP-Oriented Keyword Extraction\n\nDeep Learning for NLP-Oriented Sentiment Analysis\n\nDeep Learning for Speech Recognition\n\nDeep Learning for Speech Synthesis, Translation, and Voice Conversion\n\nDeep Learning for NLP-Oriented Grammatical Error Correction\n\nDeep Learning for Speaker Verification and Gender Recognition\n\nDeep Learning for Automatic Video Summarization\n\nDeep Learning for Information Retrieval\n\nDeep Learning for Question Answering and Spoken Dialogue Retrieval\n\nDeep Learning for NLP-Oriented Relation Extraction\n\nDeep Learning for Speech and Speaker Tracking\n\nDeep Learning for Video Text Summarization\n\nDeep Learning for Multilingual and Multimodal NLP\n\nDeep Learning for Non-parallel Document Translation\n\nDeep Learning for Sentence Parsing\n\nDeep Learning for Textual Entailment\n\nDeep Learning for Machine Translation\n\nDeep Learning for Automatic Multilingual Dependency Tree Construction\n\nDeep Learning for Textual Entailment Using Neural Networks\n \nBooks\n\nBy Stephen White\n\nThe Ghosts of Belfast\n\nThe Killing Wind\n\nThe White Hotel\n\nMURDER IN BATTALION STREET\n\nPublished by the Penguin Group\n\nPenguin Group (USA) LLC\n\n375 Hudson Street\n\nNew York, New York 10014\n\nUSA \u2022 Canada \u2022 UK \u2022 Ireland",
    "b46c0015a122ee5fb95c2a45691cb97f80de1bb6": "\nRelated Works\nIn semi-supervised learning, recent works BIBREF26, BIBREF29, BIBREF30, BIBREF36 try to alleviate the class imbalance problem by weighting the target loss with sample number when incorporating unlabeled data. However, when compared to our experimental settings, the label distribution in these methods are too unbalanced such that the resulting accuracies are lower. For the cross-domain sentiment classification problem, some methods BIBREF4, BIBREF5, BIBREF21 exploit auxiliary tasks using the unlabeled target data (see Appendix SECREF9 for the details). Those methods are not applicable in our setting since we do not know the labels in advance.\nEntropy Minimization and Self-ensemble Bootstrapping Full Results\nIn this section, we show full experimental results of entropy minimization and self-ensemble bootstrapping. For clarity, the full results on the three small-scale datasets are presented, while we only present summary results on the large-scale benchmark above. On the small-scale datasets, we use the development set from each domain as the unlabeled set, and then train the whole framework without the bootstrapping for 1/2, 3/4, 5/6, 10/10 epochs respectively. We choose the network with the smallest average loss on this evaluation set and then save this network for evaluation.\nFull Results for Entropy Minimization & Self-ensemble Bootstrapping\n\nTable TABREF34 and TABREF35 illustrate the results of neural network (CNN) filter analysis for learning with entropy minimization and with self-ensemble bootstrapping respectively on task E INLINEFORM0 BT under setting 1. In Table TABREF41 and TABREF42 in the following pages we present the results on task E INLINEFORM0 E BT under setting 2 and set 2 on task E INLINEFORM0 Y BT under setting 3. In all experiments, we choose 1/10 to denote a network without utilizing unlabeled data during training, and we compare this with networks 1/7, 2/5, 3/5 (from the network with 1/5, 2/5, 3/5 epochs only). We can observe that when semi-supervised learning is performed with proper design strategies such as entropy minimization and self-ensemble bootstrapping on both domains, CNN filter analysis on all tasks demonstrates that the learned feature representations are useful to refine",
    "5b7a4994bfdbf8882f391adf1cd2218dbc2255a0": " Through CNN filter analysis, we further confirm that the proposed framework can capture diverse target-specific sentiment expressions. We suspect that the reason is domain-specific and target-specific sentiment-related filter weights INLINEFORM0 of DAS are set to be quite different on the two domains, thus effectively distinguishing more target specific expressions. In some cases, these weights even take values at 0.\n\nReference\n\n[1] M. Eslami, A. Li, F. Xu, K. Huang. Semi-supervised semantic similarity discovery using soft pseudo-labels and semi-random forest algorithm.\n\n[2] R. Heilman, R. Kovaleva, A. Li, Y. Jiang, X.-Y. Zhou. Attention-based semi-supervised document representation learning using denoising autoencoders.\n\n[3] Q. Liu, X. Lin, Y. Jiang, B. Song, Y. Wei, C. Ji. Deep neural semantic representations for image captioning with multi-task clustering.\n\n[4] Y. Jiang, X. Lin, Y. Li, Y. Wei, and B. Song. Zero-shot cross-domain image captioning via deep and soft domain adaptation.\n\n[5] N. Lai, X. Lin, Y. Meng, Y. Wei, Y. Zhao, B. Song, B. Yuan, Y. Xiang. Domain-aware cross-view document retrieval via zero-shot attentional clustering.\n\n[6] Q. Liu, X. Lin, Y. Meng, B. Yuan. Zero-shot domain adaptation on document retrieval with knowledge-constrained cross-view clustering.\n\n[7] Q. Zhu, X. Yan, Z. Xie, Z. X. Zhang, D. Yang, Y. Jiang, X.-Y. Zhou. Learning robust, domain-adaptive image captioning from scratch.\n\n[8] C.-C. Cheng, C.-R. K. Chu, S. C. Hu, L. Lin, Y.-D. X. Li. Domain-neutral feature alignment via adversarial training for cross-domain learning.\n\n[9] B. Huang, Y. Feng, N. Li, S. Xie. Cross-domain sentiment classification via multi-task neural networks with entropy maximization.\n\n[10] N. Li",
    "9176d2ba1c638cdec334971c4c7f1bb959495a8e": " We also observe that DAS performs much better in learning target-specific sentiment expressions like those in the middle row of Table TABREF39 and the middle row of Table TABREF40.\nAcknowledgments\n\nThis research is supported in part by the National Science Foundation of the United States under Grant number 1636872. Author thanks Professor Xiang Ren for discussions. Author acknowledges financial support from Singapore National Research Foundation under the NRF Program (Grant Number: Y4D7Y30040) and NRF Strategic Research (Grant Number: S-AMF5-0056).\n\n\nReferences\n[1] B. Blitzer, M. Zens, C. D. Miller, A. Lapata, C. J. Culotta, Y. Zhang, and M. W. Cohen. 2005. Learning to compare for sentiment analysis. In Proceedings of the 2005 Conference on Empirical Methods in Natural Language Processing, pages 960\u2013968. Association for Computational Linguistics.\n\n[2] S. Chang, J. Gimpel, and T. Hofmann. 2012. Sentiment analysis with hybrid feature representations. In Ijcs conference, volume, 2, pages 2169\u20132180, 2011. ACM.\n\n[3] B. Chen, Y. Jiang, X. Liu, and J. Yuan. 2017. Learning joint embedded word representations for sentiment analysis. In Proceedings of the 2017 Conference on Neural Information Processing Systems, pages 3132\u20133140.\n\n[4] K. Chen, M. Zhang, T. Q. Liu, M. Lu, A. B. McAuley, and Z. Wu. 2016. Transferable image sentiment analysis with domain adversarial training. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 1065\u20131075. Association for Computational Linguistics.\n\n[5] K. Chen, M. Zhang, T. Q. Liu, M. Lu, A. B. McAuley, and Z. Wu. 2016. Adversarial training for effective cross-domain image sentiment analysis. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 1048\u20131059. Association for Computational Linguistics.\n\n[6] J-C. Chen, D. C. Jiang, Y. B. Wu, Q. Liu, C. Zhao, and M",
    "0ba3ea93eef5660a79ea3c26c6a270eac32dfa4c": "\n\nBIBREF0\n\nAnand N. Ramamritham, Shimon Whiteson. Question answering on open domains: from research to applications. ACM Transactions on Information Systems, 30(3):390\u2013428, 2012.\n\nBIBREF1\n\nMarcus K. S. Lee, Susan F. Martsch, Najko Gr\u00e9goire. Building SemCor by human taggers. Department of Computer Science, Princeton University, 2008.\n\nBIBREF2\n\nPeter W. Jackson, Susan F. Martsch, Yoon Kim. Building corpora using Wikipedia. In Proceedings of the 18th text workshop and conference of the North American chapter of the Association for Computational Linguistics. University of Chicago, 2004.\n\nBIBREF3\n\nSebasti\u00e1n Fern\u00e1ndez-Lleo, Anand N. Ramamritham, Michael M. Roy, Edward L. Hudson III. Evaluation of automatically generated questions. In Proceedings of the Fifth Conference on Semantic Evaluations (Senseval-5). Association for Computational Linguistics, 2005.\n\nBIBREF4\n\nMark Liberman, Steven C. Shearer. Word sense disambiguation: a survey of recent results. ACM Transactions on Information Systems, 21(2:133\u2013167, 2003.\n\nBIBREF5\n\nMark Liberman, Steven C. Shearer. Unsupervised Monosemistic Word Sense Disambiguation using Supervised Constraints. In Proceedings of the Conference on Empirical Methods in Natural Language Processing. Ann Arbor, Michigan, United States of America, 2009.\n\nBIBREF6\n\nMichael M. Roy, Anand N. Ramamritham. Senseval-5 Results. Computational Linguistics, 34(4):643\u2013660, 2007.\n\nBIBREF7\n\nRada Mihalcea, Chris Dale: Evaluating a Minimally Supervised Word Sense Disambi-gation System. In Proceedings of the 21st International Conference on Computational Linguistics: Workshop on the Evaluation of Disambiguation and Coreference. Sydney, Australia. 2007.\n\nBIBREF8\n\nDavid B. Leacock, David C. Weir. Word sense disambiguation without lexical resources. In Proceedings of the Conference on Empirical Methods in Natural Language Processing",
    "5e324846a99a5573cd2e843d1657e87f4eb22fa6": " The author would also like to thank Anna Bury-F\u00f6hrenweisser, Robert Czupry, Marcin D\u0105balt, J\u00fcrgen K\u00f6hler, Marek Lomicki and Bartosz Nieto for discussing the results and providing feedback. Further work on this topic would not be possible without contributions of previous researchers in the field, especially Michael Collins and Thomas Hofve, whose works were surveyed in Section 2 and BIBREF9 and Section 4, respectively.\nAbout the author\nGrzegorz Ma\u015blura (ms@ic.pws.edu.pl ) graduated from Wroc\u0142aw University in Computer Science and spent last three years carrying out his PhD on text mining in Polish. He is currently employed by National Center for Science and Technology, working as a researcher on the NEKST project.\n\n\n\nText copyright \u00a9 2018 by Rebecca Barrow\n\nCover and interior art copyright \u00a9 2018 by Rebecca Gratz\n\nAll rights reserved. Published by Disney \u2022 Hyperion, an imprint of Disney Book Group. No part of this book may be reproduced or transmitted in any form or by any means, electronic or mechanical, including photocopying, recording, or by any information storage and retrieval system, without written permission from the publisher.\n\nISBN 978-1-368-00165-5\n\nVisit us at SkyPonyPress.com\n\nAuthors.SimonandSchuster.com/Rebecca-Barrow\n\n## CONTENTS\n\n  1. Title Page\n  2. Dedication\n  3. Chapter 1: A Small House\n  4. Chapter 2: The Tunnel\n  5. Chapter 3: The Firefly\n  6. Chapter 4: Through the Window\n  7. Chapter 5: A New Home\n  8. Chapter 6: The Wormhole\n  9. Chapter 7: Clan and Family\n  10. Chapter 8: A New Home\n  11. Chapter 9: A New Friend\n  12. Chapter 10: A Trap\n  13. Chapter 11: Hobb\n  14. Chapter 12: A New Home\n  15. Chapter 13: The Scorpion\n  16. Chapter 14: The Snake\n  17. Chapter 15: The Sun\n  18. Epilogue\n  19. Acknowledgments\n  20. About the Author\n  21. Connect",
    "2ccc26e11df4eb26fcccdd1f446dc749aff5d572": "\n\n\nCopyright \u00a9 2015 by Robert Low\n\nAll rights reserved.  \nFor information about permission to reproduce selections from  \nthis book, write to trade.permissions@hmhco.com or to  \nPermissions, Houghton Mifflin Harcourt Publishing Company,  \n3 Park Avenue, 19th Floor, New York, New York 10016.\n\nwww.hmhco.com\n\nThe Library of Congress has cataloged the print edition  \nas follows:\n\nLow, Robert.\n\nThe man from Prague / Robert Low.\n\np. cm.\n\nSummary: \"It starts like any other morning at the Prague headquarters of the  \nCzechoslovak branch of Interpol until Agent Michael  \nPrasek is stabbed in the shoulder by an unknown assailant,  \nthen his partner, Karin Brandlova, a woman with secrets of her  \nown, uncovers a secret of a man's...\"\u2014Provided by publisher.\n\n1. Espionage\u2014Fiction. 2. Interpol (International  \nPolice)\u2014Fiction. 3. Prague (Czech Republic)\u2014Fiction.  \n4. Mystery fiction. [1. Spy Stories] I. Title.  \nPS3562.R59 M'.6\u2014dc23\n\n2014005343\n\nISBN: 978-0-544-84482-2\n\n  * Cover design by Joe Zappala\n  * Interior design by Amy Horwich\n  * Front-of-jacket image \u00a9 Michael P. Puschel Photography/Alamy\n  * Back-of-jacket images \u00a9 Shutterstock.com / Alamy Stock\n\neISBN 978-1-328-96613-9  \nv2.0917\n_For my wife_,\n\n_Dana P. Hoshfeld,  \nwife, parent, and editor\u2014  \nthanks for everything_.\n**CONTENTS**\n\nTHE MAN FROM PRAGUE\n\n**PROVIDING FOR THE FUTURE**\n\n_I. Monday, March 2, 1970_\n\n_II. Tuesday, April 21, 1970_\n\n_III. Monday, July 20, 1970_\n\n_IV. Sunday, August 6, 1970_\n\n_V. Thursday, August 21, 1970_\n\n_VI",
    "f318a2851d7061f05a5b32b94251f943480fbd15": "\n\nAcknowledgments\nWe would like to thank Michael Kochenderfer for his help and support in this work and also would like to thank our dissertation director Jeff Kling. This work would not have been possible without them.\nRecommended Citation\nBozgur, N. (2019). Using NLP to Analyze and Compare Extremist Materials Addressed to Women. SEJ-2020-02, Electronic Journal of Security & Intelligence. Available at http://epubs.surrey.ac.uk/97898868838/28\n\nReferences\n\nAl-Tamimi, M. (2017). \"The Emergence and Evolution of Radicalization in the Digital Age: ISIS's Digital Strategy,\" International Conference on Radicalization and Violent Extremism (RVX 2017), University of Oslo and the Norwegian Security and Intelligence Service (NSS).\n\nBozgur, N., Ercel, M., and Kochenderfer, M. (2018). \"Emotion Detection in ISIS Propaganda Materials Addressed to Women.\" International Conf. on Knowledge Engineering and Management in the Age of Artificial Intelligence (EUSAI 2019), European University Association, Luxembourg.\n\nDabiq (2017). \"Dabiq Magazine, Issue Fourteen: Women-Related Articles.\" Dabiq.\n\nGrimm, D., Ercel, M. and Kochenderfer, M. (2018). \"A Review of Research on ISIS Propaganda.\" International Conf. on Intelligent Text Processing and Web Mining (ICITPW 2019), University of W\u00fcrzburg, W\u00fcrzburg, Germany.\n\nLahav, G., Klinger, M., and Matuszak, T. (2018). \"Beyond the Radical and the Fanatic: Motivation and Rationales for Support or Opposition to ISIS.\" Political Behavior, Vol. 40, Iss. 3, p. 421-446.\n\nO'Callaghan, F., Ding, Y., McInerney, C. and Zingales, H. (2018). \"A Comparison of Latent Semantic Analysis and Non-negative Matrix Factorization for Topic Models in ISIS Online Magazines. \" arXiv preprint ArXiv:1811.09200.\n\nRumiyah (2017). \"Rumiyah Issue Seventeen: Women",
    "6bbbb9933aab97ce2342200447c6322527427061": "\n\nAcknowledgments\nI am deeply indebted to Anup Patnaik, Michael Gogusheva, Thomas S. Wong, and Andrew Nguyen for their guidance throughout this research. Lastly, I thank the US government for their support during my research.\nREFERENCES\n[1]\"#ISIS\" redirects here. For full coverage, see Islamic State of Iraq and Syria.]\n\nBIBREF\"In a tweet posted on September 13, 2014, Abu Musab Al-Barnawi\" redirects here. For full coverage, see Al-Barnawi (ISIS militant] BIBREF\"In a tweet posted on September 20, 2014, Al-Barnawi\" redirects here. For full coverage, see Al-Barnawi (ISIS militant] BIBREF\"In a tweet posted on October 26, 2014, Al-Barnawi\" redirects here. For full coverage, see Al-Barnawi (ISIS militant] BIBREF\"In a tweet posted on November 16, 2014, Al-Barnawi\" redirects here. For full coverage, see Al-Barnawi (ISIS militant] BIBREF\"In a tweet posted on November 23, 2014, Al-Barnawi\" redirects here. For full coverage, see Al-Barnawi (ISIS militant] BIBREF\"In a tweet posted on December 5, 2014, Al-Barnawi\" redirects here. For full coverage, see Al-Barnawi (ISIS militant] BIBREF\"In a tweet posted on January 12, 2015, Al-Barnawi\" redirects here. For full coverage, see Al-Barnawi (ISIS militant] BIBREF\"In a tweet posted on January 13, 2015, Al-Barnawi\" redirects here. For full coverage, see Al-Barnawi (ISIS militant] BIBREF\"In a tweet posted on January 27, 2015, Al-Barnawi\" redirects here. For full coverage, see Al-Barnawi (ISIS militant] BIBREF\"In a tweet posted on February 3, 2015, Al-Barnawi\" redirects here. For full coverage, see Al-Barnawi (ISIS militant] BIBREF\"In a tweet posted on February 3, 2015, Al-Barnawi\" redirects here. For full coverage, see Al-Barnawi (ISIS militant] BIBREF\"In a tweet posted",
    "2007bfb8f66e88a235c3a8d8c0a3b3dd88734706": "\n\nAcknowledgments\nThe authors would like to thank Dr. Zareen Malik for her valuable thoughts and comments on this paper. We want to thank our colleagues Dr. Elyas Nawab and Dr. Oded Maler, and especially Dr. Alasdair Al-Sarawi, for sharing their thoughts with us on this project. This paper is funded in part by a United States Army Research Laboratory grant through the Army Research Office.\n\nReferences\n\n[1] \"Abolishing Women's Rights, ISIS Threatens Women to Join Caliphate.\"\n\n<http://www.bbc.com/news/world-middle-east-17683055>\n\n[2] Al-Tamimi, Khalid. \"ISIS and the Social Media Imagery Campaign: Why They Tweet.\"\n\n<http://theconversation.com/isis-and-the-social-media-imagery-campaign-why-they-tweet-47891>\n\n[3] Al-Tamimi, Khalid, and Mervin Gainey. \"Social Media and Online Networks: Shaping the Digital Identity of IS, or \"Islamic State of Iraq and Syria\" (ISIS).\"\n\n<http://cogentoa.com/media/index.html>\n\n[4] Broughton, L. B., and K. A. Broughton. \"ISIS Social Media and Counter Extremism in the U.S.: New Platforms, New Strategies.\"\n\n<http://www.isaf.af.mil/sites/default/files/ISAF_RCO%20Research%20Note%201%20-%20Social%20Media%20&%20Counter-Extremism%20in%20the%20U.S_%20508.7%20Final.pdf>\n\n[5] Ingram, William, and K. L. Wignell. \"ISIS Propagandas: The Concealer of Evil.\"\n\n<https://www.researchgate.net/publication/319067028_ISIS_Propagandas_The_concealer_of_evil>\n\n[6] McElroy, Christopher. \"The Effect of ISIS Propaganda on European Women: A Counter Terrorism Perspective.\"",
    "d859cc37799a508bbbe4270ed291ca6394afce2c": "\n\nREFERENCE\n\nAl-Bayati, Khalid H. and Peter C. Vermeulen, editors. (2017), Counter Terrorism in the Muslim World, Springer, ch. 4, pp. 83-123.\n\nAl-Tamimi, Yazan. (2018), Identifying ISIS Online Support and Opposition on Arabic Social Media.\n\nAl-Tamimi, Yazan and Thomas F. Winter, editors. (2019). Extremist Propaganda Techniques in the War Against ISIS, Springer.\n\nAsghar, Samia I. and Fidel DeAndrade, editors. (2018), Cyber-Physical Technologies and the Internet of Things for Security and Defense, Springer.\n\nBanks, L.J. (2019), Social and Technical Perspectives on Emotional Social-Media Terrorism, Springer, ch. 6, pp. 127-150.\n\nBing, Yan et al., Influence of Propaganda and Violence against Women in the English-Language Online Magazines Produced by the Islamic State, Volume 15. Springer.\n\nBing, Yan, et al. (2018), Influence of Propaganda and Violence against Women in the English-Language Online Magazines Produced by the Islamic State, Volume 13, Springer.\n\nBIS (2018), Islamic State Recruitment, Retrieved from https://www.bis.doc/islamic-state-recruitment-tactics-and-messages/.\n\nBoone, Brendan. (2019), A Comparative Analysis of the Propaganda and Messages of ISIS Compared to Al Qaeda.\n\nBoutique, Herv\u00e9, H\u00e9l\u00e8ne Ntambue, and Aurelie Delon, editors. (2015), New Tactics in Cyberwarfare Defence, Springer.\n\nBonn et al. (2018), The Extremist Use of Social Media: ISIS, Al Qaeda and Al Nour, Springer, ch. 7, pp. 167-195.\n\nBoutique, Herv\u00e9 and Aurelie Delon, editors. (2017), Al Qaeda 2.0: A Sociological and Psychological Analysis of the Rise of a New Generation of Militant Islamists, Springer.\n\nBoutique, Herv\u00e9, et al. (2018), Al Qaeda's Response after 9/11:",
    "50e80cfa84200717921840fddcf3b051a9216ad8": "\n\nReferences\n\n[1] Flick, K.G. and D.R. Foss, 2015. Accuracy of computational linguistic models. J. Philos. Comput. 57, pp. 65\u201388.\n\n[2] Devlin, J., T. Khosla, M. Popat, and R. Zellers, 2018. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In Thirty-fourth Conference on Computational Natural Language Learning (COLING), pp. 4114\u20134124.\n\n [3] Cho, K., D. Bahdanau, and K. Kushman, 2014. On Learning Linguistically-aware Semantic Word Representations. In Advances in Neural Information Processing Systems, pp. 597\u2013604. https://www.aclweb.org/anthology/N14-1406\n\n[4] Gormati, U. and V. Popescu, 2021. Visual question answering is hard. In Proceedings of the 2021 Conference on Fairness, Accountability and Transparency (FAT*2021).\n\n[5] Eisner, A., L. Kov\u00e1cs, S. Kott, and F. Poller, 2021. Metrics and training objectives for assessing linguistic skills. Workshop at ACL 2021.\n\n[6] Lavie, A., L. Vanmiert, G. Shabram, and U. Gormati, 2018. BLEU: a method for automatic evaluation of machine translation. In Empirical Methods in Natural Language Processing, pp. 17\u201326.\n\n [7] Denkowski, B. and A. Gey, 2017. METEOR: A Metric for Machine Translation Evaluation. In Seventeenth Australasian Language Technology Workshop (ALT), pp. 55\u201359.\n\n[8] Lin, F., A. Oflazer, A. Gey, and H. Rosner, 2004. Automatic evaluation of sentence equivalence: The ROUGE project. In Proceedings of the Thirty-eighth Annual Meeting of the Association for Computational Linguistics (ACL-04), pp. 213\u2013220.\n\n[9] Baroni, M., P. Bonastelli, P. Vitulo, and M. Fogli, 2010. CIDEr: A Method for Automatic Evaluation of Machine Summarization on a",
    "b1bc9ae9d40e7065343c12f860a461c7c730a612": "\n\nReferences\n\n[BIBREF0BIBREF31]\n\nDevlin, J., Chang, M., Lee, B., Dahl, G. E., Globowshenko, M., Phillips, A., Zhegaov, V., Liang, L-L., and Hieber, J.\n\nDeep generative models for high-level visual description.\n\nCoRRabs/1806.0743\n\n[BIBREF0.1]\n\nShow & Tell.\n\nhttp://www.cs.cmu.edu/~joshuaco/projects/showandtell/\n\n[BIBREF0.2]\n\nShow & Tell: Weakly Supervised Image Captioning with Deep\n\nGenerative Models.\n\nhttps://sites.google.com/view/show_tell_weakly_supervised/\n\n[BIBREF1BIBREF32]\n\nZhang, S., Yin, C.-C., Zhai, Q., Zhang, S., Gholami, A., and Yoo, J.\n\nLearning Rich Cross-Modal Representations with Local\n\nReceptive Convolutional Networks for Image Captioning.\n\nNeurIPS 2020, 2019.\n\n[BIBREF1.2]\n\nLanguage modeling with visual context via local receptive\n\nneural networks.\n\nhttp://www.cs.cmu.edu/~sxyin/papers/NIPS2019_Show_&_Tell.pdf\n\n[BIBREF1.2]\n\nZhou, B., Zhang, Q., Yin, C.-C., Zhai, Q., Zhang, S., Gholami, A., and Yoo, J.\n\nMultimodal reasoning for image captioning via\n\nvisual context.\n\nhttps://arxiv.org/abs/2004.08051\n\n[BIBREF2BIBREF33]\n\nChen, Y., Yin, C.-C., and Zhai, Q.\n\nUsing Cross-Modal Contrastive Learning as a Prior\n\nfor Image Captioning.\n\nArXiv :2003.09365\n\n[BIBREF3BIBREF34]\n\nYin, C.-C. and Zhai, Q.\n\nJoint Visual and Semantic Learning for Vision-and\n",
    "63a1cbe66fd58ff0ead895a8bac1198c38c008aa": " The EPSRC Centre for Doctoral Training in Data Science is supported by Industrial Associates: Cray Supercomputing CCE, Microsoft Research, Fujitsu Laboratories, and Intel Labs. We are grateful for the computing resources provided by Amazon Web Service ECR.\nNotes\nThe work described in this paper is licensed under a Creative Commons Attribution 4.0 International License.\nAcknowledgments\n: we thank all the ShapeWorld authors. In particular, Emanuele D'Andrea, Joo Hyun Park, Erick Chang, Rui Peng Kuei and Piyush Goyal. Many thanks to Christopher Tomlin and Suresh Kannan for developing and maintaining ShapeWorld. We thank the anonymous review team for their feedback.\n\nReferences\n\n[BIBREF1] D'Andrea, Emanuele and others. Show&Tell: An end-to-end solution for the challenging task of image captioning. In: Proceedings of the 28th Conference on Computational Natural Language Learning, pages.\n\n[BIBREF10] Lin, Sisi and others. SPICE: A new scoring metric for image captions. In: Proceedings of the 3rd Workshop on Image Processing and Cognitive Neuroscience, pages.\n\n[BIBREF12] Johnson, Christopher and others. On the difficulty of automatic evaluation for image and text generation. In: Proceedings of the 29th Conference on Computational Natural Language Learning, pages.\n\n[BIBREF13] Kocmi, Istvan and others. BLEU Is Not Enough!: Evaluating Image Descriptions beyond BLEU. In: Proceedings of the 30th Conference on Computational Natural Language Learning.\n\n[BIBREF16] Johnson, Christopher, Chien-Yi Huang, and others. Automatic Metrics for Image and Multimodal Descriptions. In: Proceedings of the 31st Conference on Computational Natural Language Learning, pages.\n\n[BIBREF19] Devlin, Joseph, Mark Schmidt, Kristina Toutanova, and others. A simple and uniform approach for automatic evaluation of image captioning. In: Proceedings of the 34th Conference on Computational Natural Language Learning, pages.\n\n[BIBREF20] van Miltenburg, Jelle and others. Visual description: Exploration and assessment of diversity in image captioning. In: Proceedings of the 33rd Conference on Computational",
    "509af1f11bd6f3db59284258e18fdfebe86cae47": "\nReferences\n\nBIBREF0\n\n[\n\nhttps://www.aclweb.org/anthology/papers/K14-2041.pdf\n\n]\n\n[\n\nhttps://papers.nips.cc/paper/7993.pdf\n\n]\n\nBIBREF1\n\n[\n\nKendall Ely et al.\n\n](http://www.cs.rochester.edu/~changizi/cs/papers/Kendall:2017:IJCAI17.pdf)\n\n[https://www.aclweb.org/anthology/papers/K17-1442.pdf\n\n]\n\nBIBREF2\n\n[\n\n[\n](https://journals.sagepub.com/doi/10.1177/2372965518751443)\n\n[\n](https://www.aclweb.org/anthology/papers/K18-2275.pdf)\n\n]\n\nBIBREF3\n\n[\n\nZamperini et al.\n](https://www.aclweb.org/anthology/papers/K18-2339.pdf)\n\n]\n\nBIBREF4\n\n[\n\nPrajwal et al.\n](https://www.aclweb.org/anthology/papers/K19-1520.pdf)\n\n[\n\n](http://proceedings.mlr.press/v103/lapteva19a/lapteva19a.pdf\n\n]\n\nBIBREF5\n\n[\n](https://www.aclweb.org/anthology/papers/K17-1420.pdf)\n\n[\n](http://cn.nlplab.csai.csl.sduke.edu/papers/Lapteva:2019/lapteva-etal-2019-first)\n\n]\n\nBIBREF6\n\n[\n\nPapineni et al.\n\n](https://www.aclweb.org/anthology/papers/B01-3001.pdf\n\n]\n\nBIBREF7\n\n[\n\n](https://www.aclweb.org/anthology/papers/B04-2205.pdf\n\n]\n\nBIBREF8\n\n[\n",
    "23e16c1173b7def2c5cb56053b57047c9971e3bb": "\n\nREFEREF\n\n[1] J. Eisner. A semantic analysis of word segmentation. In Proceedings of the 23rd International Conference on Computational Linguistics (COLING2002), pp. 15\u201321, 2002.\n\n[2] J. Eisner, T. Mihalcea, and J. Zock. Neural machine translation by jointly learning to align, translate, and segment words. In Thirty-first Annual Conference of the Association for Computational Linguistics, 2008.\n\n[3] L. J. Feng, C. Dredze, and J. He. A unified architecture for character, word, and phrase segmentation. In Thirty-Fourth Annual Conference of the Association for Computational Linguistics (ACL), 2011.\n\n[4] T. Gu, S. Liu, Y. Zhang, and Y. Zhu. Unsupervised training of character-level neural network for Chinese word segmentation. In Thirty-Fourth Annual Conference of the Association for Computational Linguistics, 2011.\n\n[5] L. He. An end-to-end deep neural network architecture for named entity recognition in chinese. In Thirty-First Annual Conference of the Association for Computational Linguistics, 2013.\n\n[6] T. Huck. Unsupervised learning of character-based models for Chinese word segmentation. In Thirteenth International Conference on Computational Linguistics (ICCL'15), 2015.\n\n[7] L. He, T. Zhai, Y. Liu, S. Jiang, and J. Huang. Chinese characters dependency parsing using dependency language models. In Thirty-Seventh Annual Conference of the Association for Computational Linguistics (ACL), 2014.\n\n[8] Q. Huang, J. Huang, and A. W. Lam. Towards end-to-end semantic parsing of Chinese. In Thirty-Fourth Annual Conference of the Association for Computational Linguistics (ACL), 2012.\n\n[9] I. Jia, Y. Zhang, X. Liu, and X. Dong. Learning to segment words in a joint sequence-word framework by character-level convolutional recurrent neural network. In Thirty-Fourth Annual Conference of the Association for Computational Linguistics (ACL), 2013.\n\n[10] S. Ji, T. Huck, Q. Liu, S.",
    "d78f7f84a76a07b777d4092cb58161528ca3803c": " This research was further supported by U.S. National Science Foundation (CNS-1718253, 1718258).\n\nREF\n\n:BIBREF0\n\n:Wu J, Zhang L, Xue J, Huang S, Wu H. (2014). Deep learning approaches for named entity recognition. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (pp. 1434\u20131442). ACL.\n\n:BIBREF1\n\n:Lin, J, Feng, Y, Zhu, Y, He, S, and Sun, Y. (2015). Deep context-augmented word-gram language model for Chinese named entity recognition. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (pp. 1066\u20131072). ACL.\n\n:BIBREF2\n\n:He, S., and Sun, Y. (2016). Recurrent sequence-to-sequence learning for named-entity recognition of short texts. In Proceedings of the 53rd conference on Annual Meeting of the Association for Computational Linguistics (pp. 815\u2013822). ACL.\n\n:BIBREF3\n\n:Wang, W, Yu, G., and Xue, J. (2017). Chinese named entity recognition using recurrent sequence-to-sequence models in a weakly labeled domain. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (pp. 2539\u20132548). ACL.\n\n:BIBREF4\n\n:Wang, J., Yang, Z., and Zheng, Z. (2015). A survey of natural language processing with neural networks for Chinese social media data. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (pp. 1231\u20131240). ACL.\n\n:BIBREF5\n\n:He, S., and Wang, W. (2012). Recurrent neural network for Chinese sequence labeling. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (pp. 2133\u20132141). ACL.\n\n:BIBREF6\n\n:Sun, Y., and He, S. (2015). Chinese word segmentation based on a recurrent neural network and conditional random fields. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics",
    "9da1e124d28b488b0d94998d32aa2fa8a5ebec51": " The authors would like to thank all participants in our discussion groups for their helpful comments and discussion. Two anonymous reviewers have provided valuable suggestions on this paper.\n\n[1] N. Chiou, N. Li, H. Wan, and H. Dong, \"An Automatic Chinese Entity Recognition Framework for Social Media,\" Proceedings of the 19th International Conference on Computational Linguistics (Coling 2016), Hong Kong SAR, China (2016).\n\n[2] X. Wang, X. Shi, and Q. Li, \"Multi-Scale Chinese Word Segmentation With Self-Attention Module,\" in Proceedings of the 15th International Joint Conference on Natural Language Processing (IJCNLP 2014), pp. 692-698.\n\n[3] R. Jiang, A. Guo, Q. Cheng, L. Xue, Z. Zhang, Q. Liu, Z. Wu, and G. Chen, \"An Entity Linking System for Weibo Tweets,\" in Proceedings of the 20th Asian-Pacific Weibiao Conference (APWC), pp. 926-931.\n\n[4] M. Tsvetkov, D. Raut, and H. Riedel, \"Automatic Named Entity Recognition and Linking with Conditional Random Fields,\" Proceedings of the 19th International Conference on Computational Linguistics (Coling 2016), Hong Kong SAR, China (2016).\n\n[5] S. Gu et al., \"Named Entity Recognition in Chinese using Bidirectional LSTM-CNN Networks,\" Proceedings of the 18th International Joint Conference on Natural Language Processing (IJCNLP 2015), pp. 1019-1027.\n\n[6] N. Chiou, Y. Xiao, L. Shen, Q. Xu, J. Liao, T. Tsai, and H. Dong, \"A Character-Level Long Short-Term Memory Network for Chinese Word Segmentation,\" Proceedings of the 19th International Conference on Computational Linguistics (Coling 2016), Hong Kong SAR, China (2016).\n\n[7] Q. Chen, A. Guo, T. Wu, X. Li, Q. Liu, T.-Y. Wang, D. Zhou, S. Dong, and Z. Zhang, \"Named Entity Recognition in Chinese with Character Level Pre-trained Bi-Directional LSTM-CNN Architecture,\" Proceedings of",
    "37be0d479480211291e068d0d3823ad0c13321d3": " The results here are consistent with the study of BIBREF27, which found that adversarial learning has bad effect on representations.\nhttps://www.aclweb.org/anthology/papers/C19-2088.pdf\n\nhttps://www.aclweb.org/anthology/papers/C19-2089.pdf\n\nhttps://www.aclweb.org/anthology/papers/C19-2090.pdf\n\nhttps://www.aclweb.org/anthology/papers/C19-2091.pdf\n\nYunbo Liu, Xinyue Ding, and Zhengyou Zhang. 2020. BERT for Chinese reading comprehension: A question-answering approach. In Conference on Empirical Methods in Natural Language Processing (EMNLP-IJCNLP) 2020, pages. 1476-1482.\n\nhttps://www.aclweb.org/anthology/papers/C19-2092.pdf\n\nShaoyang Zheng, Xin Chen, Jianjun Gao, and Ding Zhang. 2020. A robust Chinese question answering system using context-aware attention. In Conference on Empirical Methods in Natural Language Processing (EMNLP-IJCNLP) 2020, pages. 1509-1513.\n\nMingjie Cui, Xinyue Ding, Ding Zhang, Jiaming Song, and Yinpeng Qian. 2019. DPRC: A parallel corpus for reading comprehension. In Fourteenth Workshop on Computational Linguistics for Chinese (ACL-CHN) 2019.\n\nhttps://www.aclweb.org/anthology/papers/C19-2093.pdf\n\nhttps://www.aclweb.org/anthology/papers/C19-2094.pdf\n\nhttps://www.aclweb.org/anthology/papers/C19-2095.pdf\n\nSheng Jiang, Jiaming Song, and Yinpeng Qian. 2019. CQA: A large-scale Chinese reading comprehension dataset and a novel extractive QA framework. In Conference on Empirical Methods in Natural Language Processing (EMNLP-IJCNLP) 2019, pages. 2043-2048.\n\nJun-yuan Zhong, Zongwei Jiang, Min Liu, Wencheng Qiu, and Bing Xiang",
    "a3d9b101765048f4b61cbd3eaa2439582ebb5c77": " This may be because the linear mapping cannot perfectly transfer the internal representation of multi-BERT, or other sources of data in training transfer is more important than internal representation.\n\nAcknowledgments\n\nThis research work was supported partially by the Chinese National Key R & D Program of the Ministry of Science and Technology under Grant No. 2017YFC0812004, and Shanghai Municipal Commission of Science and Technology under Grant No. 18411901905. Thanks to the anonymous reviewers for their valuable comments. We're grateful for the support provided by NVIDIA GPU Cloud and Google Cloud Platform.\nBibliography\n\nBIBREF0. Zhang, B., Li, J., Li, S., Xu, K., Zhang, G., Liu, Z. BIBREF0. 2018. Reading comprehension: A dataset of natural questions and fact-focused answers over 100M English Wikidata quora questions. In\n\nProceedings of the Eleventh Conference of the Conference on Empirical Methods in Natural Language Processing\n\nBIBREF8. Zhang, B., Li, J., Yang, H., Xu, K., Zhu, Q., Zhang, G., Ren, C. BIBREF8. 2018. A benchmark for general-domain question answering. In\n\nProceedings of the Twelfth Conference of the Conference on Empirical Methods in Natural Language Processing (EMNLP 2018)\n\nBIBREF9. Zhang, B., Li, S., Li, J., Li, J. BIBREF9. 2019. Chinese reading comprehension through attention-based encoder-decoder architecture. In\n\nProceedings of the Sixteenth Conference on Computational Natural Language Learning (CoNLL).\n\nBIBREF10. Xu, B., Li, S., Li, J., Zhu, Q., Zhang, G. BIBREF10. 2019. Reading comprehension: Understanding long texts with deep learning. In\n\nProceedings of the Twelfth International Joint Conference on Lexical and Computational Semantics (Valencia, Spain)\n\nBIBREF11. Xu, T., et al. 2019. Openquestion: Question answering on the question-answering challenge (QASC). In\n\nProceedings of the Sixteenth Conference on Computational Natural Language Learning (CoNLL)\n\nBIBREF14. Liu, Y., et al. BIBREF14. 2019. Building multilingual reading comprehension datasets: A practical approach to cross",
    "009ce6f2bea67e7df911b3f93443b23467c9f4a1": " The experiments support the hypothesis that alignment of representations in the last layer of multi-BERT is not robust.\n\nAcknowledgments\n\nThanks to the NUS-WZ and NUS-ZK joint laboratory for providing generous resources to carry out this project. This work (and code) is supported by a National Research Foundation (NRF-NRFF) under Grant NRF-NFS15-0116.\nAcknowledgments\n\nThis work (and code) was supported in part by a NSF CAREER grant under Grant NSF1755302; in part by an NSF CSE grant under Grant NSF1738000, NSF1854012, NSF1854008; in part by NSF-CSE Research Challenge Grant CCR-1629897, CCR-1734911. We thank the anonymous reviewers for their detailed comments that significantly improve the quality of the paper. We thank all our students, who contributed toward the realization of this paper.\n\n[1] M. Klinger, R. Gatt, S. Deshpande, B. Li, M. Sellam, J. Wiese, K. Cho, and J. Tenney. What are the best training set sizes for sequence models? An empirical analysis of generalization in SQuAD. In Proc. of EMNLP-CoNLL 2017 Workshop on Machine Learning in Question Answering and Text Understanding, 2017\n\n[2] C. Clark, C. D. Chen, K. Cho, E. Schuurmans, D. S. Yu, and P. Liang. Dense retriever for open-domain question answering. In Proc. of COLING 2018, 2018\n\n[3] O. Al-Rfou, G. W. Dahlstuen, K. Cho, and P. Liang. ReasonerX: Learning from unannotated data via cross-lingual supervision and transfer learning methods. In Proc. of AAAI Conference on Artificial Intelligence (AAAI 2019), 2019\n\n[4] Y. Chen, X. Li, I. P. Lal, O. Saeedi, and A. Zou. Deep learning framework for knowledge-rich cross-lingual question answering. In Proc. of SIGdial Workshop on Computational Dialogue and Artificial Intelligence, 2018\n\n[5] F. Qin, E. Schuurmans, J. Wies",
    "55569d0a4586d20c01268a80a7e31a17a18198e2": " This suggests that the improvement of transfering comes from somewhere else.\nAcknowledgements\n\nThe support from this project is from Xuanzhang Li via the project of JUMP-NLTP, a collaborative project between The University of Hong Kong and Microsoft. Our work is also supported by National Natural Science Foundation of China (NSFC) under Grant 62072355.\n\nReferences\n\nBERT. Google AI Blog. 2019. https:// googleresearch.blogspot.com/2018/10/better-language-understanding-with-larger-and.html, accessed in 2022-03-03.\n\nBIBREF0:\n\nHermann, A., R. Chen, J. Smith, T. Mikheev, M. Nam, D. Levy, and R. Foss. 2018.\n\nTraining Fast And Accurate Readers for Short Texts. In Proceedings of the Annual Meeting of Association for Computational Linguistics, pages 778-788.\n\nBIBREF1:\n\nHosseini-Asl, F., S. Bowman, and T. Mikheev. 2020.\n\nBirdcage: a general-purpose extractive qa framework.\n\nIn Proceeding of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics, pages 2022-2032.\n\nBIBREF2:\n\nRajpurkar, P., A. Karatzoglou, W. Bowman, L. Lee, B. Du, A. Rambhatla, K. Cho, and W. Wenzek. 2016.\n\nSQuAD: a challenging question answering task.\n\nIn Proceedings of the ACL-2016, pages 1804\u20131811.\n\nBIBREF3:\n\nChopra, S., A. Khashabi, A. Rostam Razavi, and R. Dasigi. 2017.\n\nLearning to read and comprehend for question answering. Transactions of the Association of Computational Linguistics 9:541\u2013558.\n\nBIBREF4:\n\nMihaylov, P., A. Hakkani-Turton, and S. Alishahi. 2018.\n\nThe roaring twenties in reading comprehension. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational L",
    "7cd22ca9e107d2b13a7cc94252aaa9007976b338": " Lastly, our modality attention module can improve overall prediction performance of models with fewer word or character-level information by effectively compensating missing modalities without having to scale up the word or char embedding matrix indefinitely.\nFuture Work\nExtending our multimodal NER model, we plan to explore multimodal transfer learning using auxiliary modality information in other NLP tasks, such as language translation.\nAcknowledgments\nThe authors are grateful to Jiajie Chen, Shravan Kudlur, Chiyuan Zheng, and C.C. Chi for useful discussions and advice.\n1. Bustin, R. S., Weikum, L. Andrade, H. Schroff, J. Westlund, D. Baevski, D. Hoffman and S. Chudnovsky. 2017.\n\nMultiword Expression Parsing from Social Media with Conditional Random Fields.\n\nIn Proceedings of SIGKDD 2017.\n2. Chang, T., and Kudo, M. 2015.\n\nTwitter as a Source of Entity Knowledge.\n\nIn Proceedings of ACL-IJCNLP 2015 Workshop on NLP for Social Media.\n3. Chang, T. Y., Cho, K.-M., Kudo, M. 2015.\n\nTwitter Entities with Entity-Word Associations and Social Networks.\n\nIn Proceedings of ACL-IJCNLP 2015 Workshop on NLP for Social Media.\n4. Chen, J., and Vig, L. 2017.\n\nA General Method for Nested Named Entity Recognition in Text and Images.\n\nIn Proceedings of ACL-IJCNLP 2017 Workshop on NLP for Social Media.\n5. Chen, J. Y., and Vig, L. 2017.\n\nEfficient Word Embedding Vector Representation for Entity Matching.\n\nIn Proceedings of NAACL 2017.\n6. Cheng, C. Y., Wang, I., Li, D., and Chang, H. 2016.\n\nDeep learning for NER with Character and Word Embeddings.\n\nIn Proceedings of EMNLP 2016.\n7. Chen, X., and Le, Q. 2014.\n\nA Recursive Neural Network Architecture for Entity Mention Resolution with an Application to Named Entity Search in Tweets.\n\nIn Proceedings of EACL 2014.\n\n8. Chang, M., Liu, Z., Lin",
    "adbf33c6144b2f5c40d0c6a328a92687a476f371": " Furthermore, we empirically demonstrate that the modality attention can further improve the NER model when visual contexts are available.\nAcknowledgments\nWe thank Jichuan Wang and Jiwon Yeom for their helpful discussions in developing the proposed modality attention module, and many participants in the deep learning group at Sogang University for their useful suggestions. We also thank the anonymous reviewers for their insightful comments.\nAppendix A Details of Model Architectures\n\nWord Embeddings\nFor the word representations, we use pre-trained word2vec (GloVE) BIBREF22. The character representations are learned via Bi-LSTM with character level output layer size 25, 100 and 200.\nCharCNN\nTo extract character-level features, we use CNN on character sequences as in BIBREF1. The output from the CNN has dimension 25, 50 and 200, and is fed to Bi-LSTM as in BIBREF0.\nInceptionNet\nTo extract visual features from the paired snap images, we first pre-train the Inception model for one hundred epochs using the original inception architecture and training script provided by GoogLeNet authors BIBREF23, BIBREF24. Note that the final layer from the inception model also can be used directly for a range of downstream visual recognition tasks as well as named entity recognition, without having to retrain the model using snap captioned images, making the Inception training more memory efficient. We use a pretrained inception model available at BIBREF26.\nCNN Bi-LSTM\nBi-LSTM+CRF for Word Embeddings\nSimilar to BIBREF0, we build the Bi-LSTM+CRF neural network mainly of a word embedding Bi-LSTM and CRF, and add a Bi-LSTM over a character sequence as in BIBREF1. The Bi-LSTM model for characters also takes as input a sentence consisting of a sequence of captioned images each with a associated character sequence. We follow the word2vec-Google architecture BIBREF22, BIBREF26, but use character sequence of length 1 as input and output, rather than a word sequence of length 3-9 as in ordinary BART BIBREF5 or GPT-2 BIBREF6, etc. In addition, we use the GloVe size of vocabulary 400K as in word2vec-Google, but do not use the unsupervised technique called",
    "f7a89b9cd2792f23f2cb43d50a01b8218a6fbb24": " When additional visual modality is available, we showed that the model is able to use more versatile signals to disambiguate polysemous entities, and to recognize trendy entities that are only mentioned in visual contexts (e.g. new and emerging celebrities, such as `Marshmello'). In addition, we reported that model performance can still improve from the proposed modality attention module even when there is a significant number of missing tokens in the word embedding matrix, showing that the method is a practical solution to improve a neural NER model without having to increase a word embedding matrix size indefinitely.\nAcknowledgements\nThis work was partially supported by the NSF through the NSF Research Traineeship and the Collaborative Research: Cyber-Physical Human-Agent Teamwork (HAT) programs.\n\nReferences\n\n[1] G. Al-Rfou and M. Grefenstreter. Joint entity extraction and semantic role parsing with deep learning. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 9-29. 2016.\n\n[2] Y. Baldrich, N. Z\u00f6ller, and M. M\u00fcller. NERsuite: building neural machine translation for word and character sequences. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 943-955. 2017.\n\n[3] G. Baroni, C. Ciaffi, and E. Farinella. Sparse-token convolutional neural networks for entity recognition. In Proceedings of the 2017 Conference of the Association for Computational Linguistics, pp. 1777-1788. 2017.\n\n[4] R. Batra, G. E. Dahl, M. J. A. Hovy, and I. Titov. Deep LSA + karma. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 632-642. 2015.\n\n[5] M. Bhat, S. Narayanan, and M. Peeples. Learning to label for sentence extraction, word-sense disambiguation, and named entity recognition using convolutional neural networks. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pp. 1286-1296. 2009.\n\n[6] M. Blunsom, T. Griffiths, E. Jozef",
    "a0543b4afda15ea47c1e623c7f00d4aaca045be0": "\n\nBy providing context resolution by both visual and textual modalities, our model can make better use of short media posts for applications such as personalized assistance (e.g. recommending nearby nearby restaurants, movies) based on the specific context, or better identifying entities in social media posts. Furthermore, we demonstrated that multimodal NER models are able to improve the robustness of NER for missing tokens without having to train word embeddings with an infinitely large vocabulary. We believe that our approach is applicable to many other multimodal understanding tasks, by combining complementary visual and textual information to handle missing or noisy token segments. Also, this modality attention module is of general applicability to combine multiple modalities of heterogeneous inputs (visual, natural language, etc.) to learn useful representations.\n\nAcknowledgements\nThanks go to many thoughtful suggestions from reviewers Sungho Jin and Xiang Ji as well Yiqi Tian, Zilong Tan, Bo Pang, and Xuan Yang for their suggestions. We also thank the anonymous reviewers for the many helpful suggestions.\nThis work was supported in part by NSF-1845578, 1847254, 1616541, and ARO W911NF-16-Y-0480, by Intel AI Lab, by Jingjing Gu, and by the NSF CAREER program (DGE 1550196).\n\n[1] T. F. Flower and D. G. Lowe. A statistical model of text. Proceedings of the 28th Annual Meeting on Association for Computational Linguistics, 1975.\n[2] J. Rinzivillo, B. Y. Zhao, and A. Y. Lau. A survey of named entity recognition. Computer Science Department, University of Cincinnati. 2007.\n[3] E. Chirchinos, D. R. Houlsby, T. F. Flower, E. M. Majumdar, S. Riedel, I. Yahav, B. H. Smith, and J. R. Smith. Co-occurrence statistics for named entity recognition. Proceedings of the 30th International Joint Conference on Artificial Intelligence, 1995.\n\n[4] M. Baldridge. Entity recognition. Speech. 2011.\n[5] C. Finkes, H. T. Martin, K. Strube, J. Auer, and S. Yoon. Conditional random fields for named entity recognition. Proceedings of the 32",
    "1591068b747c94f45b948e12edafe74b5e721047": " Lastly, we showed how the proposed modality attention model outperforms other previous neural models even without access to gazetteers information despite the small size of our new dataset.\n\nWe would like to thank all the helpful discussions with Ganesh Balaraman, Zhengyan Dong, and Alim Momenchuk. The authors also thank all Google interns at the machine reading group for brainstorming questions related to text-image multimodal neural network architectures for NLP tasks. We gratefully acknowledge all the support and encouragement of Google Brain.\n\n[1] C. Wu, Z. Lin, A. Ng, M. Iyyer, D. Deng, J. Chiu, K. Chaudhary, P. Yu. MultiWOZ: Multi-word sequence labeling with a conditional random-field. In: Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pp. 1-6, 2016.\n[2] D. D. Wang, D. N. Tao, M. Li, S. X. Yue, R. J. Liu. BIOBERT: Fine-tuning BERT for biomedical named entity recognition. In: Proceedings of 26th Annual Conference of the Association for Computational Linguistics, pp. 4440-4448, 2020.\n[3] D. D. Tao, M. Li, F. Zhang, R. J. Liu, Y. Liu, H. Wu, D. Dong, D. N. Wang. EMR: Efficient multimodal named entity recognition with visual and text context for social media posts. In: Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pp. 1711-1718, 2020.\n[4] L. Zou, G. Lu, C. K. Tan, G. Y. Yin, G. Yang, M. Li. MvLC-BiLSTM: Multi-view learning with LSTM for multimodal named entity recognition. In: Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 3250-3260, 2020.\n[5] S. Zhang, L. P. Chen, S. G. Chang, M. Li. Entity recognition via contextualized convolutional neural network. In: 2018 IEEE Congress on Evolutionary Computation, Evolutionary Intelligence",
    "193ee49ae0f8827a6e67388a10da59e137e7769f": "\nAcknowledgement\n\nWe like to thank the anonymous reviewers for their valuable suggestions. This work is supported by the Institute for Information Technology (China Science and Technology Development Fund Initiative, grant no. 2016W1C14-FJ) and IBM Faculty Awards Program.\n\nReferences [1] (BART)\n\nLan, P., Li, P., Li, B., and Xu, J. (2019b). BART: Denoising Transformers for a Better Language Model. ArXiv e-prints, ArXiv:1908.11095.\n\n[2] (BERT)\n\nWolf, K., Bond, M., and Dredze, S. A. (2020). Transformer-XL and XLM-R: Improving Language Representations with Cross-Lingualtaion Transformers. ArXiv e-prints, ArXiv:1902.04306.\n\n[3] (BIBREF0)\n\nDevlin, J. and Chang, S. and Lee, M. (2018). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. ArXiv e-prints, ArXiv:1802.00281.\n\n[4] (BIBREF1)\n\nClark, D. and Curran, R. and Lee, K. and Zhai, Y-H. (2018). BERTscore: Training and Inference with BERT. ArXiv e-prints, ArXiv:1811.03544.\n\n[5] (BIBREF2)\n\nDevlin, J., Tan, K., Pham, P., Chi, M. and Levy, S. and Dyer, C. and Kusner, M. and Gimpel, K. and Smith, E. (2018). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. ArXiv e-prints, ArXiv:1807.1105.\n\n[6] (BIBREF3)\n\nLi, G. and Ward, E. and Lin, Z. and Hakkani-Tur, D. and Liu, J. (2020). XLNet: A Large Pre-trained Transformer for General Language Understanding and Knowledge Acquisition. ArXiv e-prints, ArXiv:1905.12840.\n\n[7] (B",
    "ed2eb4e54b641b7670ab5a7060c7b16c628699ab": " Besides, as a challenging problem with many applications, it would be worth focusing on the problem of sequence-to-sequence learning models with language modeling and other language modeling-based objectives.\n# Summary\n\nAbstractive document summarization remains an open research problem, which aims at learning to generate high quality summaries from long documents with strong linguistic information by rewriting original sentences. In this paper, we proposed a sequence-to-sequence learning method Step, which can be pre-trained on large scale unlabeled texts via three unsupervised pre-training training tasks, including sentence reordering, next sentence generation, and masked document generation tasks. Compared with training from scratch, pre-training approaches have several benefits. Firstly, pre-trained models do not need to be carefully tuned to specific summarization data. Secondly, data-efficiency is an issue in abstractive summarization due to the limited number of document-summary pairs. Last but not least, pre-trained models can also benefit from the contextualized understanding of the source texts. Experiments on two real world summarization datasets and on a newly constructed unlabeled summarization dataset show significantly better performance gains for our pre-trained summarization models, which also surpasses the best published abstractive summarization systems.\n# Introduction\n\nAbstractive document summarization aims to rewrite a long document to its shorter form while still retaining its important information. Different from extractive document summarization that extracts important sentences, abstractive document summarization may paraphrase original sentences or even delete contents from them. For more details on differences between abstractive and extractive document summary, we refer the interested readers to Nenkova:McKeown:2011 and Section SECREF2. This task is usually framed as a sequence-to-sequence learning problem. In this paper, we adopt the sequence-to-sequence (seq2seq) Transformer BIBREF9, which has been demonstrated to be the state-of-the-art for seq2seq modeling BIBREF9, BIBREF12. Unfortunately, training large seq2seq Transformers on limited supervised summarization data is challenging BIBREF12 (refer to Section SECREF5). The seq2seq Transformer has an encoder and a decoder Transformer. Abstractive document summarization requires both encoding of an input document and generation of a summary usually containing multiple sentences. As mentioned earlier, we can take advantage of recent pre-trained Transformer encod",
    "beac555c4aea76c88f19db7cc901fa638765c250": " The computational resources used for this manuscript were provided by SURFsara, national supercomputer center and part funded by ZBW and TU Delft, the University of Delft.\n\nReferences\n\n[1] D. Bahdanau, Y. B. Wu, D. Cho, and Y.-Y. Li, 2015. Neural machine translation by jointly learning to align and translate. In: Proceeding of the Advances in Neural Information Processing Systems (NeurIPS), pages 952, San Diego. 10.\n\n[2] P. Buitelaar, D. Prange, A. Joty, and Q. Vossen, 2013. Automatic word alignment and morphological alignment. Computer Speech and Language 33, 75\u201399.\n\n[3] I. Djuric, S. Liu, T. Lappin, K. Sima\u00b4nski, and J. Callison-burch, 2013. Combining word alignment with neural machine translation. In: Proceedings of the International Symposium on Neural Methodology in NLP (NeurMoNLP), pages 29:1\u201329:13, Prague, Czech Republic. 10.\n\n[4] P. D.-G. Eck, K. Edsgardo, R. van Horne, H.-K. Zhang, S. Everson, and T. Zschacher, 2015. Training neural machine translation models to capture the compositionality of source-side context. In: Proceeding of the Nineteenth Conference on Computational Natural Language Learning, pages 129\u2013138. 10.\n\n[5] D. Miao, Y. Zhao, C. Gao, L. Ma, and R. Liu, 2015. Neural translation of long sentences. In: Machine Translation: Where Are We Now, Where Do We Go? (EMNLP), pages 110\u2013117, Berlin, Germany.\n\n[6] Q. Liu, S. W. Kondadadi, X. Wang, and T. Kusner, 2016. Attention-enhanced sequence-to-sequence learning for machine translation. In: Proceeding of the 2016 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1647\u20131655, Dublin, Ireland.\n\n[7] S. Riezler, B. Sennrich, S.-W. Haddow, J. Birch",
    "91e326fde8b0a538bc34d419541b5990d8aae14b": "\n\nAppendix A: Datasets\nTable A.1 provides a detailed table of the datasets that are used.\nTable A.1: Datasets\n(bpe)\n\n(giza)\n\n(wmt2015)\n\n(rwth)\n(wmt2016)\nDummy\n\n(rwa1.6.0)\n\nRWTH(EN)\n\n(rwa1.6.1)\n\n(sj)\n\n(wmt2013)\n\n(mtnews2013-2015)\n(de-en-ru-de)\n\n(wmt09)\n\n(rwa2)\n(wmt2012)\n\n(wmt12)\n(rwa11)\n\n(rwa13)\n\n(rwa17.2)\n\n(ch)\n\n(mt2003-2012)\n(mt2003-2012)\n\n(mt2003-2012)\n\n(mt2003-2012)\n\n(mt2003-2012)\n\n(mt2003-2012)\n\n(mt2003-2012)\n\n(mt2003-2012)\n(mt2003-2012)\n\n(mt2003-2012)\n\n(mt2003-2012)\n\n(rwa6)\n\nRWTH(DE)\n\nWord Alignment Datasets\nAutomatic alignment between parallel texts is a well-recognised issue in NMT and is usually solved by providing automatic alignment for training the system or guiding the attention of the attention module by hard or soft word alignments extracted from translations. For this paper we used RWTH German-English dataset which contains manual alignments. RWTH German-English is a sub-set of the RWTH machine translation shared task collection BIBREF17 containing around 160K sentences from a variety of domains. The full data set contains a wide variety of alignment errors including wrong alignment directions, wrong alignments, short and long jumps, and others. The sentences of the original data are available both in German and English.\n\nTo make our experimental setup as uniform as possible we train a state-of-the-art attentional model on parallel corpora of standard corpora and compare the performance to the attention in word alignment. We also train attentional models with input-feeding for the same corpora and compare the translation quality to automatic alignments.\n\nDat",
    "044f922604b4b3f42ae381419fd5cd5624fa0637": " The authors thank the NWO and KTH Royal Institute of Technology for funding this project.\n\n\n**LATIN AMERICAN LITERARY AND\n\n**\n\n**LANGUAGE NOVELS\n\nA BIOGRAPHICAL\n\n**\n\n**DICTIONARY\n\n_Compiled and Edited_\n\n**By**\n\n**_Edmundo O'Gorman and_\n\n**_Laird Hunt_**\n\n(LONDON)\n\n\u00a9 **2012**\n\n**ALL ENTRY WRITERS HERE TRANSCRIBED HAVE   \nGRANTED PERMISSION**.\n\n**PUBLISHER**\n\n\u00a9 **2012**\n\n**BIBLIOASIA**\n\n**AN Imprint of Bloomsbury Publishing Plc**\n\n50 Bedford Square  \nLondon WC1B 3DP  \n _www.bloomsbury.com_\n\nBloomsbury is a trademark of Bloomsbury Publishing Plc\n\nBloomsbury Publishing, London, New Delhi, New York and Sydney\n\nFirst paperback edition 2013\n\nEPub ISBN: **9781448225637**\n\nAll rights reserved  \nYou may not copy, distribute, transmit, reproduce or otherwise make available this publication (or any part of it) in any form, or by any means (including without limitation electronic, digital, optical, mechanical, photocopying, printing, recording or otherwise), without the prior written permission of the publisher. Any person who does any unauthorised act in relation to this publication may be liable to criminal prosecution and civil claims for damages.\n\nNo responsibility for loss caused to any individual or organization acting on or refraining from action as a result of the material in this publication can be accepted by Bloomsbury or the authors.\n\nBloomsbury Publishing Plc   \n50 Bedford Square  \nLondon WC1B 3DP\n\nBloomsbury is a registered trademark of Bloomsbury Publishing Plc\n\nBloomsbury Publishing, London, New Delhi, New York and Sydney\n\n_LIBRARY OF CONGRESS CATALOGING-IN-PUBLICATION DATA_\n\nO'Gorman, Edmundo   \nLatin American literary and language novels / compiled and edited   \nby Edmundo O'Gorman and Laird Hunt.   \np. cm.\n",
    "f94b53db307685d572aefad52cd55f53d23769c2": "\n\nReferences\nB. Liu and Y. Ma (2018).\n\nData-efficient active learning methods for large-scale ASR with recurrent neural networks.\n\nInproceedings\n\nB. Liu and N. Yang (2017).\n\nInformative gradient length in active learning for stochastic gradient descent.\n\nNeurips\n\nL. Meistert (1970).\n\nInformation content of gradient-lengths.\n\nPhil. Trans. R. Soc. Ser. B-Biol. Sci., pp. 471\u2013492.\n\nM. Schubert (2018).\n\nSpeech Recognition at Facebook.\n\nNeurips\n\nZ. Wang (2017).\n\nNeural active learning for large-scale automatic speech recognition.\n\nInproceedings\n\nAcknowledgments\n\nWe thank the organizers of NeurIPS 2017 and NeurIPS 2018, as well as our anonymous reviewers for their comments that improved this paper. Finally, we thank the Facebook Autolab for research support.\n\nAuthor Contributions\n\nWe thank the entire facebook autolab for fruitful discussions.\n\nDisclaimer\n\nThis research was supported by Facebook. Some of the results reported in this paper were obtained through Facebook's sponsored research program. The views expressed here are solely those of the authors and do not necessarily reflect the official opinion of Facebook.\nBibliography\n\nJ. P. Harms (1968).\n\nNeighborhood function approximations in nonstationary time-series prediction.\n\nEconometrica, pp. 787\u2013800.\n\nB. Liu and N. Yang (2017).\n\nData-efficient active learning methods for large-scale ASR with recurrent neural networks.\n\nInproceedings\n\nB. Liu and G. N. Levy (2018).\n\nVariance reduction of the expected gradient length in active learning for deep learning.\n\n\nNeurips\n\nB. Liu, D. S. Y. Cheng, H. Sun, Q. Zhan, and G. N. Levy (2018).\n\nA comprehensive study of variance reduction for end-to-end speech recognition with batch active learning.\n\nInproceedings\n\nB. Liu, D. S. Y. Cheng, H. Sun, K. J. Zhan, and G. N. Levy (2019).\n\nRobust inference in active learning for end",
    "aa7d327ef98f9f9847b447d4def04889b4508d7a": " Finally, we would like to investigate if EGL can also be used in other applications, e.g., semi-supervised learning.\nAcknowledgments\nWe are grateful to the people who helped and supported us throughout our work, particularly, Yoon-Bin Kim, Minhyuk Kim, and Xiang Bai, for their feedback and suggestions.\nReferences\n\nBai, F., et al. 2020. Active Learning for Language Models: Principles and Practice. In International Conference on Machine Learning, pages 11298\u201311011. ArXiVv:2019.3.1743.\n\nBaker, M., et al. 2017. End-to-end automatic speech recognition with sequence-level attention and convolutional network layers. ArXiV:1712.00264.\n\nDavis, S., and W. Mercer. 2013. Improving training set size based on sample informativeness. Proceedings of the International Conference on Information and Knowledge Management, pages 1090\u20131095.\n\nEngemann, N., and I. Dagan. 2016. Importance sampling for language learning in stochastic gradient descent. Proceedings of the 23rd International Joint Conference on Artificial Intelligence.\n\nGoyal, P., et al. 2017. Scalable language modeling with importance weighted random sampling. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, pages 723\u2013732.\n\nLing, X., H. Chen, and C. D. Manning. 2017. RNNLM: Sequence-level language modeling with recurrent neural networks. In EMNLP, pp. 1135\u20131144.\n\nPovey, D., et al. 2016. The fisher-yakubov-sammon model for learning from noisy mixtures of sequences. Proceedings of the 26th International Conference on Machine Learning (ICML), pp. 2227\u20132236.\n\nShotgun-Speech.org. 2006.\n\nTam, V. B., and M. S. Lee. 2008. ASR: Training on noisy data with confidence sampling. Proceedings of the 2008 International Conference on Computational Linguistics (ICL).\n\nVoita, B., et al. 2015. A confidence-scoring approach to active learning for automatic speech recognition using error-feedback and adversarial training for improved acoustic model adaptability. In ICASSP, pages 698\u2013702.\n",
    "b8d7d055ddb94f5826a9aad7479b4a92a9c8a2f0": "\n\nTable TABREF12 in the Appendix provides the exact error values at the various query percentages.\nTable 12.\nAll the experiments reported here were done using Keras and Tensorflow on an NVIDIA V100. Our implementation of BIBREF2 and BIBREF3 is based on their original papers and adapted to fit into our system.\nThe source code and pretrained models are available in our repository.\nFigure 9.\nSpeech recognition confidence scores differ from EGL\n\nBIBREF:\n\nBibliography (for citation purposes)\n\n1. Zeger, S., et al. \"Deep learning of robust end-to-end speech recognition systems.\" Proceedings of the International Conference on Acoustics, Speech and Signal Processing, ICASSP, February 2013.\n2. Jia, X., et al. \"Data augmentation and neural network architectures for end-to-end speech recognition: Two steps forward, one step back.\" ICASSP, 2016.\n3. Jia, X., et al. \"Learning to learn in deep neural networks.\" ICASSP, 2017.\n4. Li, H., and J. Chen. \"Active learning for end-to-end speech recognition via deep neural networks.\" ICASSP, 2015.\n5. Yu, C.P., et al. \"Denoising active learning for end-to-end speech recognition.\" ICASSP, 2017.\n6. Chen, J., and M. Duh. \"Learning robust end-to-end speech recognition from few examples.\" ICASSP, 2016.\n7. Chen, J., et al. \"In-domain transfer for end-to-end speech recognition via soft label noise and domain disentanglement.\" ICASSP, 2017.\n\n8. Dahl, G., and B. Haffner. \"Conditional likelihood training in continuous speech recognition models.\" Proceedings of the International Conference on Acoustics, Speech and Signal Processing, ICASSP, February 2013.\n9. Oord, A., et al. \"Convolutional sequence-to-sequence learning.\" Proceedings of the International Conference on Machine Learning, ICML, July 2016.\n\n10. Cheng, Z., et al. \"Bidirectional recurrent neural networks for acoustic modeling.\" Proceedings of the International Conference on Machine Learning, ICML, July 2015.\n\n11. Baevski,",
    "551457ed34ca7fc0878c85bc664b135c21059b58": "\n\nAcknowledgments\nWe wish to thank the anonymous reviewers for their valuable feedback.\nReferences\n\n[1]\n\nA. Adams, S. Cho, and P. Mangu. Thesis. Stanford University, 2016.\n\n[2]\n\nY. Abdelkrim, T. Grapperhaus, B. K\u00fc\u00e7\u00fck, and J. Lafferty. Learning to discriminate: Efficient exploration, gradient amplification, and active inference. In Advances in Neural Information Processing Systems (NIPS), 2017, pages 2485\u20132501.\n\n[3]\n\nK. Ahmed and S. Cho. Automatic Speech Recognition with Maximum Mutual Information for Active Learning. Proc. Interspeech, 2015.\n\n[4]\n\nS. Anantha, J. Koppel, J. Minsky, and J. Callison-Burch. Automated Language Modeling: An Analysis of Statistical Properties. Proc. ICLR Workshop on Natural Language Understanding Systems, 2010.\n\n[5]\n\nL. Berezhnoff, A. Gupta, J. Tyers, T. S. Sejnowski, B. K\u00fc\u00e7\u00fck, V. Lenc, and M. Smith. Active learning with expected gradient length for deep recurrent neural networks. In Advances in Neural Information Processing Systems (NIPS), 2017, pages 2412\u20132420.\n\n[6]\n\nD. Blunsom, L. Bai, J. Jozefowicz, F. Wang, P. Abbeel, G. Brockman, G. Riedwyl, and S. Levine. From confidence scores to importance weights. In International Conference on Neural Information Processing Systems (ICONIPS), 2009.\n\n[7]\n\nB. Cai, S. Meng, C. Li, T. Chown, and D. Saon. Learning from few examples for sequence prediction with generative adversarial networks and reinforcement learning. In Advances in Neural Information Processing Systems (NIPS), 2017, pages 1\u20138.\n\n[8]\n\nB. Cai, S. Meng, S. Popescu, and D. Saon. Learning from few examples with reinforcement learning. arXiv preprint arXiv:1611.02776.\n\n[9]\n\nA. C. Cramer, S",
    "0ad4359e3e7e5e5f261c2668fe84c12bc762b3b8": " We thank the NVIDIA Corporation for the research grant and the NVIDIA DGX-1 system for experimental support.\n\nReferences\n\n[1]  Bhagat, B., Chaudhry, Q. and Neubig, G. (2018). Long Short-Term Memory Networks for Text Generation. Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, AAAI.\n\n[2]  Bengio, Y., Deng, L., Lample, C., et al. (2011). Sequence to Sequence Learning with Neural Network Policies over a Continuous Space. CoRR abs/1409.3245.\n\n[3]  Bengio, Y., Dusmenil, A., Vincent, C., et al. (2013). Recurrent Neural Networks with Gated Activation for Machine Translation. ICML.\n\n[4]  Chang, K., Vinyals, A., Jaitly, N., et al. (2016). Learning to Segment Concatenative Text with Recurrent Neural Networks. CoRR abs/1607.00726.\n\n[5]  Chen, D. Y., Xu, K., He, Z. Y. and Su, Z. (2016). Exploiting Sentence Structure for Parsing: An Overview. In: Proceedings of the 2016 Ninth European Conference on Natural Language Processing.\n\n[6]  Dauphin, Y., Fusi, S., Piedalue, H., et al. (2014). Language Models are Unsupervised Alternating-Direction Memories. CoRR abs/1406.1067.\n\n[7]  Djalali, J., Schmidhuber, J., Bahdanau, D., et al. (2014). Sequence-to-sequence Learning with Neural Networks. CoRR abs/1409.3292.\n\n[8]  Faraj, M., Graber, D. and Klein, D. (2019). Multimodal Relation Classification with a Tree-structured Recurrent Neural Network. Submitted.\n\n[9]  Gehring, J., Farkas, D., Schwenk, C. and Gajos, M. (2018). Neural Language Inference, a Structured Knowledge Representation Framework for Natural Language Question Answering. In: Proceeding of the 2018 Conference",
    "4cbe5a36b492b99f9f9fea8081fe4ba10a7a0e94": "\n\nBIBREF0.\nT. T. B. MacArthur, S. J. Levine, R. G. M. Meeussen (2013). Optimism as a Function of Personality and Lifestyle Characteristics. American Behavioral Scientist 56:569\u2013575.\ndoi: 10.1177/00027642124745243\n\nBIBREF1.\nJ. L. Moretti (2000), Life Expectancy, Depression, and Optimism in the United States, Social Indicators Research, 62 (4), 739\u2013754, http://www.statcan.gc.ca/pub/85/05500-000-x20180001-eng.htm.\n\nBIBREF2.\nJ. L. Moretti (1995), Optimism as an Adaptation to Depression: A Review of Theory and Evidence, Social Indicators Research, 64 (1), 1-27, http://www.statcan.gc.ca/pub/85/85-06-02-x20160001-eng.htm.\n\nBIBREF3.\n\nC. D. Parot (1998), Detecting Contingency Trees in Text: A Survey and Evaluation of Parsers and Their Error Types, Journal of Discourse Processing, 9, 85\u2013120.\n\nBIBREF4.\n\nR. C. Son et al. (2011). Analyzing Argumentation Forms in Twitter Using Rhetorical Structure Theory. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP) pp. 87\u201396.\n\nhttp://aclweb.org/anthology/E11-1143/.\n\nBIBREF5.\n\nR. C. Son et al. (2015). Identifying Argumentation Forms in Language in Social Media: Identifying the Drivers for Human Decisions. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP) pp. 1533\u20131541.\n\nhttp://aclweb.org/anthology/D15-1027/.\n\nBIBREF6.\n\nP. E. Blei et al. (2016). Density-Based Models of Word Cooccurrence and a Tree-Augmented Bag of Words for Dense Text Analysis and Categorization. In Proceedings of ICASSP, 1551\u201315",
    "a4d115220438c0ded06a91ad62337061389a6747": "\n\nAuthor Declaration\nThe author(s) declare that this paper strictly represents their own work and does not violate any existing published work.\nBIBREF0.\n\nBIBREF1.\n\nS. E. Nesse, K. W. Bockmelin, P. B. Zinsser, P. J. Turnbull, and S. C. Hayes, A test of causal style as an index of mental health, Personality and Social Psychology Bulletin 40:1075\u20131083, (2016).\n\nBIBREF2.\n\nA. L. Sutter, M. C. A. Macrae, P. B. Zinsser, R. J. Davidson. Psychological differences based on social class and occupation, American Journal of Political Science, 58:621\u2013638, (2014).\n\nBIBREF3.\n\nR. Ji, Z. Bhatia, M. R. Jannati. Attributing cause and effect: an experiment with discourse structure in a text categorization task, Transactions of the Association for Computational Linguistics, 12:1297\u20131310, (2013).\n\nBIBREF4.\n\nR. Bhatia, P. T. Jannati, R. Ji, L. Smith. How to detect causal explanations using hidden structure, Proceedings of NAACL (2016)\n\nBIBREF5.\n\nB. Gao, Z. Y. Q. Tang. Neural discourse parsing for social media: leveraging discourse structure for political text categorization. Transactions of the Association for Computational Linguistics, 10:1119\u20131139, (2016).\n\nBIBREF6.\n\nY. Zhang and Y. Zhang. Linguistic causality and language usage \u2013 a probabilistic model and application to Twitter. In Proceeding of Association of Computational Linguistics, pages 1266\u20131271, (2014).\n\nBIBREF7.\n\nE. Hovy, S. Vinyals, and T. Kohonen. Unsupervised learning of discourse structure. In E. Charni, F. d Bl\u00e9court, E. T. K. Tan and C. R. Martin, Handbook of Discourse Markers and Discourse Relations. Handbooks of Linguistics and Phonetics, 47:47-82, (",
    "2c7e94a65f5f532aa31d3e538dcab0468a43b264": "\n\nAcknowledgement\nWe thank our annotators for their invaluable work in helping gather the data described here. We also thank Samyak Mishra for helpful discussions on the best features to use and for finding a dataset of good quality training data from the web.\n\n\\newpage\n\n\\newpage\n\n\\newpage\n\n\\newpage\n\n\\newpage\n\n\\newpage\n\nReferences\n\n[1] Clark, P., et al. \"Finding and Fixing Missing Intents: Designing and Evaluating Intent Classification Systems.\" In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 1577\u20131580, 2018. <https://aclanthology.org/S18-2039.pdf>\n\n[2] Clark, P. \"Designing and Evaluating Intent-Driven Dialog Systems.\" In Proceedings of the Conference on Empirical Methods in Natural Language Processing, 2019. <https://aclanthology.org/S19-2002.pdf>\n\n[3] BIBREF1 Alsentzar, J., et al. \"Improving Dialogue Systems with Unconstrained Data.\" In Proceedings of the Conference on Empirical Methods in Natural Language Processing, 2019. <https://aclanthology.org/S19-2023.pdf>\n\n[4] BIBREF2 Li, S., et al. \"Semi-Supervised Learning with Multi-Level Evidence Collection.\" In Proceedings of the Conference on Empirical Methods in Natural Language Processing, 2019. <https://aclanthology.org/S19-2017.pdf>\n\n[5] BIBREF3 Li, S., et al. \"The Effect of Training-Set Size on Intent Classification.\" In Proceedings of the Conference on Empirical Methods in Natural Language Processing, 2019. <https://aclanthology.org/S19-2028.pdf>\n\n[6] BIBREF7 TREC. Query Classification Track, 2019. <https://trec.nist.gov/projects/trec/queryclassification/qb19-task/>.\n\n[8] BIBREF9 O'Connor, D., et al. \"New Challenges in Unknown Intent Discovery and Their Relation to Dialogue State Management.\" In Proceedings of the Conference on Empirical Methods in Natural Language Processing, 2019. <https://aclanthology.",
    "149da739b1c19a157880d9d4827f0b692006aa2c": " Any feedback or questions can be sent to me or the anonymous coauthors at srobot@clinc.ai, srobot@gmail.com, and srobot@google.com.\n\nWe thank the anonymous reviewers for their helpful insights. We especially thank M. Radford, T. Lauscher, and A. Williams for reviewing an earlier draft of this manuscript. We thank A. Abend and C. Duyan for their comments on an earlier draft. Any remaining mistakes are entirely at the authors' own responsibility.\n\n1.\n\nThe code and models used in this paper are available at https://clinc.ai/oos-eval/.\n\n2.\n\nhttps://dialogflow.cloud/docs/concepts and http://rasa.io/docs/nlu/.\n\n3.\n\nSee the code and models used in this paper at https://clinc.ai/oos-eval/.\n\n4.\n\nhttps://arxiv.org/abs/1812.04349.\n\n5.\n\nhttps://fasttext.cc/docs/en/cnn.html and https://www.nltk.org/howto/word-representations.html\n\n6.\n\nhttps://arxiv.org/abs/1607.04722 and http://weede-m2.github.io/data/glove/text8.tar.gz\n\n7.\n\n<a class=\"source\" target=\"source\" rel=\"external\" data-url=\"https://data.allenai.org/bibref/clinc/BIBREF0\u2033> http://www.bibref.org/clinc/BIBREF0 </a>\n\n8.\n\nhttps://bibref.org/clinc/BIBREF8\n\n9.\n\nhttps://bibref.org/clinc/BIBREF9\n\n10.\n\nhttps://bibref.org/clinc/BIBREF2\n\n11.\n\nhttps://bibref.org/clinc/BIBREF11\n\n12.\n\nhttps://bibref.org/clinc/BIBREF12\n\n13.\n\nhttps://bibref.org/clinc/BIBREF13\n\n14.\n\nhttps://bibref.org",
    "27de1d499348e17fec324d0ef00361a490659988": "\nAcknowledgments\nThis work was supported by the National Science Foundation under grants 1527469, 1527437 and 1733687, the Amazon Alexa Prize, and grants provided by the National Science Foundation and the Air Force Office of Scientific Research to Carnegie Mellon University. The authors would also like to thank the dozens of contributors to the Alexa Prize Open Dataset Challenge.\n\n[1]\n\nDevin Vlasak et al.\n\nBERT: Pre-training of deep bidirectional transformers for language understanding.\"\n\nIn proceedings of the 2019 conference on empirical methods in natural language processing.\n\n[2]\n\nBIBREF0\n\n. https://www.trec.org/pubs/bibdata/2013/bibref-0.htm.  \nRetrieved from https://www.trec.org/pubs/bibdata/2013/bibref-0.htm.\n\n[3]\n\nDevin Vlasak et al.\n\nBIBREF1. https://arxiv.org/abs/1901.03146.\n\n[4]\n\nMichael Auli.\n\nA unified sklearn interface for machine learning and deep learning algorithms developed by the skflow project.\n\nIn Proceedings of the 2018 ICML Workshop on Machine Learning for Reinforcement Learning. PMLR, Vol. 80, (2018): 1036--1045.\n\n[5]\n\nDyre M Buewyler.\n\nA fast and deep contextual word embedding model.\n\nIn Proceedings of the EMNLP 2015 workshop on Advances in Pre-training in NLP. 2015, pages 18--34.\n\n[6]\n\nJeffrey Pennington et al.\n\nGloVe: Global vectors for word representation.\n\nIn Proceedings of the 2014 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Association for Computational Linguistics, Seattle, WA, USA, 14-17, 2013.\n\n[7]\n\nHershey Yang et al.\n\nA new look at word representation: Global Vectors for Word Representation.\n\nIn Proceedings of the 28th International Conference on World Wide Web (ICWWW), pages 2234--2240.\n\n[8]\n\nDevin Vlasak et al.\n\nBIBREF",
    "cfcdd73e712caf552ba44d0aa264d8dace65a589": "\nAcknowledgments\nT. A. Thiagarajan, O. W. Park, and B. Haddawy gratefully acknowledge support by the Defense Advanced Research Projects Agency (DARPA) under DARPA-PS-18-C-0041 and a National Science Foundation (NSF) Research Infrastructure Improvement (RI2) award (Award #1760312).\nReferences\n\n[C. L. Clark and A. Toussaint. 2018.] TREC 2018: Query classification track with crowdsourced data. In TREC 2018 proceedings, pages 45--62, 2018.\n\n[BERT J. Devlin, M. Chang, and others. 2019. Deep bidirectional transformers for sequence classification.]\n\n[Devlin B. J., Chang M., Lee K., Kloss M., and Lepire E. 2019. \"An empirical study of deep-learning techniques for intent prediction using crowdsourced data.\"]\n\n[BIBREF2. P. T. Barros and F. V. N. Neves. 2017. Conversational Intents-in-the-Wild: An Evaluation Collection of Out-of-Scope Queries from Crowdsourced Scoping, Rephrasing and Scenario Data.]\n\n[BIBREF9. M. Liu and L. S. Hovy. 2016. \"Intent Disagreement within Query and Dialogue State Tracking.\"]\n\n[BIBREF11. T. A. Thiagarajan, O. W. Park, and B. Haddawy. 2019. \"A Survey of Approaches to Evaluate Intent Classification Performance: Challenges and Applications for Dialog Systems.\"]\n\n[BIBREF12. D. Riezler, G. Beier, and M. Wimmer. 2017. Challenge 1: State Tracking in Multimodal, Conversational Dialogues. In The Twelfth Dialog State Tracking Challenge (DSTC1), 2017.\n\n[BIBREF13. S. Kassner, M. Toni, H. Dai, T. Hofmann, S. Haas, A. Reiterer, S. Schulz, and A. Wermter. 2015. \"Challenge 2: Intent Detection.\"](https//www.cl.tt/dstc13.info/challenge2.html)\n\n[B",
    "23b2901264bda91045258b5d4120879ae292e950": " Moreover, the dice loss can achieve significantly higher F1 in both accuracy and F1 loss-sensitive tasks, which means that dice loss tends to promote the model to distinguish hard examples between easy-negative ones in the end.\nFuture Work\nIn the future, we are interested in exploring better hyperparameter tuning strategies to achieve a better balance between data in the task. For instance, the cross-validation and inverse class frequency are good for selecting the coefficient, however, it is also interesting to learn a model for assigning the hyperparameters. We also want to explore whether other losses such as focal loss BIBREF16 BIBREF36 are complementary to the proposed approach.\nAcknowledgments\nThis work was supported by the Fund for the Top Talents of Hebei Province. The work has been done in the framework of the program for Innovative Talents Support Scheme, Chinese Academy of Sciences.\nReferences\n\n[1] :. :, :\n\n[2] :. :\n\n[3] : : shah2018convection, jang2018improving, yang2019cof, :\n\n[4] :.. :\n\n[5] : : : : liao2019g, zl2019cross, : ;\n\n[6] : : : li2018s, :\n\n[7] : : santos2020data, :\n\n[8] : : : hosseini2020multitask, :\n\n[9] : : : santos2020data, :\n\n[10] : :.. :. :\n\n[11] : :... :. :: :\n\n[12] : : : : : liao2020c, :. :.:....\n\n[13] :\n\n[14] : : aixi2019mrc, :\n\n[15] :\n\n[16] :... :.... :.. :.\n\n[17] : : :.., ::  :.\n\n[18] : : : : zhou2018focal: aixi2019mrc, :\n\n[19] : : :,... :,.... :\n\n[20] : :\n:\n\n[21] : : : :\n\n:\n:\n\n:\n..\n:\n\n\n[22",
    "b5bc34e1e381dbf972d0b594fe8c66ff75305d71": " Ablation studies also demonstrate the robustness of the proposed DSC loss for accuracy-oriented tasks and that the proposed method requires hyperparameter tuning in TI (S\u00f8rensen\u2013Dice coefficient). We hope this work can be extended to a broader range of tasks.\n\nAcknowledgement\n\nThe work is supported by National Key Research and Development Plan (2018YFC0702000), the Fundamental research funds in National Social Science Funds (19YZX04005), and National Social Science Foundation of China (17ZDA035).\n\nReferences\n\n[1] C. S\u00f8rensen, and E. D. Tversky. A general method for comparing similarity relations between sets of elements. Journal of the American Statistical Association, Vol. 74, No. 347, pp. 311-16, (1979).\n\n[2] J. Liang, L. Song, D. Cao, and S. X. Xie. The Role of Data Imbalances in Neural Network Training. Transactions of the Association for Computational Linguistics, Vol. 3, (2019), pp. 1499\u20131534.\n\n[3] W. Liu, J. Zhu and Q. Xiong. Textual Relation Extraction via Ranking the Confidence of Entity Pairs. In ACL-IJCNLP 2019, pp. 778\u2013796.\n\n[4] J. Li, D. Cao, R. Wang, and X. Zhang. Learning to Predict the Weighing Coefficients in Data Augmentation for NLP. In AAAI, pp. 4429\u20134445.\n\n[5] J. Liang, Q. Xiong and D. Cao. Learning to Predict Padding Samples for Improving Label Distribution in Text Classification. In ACL-IJCNLP 2019, pp. 3627\u20133640.\n\n[6] E. Kontopoulos, L. Grefenstette, S. Alyoshina and E. F. Chi. The Influence of Label Frequency and Imbalanced Data Samples on Neural Language Models for Zero-Shot Cross-Lingual Transfer Learning. In EMNLP-IJCNLP, (2018).\n\n[7] A. Dhillon, Z. Agarwal, S. Banerjee, T. Sainath, T. Sahu and G.",
    "72f7ef55e150e16dcf97fe443aff9971a32414ef": " Ablation studies show that the dice loss can also improve accuracy-oriented tasks, although this improvement is not as considerable as F1.\n\nFuture works include exploring other approaches to address data imbalance, such as adversarial training BIBREF45, reweighting losses BIBREF46, and the attention mechanism from the Transformer network BIBREF47, as well as the performance comparison between our method and other data-imbalance strategies, which include sample weights learning BIBREF25, BIBREF48, BIBREF18, BIBREF19.\n\nAcknowledgments\n{\nThis work was supported by the National Key R\\&D Program of China (grant No.2018YFB1005002, 2018YFB1005004); National Natural Science Foundation of China under Grant No.61871049; Fundamental research funding of the Ministry of Science and Technology of China (grant numbers 2019Z3B13), Knowledge Innovation Project (grant numbers 2019YFB2105000, 2019YFB2105002), Science and Technology Development Fund (grant numbers SZ20184100 and 2018460101); China Scholarship Council; XJTLU research fund (grant numbers B11019, B12026, B13088); and the Fundamental Research Funds for the Central Universities (grant numbers ZJZ1722).\n\n\n## Table of Contents\n\n  * Title Page\n  * Copyright Page\n  * Dedication\n    * To the people who care for our children\n  * Acknowledgments\n    * _To Alessandra_, who took the time\n  * Prologue\n    * _And to Luce, who made it work_, and to my parents, who first encouraged me to write, before I knew how\n  * Part One\n    * \n      * Chapter 1\n      * Chapter 2\n      * Chapter 3\n    * \n      * Chapter 4\n    * \n      * Chapter 5\n      * Chapter 6\n      * Chapter 7\n    * \n      * Chapter 8\n   * Part Two\n    * \n      * Chapter 9\n      * Chapter 10\n    * \n      * Chapter 11\n      * Chapter 12\n    * \n      * Chapter 13\n  * Part Three\n    * \n      * Chapter 14\n      * Chapter 15\n    * \n      * Chapter 16\n    * \n      * Chapter 17\n  * Ep",
    "20e38438471266ce021817c6364f6a46d01564f2": " We also argue that the proposed training loss is actually sensitive to hyperparameters (e.g., tradeoff between precision and recall for TI).\nAcknowledgments\nThis work was conducted while the first author was working in the Zanran Technology in Shanghai for part of the work. We appreciate Zanran Technology in helping us complete the work, and Zhiyun Shen for his suggestions about the text.\nNotes and References ::: References\n[BIBREF1]\n\nD. R. S\u00f8rensen and T. M. Lund, \"A Note on the Measures and Tests for Similarity in Information Theory,\" Information and Control, 8 (1971), pp. 671-674.\n\n[BIBREF2]\n\nL. H. Tan and J. W. W. Ang, \"A Study of Data Imbalance Problems in Natural Language Processing.\" In Proceedings of NTCIR-9 Workshop on Data Imbalanced Research in Information Retrieval, 2015.\n\n[BIBREF3]\n\nL. H. Tan, H. Y. Ng, C. H. Chen, and Y. Y. Zhou, \"Dataimbalance-aware Adaptive Loss Functions for Named Entity Recognition Tasks,\" 2015 Annual Conference on Neural Information Processing Systems, pp. 2626-2631, 2018.\n\n[BIBREF4]\n\nP. Shrivastava, N. P. Li, V. K. Jain, and J. Agarwal, \"OHEM: Online Hard Example Mining for Improving the Efficiency of Training Machine Learning Models,\"\n\nin 32nd International Conference on Machine Learning and Applications, 2018.\n\n[BIBREF5]\n\nK. V. Gopalu, R. Jain, and M. S. Kambhatla, \"Unbalanced-Data Mitigation in Learning with Multi-class Loss,\" in Advances in Neural Information Processing Systems, 2018.\n\n[BIBREF6]\n\nP. S. Kulkarni, A. Kumar, M. S. Kambhatla, and R. Jain, \"Unbalanced-Data Mitigation in Learning with Max-margin Loss,\" in Advances in Neural Information Processing Systems, 2018.\n\n[BIBREF7]\n\nG. Y. Chen and S. Qin, \"Data-",
    "28067da818e3f61f8b5152c0d42a531bf0f987d4": " As the references can be many sentences long in WikiBio, the table-to-text model makes use of beam search to sample possible output sequences at test time. Table TABREF57 shows some example outputs as extracted by our information extraction system.\n\nExample Evaluations\nTable TABREF60 shows some examples of instances on which different metrics perform well, while others do fairly poorly. Table TABREF55 shows that BLEU, ROUGE and iBLEU have worse correlations in WikiBio as compared to a baseline template-based system. This is expected since references are divergencing from each other, and hence they do not match the table that the model produces. While BLEU scores degrade to zero when no overlap is found, the rest of the metrics do not penalize sentences which do not accurately represent the table. Instead, they depend on comparing the table with other sources. For instance, BLEU computes the overlap of the table and the reference, and gives larger weights to such sentences than the ones which do not match the table at all. This can lead to scoring negative F-scores even on instances where the references do not mention all the attributes in the tables. Since many instances in WikiBio contain such references Table TABREF56 also has a zero F-score when computed over the divergent references. On the other hand, BLEU computes the overlap between the reference and a truncated version of the table, which is biased towards the references which mention the most attributes in the tables. All the metrics we compare are based on this truncated version of the table, and hence all of them give negative scores for the divergent references. However, Table TABREF57 highlights that using the whole table (PARENT-W) leads to a positive value on all the instances with missing attributes, and hence they all can be rated as satisfactory.\nEvaluation via Information Extraction\nBLEU\n\nBLEU, which counts overlap between the table, truncated table and the reference, was designed for assessing translation, where there might not be an actual table. It can be used in the context of table-to-text generation BIBREF6, but it should have been designed specifically for this task. For tables where many attributes are missing from the reference, BLEU can give negative F-scores even if the table itself has accurate information. This occurs since BLEU tends to treat instances where all attributes are missing as similar to those where only a few of them are",
    "bf3b27a4f4be1f9ae31319877fd0c75c03126fd5": " The first two references are typical of references in WikiBio. They express the same or similar information as the table, however with additional information. The third reference is a more challenging case as it contains no information about any of the attributes/entities in the table. For the last reference, the system produces a very fluent and grammatical text. To our knowledge, this is the highest quality output for WikiBio (cf. Table TABREF32 ), and its generation is dominated by the fluency.\nFor further example outputs, we encourage readers to visit our project page BIBREF45.\n\nIntroduction\n\nIn this work, we aim to generate more faithful descriptions of objects and events using neural table-to-text generation systems BIBREF0 BIBREF1, and information extraction systems BIBREF1 which parse tables into (entity, attribute, value) tuples.\n\nSpecifically, we study four distinct NLG settings, each with various degrees of paraphrasing of table content compared to the references:\nWikiBio BIBREF2: generating natural language descriptions of Wikipedia tables;\nBasketball Game Tables BIBREF3: generating descriptions of table based game scores;\nE2E-NLG BIBREF4: generating descriptions of RDF triples extracted from Wikipedia articles;\nWebNLG BIBREF6: generating descriptions of RDF triples extracted from Wikipedia pages.\n\nWe also compare the two types of reference evaluations we mentioned earlier: (i) evaluation using the table itself, where we only require the generated text to correspond to a small fraction of information entailed by a table (cf. \u00a7 SECREF3 ); and (ii) evaluation using the table itself along with the reference, where we require the generated text to correspond accurately to all information in the table (cf. \u00a7 SECREF23).\n\nLastly, we apply a broad range of metrics BIBREF37 to generate a set of scores for each neural model, each of which describes tables in a semi-structured format. These scores need to be calibrated in some way into real-valued scores reflecting human judgment of the quality of the model.\n\nContents\nThe rest of the paper is structured as follows. \u00a7 SECREF2 introduces the task setting and discusses recent literature BIBREF2 BIBREF8 in the area. \u00a7 SECREF3 presents our evaluation methods BIBREF1. \u00a7 SECREF40",
    "ffa7f91d6406da11ddf415ef094aaf28f3c3872d": " We list the precision, recall and F-scores for each of the (attribute, value) pairs extracted from the reference and the table. We also list the average F-scores across all attributes and values of PG-Net.\nTo evaluate generated texts, we randomly sample from the model predictions for both INLINEFORM1 and INLINEFORM2 for all the evaluation subsets. From the predictions, we select the one which is (1) most frequently selected by humans in the human evaluation, as done in BIBREF1, BIBREF23, BIBREF29 and BIBREF40, and (2) has the highest PARENT score, as computed in \u00a7 SECREF21.\nThe first requirement is a more lenient version of the content selection heuristic used in \u00a7 SECREF36, while the second is a relaxed version of recall. Following this, we generate sentences of up to 40 words using PG-Net with these selections, and parse them into tuples (attribute, value) pairs. Then our information extraction system computes F-score between the tuples INLINEFORM6 and INLINEFORM8 (for pairs from INLINEFORM1 ) and (attribute, value) pairs extracted from the ground truth tables. See Appendix SECREF52 for details of the information extraction pipeline.\nPARENT Metric\nWith the information extraction system, we compute a different set of metrics as compared to \u00a7 SECREF4. In particular, we compare to the four standard metrics of BIBREF8 as well as the standard metrics that operate over only the reference (BLEU-T, RG-F, RG) and against only the table (BLEU-T-T, RG-F-T, RG). Table TABREF61 reports the average F-scores of these methods on the development set as well as over all the evaluation runs.\nWe also include a BLEU variant that combines both the table and the reference into a single reference to account for cases where tables exhibit hallucination (i.e. they mention information not present in either the table or the reference), denoted as BLEU-T-T. To compute this metric, we used the training set and reference texts for WebNLG. For the human evaluation score for each model we use Thurstone's method introduced in \u00a7 SECREF33, as implemented in BIBREF29 for iBLEU. When evaluating metrics on the WebNLG development set",
    "b634ff1607ce5756655e61b9a6f18bc736f84c83": "\n\nThe code and data are available on the author's website.\n\nAcknowledgements\n\nC.E. thanks the Centre for Research on Financial Cryptoeconomics (CRFC) for funding this research.\n\nNotes and references\n\n[1]\n\nLoughran, R. and M.J. McDonald (2013) Mining the Web for Investment Information. Quantitative Finance 12, 14\u201330.\n\n[2]\n\nCulotta, A., W. J. Cochrane, and M. J. Gatheral (2015) Understanding the Market: Exploratory Sentiment Analysis and Predictive Trading Volume. Journal of Statistical Economics 130, 1043\u20131066.\n\n[3]\n\nBretto, F., E. A. T. Uz, and M. A. Nowak (2019). Twitter-Based Sentiment Analysis: How Much Predictive Information Does the Social-Media Ecosystem Enrich? Journal of Electronic Finance 24:1, 6\u201324.\n\n[4]\n\nCulotta, A., E. A. T. Uz, and M. A. Nowak (2017) Twitter Sentiment on the Dow: New Evidence and New Techniques for Forecasting Stock Market Returns. Working Papers in Corporate Finance Series 20, Department of Economics Working Paper 17-26, University of Michigan.\n\n[5]\n\nCulotta, A. and E. A. T. Uz (2018) Financial Sentiment: Disentangling Fact from Noise. Journal of Finance 82(2), 513-541.\n\n[6]\n\nHong, K. and J. V. Stein (2013) Empirical Tests of the Hong-Stein Reversals Regime: Evidence from the Consumer Confidence Index. Journal of Finance 68(4), 1155\u20131204.\n\n[7]\n\nYermack, A. and B. Stein (2013) Stock Market Reversals and Volatility: An Empirical Analysis on the Emissions from Power Plants. Journal of Financial Economics 90 (4), 753\u2013772.\n\n[8]\n\nKorabikis, A., D. N. Zervas, and Y. Yang (2017) Financial and Economic Volatility in the Business Press and the CPI: a Quantile Regression Approach. Journal of the American Statistical Association 122",
    "2f901dab6b757e12763b23ae8b37ae2e517a2271": "\nReferences\n\n1.\n\nBengio S., et al., 2014: Learning Phrasal Structure with RNNs. NIPS, 2014.\n\nBengio S., et al., 2003: Learning Multiple Layers in Recurrent Neural Networks, NIPS, 2003.\n\nBengio S., et al., 2017: Gated Recurrent Units. ICCV, 2017.\n\nBengio S., et al., 2011: Deep Learning with Recurrent Neural Networks, NIPS, 2011.\n\nBengio S., et al., 2013: Architecture-Aware Optimization and Inference for Language Models with Recurrent Neural Networks and Attention. NIPS, 2013.\n\nKumar D., et al., 2017: Zoneout: Zone-aware, Stochastic Gradients for Deep Neural Networks. ICLR, 2017.\n\nHuang H., Lee C.-C., 2017: Masked Gated Convolutional Neural Networks for Natural Language Processing. ArXiv, 2017.\n\nIyyer M., et al., 2016: Dropout Guided Averaging for Very Deep NN. ArXiv, 2016.\n\nKumar D., et al., 2017: Variational Recurrent Dropout, ICLR, 2017.\n\nLiu H., et al., 2015: Recurrent Dropout: An Efficient Regularization Method for LSTMs. ArXiv, 2015.\n\nNishida W., et al., 2016: Bidirectional T-RNNs for Sequence Modeling. ArXiv, 2016.\n\nPeewee D., et al., 2015: Convolutional Long Short-Term Memory Recurrent Neural Network for Language Modeling, NIPS, 2015.\n\nZhang T., etal., 2016: Neural Network Language Modeling with Recurrent-Convolution Neural Networks, ArXiv, 2016.\n\nAcknowledgments\nWe thank Vishnu Srinivasan, Abhinav Gupta, and Daniel Leavitt for valuable discussions. For the language modeling experiments, we used code provided by Denny Gupta.\n\nCitations of this work should use the following reference:\n\n@Manuscript(2019):Layman2018QuasiRNNs,\n\n@article{Layman2018QuasiRNNs,\n  author =   {Layman, Andrew and Gupta, Denny and Ghaz",
    "b591853e938984e6069d738371500ebdec50d256": "\nAcknowledgments\n\nThis work is based on contributions from the BIST project, funded by the USARL CSTB and Intel PAR. We'd also like to thank Google's AIML group for generously providing us a free evaluation of their GPU cloud computing resources and GPUs. We thank our coauthors, Joshua Tingley and Patrick Chang, on the T-RNN paper for providing useful discussions about QRNNs and for an independent implementation of several key techniques.\n\nReferences\n\nBIBREF0.\nhttp://arxiv.org/abs/1408.1555\n\nhttp://jzj.ccf.nju.edu.cn/papers/t-grnn.pdf\n\nBIBREF0.\nBIBREF1.\n\nhttp://www.aclweb.org/anthology/J15\u20131017.pdf\n\nBIBREF1.\nhttp://www.aclweb.org/anthology/W15\u20130869.pdf\n\nBIBREF1.\n\nhttp://arxiv.org/abs/1508.01601\n\nBIBREF2.\n\nhttp://arxiv.org/abs/1410.1833\n\nBIBREF2.\n\nhttp://arxiv.org/abs/1611.00042\n\nBIBREF2.\n\nhttp://arxiv.org/abs/1411.1492\n\nBIBREF3.\n\nhttp://arxiv.org/abs/1409.1114\n\nBIBREF3.\nhttps://www.aclweb.org/anthology/D15\u20131143.pdf\n\nBIBREF4.\n\nhttps://www.aclweb.org/anthology/D18\u20131266.pdf\n\nBIBREF5.\n\nhttps://dl.acm.org/doi/10.1145/3400.3420\n\nBIBREF6.\n\nhttp://www.aclweb.org/anthology/W15\u20130848\n\nBIBREF7.\n\nhttp://www.aclweb.org/anthology/W16\u20130617\n\nBIBREF8.\n\nhttp://arxiv.org/abs/1408.1571\n\nBIBREF8.\n\nhttp://rnn.liupeng.me/papers/acl",
    "a130306c6662ff489df13fb3f8faa7cba8c52a21": " In practice, we used a target length of 10 to avoid excessively long hypotheses. However, we found this criterion both sufficiently discriminative and sensitive to INLINEFORM1 values, even at 5, on the more complicated evaluation corpora.\n\nAcknowledgments\nWe would like to thank Noam Shazeer for his advice and insight into QRNN architectures, and to both Bishvat Tsur and Jiongxuan Xu for their comments on the manuscript.\nReferences\n\n1.  Krizhevsky, A., Sutskever I., Higgins J., Sutskever D.  2015. ImageNet Classification with Deep Convolutional Neural Net.,.\n\n2.  Sutskever, I., Martens L., Jafar D.  2017. Sequence to Sequence Learning with Neural Networks.,.\n\n3.  Sutskever, I., Choromanski L.  2014. Dynamic Routing Between Convolutional and Recurrent Neural Networks..\n\n4.  Cho, K., Gulcehre C., Zhang Y.  2014. Learning Phrases and Factored Distributed Representations. .\n\n5.  Cho, K., Van Merri\u00ebnboer B.A.  2018. A Unified Neural, Probabilistic, Multi-Objective Language Model for Neural Machine Translation..\n\n6.  Sutskever, I., Martens L., Jafar D.  2017. Recurrent Neural Networks, Attention, and LSTMs.,.\n\n7.  Sutskever, I., Martinez B., Sordoni C.  2017. Question Answering with Attention and Memory Networks..\n\n8.  Sutskever, I., Martens L., Sordoni C.  2017. Learning to Ask Questions and Answering Them as Deep Representation Learning Problems..\n\n9.  He et al.  2016. Long Short-Term Memory Recurrent Neural Networks.,.\n\n10.  Sutskever, I., Zhang Y.  2017. The RNN Challenge.,.\n\n11.  Rajeswaran, J., Zhang Y., Lipton D.B.  2018. End to End Memory Networks.,.\n\n12.  Bahdanau, D., Chopra",
    "b1cf5739467ba90059add58d11b73d075a11ec86": "\nBlock Zoo. The Block Zoo would be extended to cover more common NLP components, such as Bias Correction, Pointer Network, etc. The Model Zoo is also planned to be extended to more NLP tasks, such as question generation and summarization.\nModel Zoo. Most of the end-to-end network templates are constructed with RNN, CNN, and attention layers. In the future, we will try to explore better configurations with Transformer and Highway network.\nPlatforms. As one promising direction in the future, we would try to integrate NeuronBlocks with more resource management platforms like AutoNLP BIBREF18, CloudTPU BIBREF19, and SparkMLBIBREF20.\nAcknowledgments\nThis work was supported in part by Alibaba Cloud, Baidu AI Lab and Alibaba Deep Learning Platform. \nNeuronCaps: Deep Learning for NLP Tasks\n\nChanghan Yu, Yifan Hu, Ming-Ming Ma, Zhaozhe Wang, Hao Zhang\n\nAbstract: While neural networks have been widely used for Natural Language Processing (NLP) tasks in industry, their adoption and deployment is hindered by several challenges such as productivity and user experience. Previous efforts such as TensorFlow Hub BIBREF21, AllenNLP BIBREF22, and OpenNMT BIBREF23 have provided abstractions to address some specific problems. However, they cannot be adopted in large scale, and lack the capability of supporting flexible components based on current mainstream DNNs. Thus, we propose a new neural network toolkit named NeuronCaps to serve as an open-sourcing and community-driven solution to boost the productivity and user experience for developing DNN for NLP tasks.\n\nChallenges\nWe surveyed 100 NLP engineers from two industry-scale platforms and found that over 85% of surveyed engineers used to develop and deploy DNN deep learning based NLP models. But a typical survey identified that they faced numerous barriers when they develop NLP neural networks. These challenges are summarized into the following two aspects\n\n[itemsep = -0.4em,topsep = 0.3em, align=left, labelsep = -0.6em,leftmargin = 1.2em]\n\nInterpretability for engineers: The black box neural network often hinders the engineering efficiency and efficiency of applications. Engineers need to do deep",
    "2ea4347f1992b0b3958c4844681ff0fe4d0dd1dd": "\n[itemsep= -0.4em,topsep = 0.3em, align=left, labelsep=-0.6em, leftmargin=1.2em]\n\nAiming towards the next level of abstraction, NeuronBlocks is extended to support other popular back-ends including TensorFlow BIBREF18 and JAX BIBREF19. This extension is required for the future interoperation with other open-source toolkits for NLP purposes.\n\nOn top of the toolkits for back-ends, NeuronBlocks is extended to support more specific NLP tasks involving more neural network architectures, such as neural machine translation and dialogue reasoning. The current module gallery needs to be further enriched with more common components for sequence extraction and dialogue reasoning tasks.\nFurthermore, NeuronBlocks has strong compatibility with existing deep learning frameworks and toolkits in NLP, such as OpenNMT, AllenNLP and Huggingface. We continue to improve the interoperation mechanisms of these toolkits with our block zoo. Such improvement allows the toolkits to share components or models built with NeuronBlocks, thus improving productivity for model development.\n\nWe are also planning to collaborate with the related open-source groups like DeepSpeed BIBREF4 for joint exploration of the new deep learning architectures for NLP tasks.\n\n[itemsep= -0.4em,topsep =0.3em, align=left, labelsep=-0.6em, leftmargin=1.2em]\n\nZhang, P., Dyer, C. C., & Manning, C. D. (2018): Attention is all you need: Building an effective language model, in Proceedings of the 2017 Conference of the Association for Computational Linguistics (ACL 2017), pp. 1785 \u20131792.\n\nLiu, X., Liu, K., & Yan, Q. (2018). Attention is all you need? A simple view of bidirectional attention. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pp. 3439\u20133449.\n\nHe, M. R., Ranzato, M. A., Zoph, B., Pfeiffer, F., & Dean, J. (2016): Distilling the Knowledge in a Neural Network, in Proceedings of the 30th International Conference on Learning Representations, 2016.\n\nSchuster",
    "4f253dfced6a749bf57a1b4984dc962ce9550184": " Firstly, we will expand the model zoo and add more common NLP tasks and end-to-end network architectures. Secondly, more customizable blocks based on attention mechanism will be added into the gallery of Block Zoo. Thirdly, NeuronBlocks could be extended to support more platform, such as Google's TPU and Baidu's Deep AI.\n[itemsep= -0.4em,topsep = 0.3em, align=left, labelsep=-0.6em, leftmargin=1.2em, font = \\normalfont\\Boldfont\\nab\\bfseries\\leftjustify]\n\nAcknowledgements: Thanks to the members of the search engine project group, especially the founders Jincai Liu and Yufeng Huang. We would like to thank Ying Li, Chenjun Lu and Xinqi Zhang for their help on data processing as well as helpful discussion on the toolkit. We also apologize for the obvious mistakes in the paper.\n[itemsep= -0.4em,topsep = 0.3em, align=left, labelsep=-0.6em, leftmargin=1.2em, font = \\normalfont\\Boldfont\\a:Nab\\bfseries\\leftjustify]\n\nNotes\nSome of the design ideas in this paper are inspired by AutoGluon BIBREF18 and TPU Toolkit BIBREF19. We are also grateful to the organizers and reviewers of EMNLP 2020 conference paper workshop, where this work has been presented.\n[itemsep= -0.4em,topsep = 0.3em, align=left, labelsep=-0.6em, leftmargin=1.2em, font = \\normalfont\\Boldfont:Nab\\bfseries\\leftjustify]\n\nReferences\n\n[itemsep= -0.4em,topsep = 0.3em, align=left, labelsep=-0.6em]\nAnderson, J., Hui, C., Zhang, T., Huang, Y., and Li, Y.-J., 2018. Fast.ai. https://www.fast.ai/projects/docs/Neural-networks-with-PyTorch/\n\nChowdhery, S., Dredze, H., and Fisch, D., 2015. A novel method for training neural networks",
    "dc1cec824507fc85ac1ba87882fe1e422ff6cffb": "\nACKNOWLEDGEMENT\n\nThis research work was partly supported by the University Grant by Indian Department of Science and Technology. We would like to acknowledge Dr. Debajit Das with his valuable feedback regarding this work.\nREFERENCES\n\nREFERENCES\n\nBandyopadhyay S. et al., \"A Survey on Bengali Text Question Classification using Machine Learning Techniques\", International Journal of Machine Learning and Computing, Vol. 2 (2), 2015.\n\nBanerjee S., \"A Rule Based Approach towards Bengali Question Classifers and a Feature Extraction Based Bengali Question Classifier\", International Journal of Machine Learning and Computing, Vol. 5 (5), 2017.\n\nFareed, A. H. et al., \"English QA System Over Bengali Dialects with Syntactic Analysis\", International Journal of Machine Learning and Computing, Vol. 1 (4), 2013.\n\nHaq M. S. et al., \"Factoid Questions Classification using Question Analysis and Answer Type Analysis\", International Journal of Machine Learning and Computing, Vol. 2 (2), 2014.\n\nHassani K. et al., \"Bengali Text Question Classification and Answer Type Classification Using Natural Language Processing Tools and Feature Extraction Techniques\", International Journal of Machine Learning and Computing, Vol. 6 (3), 2018.\n\nKumar S. et al., \"Performance Evaluation and Classifier Algorithms Comparative Analysis of Arabic QA Systems\", International Journal of Machine Learning and Computing. Vol. 6 (2), 2018.\n\nPoonam Choudhary and Chirashi D. Kaur, \"A Comparative Analysis of Various Question Classifier Algorithms in Machine Classification of Text Data\", International Journal of Machine Learning and Computing, Vol. 5 (2), 2017.\n\nSomnath Banerjee, \"Machine Learner for Bengali Question Classifier\", International Journal of Machine Learning and Computing, Vol. 2 (3), 2014.\n\nSyed Mehedi Hasan Nirob, \"A Survey of Bengali Q&A Question Classification and Text Question Classifiers for Bengali, English, and Hindi-Urdu: An Empirical Study\", International Journal of Machine Learning and Computing, Vol. 3 (1), 2015.\n\nXin Li, Dan Roth, \"A New Set of Question Categories for TREC Systems\",",
    "f428618ca9c017e0c9c2a23515dab30a7660f65f": "\nAcknowledgments\nI deeply thank the University of Dhaka as without providing support and help, this work would have not been possible to complete. And I deeply thank my father, my family and my friends. And I am grateful to my department's librarian Mr. Asifur Rahman and Mr. Md. Jahidur Bhai for helping me through out this research.\n\nTable I\nQuestion classes based on two layer taxonomy and their description.\nTable II\n\nAccuracy and F1 score of 7 different classification algorithms using different features.\nTable III:\n\nQuestion classes based on two layer taxonomy and their description.\nTable IV:\n\nAccuracy and F1 score of 7 different classification algorithms using different features.\nList of used abbreviations.\n\nBibliographic References\n\n1. S. Gopinath and Kalyan Ramaswamy. A Survey of Bengali question QA System from Question Word to Answer Generation. International Journal of Information and Knowledge Management, 2013. pp. 1-17. http://link.springer.com/article/10.1007/s41415-013-0015-4.\n\n2. G. Shibnath. A Survey of Bengali Question Classification and QA System. International Journal of Computer Applications, 2014. pp. 930-934. http://link.springer.com/article/10.1186/s12859-014-0117-4.\n\n3. Pranay Kumar Dey. Developing a Question Answering System (QAS) based on Bengali Language and Machine Learning. https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6790589\n\n4. J. Kocmi, K. Nussbaum, G. Shibnath et al. BanglaWAS (Bengali Question Answering system in Wikipedia). In Proceedings of the 14th ACM International Conference on Web Search and Data Mining (WSDM'11), 2011. pp. 15-23. http://citeseerx.ist.psu.edu/kocmi11/pdf/Kocmi11BanglaWAS.pdf.\n\n5. A. Banerjee, R. Mukherjee, S. Sarkar, & M. Bandyopadhyay",
    "8ce11515634236165cdb06ba80b9a36a8b9099a2": "\n\nThis work was supported in part by a Grant-in-Aid for Scientific Research (S) 18K12176 from the Japan Society for the Promotion of Science. We would also like to thank the anonymous reviewers for their comments and valuable insights for this paper.\n[1] Cho, K., & Bahdanau, D. (2014) Neural Machine Translation by Jointly Learning to Align, Translate, and Reconstruct. In Proceedings of the 24th Conference on Computational Natural Language Learning (CoNLL), pages 18\u201324.\n[2] DzmitryBahdanau, K., Chopra, S., & Le, Q. V. (2015) Neural Machine Translation by Jointly Learning to Align, Translate, and Reconstruct. In Proceedings of the 26th Conference on Computational Natural Language Learning (CoNLL), pages 113\u2013122.\n[3] Dong, X., Sun, Z., & R\u00e4ih\u00e4, L. (2017) Overcoming Under- and Over-Translation: A Contextual Attention Mechanism for Neural Machine Translation. In Proceedings of the Thirty-First International Conference on Computational Linguistics (COLING), pages 1665\u20131673.\n[4] Jiang, T., Sennrich, R., Zhang, G., & Haddow, B. (2016) Fast Neural Text Translation using Convolutions. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL), pages 2118\u20132127.\n[5] Kaji, H., Nakayama, T., & Katsumata, T. (2017) Attention-Based Neural Machine Translation at Scale: Learning to Augment Bidirectional Recurrent Neural Networks. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL), pages 2153\u20132159.\n[6] Kudo, A., Inui, K., & Iwata, J. (2016) Attention-Based Neural Machine Translation for Text Generation. In Proceedings of the 25th Conference on Computational Natural Language Learning (CoNLL), pages 19\u201327.\n[7] Kudo, A., Yamada, S., & Iwata, J. (2016) Attention-Based Neural Machine Translation for Text Summarization. In Proceedings of the 25th Conference",
    "6024039bbd1118c5dab86c41cce1175d99f10a25": "\n\nAcknowledgement\nWe would like to thank Kiyoshi Tu and Tomohiro Miyazaki for guiding our experiments, and Yoshinori Mekaru for the great discussions.\n\nBibliographical Note\n\n1.. Bahl, C., K. Cho, M. Kalchliut. 2015. The Attention-based RNN Reader: A Sequiturial Architecture for Neural Machine Translation. Proceedings of the 32nd Conference of the Association for Computational Linguistics,\n\nVol. 1: Human Language Technologies: Clinical Natural Language Processing, pp. 1120\u20131138, Atlanta, USA.\n\n2.. Cho, K., M. Kalchliut. 2014. A Gradient-based Training Algorithm for Neural Machine Translation. Proceedings of the 24th International Workshop on\nNatural Language Generation and Evaluation, pp. 24\u201332, Prague, Czech Republic.\n\n3.. DzmitryBahdana, D. 2014. Sequence-to-sequence Learning with Neural Networks. CoRR, abs/1412.3564, ArXiv:1412.3564.\n\n4.. S. Ding, K. Cho. 2015. Fast and Accurate Neural Machine Translation by Augmented Constant Phrasing. Proceedings of\n\nthe 32nd Conference of the Association for Computational Linguistics: Human Language Technologies: Clinical Natural Language Processing, Los Angeles, CA, USA.\n\n5.. S. Ding, K. Cho, H. Jain. 2015. Fast and Accurate Neural Machine Translation by Augmented\n\nConstant Phrasing. Proceedings of the 34th Annual Meeting of the Association for Computational\n\nLinguistics, pp. 1325\u20131327, Philadelphia, PA, USA.\n\n6.. Du, C.S., Y. Li, C. Xu. 2016. Coverage-Based Phrase-Level MT Evaluation Method for Neural Machine Translation:\n\nAn Empirical Study. Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics, Florence, Italy.\n\n7.. DzmitryBahdana, D. 2016. Sequence-to-sequence Learning with Neural Networks. CoRR, abs/1610.00387, ArXiv:1610.00387.\n\n8.. Kahlau, S., S. Schuster, C",
    "de5b6c25e35b3a6c5e40e350fc5e52c160b33490": " INLINEFORM24 = INLINEFORM25.append( INLINEFORM26 ) INLINEFORM27 = INLINEFORM28 + INLINEFORM29 In[ INLINEFORM18 ] LabelGenerationReference,sentences, lengthLimit INLINEFORM0 =.append( INLINEFORM19.replace(Label, INlineInfo ) INLINEFORM25( )[len( INLINEFORM20 > lengthLimit) ] INLINEFORM28 INLINEFORM34 = LabelGenerationReference( sentences, lengthLimit ) LabelGenerationReference,sentences, lengthLimit INLINEFORM0 = \u03c1 INLINEFORM1 = INLINEFORM2.append( INLINEFORM20 ) INLINEFORM30 INLINEFORM31 INLINEFORM32 INLINEFORM33 INLINEFORM34.append( INLINEFORM27 ) INLINEFORM35 INLINEFORM36 = INLINEFORM37 INLINEFORM14 INLINEFORM5 = INLINEFORM25.append( INLINEFORM32 ) INLINEFORM37 = LabelGenerationReference( sentences, lengthLimit ) INLINEFORM34 This algorithm is designed to generate the extractive labels based on the human-made abstractive summaries, i.e. abstracts. The algorithm extract_from_abstract( LabelGenerationReference, sentences, lengthLimit INLINEFORM0 ) LabelGenerationReference = LabelGeneration( sentences ) INLINEFORM0 = LabelGenerationReference.append( sentences.pop( ) [ INLINEFORM35] LabelGenerationReference, sentences, lengthLimit INLINEFORM0 =.append( INLINEFORM22 ) [ INLINEFORM37] LabelGenerationReference, sentences, lengthLimit INLINEFORM0 =.append( INLINEFORM19 ) INLINEFORM35 = labelGenerator.generate_extract( sentences ) INLINEFORM36 INLINEFORM37 = labelGenerator.generate_extract( sentences ) INLINEFORM27 INLINEFORM15[ INLINEFORM35 < lengthLimit INLINEFORM0 ] LabelGenerationReference,sentences, lengthLimit INLINEFORM0 =.append( INLINEFORM25 ) INLINEFORM33 INLINEFORM35 INLINEFORM36 INLINEFORM37 = labelGenerator.generate_extract( sentences ) LabelGenerationReference,sentences, lengthLimit INLINEFORM0 =.append( INLINEFORM20 ) INLINEFORM37 = labelGenerator.generate_extract( sentences ) LabelGenerationReference,sentences, lengthLimit INLINEFORM0 =.append( IN",
    "b66c9a4021b6c8529cac1a2b54dacd8ec79afa5f": " for sentence INLINEFORM1 in INLINEFORM21, INLINEFORM2 in INLINEFORM3 : if INLINEFORM9 : INLINEFORM15 INLINEFORM21 break INLINEFORM24 for INLINEFORM21 INLINEFORM3, INLINEFORM1 = 0 INLINEFORM2 INLINEFORM22= INLINEFORM5+ INLINEFORM10 INLINEFORM23 break ITERATIONAL( INLINEFORM11, INLINEFIELD0 INLINEFIELD1 : INLINEFIELD0 INLINEFIELD2 : INLINEFIELD2 0.0, INLINEFIELD1 INLINEFIELD3 : INLINEFIELD3 ) INLINEFORM25 INLINEFIELD3 = INLINEFIELD3 + INLINEFIELD1 break INLINEFORM26 INLINEFIELD3 = INLINEFIELD3 +1 INLINEFIELD5 INLINEFIELD1 : INLINEFIELD5 INLINEFIELD2 : INLINEFIELD3.append( INLINEFIELD4 INLINEFIELD3 ) INLINEFIELD1 = INLINEFIELD1 + INLINEFIELD2 INLINEFIELD2 = INLINEFIELD2 +1 INLINEFIELD3 INLINEFIELD4 : INLINEFIELD4 INLINEFIELD3: INLINEFIELD3.append( INLINEFIELD5 ) INLINEFIELD5 INLINEFIELD1 : INLINEFIELD1 INLINEFIELD2 : INLINEFIELD3.append( INLINEFIELD5 ) break INLINEFIELD6 INLINEFIELD1 : INLINEFIELD1 INLINEFIELD2 : INLINEFIELD2 3 ) INLINEFIELD7 : break INLINEFIELD8 INLINEFIELD1 : break INLINEFIELD10 INLINEFIELD1 : INLINEFIELD1 INLINEFIELD2 : if INLINEFIELD10 InlineField1 < sentence INLINEFORM3 : else: break INLINEFIELD10 sentence INLINEFORM3 : break INLINEFIELD16 INLINEFIELD3 = INLINEFIELD8 INLINEFIELD8 = INLINEFIELD10+1.append(0 INLINEFIELD10 ) ) INLINEFIELD9 : append( INLINEFIELD4 INLINEFIELD9 ) InlineField2 = INLINEFIELD1 in INLINEFIELD1,2 : if InlineField1 < sentence INLINEFORM3 : elsebreak INLINEFIELD12 in INLINEFIELD1,3 : if InlineField2 > INLINEFIELD2 : elsebreak INLINEFIELD14 sentence INLINEFORM1, INLINEFORM2 INLINEFORM3 : if INLINEFIELD",
    "6bfba3ddca5101ed15256fca75fcdc95a53cece7": "\nThis work was partially supported by the Qatar National Research Fund (QNRF).\n\nReferences\n\n<http://cs.hku.hk/~kuep/propaganda/> BIBREF0.\n\n<https://research.ibm.com/projects/ai_solutions/trustworthy-information/> BIBREF1.\n\n<https://web2.cs.uoregon.edu/\u223cm_muralu/proceedings/proceedings_2017.html#/v4.1/BIBREF2/BIBREF3/BIBREF4/BIBREF4.html BIBREF3.\n\nBIBREF4.\n\n<https://rudd.us/research/publications/BIBREF5.pdf/> BIBREF5.\n\n<https://www.facebook.org/business/news/BIBREF6.\n\nBIBREF6.\n\n<https://osf.io/yKFy3/download/> BIBREF7.\n\n<https://www.researchgate.net/publication/282365132_BIBREF8/file/argotario-annotated-corpus-en/>. BIBREF8.\n\n<https://osf.io/2T3qC/download/> BIBREF9.\n\n<https://www.researchgate.net/publication/264881693_BIBREF10/file/propagandist-news-corpus-and-fine-grained-propaganda-detection> BIBREF10.\n\n<https://osf.io/MJ1yH/download/> BIBREF11.\n\n<https://paperswithcode.com/project/propaganda-analysis-corpus> BIBREF12.\n\n<https://paperswithcode.com/task/propaganda-analysis-corpus?page=4> BIBREF13.\n\n<http://www-murl.eu/papers/LREC_Tutorials2016.html> BIBREF17.\n\n<http://www.facebook.com/tr?q=slogan> BIBREF18.\n\n<https://www.facebook.com/groups/BIBREF19.\n\n<https://www.facebook",
    "df5a4505edccc0ee11349ed6e7958cf6b84c9ed4": " The authors further acknowledge Alya Al-Hamad, Jalila Arslan, Tara E. Guo, Michael J. J. Kassner, Alaa Atef, Aliza Katz, Eman Jarrar, John A. Koeneman, and Souraya T. Rizvi.\n\nThe authors acknowledge generous financial support from the National University of Singapore (NUS) Research Agency (RAA), the Advanced Technology Application Center (ATAC) and the Singapore-MIT Alliance for Research and Technology (SMART), as well as the National University of Singapore (NUS) Office of the Associate Dean for Research (OADR).\nOpen Review\n\nThis manuscript was reviewed by the participants in NLP4IF@EMNLP-IJCNLP 2019 workshop. The authors acknowledge all reviewer suggestions that led to a significant improvement of the manuscript, especially: a much more detailed evaluation of the systems on the development set and an evaluation of the results on an external corpus, as well as the organization of an online-and-evaluated workshop to provide immediate feedback.\n\n  \n\n\nREF A1.\n\nR. Iyyer and T. Kikuchi, Evaluating the spread and impact of hoax and propaganda content online: An update, Proceedings of the 2016 Workshop on Automatic Content Extraction and Summarization (ACE2016), pages 14\u201317, June 14-18, 2016, Singapore.\n\n  \n\nBIBREF B1.\n\nH. Kieser and W. J. Duffy, A review of approaches and tools for automatic content extraction, Proceedings of the 15th Conference on International Conference on Language Resources and Evaluation (LREC'02), pages 1075\u20131079, May 9\u201314, 2002, Athens, Greece.\n\n  \n\nBIBREF B2.\n\nB. M. Iyyer, R. J. V. Murphy. The Stanford Hoax Archive: An annotated collection of hoax news stories from the Web.\n\nProceedings of the 11th International Conference on Language Resources and Evaluation (LREC'09), LREC, European Language Resources Association, 2009.\n\n  \n\nBIBREF B3.\n\nG. Tzanetakis and M. G. Ganesan, Propaganda detection through content analysis of news articles.\n\nProceedings of the 2015 Conference on Empirical Methods",
    "fd753ab5177d7bd27db0e0afc12411876ee607df": " QCRI developed the annotation scheme for the corpus and A Data Pro performed the annotation.\nBART\n\nThe paper is available in PDF format on the web-site http://arxiv.org or (for anonymous FTP) as /ai/papers/bart/9805.1267.pdf.\nReferences\n\n[BIBREF1]  W. Bebi, C. Fabbri, V. Marchetti, P. N. Maniatis, and A. Sorvietto, F. Ferro, V. Vellai, S. Rossi, S. De Sanctis, V. Jadbattista.\n\nNLP4IF Task on fine-grained propaganda detection through the lens of text similarity distance.\nIn Proceedings of 9th Language Technologies and Knowledge Engineering Conference (EMNLP-IJCNLP 2019), page 2, 2019.\n\n[BIBREF2]  S. Jafarinia, V. S. Sharma, and J. R. R. Uteger.\n\nFine-grained article-level propaganda and trustworthiness detection: a shared task at IJCNLP 2019: Towards a new generation of systems.\nIn Proceedings of 9th Language Technologies and Knowledge Engineering Conference (EMNLP-IJCNLP 2019), pages 1271\u20131279, 2019, Association for Computational Linguistics, Inc (ACL), 2019.\n\n[BIBREF3]  M. Hajij, S. D. C. E., G. Liu, and W. P. Yao.\n\nComparing deep classification and topic-based classification for binary propaganda detection.\nCoRR abs/1811.11185, 2018.\n\n[BIBREF4]  M. Hajij and A. Sorvietto, F. Ferro, S. Jafarinia, S. De Sanctis, V. Marchetti, P. N. Maniatis, V. Jadbattista, and R.-J. S.\n\nP. News-type classification of online newspapers by exploiting the semantic meaning of news articles.\nIn Proceedings of 4th Workshop on Argument mining for social networks (WASN 2019), page 4, Association for Computational Linguistics, Inc (ACL), 2019.\n\n[BIBREF5]  M",
    "88e62ea7a4d1d2921624b8480b5c6b50cfa5ad42": "\n[1] Kaczmarz, G.M. and Soo, A. (2005) Building Better Ontologies Using Latent Semantic Indexing Techniques and Co\u2013Occurrence Data. In Proceedings of the 11th International Conference on Intelligent User Interfaces (IUI '05). Seattle, WA, USA. Association for Computing Machinery, New York, NY, pp. 77\u201382.\n\n[2] Kaczmarz, G. (2005) Ontologies and User Interfaces. In K.T. Wobbrock, D. Schindler, and F.R. Kuhfeld (eds.), Intelligent User Interfaces. New Jersey, USA: John Wiley and Sons.\n\n[3] Kaczmarz, G.M., Kamps, P., and Soo, A. (2007) Measuring Word Similarity Using Word Co\u2013Occurrence Statistics. In Proceedings of the 13th International Conference on Intelligent User Interfaces (IUI '07). Vienna, Austria. Association for Computing Machinery, New York, NY, pp. 127\u2013135.\n\n[4] Kaczmarz, G.M., Kamps, P.K., and Soo, A. (2008) From Word Co-Occurrence Statistics to Co-Occurrence Indexes. In Proceedings of the 17th Intelligent User Interfaces Conference (IUI '08). Boston, MA, USA. Association for Computing Machinery, New York, NY, pp. 163\u2013170.\n\n[5] Caviedes, C.R., Loper, E.N., and Smyth, P. (2004) Finding Similar Words in Biomedical Literature Using Co\u2013occurrence and Contextual Context. In Proceedings of the 14th European Semantic Web Conference. Edinburgh, UK, pp. 53\u201360.\n\n[6] Caviedes, C.R. (2009) A Query-Based Approach to Information Retrieval for Biomedical Information. PhD thesis. Department of Computer Science, University of Edinburgh. Electronic Thesis and Dissertation Repository. Edinburgh: The School of Informatics, University of Edinburgh.\n\n[7] Jannidis, E., Kaczmarz, G.M., Fazly, H., and Soo, A. (2010) Measuring Word",
    "4dcf67b5e7bd1422e7e70c657f6eacccd8de06d3": "\nReferences\nMuneeb, B., and L. Pakhomov. 2015. Evaluating Semantic Similarity and Relatedness Measures: A Comprehensive Benchmark Analysis. NLP-CfC. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 783\u2013827.\n\nPakhomov, M., J. Toutanova, and L. Pakhomov. 2016. A Corpus-based Approach to Measuring the Semantic Relatedness of Terms in Medicine. NLP-CfC. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 1601\u20131614.\n\nBatet, A., S. V\u00e1squez, and L. Pakhomov. 2011. Measuring the Semantic Relatedness Between Clinical Terms. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing (EMNLP-IJCNLP), pp. 945\u2013951, Berlin, Heidelberg: Springer.\n\nLesk, M. 1986. A Cognitive Theory of Word-Sense Disambiguation. Artif Intell 28(2\u20133):237\u2013264.\n\nJiang, C., M. Pek\u00e1r, R. Lin, and J. Zhou. 2007. A Lexical Measure of Semantic Relatedness for Word Sense Disambiguation. In Proceedings of the 10th Conference on Computational Linguistics: Human Language Technologies, pp. 1427\u20131435, Stroudsburgh: Association for Computational Linguistics.\n\nLin, R. and P. Resnik. 1998. Word Similarity, An Information\u2013Theoretic Approach. Comput. Linguist 23(4):629\u2013651.\n\nResnik, P. 1995. Word Similarity: A Study of Semantic Association. Computational Linguistics 21(4):343\u2013383.\n\nRada, P., L. Caviedes, X. Guevara, N. Lopez, and L. P\u00e9rez-Lloret. 2009. A Taxonomic Measure of Word Disambiguation Performance. In Proceedings of SemEval 2009: Workshop on Evaluating and Enhancing Word Sense Alignment Across Languages, TDT.\n\nZhou, J., D. N. Ingels, R. J. Dale, and B. G. Boden",
    "8b3d3953454c88bde88181897a7a2c0c8dd87e23": "\nAcknowledgement\n\nWe would like to thank Andrew Goldfarb for his guidance and assistance with the development of the second\u2013order vector measure.\nReferences\n\nBIBREF2\n\nSatoDMM17\n\nSatoDMM, MoralesIW, SatoHJ, MeilijsonE. Measuring semantic similarity using lexical features and information content. Sci. Signal Transf. (2017). doi:10.1126/scitransl.aaf7634.\n\nBIBREF3\n\nMikheevK, GraveS, and SteyversSJ. A survey of measures of semantic relatedness. ACM Computing Surveys. Vol. 37, No. 3. 2015. pp. 79\n\nBIBREF4\n\nBanerjeeP, ChoiJY, and MeilijsonE. The conceptual distance measure: A method of quantifying the dissimilarity between concepts. In Proceedings of the 37th Annual Conference of the Association of Computational Linguistics (ACL), pp. 933\u2013942. 2003.\n\nBIBREF5\n\nResnikN. Measuring semantic similarity and relatedness. Linguistic Inquiry 20 (1):5\u201325. 1989.\n\nBIBREF6\n\nDaganFM, WeischedelE, and O'NeilP. A measure of semantic similarity based on information theoretic analysis of semantic fields. J. Artif. Intell. Res. 5:323\u2013344. 1993\n\nBIBREF7\n\nMihalcevaR and MoralesIW. Statistical distributional semantics. J. Artif. Intell. Res. 18(4):351\u2013394. 2007.\n\nBIBREF8\n\nMihalcevaR, MoralesIW, MeilijsonE, and SteyversSJ. A comparison of distributional similarity measures. Trans. of the EACL 2008. 2009.\n\nBIBREF9\n\nMikheevK, GraveS, and SteyversSJ. Learning word representations from corpora of short texts. In Proceedings of the 30th International Conference on Computational Linguistics (COLING), pp. 1874\u20131883. 2014.\n\nBIBREF10\n\nMihalcevaR and SteyversS",
    "784ce5a983c5f2cc95a2c60ce66f2a8a50f3636f": " In addition, we plan to utilize both the encoder-decoder model and attention modeling to learn robust neural semantic parsers and improve knowledge representation learning. Finally, we would like to extend this model to work with more complex tasks such as relation extraction and question-answering on knowledge graphs.\n\n[1]\n\n[BIBREF1]\n\nLampadaridis, Panos, Tomas Mil\u00e1cek, Martin Dzyugotov, and Huan G. Liu. 2012. \"Answer-Only Evaluation of the Yahoo! Answers Community Question Answering Service.\" In Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining.\n\n[BIBREF2]\n\nChen, Jiyuan, Huan G. Liu, and Tomas Mil\u00e1cek. 2013. \"Bridging Search to Question Answering with Linguistic-to-Q-A Compression.\" Proceedings of the 22nd International Conference on World Wide Web.\n\n[BIBREF3]\n\nTsur, Joseph, and Huan G. Liu. 2015. \"Learning to Rank for Open-Domain Question Answering.\" In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics.\n\n[BIBREF4]\n\nHochreiter, Sepp, and J\u00fcrgen Schmidhuber. 1997. \"Long Short-Term Memory.\" Neural Computation 9 (8): 1735\u20131780.\n\n[BIBREF5]\n\nGraves, Andy, James Bradbury, and Yoshua Bengio. 2013. \"Complexity Functions in Neural Networks: Tuning by BackPropagation.\" In ICML'13.\n\n[BIBREF6]\n\nHermann, Thomas, Niki Kummerfeld, Erich Sch\u00fcller, Raffaella Petroni, Daniel S. Weld, and R. Zens. 2015. \"Learning to Read, Write, and Compose with Networks of LSTM.\" CoRR abs/1504.6113, URL http://arxiv.org/abs/1504.6113.\n\n[BIBREF7]\n\nCotterell, Jon Phan, Yevgeny Yudin, Vivek Singh, and Kartik Tayal. 2014. \"GeoQuery: A Tool for Locating Ge",
    "7705dd04acedaefee30d8b2c9978537afb2040dc": " We also hope that future learning models will incorporate richer external knowledge sources for better question-answering accuracy.\n\nAcknowledgments\nThanks goes to Chenqing Zhang, Yan Du, Piyush Khot, and everyone in the UC Berkeley Semantic Parsing Lab for valuable feedback.\nReferences\n\n[Babyturkus] Babyturkus. University of Southern California. http://babyturkus.io/\n\n[BIBREF0]\n\n[BIBREF1]\n\n[BIBREF10]\n\n[BIBREF11]\n\n[BIBREF12]\n\n[BIBREF13]\n\n[BIBREF14]\n\n[BIBREF15]\n\n[BIBREF16]\n\n[BIBREF17]\n\n[BIBREF18]\n\n[BIBREF19]\n\n[BIBREF20]\n\n[BIBREF2]\n\n[BIBREF2]\n\n[BIBREF3]\n\n[BIBREF4]\n\n[BIBREF5]\n\n[BIBREF6]\n\n[BIBREF7]\n\n[BIBREF8]\n\n[BIBREF9]\n\n[BIBREF10]\n\n[BIBREF10]\n\n\n_This book is lovingly dedicated to my grandfather, Paul, who once said, \"To tell a story is to make a world\"_\n\n_I've dedicated this book to my grandfather simply because I always felt as though he were part of the world I would create with my writing. He would have loved my writing, I am sure of that. No, not simply because he loved reading; I think he would have loved the way words took hold of him like they did me, because words did something, they rearranged his world and made it a little nicer. They rearranged the world for me, too, and every time I look at a book and imagine Paul reading, the feeling is quite visceral and quite real and quite wonderful: he'll be so excited, I know he will. He'll be so excited, and that in itself makes me excited. We will sit together on a bed by an iron stove and, for a moment, all of our lives will be summed up in that time and that place as though we were alive in the same",
    "44497509fdf5e87cff05cdcbe254fbd288d857ad": " I would be very grateful to Professor A. Sundararajan and Dr. Anuradha Devi, Department of Computer Science and Engineering, Amrita University for their suggestions and corrections on the presentation.\n\nReferences\n[BIBREF0 ]\n\nBeesley, P., Collins, M., Callan, E., Clematide, P., & Le Cun, Y. (2011). Neural Machine Translation. Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing and 2013 Conference on Human Language Technologies.\n\n[BIBREF1 ]\n\nAnanthakrishnan, K., Hsu, K., Yang, H. & Zong, Y. (2017). Tamil Morphological Corpus Generation. In: International Tamil Computing Conference, ITC, (pp. 1.11.1\u20131.11.8).\n\n[BIBREF2 ]\n\nBalajapally, R. & Hsu, K., (2017). A Large Tamil SMT System Based on Deep Architectures for English to Tamil.\n\n[BIBREF3 ]\n\nGiglietta, C., Gamon, S. & De Gispert, P. (2012). Scalable neural machine translation. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL).\n\n[BIBREF4 ]\n\nBahdanau, D. & Cho, K. (2014). Neural Machine Translation by Jointly Learning to Align and Translate. Cornell University\n\n[BIBREF5 ]\n\nJiang, C. A. y. (2018). Comparing Neural Machine Translation Systems. IEEETAI, 10, 6, 33\u201343.\n\n[BIBREF6 ]\n\nKundur, C., Lecun Y., Schmidhuber, J., & Zemel, R. (2009). LSTM\u2013CRF Systems to Improvise Language Models for Image Classification. International Joint Conf. on Neural Networks (IJCNN)\n\n[BIBREF7 ]\n\nHsu, K., Balajapally, R. & Yang, H. (2018). Deep Architectures for Sequence Learning with Application to Neural Machine Translation (2nd edition).\n\n[BIBREF8 ]\n\nReichart, R., Dredze P., Collins, M.",
    "0ee73909ac638903da4a0e5565c8571fc794ab96": " This study material would not have been possible without the corpus and resources created by Dr. S. Anand Panchapanigrahi and the team at Au-KBC. This research was supported by Amrita University's R&D grants.\nReferences\n[Ahmed2016] Ahmed, Azreen Farah. 2016. Exploiting Deep Structures of Morphologically Rich Language Using Recurrent Networks. In Proceedings of The 16th International Conference on Language Resources and Evaluation (LREC 2016), 2617-2621.\n\n[Anand2017] Anand, M. 2017. Statistical Machine Translation for Morphologically Rich Languages - A Phrase-Based Multilingual Translation System Development Tool chain BIBREF26.\n\n[Anand2015] Anand, M. 2015. A Parallel Corpus-Based Phrase-based Statistical Machine Translation System for Morphologically Rich Languages. In Proceedings of the 17th NTCIR Conference on Evaluating Research into Language Processing Technology, 718-726.\n\n[Bahdanau2014] Bahdanau, Dzmitry. D., Karpathy, A., Cho, M. & Gulcehre, C. 2014. Neural Machine Translation by Jointly Learning to Align and Translate. In\n\nN. Iyyer, S. Vuli?, M. Balas, S. Vilar (Eds). Machine Translation 36: Neural and Statistical Models. IOS Press. Pp. 65\u201383.\n\n[Bahdanau2015] Bahdanau, Dzmitry. D., Cho, M., Bengio, Y. & Jaitly, N. 2015.\n\nNeural Machine Translation with Attention. In Proceedings of the 14th International Conference on Intelligent Systems for Molecular Biology and 15th International Conference on Intelligent Systems for Molecular Biology, 1289-1299.\n\n[Bahdanau2017] Bahdanau, Dzmitry, Cho, M. & Bengio, Y. 2017.\n\nAttention is all you need: A neural method of machine translation. CoRR abs/1706.02146.\n\n[Bahdanau2016] Bahdanau, Dzmitry, Cho, M., Wang, Y., Schwenk, H., Firat, A., Gulcehre, C., Luong, M. H. &",
    "1f07e837574519f2b696f3d6fa3230af0b931e5d": "\n\n1.\n\nThe SMT systems employed an alignment based on word meaning representations BIBREF33, BIBREF35, where the word meaning representations of two sentences were aligned to be maximally similar, before translating them.\nBIBREF1\n\nPhrase-based Machine Translation by Statistical Analysis of Ordering\n\nBIBREF10\n\nA Joint Model for Translation, Parsing, and Syntax-Aware Reordering\n\nBIBREF11\n\nTheory and Implications of Reordering in Phrase-Based Machine Translation\n\nBIBREF12\n\nPre-order Reordering Rules in Phrase-Based Machine Translation\n\nBIBREF13\n\nReordering for Phrase-Based MT\n\nBIBREF14\n\nDetermining Best Transcription Phrases for Phrase-Based Statistical MT\n\nBIBREF15\n\nUsing Dependency Parse for MT Reordering\n\nBIBREF16\n\nA Fast, Robust and Modular Parallel Beam Search Decoding Algorithm\n\nBIBREF17\n\nModeling Head-child and Sibling Relationships for Phrase-based MT\n\nBIBREF18\n\nA Framework for Statistical Machine Translation\n\nBIBREF19\n\nImproving Neural Machine Translation Quality in a Phrase-Based Architecture\n\nBIBREF20\n\nPenn Treebank version 3.0\n\nBIBREF21\n\nTools for Machine Translation II: Alignments and Word-Weights\n\nBIBREF22\n\nPairwise Ranked optimization for Phrase-Based Statistical Machine Translation\n\nBIBREF23\n\nMATE: Multilingual Annotated Treebank, Version 6\n\nBIBREF24\n\nCombining Phrase-based and Pointer-Based Machine Translation\n\nBIBREF25\n\nN-Best Maximum-Likelihood Decoding\n\nBIBREF26\n\nBleu\n\nBIBREF27\n\nBootstrap resampling for Testing Statistical Machine Translation\n\nBIBREF28\n\nImproving Phrase-based SMT for Low Frequency Phrases through Reordering\n\nBIBREF29\n\nImproving Neural Phrase Translation Using Context-Based Language Models\n\nBIBREF30\n\nIntegrating Hierarchical and Phrase-based SMT for Chinese\u2212English Translation\n\nBIBREF31\n\n",
    "5a65ad10ff954d0f27bb3ccd9027e3d8f7f6bb76": "\n\nAcknowledgement\nThe authors are thankful to Dr. Hui Liu and Dr. Jason Reeves for valuable discussions and feedback on the paper. The support of this work was made possible by the National Research Foundation through the Australian Research Council's Discovery Projects scheme (Discovery Project DP150100221).\nReferenced Data and Code\nThe names of third party software and hardware are used for identification purposes only and are the sole property of their respective owners.\n\nThis research is supported by the National Science Foundation and the Natural Science Foundation of China (Grant numbers 14116021, 61460104, 61403020), the Australian Research Council and the Leverhulme Trust.\n\nReferences\n\nAbdul J. Jaffry, Mishuana Shaikh, Yair Kahn, Alexander Tkacik and Zekeriya Ergun, 2010, FgNER System for Querying Wikipedia-like Corpora, Text & Talk, 3(3), 243\u2013262.\n\nAli, Hisham, and Dan Roth, 2010, Mining Wikipedia for fine-grained named entity recognition, in Proceedings of the 2011 Conference on Information and Knowledge Management, USA.\n\nAgarwal, Sushmita, and Surya Ganguli, 2012, Linking Wikipedia with DBpedia for Relation Extraction, in Proceedings of the 21st International World Wide Web Conference, Rio de Janeiro, Brazil.\n\nAmores, C., L\u00f3pez S., Gonz\u00e1lez A., and Ebert M., 2014, A Fine-grained Named Entity Recognition System based on Syntactic Context, in Proceedings of the 14th Conference on Human Language Technologies: Special Interest Sessions, Chicago, Illinois.\n\nBachman, A. D., Li, L., and Peeples, J., 2014, Leveraging DBpedia for Named-Entity Extraction: A Distant Supervision Approach, International Journal of Human-Computer Studies 7(68), 1243\u20131255.\n\nBIBREF19\n\nPeter Blohmann, Martin J\u00e4ser, Daniel R. Roth, and Noam Chomsky, 2017, ELMo: Deep Learned Representations, 2017, arXiv:1706.03825v1.\n\nBIBREF20\n\nTreyton Heidar, Michael Auli, Yonatan Belinkov, Daniel",
    "729694a9fe1e05d329b7a4078a596fe606bc5a95": "\nAcknowledgement\nWe thank our advisors: Mr. David Hsu, Prof. Stephen Boyd, and Prof. Tommi Jaakkola for their valuable guidance.\nAppendix\nThis appendix discusses in detail the evaluation performed on the Wik(gold) dataset to ensure fair comparisons with previously published works. We first provide the mapping from the Wik(gold) label hierarchy and OntoNotes label hierarchy, followed by how we generated the test data by combining training data from Wiki(gold) to OntoNotes. We then present the results generated using the test data from OntoNotes and combine the train data from Wiki(gold) with OntoNotes. The remaining section provides an analysis of how the model performed given the label imbalances.\n\nWikipedia-to-OntoNote Mapping\nIn order to perform a fair comparison with previously published works, the label hierarchy present in the gold standard should be the same as the one that is used by NerTagger BIBREF29, which is the latest release of OntoNotes. Furthermore, the domain of the two label hierarchies should match. NerTagger is a multilingual open source tool designed for English, Chinese, and Japanese languages. The OntoNotes domain is a journalistic corpus. In this study, we use the English subset of OntoNotes. Following these constraints, we have performed the following mapping from the Wik(gold) label hierarchy to the NerTagger corpus as shown in Table TABREF30.\n\nTest Data Generation\nBefore generating the test data, we first look at the distribution of labels in the Wik(gold) train. From this, we choose a number of categories of which we know that the training data will not cover completely. For example, the category occupation has a total of 984 mentions in the training set, with only 1, 2, 4, 2, and 10 mentions for lawyer, doctor, doctorate, scientist, and engineer respectively. It is worth noting that all of these classes are not covered in the Wiki(gold) training set. The training set is further described in Section 2.4, while the test data is shown below in Table TABREF31.\n\nWiki(gold) Training Data\nThe train data was automatically generated using the Wikipedia sentences corpus. In this paper, we use the Wikipedia train sentences from the date of March 20, 2018.\nOntoNotes Training Data\nWe use the train data from March",
    "1c997c268c68149ae6fb43d83ffcd53f0e7fe57e": " We also note that due to the limitation of the vocabulary found in Wiki(gold), we do not train on or utilize knowledge base information. We instead perform a fine-grained evaluation in order to assess the model for a broader domain. We plan to improve our clustering methodology, in addition to investigating the use of knowledge bases to boost performances further.\nAcknowledgements\nThis work was supported by a grant from the Defense Advanced Research Projects Agency (DARPA) to the Stanford Knowledge Systems Laboratory and was partially supported by an Early Career Research Award from the Defense Advanced Research Projects Agency (DARPA) to the Defense Intelligence Agency (DIA). Any views, findings, conclusions, or recommendations expressed in this paper are those of the authors and do not reflect the official position of DARPA, DIA, or the United States government.\n\nReference\n\n[1]\n  Shimaoka, L., Nakamura, S., Isozaki, K., and Sheng, H. (2017) Attentive network approaches to natural language inference with LSTM-CRF. In COLING 2017 Workshop Information Extraction (ie-coling 2017), LNG: 14\u201315. Cited Date: 27 March 2017.\n\n[2]\n  Weitzman, S. C., Bar-Haim, B., and Berant, J. (2008) Automatic knowledge base construction using active learning. In SIGDIAL, 108\u201316. Cited Date: 27 March 2017\n\n[3]\n  Chen, J., Huang, H., and Zhou, X. (2015) Fine-grained named entity recognition using hybrid convolutional neural networks. In Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics, San Diego, CA: Association for Computational Linguistics. Cited Date: 27 March 2017.\n\n[4]\n  Chen, J., Huang, H., & Zhou, X. (2016) Unsupervised entity typing using neural language model. In Proceedings of International Conference on Language Resources and Evaluation, Reykjavik, Iceland. Cited Date: 27 March 2017.\n\n[5]\n  Li, Y., Roth, S. F., & Mitchell, M. (2015) Cross-lingual entity type discovery. In Twenty-fifth EURALex Workshop, Vilnius: EuroLanguages. Cited Date: 25 March",
    "5cc2daca2a84ddccba9cdd9449e51bb3f64b3dde": "\nBIBREF0. Mapudungun is an indigenous language of the American continent and has around 100,000 speakers in Argentina and 100,000 speakers in Chile (Ethnologue).\nBIBREF1. BIBREF2. It is a polysynthetic language (BIBREF1). For a brief overview see: BIBREF3.\nBIBREF2. Its morphology is quite different from the other South American polysynthetic languages, such as Quechua (BIBREF4, BIBREF5) because it allows Noun incorporation (BIBREF1).\nBIBREF3. It has been described as a language with a number of productive polysynthetic affixation slots for agglutination. For example, a complex agglutinative verb with five or six affixes in the Mapudungun grammar combines its direct object with its subject while its first-person direct object is also incorporated into the verb as an obligatory first-person possessive marker. BIBREF3 provides a morphological analysis of Mapudungun.\nBIBREF4. One further peculiarity of Mapudungun is that it is a polysynthetic language, that is, it incorporates nouns. BIBREF3 shows that Mapudungun has two possible arguments in its verb: A subject argument that is the verb object pronoun, and a subject argument that is a noun phrase. This noun phrase is incorporated into the verb phrase as its direct object, but as it is also a subject, agreement is possible and obligatory.\nBIBREF5. It has inverse voice (BIBREF6), which places the highest agreement on the subject argument regardless of thematic role (BIBREF6).\nBIBREF6. It consists of 4,500 affixes (BIBREF1).\nBIBREF7. Using found data techniques we found and synthesized high-quality speech data in 70 languages, producing systems that can be used for speech recognition, speech synthesis, and machine translation.\nBIBREF8. The morpho-stamatistic relations of the language can also be studied in BIBREF30 via an analysis of the prosody.\nBIBREF9. For speech synthesis, we could use a different technique, see BIBREF4.\nBIBREF10. See: BIBREF9 for details of our methodology.\nBIBREF11. Kaldi",
    "f9bf6bef946012dd42835bf0c547c0de9c1d229f": " The opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation.\n\nAdditional acknowledgement is due to The Andrew W. Mellon Foundation, Konex Foundation, and CONICYT (Chile) for funding the AVENUE project as well as supporting the IEI Mapudungun research team that performed the collection and transcribing of the data.\nBibliography\n\nThis bibliography will appear in the final version of the paper. We will include citations to resources which we consulted in order to produce this paper, including academic papers and books (BIBREF1, BIBREF2, BIBREF4) as well as the AVENUE and IEI websites (BIBREF?), including but not limited to, all Mapudungun resources listed below. All URLs will be included in the final document.\nThe following list contains some of the most relevant works currently available in Mapudungun. We present them by the following classifications:\n\n  * (Cultural) : Cultural documents describing Mapudungun, often written by Mapudungun. While some of these (e.g. BIBREF22) focus on Mapudungun grammar, others (e.g. BIBREF29) focus on Mapuche culture.\n\n  * (Historical) : We divide this section into two sub-categories: works that are purely historical from the time Mapudungun was first written down, and works which are partially historical, but also include recent analyses of orthography.\n\n  * (Linguistic) : This category is further divided by language sub-category (spoken and written) and by NLP domain (speech, grammar, orthography).\n\n  * (Speech Synthesis) : We divided this part into two sections, the first containing resources for building a spelling-correcting spell synthesis system BIBREF7, and the second containing resources suitable for speech synthesis.\n\n  * (Speech Translation) : Lastly, we divided this portion of the bibliography into a section for the work that was done in the AVENUE project, BIBREF10, and a section for the work done on neural translation, BIBREF13, and a section including the relevant papers that build on our previous work.\n\n\nBIBREF1. Hosea, S., & Jain,",
    "6a633811019e9323dc8549ad540550d27aa6d972": " Moreover, the authors wish to express their gratitude to the Wikimedia Italia community that has provided the collected data, to Dimitri Vamvasopoulos from Wikimedia Italia for his valuable contribution on the medical domain-related features, and to Dr. Maurizio Bagnato for his valuable contributions.\nBIBREF0. M. A. Jones and N. G. A. Gavino, Nature News, Nature 548, 201 (2017).\nBIBREF1. Wikimedia Foundation, \"Judging Wiki Good Faith\", available at: http://www.nature.com/news/20121115/news-and-views/judge-wiki-good-faith.html\nBIBREF2. E. Flesch and R. Kincaid, Psychological Review, 19, 211\u2013243 (1974).\nBIBREF3. S. Serrano and H. Hjalmarsson, arXiv, https://www.nature.com/news/2016/160629/full/full/nature.16229, doi: 10.1038/nmeth.3322.\nBIBREF4. R. V\u00e4sterholm, B. H. Bengtsson and L. E. Karlsson, arXiv, https://www.nature.com/news/2016/160605/full/full/nature.16233, doi: 10.1038/nmeth.3312.\nBIBREF5. N. Yulis, J. A. Andersson and M. Q. V. Aaltonen, arXiv, https://www.nature.com/news/2017/170524/full/full/nature.n.3995, doi: 10.1038/nmeth.3898.\nBIBREF6. J. L. O. Henner, H. D. Nguyen and P. W. Yeh, arXiv, https://www.nature.com/news/2016/160726/full/full/nature.16237, doi: 10.1038/nmeth.3895.\nBIBREF7. Wikipedia Foundation, \"Wikipedia: The actionable model in production\", available at: https://en.wikipedia.org/w/en/blog/actionable-model-in-production\nBIBREF8. G. Maronato and R. Basile, Quality and",
    "6b9b9e5d154cb963f6d921093539490daa5ebbae": " This material is based upon work supported by NSF OAC-1847812. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation.\nReferences\n[1]M. E. M. Hector and C. D. Manning, (2014). Autoregressive Distributed Representations for Semantic Analysis on Long Texts. Proceedings of the Forty-second Annual Meeting of Association for Computational Linguistics, 2014 ([Paper]).\n[2]C. D. Manning, M. E. M. Hector, and E. Chu, (2010). Distributive Semantics, Proceedings of the 43rd Annual Meeting of Association for Computational Linguistics, 2010.\n[3]E. Chu, M. E. M. Hector, and C. D. Manning, (2010). On Learning Lexical Subword Representations. Proceedings of the 39th Annual Meeting of Association for Computational Linguistics, 2010.\n[4]C. D. Manning and M. E. M. Hector, (2009). Learning Distantly Supervised Subword Units with Lexical Generalization, Proceedings of the 40th Annual Meeting of Association for Computational Linguistics, 2010.\n[5]M. E. M. Hector and C. D. Manning, (2013). Distributional Semantics from Infinitesimal Bags of Words, Proceedings of the 41st Annual Meeting of Association for Computational Linguistics, 2013 (Paper).\n[6]M. E. M. Hector and C. D. Manning, (2012). Distributional Subword Semantics. Proceedings of the 34th Conference on Association for Computational Linguistics, 2012.\n[7]M. S. Johnson, R. Manjunath, E. Chu, and C. D. Manning, (2010). Learning to weight words for context, Proceedings of the 39th Annual Meeting of Association for Computational Linguistics, 2010.\n[8]D. Turney, J. Martin, E. Chu, C. D. Manning, and M. E. M. Hector, (2012). Context Triggers Phrasal Analogies. Proceedings of the 2nd Workshop on Foundations of Statistical Natural Language Processing, 2012.\n[9]T. Hofmann, M. E. M",
    "bc4dca3e1e83f3b4bbb53a31557fc5d8971603b2": " The text from this paper have been prepared using Abibition.\nReferences\n\nAgarwal A, Klein P, Leuschel C (2014) The curious case of negative-PMI word analogy. In: Proceedings of the Eighth Workshop on Computational and Quantitative Approaches to the Analysis of Discourse. Association for Computational Linguistics, Stroudsburg, PA.\n\nBiberauer D, Hirst G, Manning C (2013) Efficient training of GloVe word vectors. In: Annual Conference of the Association for Computational Linguistics, June 23\u201329, Istanbul, Turkey.\n\nBilu R, Aharoni A, Carmel Y, Hakkani-T\u00fcr A, Goldberg D, Goldberg Y, Levy N (2019) Scaled unigram features are superior to other unigram features for lexical context modeling in multilingual, cross-lingual sentiment analysis. In: Proceedings of the Fourteenth Conference on Computational Natural Language Learning.\n\nBing S, S\u00f8ndergaard E, Ip A, et al (2018) GloScrabble: A new approach to fast computation of distributional semantics on large corpora. CoRR, abs/1805.08134.\n\nBouamama Al Dhabi E (2019) Clipped negative pointwise mutual information. In: Proceedings of Third International Workshop on Unstructured Data Analysis for Semantic Applications.\n\nCaliskan K, Cetin S, van Genabith JG (2015) Exploiting negative word pairs in context-specific word representation learning via online SGD. In: Annual Conference of the Association for Computational Linguistics and Human Language Technologies, March 12\u201317, Copenhagen, Denmark.\n\nCaliskan K., van Genabith, J. G. (2017) Negative pointwise mutual information and its applications. In: Computational Linguistics, 39(5):1227\u20131235.\n\nCaputo Y, G\u00fcnes G, Derczynski J, Marcu L, et al. (2019) Pmips: Learning word vectors using positive and negative pointwise mutual information. In: Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics.\n\nCaruana R, Coate D, Coenen M, et al. (2017) Distributional similarity for sentiment analysis",
    "d46c0ea1ba68c649cc64d2ebb6af20202a74a3c7": " We thank the anonymous reviewers, the ACL program organizers and the conference participants who gave us valuable feedback for this paper. We thank Benno Stein and the SimLex team for sharing the original SimLex corpus, the Google Answers team for sharing the GSem analogies, the organizers of SemEval, DARPA's Natural Language Inference Program (NLINF) and Stanford's Computational Linguistics Program for sharing the DARPA SyntaxNet corpus, as well as the authors of the Penn Treebank and the SimLex and WSJ treebanks for publicly making these corpora available.\nReferences\n\n1\n\nThe author is grateful to David McCloskey for sharing ideas about distributional notions with him during his first visit to the University of Toronto in 2010.\n\n2\n\nR. A. Gurevich, D. Koppel and D. Yarowsky,\n\nThe principles of semantic entropy.\n\nIn Advances in neural information processing systems, 2010.\n\n3\n\nFodor, J. (ed.) (1975), The language of knowledge: essays on conceptual representation and semantic theory, MIT Press, Cambridge, MA, USA\n\n4\n\nMesoudi, S., F. R. Martin, and J. P. Horgan,\n\n(2009),\n\nThe unweighted distributional dependency model: a grammar-like model for lexicalism and collocation extraction.\n\nIn Proceedings of the 15th international workshop on computational semantics (NAACL).\n\n5\n\nDeerwester, S., Hibberd, P., Haddow, S., Kudo, W., and Grefenstette, T.,\n\nAutomatic word-sense disambiguation via training a collocation extraction model over a large collection of semantically ambiguous antonyms.\n\nIn Proc. 15th conf. on machine learning (ICML).\n\n6\n\nManning, C. D., Raghavan, P. and Joachims, T.,\n\n(2015),\n\nThe Wikipedia 100M word sense disambiguate corpus.\n\nIn Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Austin, TX.\n\n7\n\nGloVe: Global vectors of words for word representation.\n\nIn Proceedings of the 2014 Conference on Emp",
    "6844683935d0d8f588fa06530f5068bf3e1ed0c0": "\n.\n\n.\n\n.\n\n.\n.\n.\n.\n.\n.\n.\nSome people will argue that BIBREF15 is a result of the choice to use a symmetric lexical window, but it is important to understand that LexVec was specifically designed to learn semantics from symmetric windows, so we think the choice to use a symmetric window does not have the effect of making the embedding a more semantic abstraction of the language.\n\nWord2vec has used this window since its inception and works very well on downstream tasks.\n\n. The skipgram does not model word sense, but word sense model is orthogonal.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n. With the original objective, LexVec learns a distribution for the cooccurrence count, and the reconstruction-error objective uses this distribution of counts to weight the reconstruction error.\n\n.\n.\n. To mitigate the effect of large unigram counts on the final embedding, we normalize the reconstruction error of each word by the co-occurred window size $e=|C_i| + |W_i|$. See $\u00a7$ \u00a74 for more details.\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n. For most of the tasks we use random sampling since it is much faster than negative sampling (which is usually employed in language modeling work). Empirically we find this works quite well.\n\n.\n.\n. In GloVe, the reconstruction error is of the same order of magnitude as, and always larger than, the reconstruction error of the window. This is the underlying reason why the final embedding is different from the original cooccurrence count, allowing for more efficient windowed SGD updates during training.\n\n.\n.\n\n.\n\n. Although these matrices are weighted, they are not actually learned by means, so we call them pre-weighted here.\n\n.\n\n. In practice we find this works better because it requires much less SGD steps during training.\n.\n.\n. The fact that the skipgram captures distributional semantics of words (and lexical neighborhoods) has been recently empirically confirmed with BERT BIBREF25, GPT-2 BIBREF26 and others.\n.\n\n. In this manuscript, we use the more general term negative",
    "8acab64ba72831633e8cc174d5469afecccf3ae9": " For example, the oracle does not know how to translate words like \"polic\u00eda,\" \"polic\u00eda,\" nor \"polic\u00eda.\"\nCross-utterance matches\nSince the ZRTools algorithm matches acoustically similar segments, it frequently matches segments that belong to the same utterance \u2014 for example, in the third call in the third row of Table TABREF9, the discovered pattern matches \"polic\u00eda\" in c1, \"de polic\u00edas\" in c1, and \"perpetuamente\" in c2. In some cases, a single word is assigned to several UTD clusters. Since the training data contains only one utterance, we cannot learn a translation model for any single one of these words.\n\nThe UTD approach is sensitive to acoustic differences with other speakers, meaning cross-utterance matches can split words across different clusters. Note that, even for the best-covered call, most of the found clusters have only a partial cross-utterance match across two speakers.\n\nDifficulty producing good clusters for rare words\nAs shown in Fig. FIGREF4 and Table TABREF10, many of the discovered word patterns are rare in the training data, often appearing only once. In these cases, many common types are found in just two different speakers, leading to less-accurate translations. Across all speakers, the average number of distinct words in the cluster is eight, while for gold patterns most types appear in at least eight different speakers, meaning a better cluster is likely to match more different speakers. To help with the challenge of handling the rare cases, we performed word-clustering for the clusters. However, since all the patterns were discovered unsupervised, we do not know whether those are the right patterns to cluster.\nLack of translation supervision leads to inaccurate translation\nEven though the MT training data for each speaker is relatively small, the oracle OOV rate is only 2.82% (Table TABREF11 ). This is much higher than the UTD OOV rate of 2.47%, suggesting UTD is more robust to noise than the gold data. The OOVs are not just the most frequent words \u2014 they include many words that occurred only once while training. In most of the cases, we did not find any translations for these words. This may be partly due to small sizes and no parallel text, but could also reflect the differences between UTD and the gold cluster-to-pseud",
    "53aa07cc4cc4e7107789ae637dbda8c9f6c1e6aa": "\nUTD is difficult for multiple speakers in a corpus\nMost speakers in our data have a low cluster purity (Table TABREF9 ). These low-purity speakers tend to appear in both training and test, which leads to greater challenges from multiple speakers. The problem is more severe in the utterance-level split (Table TABREF11 ), where cluster purity is 27% instead of 38%, and low-purity speaker types are included in both training and test (Table TABREF12 ). To illustrate, Fig. FIGREF5 shows that for the call-level split, two of the top-performing speakers (0.85 and 0.82) translate at lower rates than the least-performing speaker (0.32), and that speaker 0.85 translates only on average 33 out of the 36.8 words per utterance while speaker 0.82 translates an average of 48 words per utterance.\n\nIn fact, some speaker types appear with very small and even negative translations under these low-purity conditions, which suggests either the use of noisy alignment or a very small number of actual words represented in the corpus.\n\nFigure 2: Example word cluster assignments by the three models. In the oracle, we include gold translations for the cluster c2. The proposed system ignores the errors in c2 and uses the remaining clusters. The baseline system assigns several words (in B) to cluster c2, which have the same acoustic patterns (in A). Using these clusters incorrectly causes a high degree of fragmentation of the words (B).\n\nTable 2: Translation accuracy and error metrics for the three models on the CALLHOME Spanish-English corpus. All systems achieve low translation error under all conditions, including across-speaker clusters, with translation errors for nearly every speaker. The baseline system suffers from over-fragmentation of words, while the proposed system is more stable.\n\nFigure 3: Example partial word-cluster assignments by the three models. In the oracle, word types in c2 get a full translation (highlighted in capital). Both the baseline and proposed system assign one word in c1 to c2. Although the proposed system is correct, this results in negative translation rates in B and C.\n\nFigure 4: Two different speaker representations, corresponding to the blue and red speakers in Fig. FIGREF5 (upper left). The proposed system has a more consistent representation of these speakers than the baseline.\n\nWe also experimented",
    "72755c2d79210857cfff60bfbcb55f83c71ada51": " Adding additional training utterances to each cluster does help in improving UTD accuracy, but the OOV rate increases. This reflects the difficulty of clustering multiple speakers at the same word.\nThe quality of UTD is highly dependent on the acoustic similarity threshold. We found that the default threshold of 50ms performs well on most of the calls, but there is substantial variation across calls, especially for the utterance-level split. In many calls, UTD discovers more clusters at high acoustic similarity.\n\nTable TABREF9: Performance by speaker. In both splits, the oracle does better on every speaker, except for the low-coverage split, where ZRTools also shows lower performance.\n\nAnalysis of challenges from pseudotext inefficiency\nThe pseudotext is often too sparse for MT. For example, for 30\u201340% of the utterances, translation performance for the call-level train/test split is worse than for random. To address this, we tried a variety of improvements to the training data: we simulated a perfect UTD system by randomly sampling every word, and we removed clusters that appear less than 10% of the time from any pair they overlap in. Both improvements improved performance.\nFig. 6: UTD clusters by length. Average cluster size and length correlate with UTD coverage. Call-level results use 90% of the discovered clusters. Inefficiency of the current set of clusters has the effect not only of reducing corpus size, the training model translates much worse on OOVs.\n\nUTD clusters are a function of acoustic similarity, and some clusters do not match at all across speakers, as in Fig. FIGREF4. Since we do not have access to a manually transcribed corpus, an even better UTD could use word-level timing patterns for additional refinement. Adding a manually annotated corpus is another way to improve UTD (but would not make pseudotext redundant). UTD can be used to bootstrap a translation model, but a better UTD is also needed.\n\nAnalysis of speech-to-text translation for the CALLHOME corpus\nWe applied our MT model to both the training and test data, using 50% of the total training audio combined with pseudotext of the rest to create a combined UTD model. As a translation model we used a standard, off-the-shelf text translation model, based on IBM Model 1 BIBREF11 but with a Dirichlet prior over translations over all",
    "7d2f812cb345bb3ab91eb8cbbdeefd4b58f65569": "\n\nFigure\n\nF21. Analysis of multitask learning in predicting ERP components of language processing.\nFigure: Visualization of results presented in Table TABREF16 of the main paper.\nThis network predicts ERP components and is pretrained by joint learning with eye-tracking experiments, self-paced reading time, and ERP components data, which are all recorded with the same participant (as described in Section 3) at different time points (A-B, C-F). We train the network using a set of shared multitask learning parameters (i.e. shared between the eye-tracking and the ERP components, but otherwise independent parameters) to predict ERP components. We fit ERP and eye-tracking data to our model using a similar approach to what is used in multitask learning (using M-learning). ERP components are then divided based on their ERP frequency band, either in the alpha, beta, gamma, or low-frequency band (A-F). Each timepoint is then regressed against the predicted ERPs of the corresponding timepoint using multitask learning parameters M. The error from this regression is then used to fit to the decoder network (i.e. the forward, bi-LSTM, backward, and forward-with-backward encoder configurations). The resulting neural predictions with respect to behavioral data are presented in Table TABREF16. (For an interactive visualization of this data, see Figures FIGREF23\u2013 FIGREF24.)\n\nFigure 21: Eye-tracking and ERP predictions, eye-tracking and ERP data.\nFigure: Visualization of results presenting in Table TABREF23 of the main paper.\n\nWe train separate predictive neural networks to predict the different frequency bands of the ERPs from the data collected for our experiments. The network is pretrained by joint learning with eye-tracking experiments, self-paced reading time, and ERP components data to predict eye-tracking (A-I), ERP components (i.e. by joint learning all three modalities) (Ji), or ERP components (i.e. single modality) (Ki). The network is then used to predict (A-II) eye-tracking by ERP component regressiion (i.e. using only eye-tracking), (B-III) ERP components from eye-tracking (i.e. using only ERP components), and ER",
    "bd6dc38a9ac8d329114172194b0820766458dacc": "\nBIBREF0  D. A. Poeppel and J. A. Marslen-Wilson, Front. Psychol. 12, 433 (2011).\n\nBIBREF1  J. A. Marslen-Wilson and D. A. Poeppel, PLoS Biol. 6:e252 (2008); G. Hulshoff Pol & C. J. G. van Leeuwen, Biol. Psychol. 106, 175 (2013).\n\nBIBREF2  B. De Boer and G. Hulshoff Pol, Psychol. Psychol. 21, 245 (2017).\n\nBIBREF3  J. A. Kutas, Trends Cognit. Sci. 12, 349 (2009).\n\nBIBREF4  M. van Oost, H. R. Hulkoto & G. Hulshoff Pol, J. Cogn. Psychol. 25, 1514 (2014).\n\nBIBREF5  H. R. Hulkoto, A. P. Moelants & G. Hulshoff Pol, Psychol. Cogn. Neurosci. 4, 879 (2016).\n\nBIBREF6  D. A. Poeppel, Cognition 133, 10 (2010).\n\nBIBREF7, H. R. Hulkoto, A. P. Moelants & G. Hulshoff Pol, Psychol. Cogn. Neurosci. 8, 1634 (2017).\n\nBIBREF7, O. G. Zwaigenbaum et al., Sci. Rep. 7, 69093 (2017).\n\nBIBREF7, L. Nogiec, M. Morreale & D. A. Poeppel, Trends Cogn. Sci. 33, 1 (2018).\n\nBIBREF8, G. Hulshoff Pol & E. T. Vogeley, PLoS Biol. 19, e316518 (2013).\n\nBIBREF9, A. J. Sleightholm & A. Beaver, Brain Topogr. 22, 1 (2019).\n\nReferences\n\nTABLE 1\n\nCorrelations of input and output features with behavioral measures. The left column gives the Pearson correlation coefficient (rho) and the diagonal (marked",
    "3ddff6b707767c3dd54d7104fe88b628765cae58": " Furthermore, since a new wave of work is emerging in which word vector representations are trained directly on annotated corpora, as described by BIBREF18, this approach is yet another path to explore.\nAcknowledgements\n\nWe are grateful to Christophe Vidal and the MarMoT team for sharing their knowledge and results. Our work was partially funded by the ANR DIGITALEURA grant and by the Wallon consortium STARS2-ID2R.\n\nREFERENCES\n\nBIBLION. (2005). A comprehensive morphology-based part-of-speech tagger for French. In Proceedings of COLING-ACL 2005, Prague, Czech Republic, pages 14\u201323.\n\nBIBLION, B. (2006). An open-source part-of-speech tagger for French. In Proceedings of ACL 2006: Conference of the Association of Computational Linguistics, pp. 712\u2013721.\n\nBIBLION, B., CARREAU, F. & FONTELLA, C. (2012). A comparison of several tagging systems for French. In Proceedings of LREC 2012, Portoro\u017e, Slovenia, pp. 1475\u20131482.\n\nBIBLION, B. & CARREAU, F. (2010). Part-of-speech tagging in French: A cross-linguistic evaluation. In Proceedings of LREC 2010, Valencia, Spain, pp. 3331\u20133338.\n\nBIBLION, B., CARREAU, F., FONTELLA, C. & VAYRAC, J.-F. (2011). Morphological PoS taggers for French. In Proceedings of LREC 2011, Lyon, France, pp. 1652\u20131654.\n\nBIBLION, B., FRAGA, J., BOC, F., MOTTET, J., BONNET, C. & PELARD, T. (2016). MElt: A feature-based and contextsensitive system for PoS tagging. In Proceedings of ACL 2016, Vancouver, Canada, pp. 1852\u20131864.\n\nBIBLION, B., FONTELLA, C., DEUSDIN, E., FRAGA, J., RICHOMME, D. & BOC, F. (2013). Improving part-",
    "0a5ffe4697913a57fda1fd5a188cd5ed59bdc5c7": " In addition, we should also be interested in using lexical information encoded in external morphosyntactic lexicons in neural models in other tasks and not only for PoS tagging. For instance, this lexical information might be used as additional features when training neural networks used for sentence classification.\n\nReferences\n\nTable 1:\n\nCorpus statistics\nTable 2:\n\nStatistics on words from morphosyntactic and external lexicons\nTable 3:\n\nList of morphosyntactic lexicons\nTable 4:\n\nCorpora statistics for lexical variability analyses\n\nTable 5:\n\nLexical variability statistics for morphologically rich and less variable languages\nTable 6:\n\nNumber of words in corpora\n\nTable 7:\n\nNumber of sentences in corpora\n\nTable 8:\n\nList of languages\n\nTable 9:\n\nList of words in morpho- and morphosyntactically annotated corpora and associated external lexicons\n\nTable 10:\n\nList of prefixes and suffixes associated to each word in morpho- and morphosyntactically annotated corpora and associated external lexicons\n\nTable 11:\n\nList of morphosyntactic lexicons used in comparison\nTable 12:\n\nComparison of all PoS tagging models over all corpora and languages\nTable 13:\n\nImpact of external lexical resources on performance of PoS tagging models (averaged over morphologically rich and less variable languages, excluding Portuguese)\nTable 14:\n\nNumber of words per corpus\nTable 15:\n\nNumber of words per corpus\nTable 16:\nList of feature sets included in the analysis\nTable 17:\n\nResults achieved without external lexical information\n\nTable 18:\n\nList of lexical features included in the analysis\n\nTable 19:\n\nResults achieved with external lexical resources\n\nTable 20:\n\nComparison of all PoS tagging models over all corpora and languages\n\nTable 21:\n\nUniversal Dependencies v1.2 corpus used in corpora analysis\n\nTable 22:\n\nTraining and evaluation conditions of external lexical resource systems used in this study\nTable 23:\n\nList of Universal Dependencies v1.2 corpora used in language coverage analysis\n\nTable 24:\n\nComparison of results obtained by feature- and neural-based models over all corpora and languages\n",
    "06be47e2f50b902b05ebf1ff1c66051925f5c247": " In doing so, the suggested methods open opportunities for additional investigation in the political studies of IR and are relevant for any scholar that works with textual data and wishes to measure interest similarity in a multidimensional setting.\nAcknowledgements\nThe authors wish to thank the numerous co-authors, authors, and reviewers of the various manuscripts which laid the foundation for this research work, including the editors of Proceedings of the National Academy of Sciences, International Political Science Review, Political Analysis, Political Research Quarterly, Scientific Reports, and the Stanford Network Analysis and Social Inference Conference (SNAASI).\n\nReferences\n\nAcemoglu, D., Z. Kucuk, V. Lillo-Martin, and J. Luttmer. 2016. Economic Backwardness and Civil War. American Economic Journal: Macroeconomics, 6 (3), 138\u201366.\n\nAcemoglu, D., Z. Kucuk, and J. Luttmer. 2012. The Determinants and Consequences of Civil War. American Economic Journal: Economic Policy, 4 (3), 105\u201340.\n\nAcemoglu, D., Z. Lillo-Martin, and J. E. Luttmer. 2017. The Determinants and Consequences of Civil War. American Economic Journal: Economic Policy, 9 (3), 305\u201346.\n\nAgafonov, E., J. E. Luttmer, and E. Aliev. 2019. Democracy and the Great Powers: A Cross-Country Analysis of International Conflict. American Political Science Review, 113 (3), 597\u2013634.\n\nAlex, C. S. 1992. Foreign Policy and Unilateralism in Multilateral Disarmament Negotiations: Why America Was the One That Could. Journal of Peace Research, 33 (1), 81\u201398.\n\nAlfaro, R., S. Piazza, and M. G. Palumbo. 2003. The Effects of Nuclear Weapons on the Decision to Go to War. International Studies Quarterly, 50 (3), 315\u201339.\n\nAnderson, K. L., D. D. M. Hanley, and J. L. H. Liu. 2014. Arms Races: An Empirical Analysis of the Determinants of Nuclear Proliferation. Science, 343 (6169), 1315\u201318.\n\nAnderson, K. L., S. C.",
    "003d6f9722ddc2ee13e879fefafc315fb8e87cb9": " This indicates that these methods have fruitful potential for increasing our capacity to accurately predict behavior in political science.\nThe most widely used measure of polarization in IR is UN roll call votes and GD statements, but this source of information is limited by a few issues which have motivated research to look to alternative sources to estimate states' preferences BIBREF22, BIBREF47, BIBREF48, BIBREF49, BIBREF50. In this section, we review measurements used in these settings and illustrate their general shortcomings compared to our suggested approach which utilizes votes and textual data in conjunction.\nScaling approaches. The scaling literature provides a method by which to operationalize preferences by reducing the vector space of states to one or a few dimensions and thereby making the concept of polarization readily testable by regression models BIBREF50, BIBREF51, BIBREF52. In particular, scaling measures attempt to approximate the variance among states' preferences by reducing this vector space to reduced dimensions. There exists an entire class of different dimensionality reduction methods in scaling studies from linear (e.g. latent semantic analysis, PCA) to nonlinear (e.g. Isomap, t-distributed stochastic neighbor embedding, UMAP) methods. These different methods tend to produce different estimates of preference similarity, but broadly speaking, they have the same goal for IR research: to uncover latent dimensions to which a given state policy position can ideally be mapped. Scaling methods assume that, through the use of one or a few latent dimensions, one can model and predict behavior in international politics through regression models such as the temporal exponential random graph model. However, scaling methods tend to underperform when there exist multiple dimensions of concern to a given state that are important for determining behavior in international affairs. In contrast to BIBREF27 and our approach, scaling methods attempt to map states to a one-dimensional space which we label the scaling dimension, but they do not attempt to uncover meaningful groups of states who align on the same reduced dimension. The scaling dimension is usually determined by plotting these latent dimensions against the outcome variable of interest, such as conflict onset. If there exist meaningful communities of states, then states who fall on the same latent dimension should tend to have more similar or dissimilar outcomes in international politics. If, however, multiple dimensions of interest exist, then states will tend to be more or less dissimilar on these dimensions than they will be on their latent dimension. Multidimensional scaling methods have been crit",
    "c88a846197b72d25e04ec55f00ee3e72f655504c": " This is illustrated by the multilayer model which improves substantially upon the in-sample fits and out-of-sample performance of the original models.\nAcknowledgments\n\nWe are thankful to Peter Hans (Oxford) and Peter Sanderson (Stanford) for reading early versions of this paper and providing feedback. All errors are our own. Any omissions are the author's. We also thank our colleagues for helpful comments: D. P. H. Kessler, D. D. Wilson (both Oxford), M. Z. J. H. Hekkert and S. N. A. Slootha (both Cambridge), and W. A. Gleditsch. This work was sponsored by the Oxford-Cambridge Research Programme in Criminology and International Policy. We gratefully acknowledge the British Academy for their support of Oxford-Cambridge Research Programme in Criminology and International Policy, without which this research would not have been possible. The UK Research Councils UKIERI (United Kingdom Informal Institutions in Europe Research Initiative), the Oxford-Cambridge Research Council, the British Academy, and the UKRI Public Policy Programme are acknowledged for financial support.\n\nData are available on the Internet at the following URL: https://www.princeton.ed/projects/polis/general-debate-on-the-united-nations/\n\n1.\n\nMorgan E. S. and T. Bollen, \"State-Centered Preferences in a Multifacet of Voting Activities and the Origins of National Legitimacy,\" Journal of Conflict Resolution 47 (2003): 828\u2013846.\n\n2.\n\nT. Bollen and M. J. E. S. Donner, \"Constrained Choice by Actors: The Effects of Legislative Agendas on National Preference Structures,\" American Political Science Review 101, no. 1 (2017): 1\u201316.\n\n3.\n\nK., J. A., M. Z. J. H., S. N. A., S., and E. A., \"Cross-Sectoral Dynamics and Long-run Political Change: The Example of Europe,\" Journal of Politics 77 #2 (2017): 389\u2013398, p. 390.\n\n4.\n\nM., R., and I. K., \"Measuring Unobserved State Preferences from Roll Call Votes,\" Econometrica 85, no",
    "4d28c99750095763c81bcd5544491a0ba51d9070": " For each profile, we show the top and bottom 5 tweets in the tweet score percentile buckets, along with the characterization scores for these tweets. The tweets are also presented in original form, and with hashtags and emojis removed. The corresponding characterization scores are highlighted in red and blue respectively.\nA complete set of code and documentation for this work, including the above dataset and results, may be found at: http://compressionveenman.com/twitter.\n\nAcknowledgments ::: We have been greatly inspired by the work of prior authorship verification researchers. Our approach of token tokenization and use of token-level features is similar in spirit to lopez2015discriminative. In particular, we make use of the same document embedding approach as rocha2016authorship, and the same sequential modeling as peng2016bit. Our model of n-gram probabilities (Approach SECREF26) is related to unigramsandbigrams. As such, we owe a large part of our results to their work. BERT has been trained and used in an enormous range of papers, and we are pleased to be able to apply its methodology to this problem, particularly in our sequential modeling approach. We thank the authors of these and other influential works for their work in this line of research.\n\nWe are responsible for the remaining content and conclusions. The authors have no competing interest/ conflicts of interest.\nREFERENCE BIBLIOGRAPHY\n\n[Alvarez-Montes] Alvarez-Montes, A., and C. Rodriguez. 2012. Compression distance for document classification. In Advances in neural information processing systems, pages 1143\u20131148.\n\n[Altmann] Altmann, B. 2005. A novel algorithm for automatic document classification through topic modeling in an unsupervised setting. In Proceedings of the 2nd International Conference on Text Mining and Social Media, volume 3214 of Lecture Notes in Computer Science, pages 146\u2013155.\n\n[Andr\u00e9s] Andr\u00e9s, R., and J. Poblete. 2014. Detecting abusive content in tweets. Available at: https://www.aclweb.org/anthology/K/K13/paper/K13/K13/Andr\u00e9s_14.pdf\n\n[Andr\u00e9s] Andr\u00e9s, R., and J. Poblete. 2016. Sentiment and sarcasm identification in Twitter: a",
    "78292bc57ee68fdb93ed45430d80acca25a9e916": "\n\nAcknowledgments\nWe would like to thank the anonymous reviewers and the editors for helpful suggestions.\n\nReferences\n\nBIBREF0   Zou, V., Rambow, S., Bansal, N., Mishra, A., & He, C. (2019). Open Domain Question Answering with a Large Pretrained Language Model. International Conference on Machine Learning, pp. 5905\u20135918.\n\nBIBREF1   Dhingra, P., Lee, M., Eslami, S., & Jurafsky, D. (2019). Transformer-XL: Bigger, Better, Faster Transformers. Transactions of the Association for Computational Linguistics, 7(9), 1099\u20131116.\n\nBIBREF2   Schwartz, J., & Dredze, M. (2019). ELMo: Deep contextualized word representations. In Thirty-first Conference of the Association for Computational Linguistics, pp. 1532\u20131543.\n\nBIBREF3   Howard, J., Zaremba, W., Chen, Y., Dean, J., & Chen, Y. (2018). BERT: Pre-training of deep bidirectional transformers for language understanding. Proceedings of the Thirty-seventh Conference of the Association for Computational Linguistics, pp. 4168\u20134186.\n\nBIBREF4   S. A., Ejazi, S., & Hajishirzi, M. (2019). T-REx: A Large-scale Knowledge Graph for Question Answering. Transactions of the Association for Computational Linguistics, 7(9), 2463\u20132477.\n\nBIBREF5   Liao, O., Li, Y. K., & Su, L. (2019). ConceptNet: A Common Sense Knowledge Base. Transactions of the Association for Computational Linguistics, 7(9), 2918\u20132949.\n\nBIBREF6   Rajpurkar, P., Kumar, V., He, M., & Zettlemoyer, L. (2016). SQuAD: 100,000+ questions for machine comprehension of textual content. Proceedings of the 2016 Conference on Neural Information Processing Systems, pp. 2975\u20132984.\n\nBIBREF7   Jia, S., Duan, J., &",
    "443d2448136364235389039cbead07e80922ec5c": "\nAcknowledgement\nWe would like to thank our supervisors Prof. A.K. Ganguly and Prof. P. Mishra, and also the colleagues in IBM Research for their support and guidance on this project.\nBIBREF0 P. K. Mishra, M. S. Alam, H. Naveen, P. Ramegowda, P. Jain, Y. Gagalawada, R. Vadlamudi, M. Natarajan, K. V. Prabhu, V. Gupta, M. Rani, B. Natarajan, S. V. P. Mishra, M. Keshri, R. R. P. Pradeep, V. Y. Gargi, G. M. Yadav, T. Prasad, and their colleagues in HR, for their help and feedback during this project.\nBIBREF1 K. Yadav, J. D. Wiebe, A. Patwardhan, T. K. Chen, O. Shikata, Y. G. Jadhav, P. Niyogi, R. Vadlamudi, V. Gupta, G. N. Bhatt, V. Gupta, K. K. Nath, R. Vadlamudi, P. Jain, K. Srivastava and D. K. Mohapatra, 2010. Statistical Evaluation of the Quality of Employee Performance Evaluations. Advances in Management Information Systems 2012.\nBIBREF2 J. D. Wiebe, J. W. Wiebe, Y. G. Jadhav, S. Tadepalli, 2011. \"Improving Performance Management Methods for Software Engineering: A Statistical Approach\", The Journal of Systems, Management and eBusiness, 15(1), pp. 13-32.\nBIBREF3 S. Srinivasan, A. K. Ganguly, N. L. Nirmal, and R. W. Prabhu, 2012. \"Performance Management: Automated Analysis, Personalization, and Learning\", Communications of the ACM, (December), pp. 56-62.\nBIBREF4 K. Kumar, N. Pawar, W. Jiang, Y. Wu, 2007. \"Performance Appraisal Process in a Large Telecom Corp: Understanding",
    "aa6d956c2860f58fc9baea74c353c9d985b05605": "\nAcknowledgements\nWe are grateful to the reviewers for insightful feedback and careful reading of our earlier versions of this paper. We would like to thank our research colleagues in Citrix, Facebook and Cisco for their kind support. We are grateful to U.S. National Science Foundation and Indian Department of Science and Technology (DST) for supporting this work.\n\nTable 1.\nTabulated performance appraisals data from a large IT company.\nTable 2.\nList of attributes used in PA for classifying employees in the organization.\nTable 3.\nList of text mining parameters used in experiments and their meaning.\nTable 4.\nPerformance metrics for PA system.\nTable 5.\nPreliminary metrics of PA text analysis.\nTable 6.\nPA performance metrics in the organization.\nTable 7.\nDistribution of strengths, weaknesses and suggestions across employee-years of experience.\nTable 8.\nClassification accuracy of sentence patterns for strengths, weaknesses and recommendations.\nTable 9.\n\nClassification accuracy of POS sentences using various methods.\nTable 10.\n\nPerformance metrics on manually-extracted gold-standard dataset D1.\nTable 11.\nComparison of sentence classification algorithms used in Sci-Kit Learn.\nTable 12.\nComparing text mining techniques for sentence classification.\nTable 13.\nComparison of sentiment analysis techniques for sentiment in strengths, weaknesses and suggestions.\nTable 14.\nNumber of words in sentences for strengths, weaknesses and suggestions.\nTable 15.\nClassification accuracy of POS based sentence pattern extraction.\nTable 16.\nAutomatically discovered clusters of strengths.\nTable 17.\nAutomatically discovered clusters of strengths.\nTable 18.\nAutomatically discovered clusters of weaknesses.\nTable 19.\nAutomatically discovered clusters of weaknesses.\nTable 20.\nStatistics of attributes used for performance evaluations\nTable 21.\nMulti-class multi-label classification results on manually-extracted gold-standard dataset D2.\nTable 22.\nMulti-class multi-label classification results on manually-extracted gold-standard dataset D2.\nTable 23.\nMulti-class multi-label classification results on manually-extracted gold-standard dataset D2.\nTable 24.\nMulti-class multi-label classification results on manually-extracted gold-standard dataset D2.\nTable 25.\nMulti-class multi-label classification results on manually-extracted gold-standard dataset D2.",
    "4c18081ae3b676cc7831403d11bc070c10120f8e": " These performance attributes cannot be inferred from PA text but they can be used for evaluating the performance from a different perspective.\n\nWe are currently investigating the use of deep learning models (such as CNN) as an alternative to the sentence classification model (Table TABREF29, Table TABREF35 and Figure SECREF6 ). For the multi-class multi-label classification, we are experimenting with various deep learning models like LSTMs and Attention models (such as ATTNET BIBREF23 ).\n\nACKNOWLEDGMENTS\nThe authors wish to specially thank Ms. Shweta Sarkar for her help in developing the summarization algorithm and in organizing the data for the experiments.\nREFERENCE BIBLIOGRAPHY\n\n[1] Alizadeh et-al., Deep Learning at Scale, https://research.att.com/deep-learning-at-scale/.\n\n[2] Ashish Gupta, Pawar R., Apte S., Jha P. A., Kumar V. (2012) Performance Appraisal System Using Kernel Methodology with Multiclass Text Classification. Int. Conference on Industrial and Information Systems.\n\n[3] Apte S., Jha P., Ashish Gupta, Gupta A. (2013) A Semi-Supervised Approach to Matching Employee and Manager Perspectives in HR Meetings. International Conference on Human Computer Interaction.\n\n[4] Apte S., Srinivasan J. S., Jha P., Gupta A. K. (2018) Performance Appraisal System Using Multiple Perspectives. Journal of Human Resources Management.\n\n[5] Apte J., Kumar P., Jha P., Gupta A. (2016) Using Label Propagation to Discover Aspects in Performance Appraisal Text. International Conference on Human Computer Interaction.\n\n[6] Deshpande A., Jha P., Gupta A. K. (2019) Automated Analysis of Performance Appraisal Text Using Semantic Similarity. Journal of Computational Linguistics.\n\n[7] Jha P., Gupta A. K. (2018) Discovering Aspects in Performance Appraisal Data based on Sentiment, Subjective & Objective Clustering. International Conference on Human Computer Interaction.\n\n[8] Jha P., Gupta A. K., Apte J., Trivedi P.,",
    "fb3d30d59ed49e87f63d3735b876d45c4c6b8939": "\nReferences\n\n[BIBREF1] Horne, C., Sprenkelsmeyer, C. and Vazquez, D.J. 2014. Performance Management in the Social Organization. Boston, MA: Harvard Business School Publishing.\n\nhttps://www.hbsp.harvard.edu/ecomp/it-papers/Performance_Management_In_The_Social_Organization_Horne_et_al._2014.pdf\n\nChapter 3, 3.3.2.\n\n[BIBREF2] Pawar, N., Apte, P. and Srinivasan, R. 2014. Performance Appraisal: A Classification Study. International Journal of Human Resource Management. Vol. 23, No. 2, pp. 169\u2013193.\n\n<https://www.hindawi.com/journals/ijhrm/2014/463268/abs/\n\n[13]\nThe classification algorithm used in this paper was improved from the algorithm presented in Pawar et al. 2014. The algorithm introduced sentence clustering features that were helpful.\n\n[BIBREF3] Marino, A. 2017. Design of Performance Evaluation Processes with Automated Sentence Classification.\n\n<http://www.lrec-conf.org/proceedings/lrec2017/pdf/768.pdf\n\n[BIBREF4] Khoo, B.Y., Cheung, L. and Ramnarayan, M. 2016. Understanding the Text in Performance Appraisal Systems.\n\n<http://www.springer.com/us/book/10.1007/978-3-319-62929-8>\n\n[BIBREF5] Ramrakhiyani, S.K., Grewal, V. and Srinivasan, R. 2015. Performance Evaluation Metrics: Discovering Aspects, Attributes and Targets.\n\n<https://www.springer.com/us/book/10.1007/9783319302728>\n\n[BIBREF6] Apte, P., Pawar, N. and Srinivasan, R. 2017. Machine Analysis of Supervisor Comments in Performance Appraisal.\n\n<http://www.springer.com/us/book/10.1007/978-3-319-62930-",
    "197b276d0610ebfacd57ab46b0b29f3033c96a40": " We are also exploring whether other PA text forms such as reports by employees or reviews of software products can be analyzed using the text-mining techniques described in this paper to yield insights for the business.\n\nAcknowledgements\nWe thank our internal (B&L) PA team for providing us the PA data for this work. We thank Dr. Anand Narayanan for his comments during review and Dr. Chandrashekar Prabhu for his comments. We thank Mr. Hitesh Jain for helping with the data analysis. Finally, we thank the anonymous reviewers of IJCAI-2016 paper for their suggestions, which helped us to make important improvements to this paper.\n\nReferences\n[1] G. Buzina, N. Chawla, \"Performance appraisal in a telecommunication enterprise,\" in: Proceedings of the 12th International Conference on Datamining (ICDM '04). ACM, New York (2004), 10\u201318.\n\n[2] R. Chandaria, E. Erotem, eds., \"Performance Appraisal Handbook,\" 5th ed., Prentice Hall, Upper Saddle River, NJ, (2018).\n\n[3] T. Deka, A. C\u00f4t\u00e9, eds., \"Human Recourse Management: The HR Connection, 3rd ed,\" Wiley-Blackwell, John Wiley & Sons, New York, (2017).\n\n[4] Z. Hu, X. Jin, X. Jin, L. Wu, W. Li, \"Sentiment Analysis for Text Mining,\" Wiley-Blackwell, John Wiley & Sons, New York, (2016).\n\n[5] J. H. S. Choi, L. T. H. Lam, \"Supervising Software Engineers\", Addison Wesley, Addison-Wesley Pub. Co., Boston, MA, (2007).\n\n[6] A. Ramrakhiyani, S. Natarajan, \"Performance Management in IT Services,\" 1st ed., Springer, London Heidelberg New York, (2017).\n\n[7] S. Deshpande, M. Bharadwaj, S. S. S. Rizvi, \"Classification of Sentence Types in Employee Feedback,\" in: 4th Annual Conference on International Information Intelligence and Big Data (III-BD '14). ACM, New York (2014), 1\u20138",
    "e025061e199b121f2ac8f3d9637d9bf987d65cd5": "\nAcknowledgments\nThis research is supported by Dassault Systmes; Microsoft Research; and Google. We thank Ms. Ashwini Chandrahan at Microsoft Research for suggesting this problem and helping with testing our summarization system at Microsoft. We thank Ms. Rhea Chhabra at Microsoft Research for discussing the problem and providing technical suggestions.\nReferences\n1. Cimiano, R. (2017) Building the best people from the best places. Harvard Business Review 2(12): 1-5.\n2. Chandra, A., S. Chhabra, I. Gretz and N. Zhang (2020) A comparative study of unsupervised techniques for automated identification of strengths, weaknesses and suggestions in performance assessment. Expert Systems With Applications 127(2): 114-122.\n3. Chandra, A., T. S. Chakravarthy and S. Chhabra (2018) Measuring, measuring, measuring in the performance appraisals. In Proceedings of the 26th Australasian Conference on Intellectual Property Management, AIIPM 2018. Available at: https://papers.ssrn.com.au/sol3/papers.cfm?abstract_id=3465185.\n4. Nitin Jain, Alain Delahaye, Pranam Chhabra, M. C. Lin and M. V. Ramaswami (2016) Data mining of performance reviews. In Proceedings of the 16th SIGKDD International Workshop on Mining of Social Media. P. 779\u2013786.\n\n5. Nitin Jain, A. Chandra, T. S. Chakravarthy and S. Chhabra (2018) Multi-dimensional assessment of employee attributes using label propagation. In Proceedings of the 39th Annual Conference of the International Speech Communication Association, INTERSPEECH 2018. P. 2420-2425.\n6. Nitin Jain, Pranam Chhabra, S. Chhabra, T. S. Chakravarthy and M. V. Ramaswami (2017) Automated analysis of performance appraisal corpora. In Proceedings of the 43rd Annual Conference of the Association of Computational Linguistics, ACL-IJCNLP 2017.\n\n7. McKnight, M. and S. R. Srinivasan (2006) Learning to identify speech acts in biomedical text by using support vector machines",
    "61652a3da85196564401d616d251084a25ab4596": "\nAcknowledgements\nWe thank the reviewers of the journal version of this paper for their suggestions that improved this paper.\n\nReference\n\nBIBREF0 Ghosh, S., and M. Poon, \"Automated analysis of performance evaluation text using text mining and machine learning \u2013 a survey\", Journal of Expert Systems with Applications, Vol. 41, pp. 34-37, 2016.\n\nBIBREF1 Khodke, A., N. Sharma, and S. Ghosh, \"Automated analysis of business text using hidden markov model feature selection and machine learning\", International Journal of Advanced Computer Science and Applications, Vol. 5, pp. 67\u201374, 2016.\n\nBIBREF2 Karimi et al., \"An Evaluation of Sentence Classification Algorithms using Convolutional Neural Networks and Convolutional Deep Belief Networks\", in Proceedings of the 16th ACM International Joint Conference on Pervasive and Ubiquitous Computing, 2017.\n\nBIBREF3 Ghosh et al., \"Evaluating Different Deep Structured Neural Network Architectures for Sentence Structure Classification and Predicting the Best Model for a Target Class\", in Proceedings of the 25th International Conference on Semantica, 2016.\n\nBIBREF4 Poon et al., \"Semantic Mapping of Performance Appraisal Text using Neural Network Classifiers\", in Proceedings of the 2016 Conference on Analytics of Social Media, 2016.\n\nBIBREF5 Apte et al., \"Discovering Aspects in Supervisor Assessments Using Labelled Sentences\", in Proceedings of the 19th International Conference on Database and Expert Systems, 2016.\n\nBIBREF6 Ghosh et al., \"Semantically Mapping Performance Attributes Using Weak-Supervision\", in Proceedings of the 19th International Conference on Database and Expert Systems, 2016.\n\nBIBREF7 McKnight, D., and Cyril Niyato Srinivasan, \"Classifying Sentences in Biomedical Abstracts into Classes\", in BiNLP at EACL, 2016.\n\nBIBREF8 Yamamoto, H., and Takeshi Takagi, \"Building Classifiers of Sentence Structure Using Semantic Dependencies\", in Proceedings of ACL 2015, 2015.\n\nBIBREF9 Cohen, Y., A. J. Lesk, and P. Langley, \"Learning Speech Act Word Patterns from Email",
    "14b74ad5a6f5b0506511c9b454e9c464371ef8c4": "\n\nFigure FIGREF18\n\nWe illustrate examples of problems caused by the lack of sparsity in the attention.\nFigure FIGREF19\n\nExamples of problems caused by the lack of constrained sparsity.\n\nFigure FIGREF20\n\nWhat are the language pairs explored in this paper?\n\nIntroduction\nIn the last years, recurrent neural networks (RNNs) showed success in various computational tasks (in particular in sequence processing) BIBREF25, BIBREF26. As a result, attentional models for deep learning emerged as a valuable paradigm BIBREF27, BIBREF28, and the majority of the recent NLP models use RNN layers BIBREF29 with attention, in what is called attentional transformer (AoT) models. This success story is related to the remarkable development of the transformer model architecture BIBREF30, BIBREF31, designed to efficiently learn representations of long-range dependencies, which is highly challenging for RNNs.\n\nTransformer models have achieved unprecedented success in NLP tasks, such as machine translation, in which RNNs had previously been used as the only approach BIBREF32. However, some questions have been raised about the applicability of transformer architectures to machine translation BIBREF33, BIBREF34. In particular, such as the lack of a formal justifica-tion for the attention mechanism, which does not appear in any of the formal transformer analysis and has not been validated empirically.\nIn this work, we attempt to provide a rigorous analysis of attentional models, which not only extends the transformer model architecture, but also allows us to design new approaches. Namely, we derive a set of mathematical conditions (Proposition EQREF3 ) that need to hold for an attentional model to achieve any level for efficiency, such as time, or accuracy, as well as a number of transformations that satisfy these conditions. This is important not only as a useful tool for understanding the performance of transformer models, but also because those conditions can be used to introduce efficient alternatives to the attention mechanism, while remaining within the same paradigm.\nWe discuss some of the most recent approaches to attention mechanisms in deep learning. To prove the conditions, we consider the attention transformation as a function of a number of model parameters. The main theorem (Proposition EQREF1 ), which connects our model architecture with the attention mechanism, is based on a similar type of arguments BIBREF33. We",
    "5c88d601e8fca96bffebfa9ef22331ecf31c6d75": "\nAcknowledgements\nWe would like to thank our colleagues Arne Straesser for assisting in the quantitative analysis and Sebastian Sch\u00fctze for assisting in the application of the framework to ReCoRd and HotpotQA data.\n\nReferences\n\n[1] Zdora2021. The future of language understanding\n\n[2] Wiegold2020. A language-independent approach to summarization at scale\n\n[3] Zdora2020. Beyond language matching: What is machine reading comprehension?\n\n[4] Zdora2019. Reading like an expert: Measuring and comparing reading capabilities of NLP models with multiple-choice questions. arXiv: 1905.10339\n\n[5] Devlin2018. BERT: Pre-training of deep bidirectional transformers for language understanding\n\n[6] Huang2015. Summarizing text while learning to read comprehension\n\n[7] Zhang2019. Reading-Comprehension-based Natural-Language-Inference Models\n\n[8] Gupta2019. DeepQuestionanswering \u2013 An End-to-End Approach for Knowledge Tracing\n\n[9] Chen2016. Open Questions: Language and data for question answering\n\n[10] Eisenschlos2019. The Evaluation of Language Understanding\n\n[11] Zdora2017. The Problem of Understanding Question-answering Systems\n\n[12] Zdora2018e. An Interpretable Method for Evaluating Textual Question Answering Performance. In Proceedings of the Eleventh International Workshop on Machine Learning and Data Analytics for Question Answering, 2019. pp. 12\u201317.\n\n[13] Yatskar2019. When Question Answering goes wrong\n\n[14] Zdora2019b. The Language Complexity of Evaluation Data: Insights from the State of the Art\n\n[15] SQuAD2018. SQuAD: 100,000+ Questions Answered\n\n[16] Lin2014. Statistical Machine Translation\n\n[17] Liu2016. ROUGE: A Package of Resources for Evaluating Summarization\n\n[18] Tsujii2018. Machine Reading Comprehension: Defining a New Challenge for Research in Natural Language Processing\n\n[19] Wang2019. A Study of Human and Machine Complexity in Question Answering\n\n[20] Zdora2020a. Question Answering",
    "71bd5db79635d48a0730163a9f2e8ef19a86cd66": "\nLimitations\nWhile we demonstrate the value of the framework by analysing six MRC literature benchmarks, it is clear that the proposed framework is not perfectly suited for all types of MRC gold standards. As the main categories of our framework (i.e. the ones we labelled as linguistically challenging and linguistically simple) are based on simple features such as the presence of Distractors and Synonyms, not all questions can be fully described by our proposed taxonomies BIBREF43. Concretely, we observe the presence of distractors in e.g. SQuAD, but in HotpotQA we do not observe their presence due to the strict requirement of matching every non-stop word exactly and the lack of distractors in DROP due to not allowing arithmetic operations. In ReCoRd, where the question is related to a specific event, it may sometimes be sufficient to answer the question simply by reordering or combining the entities mentioned in the passage accordingly. We propose to address this issue by introducing further subtags in the annotation as discussed in the supplementary material, thus allowing to separate out questions for which the reading comprehension is not necessarily challenging.\nAcknowledgement\nThe authors of this work are grateful for the open-source contributions to the PyTorch machine learning framework and HuggingFace sentence representation modeling library used in our work, as well as the open-source contributions to several of the considered gold standards.\nAppendix (a)\n\n(a) Annotation Instructions\n\nTo allow readers to directly and reproducibly reproduce our experimental work, the raw data underlying this paper will be made available upon release of this paper when our paper is accepted. The annotation instructions are included in the files in Appendix.\n\nAppendix (b)\n\n(b) Raw Data\n\nThe annotated gold standard data is also available in an extended version in Appendix A of the supplementary material. It is accompanied by the raw passages where every paragraph is annotated with its question and answer and with the supporting facts present (if used at all).\n\nAppendix (c)\n\n(c) Detailed Annotation Scheme Overview\n\nWe introduce the full detailed annotations scheme used in this paper. We first provide a short preview of our annotations using high-level categories and then include all features, their description, guidelines for their annotation and examples. Finally, we list all features used by all gold standards studied in this paper in the table below.\n\nAppendix",
    "9ecde59ffab3c57ec54591c3c7826a9188b2b270": " Additionally, this might allow us to understand what exactly is learned from such gold standards and how to leverage these features for future improvements.\nAcknowledgments\n\nThis work is in part supported by the European Union's Horizon 2020 research and innovation programme under grant agreement No. [H2020-RISE-2015-2017, H2020-RISE-742997, H2020-RISE-742998, European Research Council Advanced Grant EP/i505797/1 and Eurostar-CLARITY project number 81088.\n\nWe thank our colleagues at the Centre for Scientific Computing and the Simula research laboratory for helpful feedback, and in particular, we are grateful to Yannis Vlachos, Rianne Van Dyke, and Yurui Zhang for their assistance in the manuscript preparation.\nAbhay, Poshni & Barzilay, Antoine (2018). SQuAD v2.0: A General-Purpose Dataset for Question Answering. Transactions of the Association for Computational Linguistics, 3(1):1133\u20131148.\n\nAharoni, Liora & Vylomova, Marina (2017). A simple and fast strategy for generating paraphrases. Transactions of the Association for Computational Linguistics, 3(04):613\u2013629.\n\nBender, Max (2018). How Good Are Question Answering Systems?. Lecture Notes in Computer Science, 12156, 15\u201330.\n\nBertsimas, Dimitris (2016). Contextualized word vectors: Deep learning for semantically rich word representations. Ph.D. Thesis. University of Amsterdam.\n\nCambria, Javier, et al. (2017). Reading and answering Wikipedia: The SQuAD challenge. First International Conference on Learning Representations for Question Answering at Human Scale, Workshop Notes 2017.\n\nDai, Liang-Jie, et al. (2019). SQuAD-Math: A Multidimensional Reading Comprehension Benchmark Dataset for Complex and Conversational Spatio-temporal Reasoning. ArXiv e-prints, 1704.07722. Pre-print.\n\nDas, Sumit, et. al. (2018). SQuAD3.0: A General-Purpose Dataset for Question Answering. Transactions of the Association for Computational L",
    "005cca3c8ab6c3a166e315547a2259020f318ffb": "\nAcknowledgements\nThe authors would like to thank the anonymous reviewers for their helpful feedback. We would also like to thank the annotators of the proposed gold standards for their invaluable help in annotating the samples.\nReferences\n\n[1] A. Agarwal, B. Akgul, R. Barzilay, S. J. Choi, Y. Y. Liu, H. R. Martin, Z. Nagarajan, A. Cui and J. R. Wohlhart. 2015. Data complexity in machine reading comprehension evaluation. In ACL, pages 4327\u20134338.\n\n[2] A. C. Berg, Y. M. Bachrach, H. Gebru, M. Iyyer, K. Salloff, S. Wang. 2017. Understanding the performance of current question-answering systems with external knowledge. In EMNLP, pages 4587\u20134594.\n\n[3] G. Bojanowski, B. Iyyer, P. Chen, R. Klein, D. C. Lee, S. Bauer, J. Liang, G. Corrado, Y. Cui, J. DeNero, B. E. Foster, S. Gubbay, J. H. Martin, S. R. Sadol, H. S. Thompson, C. D. Williams, M. E. Jones, M. Johnson, A. R. Knight, C. Liao, R. Lextra, M. Luong, A. P. Mitchell, J. Bansal, B. K. Lee, J. Petkowiak, A. R. Pfeiffer, I. Sutskever, J. Zhang, C. Wong, P. Liu, M. G. Peterson, A. Rambow, Y. Zhu, J. Zico, N. Zhang, S. Yuille, S. Garg, P. H. Lee, A. Loper, M. Gupta. 2017. GLUE: The GL Assessment of Usage. In TAC, pages 67\u201372.\n\n[4] G. Bojanowski, B. Iyyer, M. Iyyer, E. Hecht, T. D. J. Corrado, R. Klein, D. C. Lee, H. Gebru, K",
    "af34051bf3e628c1e2a00b110bb84e5f018b419f": "\nAppendix::: Additional Qualitative Experiments\n: In subword-level experiments, we investigate the translation quality of TCEN compared with baselines. Figure FIGREF40A shows translation results. Our system generates longer target sequence while maintaining reasonable accuracy. Figure IGREF21 shows translation results based on different model setups. Our method brings more gains to vanilla baseline when the MT dataset is larger.\n: Figure IGREF22 and IGREF23 provide translation results on a few challenging sentences from the ST-TED test set. Compared to other models, our system manages to produce a plausible and grammatical target sentence.\n\nAppendix::: Loss Analysis\n: We inspect the effects of different model parameters and hyper-parameters on models performance by analyzing the BLEU score trend in pre-trained stage. Figure IGREF24 shows that with increasing number of layers, our model improves much more. The BLEU score in each pre-training epoch is shown in Figure IGREF25. This figure confirms that with deeper networks, the model has more capability to recognize linguistic features.\nAppendix::: Experimental Details\n: We report parameters used in other papers in Table TABREF46, where the source and target vocabulary sizes are denoted as $D_{s}$ and $D_{t}$, respectively. For our baseline models, we set $T=128$ for speech encoders and $K=512$ for speech decoders. For our TCEN model, we set $d=1024$ for the encoders and $K=512$ for the decoder. For our MT model, we use the source-end word embedding size of $32$ and the source vocabulary size of 5k tokens.\n: The loss weight of the fine-tuning stage is set as $a$ in our model, where $a=0.8$ for MT, and $b=1$, $c= 1$ for ASR and ST. We use the standard Adadelta training method BIBREF19 for all models with a learning rate of 1.0 for 50 epochs. The maximum frame length for input audio in pre-training stage is set as $T_x=16000$ and for fine-tuning stage as $T_x=2000$. The RNN hidden dimension in pre-training stage is set as 256 for both text and speech encoders. For fine-tuning stage, we set LSTM hidden size as 256",
    "022c365a14fdec406c7a945a1a18e7e79df37f08": " Besides, we use the pre-trained MT attention module in our final model to address the previous pre-trained attention issues. Note that, our model can also be employed by combining it with a cascaded model. Furthermore, we are the first method to effectively use noisy input MT data for large scale training.\n\nAppendix. A.1 CTC Loss Function In order to get rid of the necessity of a decoder, the CTC loss function is used to train the speech encoder. In this work, we consider a linear CTC model, although non-linear models are also possible. We use an approximate softmax to approximate the softmax function:\nwhere the approximation is made by choosing the index corresponding to the maximum value in $K_t$. It is proved in BIBREF7 DBLP:conf/interspeech/WeissCJWC17 that the linear softmax is able to approximate an exact softmax with exponential function. The CTC loss function for an input sequence $x = (x_1 \\cdots, x_{T_x})$, and a label sequence $y^s = (y_1^s, \\dots, y_T_s^s)$, is defined as:\nwhere $T_s$ is the length of the label sequence and $k_* \\in V_{src} \\cup $ {`-'-} is the label in a CTC path. Notice that, $Q(y_i^s | x_i, (k_*), \\dots, (k_*)-1) = y^s_i$ and we take $y_i^s$ as an observed label, which can be a blank token or a repeated one with length $T$ such as `-'.'\n\nAppendix. A.2 Role of Subnets in Pre-training for ASR\nIn this work, we propose a novel model TCEN, which is able to utilize all subnets in pre-training and keep the roles of sub-nets consistent during fine-tuning. Here, we introduce three examples to illustrate why a traditional ASR model is not able to utilize all subnets in pre-training.\n\nASR without Pre-training ::: A subnet-waste model\nFigure BIBREF24 shows a subnet-waste network where all the subnets are used in pre-training but discarded during fine-tuning. First of all, a pure acoustic model",
    "5260cb56b7d127772425583c5c28958c37cb9bea": "\nComparative Studies of Language Models on Switchboard Dialog Act Corpus\n\n(a)\n\nTable 1\n\nTable 2\n\nTable 3\n\n(b)\nTable 4\n\nTable 5\n\nReferences\n\n1 O. Cho and R. Zhang, \"Sociolinguistic Features in Tone of Voice and Language in English Spontaneous Conversations,\" in Proc. ACM Symposium on Applications of Computational Linguistics (SACLing 2014), Boston MA, USA, January 2014, pp. 3, 2013.\n\n2 I. Tenenbaum and G. Lang, \"Deep speech processing for automatic language identification,\" Proc. ACM-SIGIR Conf. on Speech and Language (Interspeech 2008), Barcelona, Spain, Sept. 2008, pp. 1388\u20131391.\n\n3 V. Mikolov, K. Chen, and J. Dean, \"Latent semantic analysis,\" in Proc. NIPS, 2012, pp. 808\u20131414.\n\n4 I. Sutskever, A. Veness, T. Chung, J. Dean, M. Cho, T. Lillicrap, S. Hoyer, and G. Dieleman, \"Sequence-to-sequence learning with neural networks,\" in Proc. AISTATS 2013, pp. 1347\u20131355.\n\n5 V. Mikolov, K. Chen, and J. Dean, \"Distributed representations of sentences and documents,\" CoRR, vol. abs/1305.2465, 2013, pp. 1, 2013.\n\n6 S. Hochreiter and J. Schmidhuber, \"Long short-term memory,\" NeurIPy Conf. on Recurrent Neural Network, 2001, vol. 1, pp. 1\u20137.\n\n7 T. L. Graves, \"Modeling word-sense disambiguation using recurrent neural network,\" in Advances in Neural Information Processing Systems, 2010, pp. 25\u201332.\n\n  8 D. Mikolov, I. Purgata, C. D. Cowgill, K. Chen, C. J. C. Griffiths, and A. K. Rayner, \"Scaling up word vectors,\" in Proc. IWCS, 2014, pp. 281\u2013287.\n\n  9 K. Kuele, H. B.",
    "9b97805a0c093df405391a85e4d3ab447671c86a": "\n\nOur work shows promising results in the noisy real spoken document listening comprehension task.\n\nIn future work, we hope to improve our results by exploring more advanced techniques for domain adaptation. The results show that the proposed domains adversarial learning could be effective.\n\nReferences\n\n[1] K. A. Bender et al. Spoken question answering and summarization. arXiv preprint, December 2019.\n\n[2] F. Chen et al. Evaluating multiple-choice machine reading comprehension. In Proc. of NAACL-HLT, 2018.\n\n[3]  P. Das et al. Talking for understanding: a large-scale corpus of real-world spoken question answering. arXiv preprint, February 2020.\n\n[4] K. D. Dahlmeier et al. Spoken question answering: from retrieval to reasoning. In Proc. of COLING, 2014.\n\n[5] Z. H. Dong et al. Modelling spoken-text data retrieval. Speech Commun., 44, 3 (November 2017), pp. 873\u2013891.\n\n[6] Ning Gan et al. Spoken-SQuAD: Automatic construction of a spoken question answering corpus. Proceedings of the 54th Annual Conference of the Association for Computational Linguistics: Student Research Workshop, 2019.\n\n[7] N. Gulordava et al. Adversarial sentence-level image captioning by learning to deceive. In Proc. of ACM SIGIR International Conference on the Web and Social Media, 2017.\n\n[8] Z. H. Dong et al. Modelling sub-word-unit transcriptions as domain-specific features for spoken language understanding. Comput. Speech and Lang., 43, 8 (January 2019), pp. 2443\u20132456.\n\n[9] M. Guzdial et al. Learning domain-general representations from multiple domains. In Proc. of ICML, 2018.\n\n[10] X. Han et al. Adversarial deep clustering for training domain-general language generative models. In Proc. of ACL, 2018.\n\n[11] M. Iyyer et al. Sequence tagging by adversarial neural clustering. Transactions of the Association of Computational Linguistics, pp. 18\u201332.\n\n[12] F. Jia et al. Unsupervised deep parsing of treebanks. In Proc",
    "38f58f13c7f23442d5952c8caf126073a477bac0": " It can also be applied to other QA models.\n\nReferences\n\n\\references\n\nBIBREF5 Li, W. et al. Spoken-SQuAD: a spoken question answering benchmark with subword units as inputs. 2019.\n\nBIBREF6 Chen, Y. et al. Spoken language understanding by machine: first steps into the era of automatic test preparation. 2022.\n\nBIBREF7 Zhu, Y. et al. Learning domain-general representations from multiple domain-specific task data for spoken term detection. 2019.\n\nBIBREF8 Li, L. et al. Document retrieval with sub-word units using acoustic modeling and cross-lingual transfer. 2018.\n\nBIBREF9 Ardizzone, C. et al. Domain adaptation for automatic speech recognition. 2018.\n\nBIBREF10 Wang, Z.-Y. et al. Adversarial domain adaptation for fast model update and data reuse for downstream speaker adaptation. 2019.\n\nBIBREF11 Yi, J. et al. Adversarial transfer learning for acoustic model update and parameter transfer for downstream speech processing. 2020.\n\nBIBREF12 Huang, L. et al. Adversarial domain adaptation for automatic speech recognition. 2022.\n\nBIBREF13 Zhang, Y., Yu, L., and Li, Y. Hierarchical adversarial training for audio speaker transfer. 2020.\n\nBIBREF14 Liu, J., and Lane, D. C. Learning joint acoustic and visual features from multiple domain-independent spoken dialogue corpora. 2018.\n\nBIBREF15 Zhu, Y., Lin, X., and Lan, J. Transfer between shared domain-specific speech features and ASR hypotheses for spoken language understanding. 2019.\n\nBIBREF16 Li, L., Lan, J., Zhu, Y., and Zhang, Y. Spoken cross-lingual language-modeling with cross-domain adversarial learning. 2019.\n\nBIBREF17 Jiang, W., Zhang, Z., Xiong, S., Wang, X., Chen, J., and Song, L. Transfer-learning with cross-domain adversarial feature learning and cross-domain attention for slot-tagging. 2019.\n\nBIBREF18 Feng, Z., Sun, J., Gao, Y., and Chen, C.-L. Fasttext: building",
    "7ee5c45b127fb284a4a9e72bb9b980a602f7445a": "\nOur source code is available at https://gitee.com/doudian/speakqa-train/tree/ master.\nREFERENCES\n\n<1>\n\nRajpurkar, P., Jia, Y., Fei-Fei, L., Anand, A., Liang, Y., Li, Y., Xu, X., Chaudhuri, S., Li, W., Hasty, P., and Riley, C. (2016). SQuAD: 100k questions\nanswered in context from Wikipedia. ArXiv, abs/1606.01481. [Online]. Available: https:// arxiv.org/abs/1606.01481.\n\n<2>\n\nRajpurkar, P., Zhang, Z., Lo, K.-H., Yao, Y., Jia, Y., Chaudhuri, S., Li, W., Hirst, C. (2018). T5: A Neural, Probabilistic Text-to-text Engine for Language\n  Generation and Question-answering in Tensorflow. [online]. Available:\n\n<https://arxiv.org/pdf/1803.06113.pdf>.\n\n<3>\n\nHwang, T.-J., Houlsby, T., Dyer, C. et al. (2014). Document retrieval with phrase-based word clusters. In\nProceedings of the 24th international\njoint conference on Natural Language processing and Chinese computer\n  engineering, pages 699\u2013703.\n\n<4>\n\nKumar, P., Yang, G., Ngiam, S., Ng, S. Y. et al. (2018). Query-guided neural document\n  retrieval. In Proceedings of the 55th annual meeting of the association\n  for computational linguistics, pages 3327\u20133334.\n\n<5>\n\nWu, T., Liu, R., and Yang, G. (2019). Extractive spoken question answering via\nsemantic graph generation: an overview and recent advances. International\n  Journal of Speech-Language Pathology, 111, 1\u201320.\n\n<6>\n\nXiong, L., Lu, C.-Y., and Ng, S. Y. (2019). ODSQA: an open-domain\n  Spoken Question answering  corpus.",
    "ddf5e1f600b9ce2e8f63213982ef4209bab01fd8": "\nFuture Work\nFor future work in SQA, there are still many issues that need attention. One issue is the effect of unsupervised learning of the domain-discriminator. In this work, we have no training data of reference transcriptions. However, we find that domain discriminator enables the model learning ASR-error robustness. Hence, we think we can adopt an unsupervised learning approach to further improve the robustness when it is further studied. Another issue is the effect of the proposed approach in the open domain setting. Even though this work uses only a limited number of annotated questions in the open domain, it achieves a promising performance. Therefore, we think the proposed approach can generalize over large-scale spoken questions from corpora like Open Domain Question Answering Corpus BIBREF21. Furthermore, we are interested in adopting our approach in other tasks, e.g. spoken document retrieval. Finally, the problem needs to be studied in the future work in terms of the effectiveness of the learned shared representation. In our future work, we are going to release an open source implementation of the proposed approach.\nACKNOWLEDGMENTS\n\nWe want to thank the anonymous reviewers for the useful feedback.\n\nREFERENCES\n\n1.\n\nS. Chopra and J. D. Weston (2016) \"The SQuAD objective: 100,000 question-answer assertions for assessing comprehension of English text\", In: BMVC, 2016\n\n2.\n\nP. Lample, A. Conneau, V. van den Oord, Y. Bengio, and J. Weston (2018) \"The lost literature of the deep learning revolution: a survey and taxonomy of machine comprehension models\", Transactions of the Association of Computational Linguistics, 2017\n\n3.\n\nO. Sutskever, I. Sutskever, and H. Hasselstrom (2013) \"Sequence to sequence learning with neural networks\", In: Neural information processing systems (pp. 3016\u20133024), 2013\n\n4.\n\nB. Zhao, Y. Wan, and C. G. Raths (2017) \"Spoken question answering: current status and future prospects\", The Journal of Applied Language Technologies, 29(2), 2017\n\n5.\n\nM. Chen, G. M. Zhou, Z. Gao, S. Liu, and W. Zhang (",
    "27275fe9f6a9004639f9ac33c3a5767fea388a98": "\n\nBIBREF\n\nBibrefference\n\nBIBREF0\n\nJ. Mikolov and Y. Chen\n\nBibrefference 0\n\nBIBREF1\n\nK. Sogaard and G. K. Kirstedt\n\nBibrefrence 1\n\nBIBREF2\n\nD. M. Cohen\n\nBibrefrence 2\n\nBIBREF3\n\nJ.-Y. Mao and J. Liu\n\nBibrefrence 3\n\nBIBREF4\n\nS. Vyas, S. E. Leskovec, and M. R. Kale\n\nBibrefference 4\n\nBIBREF5\n\nK. F. Doermann, M. K. Singh, M. P. P. Nieuleski, and A. M. Roy\n\nBibrefference 5\n\nBIBREF6\n\nP. M. S. Gouws, D. V. Kulkarni, Y. Zhou, Y. Li, X. Lei, and D. P. S. T. Corr\u00e8ge\n\nBibrefrence 6\n\nBIBREF7\n\nF. Yin, K. T. Bowden, M. Li, D. P. S. T. Corr\u00e8ge, and M. R. Kaleski\n\nBibrefrence 7\n\nBIBREF8\n\nS. E. Leskovec, C. Cregin, B. Filippova, F. Petrossian, S. Ermon, and A. Z. C. Bray\n\nBibrefference 8\n\nBIBREF9\n\nS. E. Leskovec, C. Cregin, B. Filippova, F. Petrossian, T. Kudo, S. Ermon, S. Chopra, A. Z. C. Bray, and J. Liu\n\nBibrefrence 9\n\nBIBREF10\n\nS. Ermon, R. Socher, C. H. Ng, C. Cregin, B. Filippova, M. Li, S. Ermon, T. Kudo, F. Petrossian, S. Ermon, and A. Z. C. Bray\n\nBibrefrence 10\n\n",
    "ef3567ce7301b28e34377e7b62c4ec9b496f00bf": " and Abbreviations\nAI Artificial intelligence \nANN Artificial neural network\n\nBERT Brain-inspired transformer\n\nBIBREF0 Word2vec: Distributed Representations of Words\n\nBIBREF1 Bert: Pre-training of deep BERT (BERT-base, BERT-large)\n\nBIBREF2 Roberta: A bidirectional language model (Roberta-base, Roberta-large)\n\nBIBREF3 DistilBERT (DistilBERT-base, DistilBERT-large)\n\nBIBREF4 Attention-based neural network (self-attention, intra-sentential, masked)\n\nBIBREF5 Comparing the accuracy of word embedding models on downstream NLP tasks\n\nBIBREF6 The effect of parameters and training strategies for word2vec \nBIBREF7 Combining word2vec with other word embedding methods \nBIBREF8 Wiki News Abstract by BIBREF8\n\nBIBREF9 Wiki Simple from BIBREF9\n\nBIBREF10 Billion Word from BIBREF10\n\nBIBREF11 IMDb for sentiment analysis by BIBREF11\n\nBIBREF12 Meaning Bank from BIBREF12\n\nBIBREF13 Semantic and syntactic analogies by BIBREF13\n\nBIBREF14 The effect of context during deep neural network training in NLI tasks\n\nBIBREF15 Neural networks for natural language processing (BIBREF15)\n\nBIBREF16 Word similarity from embedding vectors by BIBREF0\n\nBIBREF17 Gensim (python implementation of word2vec)\n\nBIBREF18  Latent dirichlet allocation (LDA) and latent semantic analysis (LSA) \nBIBREF19 Neural network models: Hyper-parameters and training\n\nBIBREF20 Comparative results on word similarities by BIBREF20\n\nBIBREF21 Empirical study on training time and time to load a large vocabulary word2vec model \nBIBREF22 NLTK\n\nBIBREF23 Energy usage and time-efficiency of word2vec models\n\nBIBREF24 Comparison of different word vectors for evaluating similarity on a set of sentences \nBIBREF25 Comparison of word2vec models across different corpora\n\nBIBREF26 Comparison of word vectors on NER",
    "7595260c5747aede0b32b7414e13899869209506": " and Abbreviations\n\nBIBREF0\n\nD Blodgett, G Callan, G Cherniack, J Devlin, B Mitchell, A Tyers, \"Word2Vec: Distributed Representations of Words and Phrases from Texts.\" Proceedings of the 20th International Conference on World Wide Web, 2016\n\nBIBREFB\n\nT. LeBauer. L. A. Zettlemoyer. D. Blodgett, H. H. Chien, H. C. S. R. Zittel, H. Wu, A. Tyers, G. Callan, L. A. Zettlemoyer, K. Cholakyan, J. Devlin, G. K. Cherniack, F. Eriguchi, Y. Kim, B. W. Mitchell, M. Fonseca, S. M. Smith, and A. T. Wu, \"Skipgram: Learning to Predict and Extract Contextual Word Pairs,\" Proc. ACL, 2015\n\nBIBREF1\n\nA. Clark, H. Chen, A. D. Klein, P. Jain, M. Liang. Learning Deep Neural Networks for Unsupervised Semantic Representation. KDD workshop on Representation, Language Models and Deep Learned Semantics, 2015\n\nBIBREF2\n\nP. Zhang, J. Huang, Y. Cheng, L. Guo. Deep Learning with Bidirectional Encoder Representations for Relation Extraction. KDD 2015\n\nBIBREF3\n\nY. He, X. Shen, S. G. Jordan, Z. Wu, P. Zhang. A Deep Neural Network Model of Word Vectors. 2017\n\nBIBREF4\n\nR. Huang, U. V. N. V. Prabhakar. Understanding deep neural language models through bi-directional attention. The 25th International Conference on Machine Learning. 2017\n\nBIBREF5\n\nH. Chen. Word Embeddings in Neural Networks: The Common Features of Word Vectors with Context and Sentence Embeddings. Arxiv preprint 2018\n\nBIBREF6\n\nW. Lecun, P. Solla. Imagenet classification with 10k parameters. 2013\n\nBIBREF7\n\nA. Agarwal, M. Fazly,",
    "c2d1387e08cf25cb6b1f482178cca58030e85b70": "\n\nA/A\n\nAvg.\n\nBW\n\nBillion.\n\nBIBEF\n\nBahdanau et al.\n\nBIBREF0\n\nBILSTM\n\nBidirectional long short term memory network.\n\nBERT\n\nBidirectional encoder representations from transformers.\n\nc\n\nC\n\nCAT\n\nCategorical.\n\nCMMD\n\nContext-memory model of meaning\n\nCNN\n\nConvolutional neural network\n\nCNP\n\nContinuous negative pooling\n\nDNN\n\nDeep neural network\n\nDMLN\n\nDeep mean-learner network\n\nGMDB\n\nGroningen Meaning Bank\n\nGMB\n\nGMDB\n\nGMB\n\nGMDB\n\nGMB\n\nGMB Dataset\n\nLSTM\n\nLong short term memory network\n\nLSI\n\nLatent sematic index\n\nMDN\n\nMeaning detector network\n\nMLLT\n\nMinimum length language model\n\nNLTK\n\nNatural language toolkit\n\nNLM\n\nNatural language model\n\nNER\n\nNamed entity recognition\n\nSA\n\nSentiment analysis\n\nSSA\n\nSparse skipgram architecture\n\nSW\n\nSimple Wiki corpus\n\nV/V\n\nVector space similarity\n\nVOC\n\nVocabulary\n\nVOSM\n\nVocabulary order sensitive model\nReferences\n\nBahdanau et al.\n\nBahdanau et al. (2014). Neural machine translation by jointly learning to align and translate. Trans. of ACM. 20:1754-1760. https://doi.org/10.1145/2661448.2666108\n\nChen et al.\n\nChen et al. (2015). A modeled word with distributed memory. In: K\u00fcbler et al. (eds.). Proceedings of the 34th International Conference on Computer Processing of Oriental Languages (ICCPOL). Tottowa, Japan, pp. 1643-1654. https://doi.org/10.1145/2813051.2813055\n\nDavidson et al. (2017). Convolutional neural networks for biomedical image recognition. In: Ieee international conference on bio-inspired computing: theory and applications (BIC-TA).",
    "5a22293b055f5775081d6acdc0450f7bd5f5de04": "\n\n \n# Praise for C.J. Box\n\n\"The great new series starring Joe Pickett that C. J. Box began with Open Season. The latest Pickett novel is full of the Wyoming man's signature wit and wisdom. It's a wonderful return to a popular world that will make both new and longtime fans happy.\"\n\n\u2014Lee Child\n\n\"In Joe Pickett, C. J. Box has created one of the best new characters in recent crime fiction.... Pickett is a likeable cowboy in the true Wyoming style who is a delight to read about. Anyone who's a fan of the Westerns of Louis L'Amour and of Elmore Leonard's short stories, as well as of those modern books such as Cormac McCarthy's The Road and Annie Proulx's Brokeback Mountain, will find a lot to like about Box's stories.\"\n\n\u2014William Kent Krueger\n\n\"If you like Lee Child and Craig Johnson, you'll like C.J. Box. If you like Louis L'Amour and W.P. Kinsella, you'll love C.J. Box. If you love great writing, you will love C.J. Box.\"\n\n\u2014Michael Korda\n\n\"Joe Pickett is the most engaging and sympathetic detective hero to enter the mystery scene for a long while. At once wry and serious, tough and compassionate, Joe is the kind of hero I'd like to see when I've got my own problems to solve.... There can be no doubt that C. J. Box is the preeminent crime writer of our generation.\"\n\n\u2014Don Lee\n\n\"Joe Pickett is a strong, appealing, engaging hero. He's smart, tough and tenacious in the best old-fashioned tradition, and he faces a mystery of great complexity. _Shimmering Ashes_ is one of C. J. Box's strongest novels that moves forward with suspense and surprise throughout. Box's storytelling is superb, his eye and ear for the milieu of the American West as keen as ever, and he gives us a great supporting cast of characters, from the usual suspects to the charming old grandmother. With Joe Pickett, C. J. Box gives us one to watch.\"\n\n\u2014Steve Hamilton\n\n#\n\nPraise for **_Shimmering_ Ashes_ :**\n\n\"A tightly",
    "03c967763e51ef2537793db7902e2c9c17e43e95": "\nCite as\n\nGong E, Xiang Z, Sun YB. A Hierarchical Encoder for Table-to-Text Generation via Modeling Information in Row, Column and Time Dimension. In Proceedings of the Thirty-second Annual Meeting of the Association for Computational Linguistics: Short Papers (Volume 1). New Orleans, Louisiana, USA, 2018, pp 11\u201319.\n \nThank you for downloading this Gallery Books eBook.\n\n* * *\n\nSign up for our newsletter and receive special offers, access to bonus content, and info on the latest new releases and other great eBooks from Gallery Books and Simon & Schuster.\n\nCLICK HERE TO SIGN UP\n\nor visit us online to sign up at  \neBookNews.SimonandSchuster.com\n\nPublisher's Notice\n\nThe publisher has provided this ebook to you without Digital Rights Management (DRM) software applied so that you can enjoy reading it on your personal devices. This ebook is for your personal use only. You may not print or post this ebook, or make this ebook publicly available in any way. You may not copy, reproduce, or upload this ebook, other than to read it on one of your personal devices.\n\nCopyright infringement is against the law. If you believe the copy of this ebook you are reading infringes on the author's copyright, please notify the publisher at: simonandschuster.biz/online_piracy_report.\nFor my readers and their friends: the next book coming this January\n\n## INTRODUCTION\n\n* * *\n\nI am a man who finds excuses everywhere, and I have only one excuse for making this novel into six novels and more than eight hundred pages. Simply put, my story is too big. Yes, the story of a man and woman who find themselves drawn inevitably together, only to discover that they never actually wanted to be in love with the same partner in the first place. I don't know how it happened, but I think I can be forgiven. I have no desire to spend the time\u2014or money\u2014to try my hand at self-promotion or self-advertising; I am not in the market to exploit this material. This story was too big to be contained neatly within the spine of a single volume.\n\nThere were so many things to share! So many details of",
    "26327ccebc620a73ba37a95aabe968864e3392b2": "\n\n[Arai14] Arai, S., and E. H. Hovy (2014). Towards Measuring Argumentative Competence in Real-Time through Interactional Linguistic Features. Proceedings of the Workshop on Language Models and Human Behavior 2014.\n\n[Arai2016] Arai, S., and V. Niculae (2016). Modeling Argumentative Strategies in Debates: Learning Argumentative and Rhetorical Features from Multimodal Interaction. In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics, pp. 1189\u20131196. \n\n[Aronoff+09] Aronoff, R., J. M. Blythe, D. L. Cramer, and K. Hasegawa (2009). Using the Turn Structure of Dialogue to Predict Conversation Outcomes. Computational Linguistics 35, pp. 189\u2013210.\n\n[Baker13] Baker, B., N. D. Bontcheva, R. Albrecht, and A. Y. Yu (2013). Informal Argument: A Case Study. In Proceedings of the 8th International Conference on Language Resources and Evaluation, pp. 12\u201320.\n\n[Bontcheva+10] Bontcheva, N. D., E. M. Hovy, R. B. A. Jelinek, and T. DeVault (2010). Informal Argument: Using Speech Act Recognition to Capture Public Dialogue Arguments. Computational Linguistics 32, pp. 95\u2013116.\n\n[Chawla14] Chawla, S., E. M. Hovy, G. Chrupa\u0142a, and R. B. A. Jelinek (2014). Automated Argument Structure in Interpersonal Dialogue Using Linguistic and Non-Linguistic Features. Computational Linguistics 39, pp. 103\u2013119.\n\n[Chinchille16] Chinchille, B., E. Hovy, G. Chrupa\u0142a, N. D. Bontcheva, T. P. DeVault, and R. B. A. Jelinek (2016). Who Concedes More? Towards Automated Argumentation on Social Media. In Proceedings of the Conference of the North American Chapter of the Association for Computational L",
    "ababb79dd3c301f4541beafa181f6a6726839a10": "\nAppendix A\nAnnotators' Notes\nFor each question, we also ask the annotators to record, as part of their notes, any other comments they make that are not reflected in their annotations. Here we include these notes as well.\n(a) Oxford-style Debates. The Oxford-style debate format is the first one introduced in Table TABREF8. Oxford-style debates have a fixed motion of their own selecting sides that have in general high social status (thus, a fair amount of money, status, etc.). The motion is put forward right from the beginning and serves as the key focus of the debate and both sides generally agree that it will be disputed during the debate. The winning side is not necessarily the one whose opinion is most popular among others, but rather is determined in a second vote which takes place right before the final round. This means that even if one of the sides starts with a high lead for the first vote, if it fails to sway enough people to vote in the second vote, it can fail to win even though most people might be in favor of the motion. This makes Oxford-style debates a setting where the strategy of the debaters is really decided during the debate itself, since they have been given a motion of their own as a starting point, and by making a good impression as debaters and swaying enough people to vote in the second vote, they can win despite starting with a low score.\n(b) Definition. For the purpose of this definition, when debaters are commenting on one another's arguments, we call it 'debate'. We leave out those kinds of comments when debaters are making commentary or personal remarks, because even if they can be considered to be addressing other debaters' points, they tend not to be informative and serve a different purpose.\n(c) Turn Structure. The turn structure of a debate is pretty straightforward in an Oxford-style debate: a single team member's talk counts as a single turn. This is in contrast to a \"formal debate\" where debates tend to have two or three members each from both sides and it is quite common for entire debates to be made up of several consecutive monologues, as in the case of American Presidential debates.\n\n(d) Scrutiny. The focus of scrutiny does not necessarily have to be on a debater as a person, but can also be on the motion that is being discussed and discussed in more general terms",
    "c2b8ee872b99f698b3d2082d57f9408a91e1b4c1": "\nAcknowledgements\n\nThis work was supported by the German Federal Ministry of Economics and Energy (IMI) under project number 042E12, and by the German Federal Ministry for Education and Research (BMBF) under project number 03ZK06.\nBIBREF0  A. L. Barone.  S. B. Laptev, D. Kowal.  J. Lee, A. K. Barzilay, Z. Ghaffar, R. A. Klein.  A. P. Martin, O. Chapelle.  I. Bajaj, S. Lee, C. R. J. C. Burges.\n\nBIBREF1  G. Ammalati, P. Martin.  K. Kowal.  R. N. R. Miller, A. Tsvetkov, I. Bajaj.  M. R. Heilmann.  J. R. P. Koehn, F. Strube, D. Petroski, C. Kott, J. Briscoe, G. A. Bradshaw.\n\nBIBREF2  A. L. Barone.  S. B. Laptev, D. Kowal.  J. Lee, A. K. Barzilay, Z. Ghaffar, R. A. Klein.  A. P. Martin, O. Chapelle.  I. Bajaj, S. Lee, C. R. J. C. Burges.\n\nBIBREF3  C. Bollen, L. Tsatsaronis, S. Lascarides, J. R. P. Koehn, F. Strube, C. Kott, J. Briscoe, G. A. Bradshaw.\n\nBIBREF4  D. Cai, L. V. Catena.  T. A. Kim, C. Huang, C. Loper, M. A. L. Pilehuf, N. Roy, A. Zhai.  B. Buneman, J. Briscoe, S. J. Higgins, O. Chapelle.\n\nBIBREF5  M.-J. Chang, O. Chapelle, S. Callan, K.-W. Chang, K. Choe, D. Pet",
    "8eefa116e3c3d3db751423cc4095d1c4153d3a5f": "\nAcknowledgements\nThe work presented here was carried out as a part of the DATEX (Data-centered Technologies for e-Science) project. This project is based on the initial investigations of the GENIA Project at the Institute for Computer Technologies and Automation (ITA) of Graz University of Technology. Furthermore, we want to thank all volunteers involved in the GENIA annotation task for their voluntary work and for sharing their annotations. Specifically, we acknowledge the work of the whole annotation teams, e.g. BIO1, BIO2, BIO3. We also thank the efforts of the following people:\n\nEva Heer, Bernhard Kiebler, Christian Leitner, Gerhard Linder, Philipp Ludwig, Hans-Ulrich Lieser, Philipp Marklein, Gerg\u00f6 Oberteuffer, David Pfeffer, Johannes Pfautsch, Helger Pichler, Michael Rehberger, S\u00f6ren Schleininger, Thomas Schreibner, Karolina Uhrig, Johannes Verwilst\nPublication related to this paper has already appeared in BIBREF1 at the NER workshop at NAACL 2015. Therefore most material was modified for space reasons.\nReferences\n\n[Apostolopoulos, 2010] Apostolopoulos, S. (2010). The C++ NLTK Toolkit. In\n\n[Apostolopoulos, 2011] Apostolopoulos, S. (2011). The Anaconda Python Toolkit for NLP.\n[Austin, 2014] Austin, M. (2014). The NLTK 2.0 Toolkit For Natural Language Processing.\n[Baker, 2013] Baker, L. A. (2013). The NLTK 2.1 Toolkit For Natural Language Processing.\n\n[Barzilay, 1992] Barzilay, R., Hirst, B., and Jurafsky, D. (1992). An Analysis of Lexical-Functional Grammar.\n[BIB-GON, 2012] BIB-GON Consortium. (2012).\n\n[Brants, 2000] Brants, E. (2000) Automatic Recognition of Named Entities in Biomedical Literature by Combining a Context-based Coarse-Grained Pattern Matching Method with Machine Learning Methodologies. Proceedings of the Twelfth Workshop on Natural Language Generation, pp. 75\u201384.\n[C",
    "133eb4aa4394758be5f41744c60c99901b2bc01c": " The proposed approach can be also explored using word vectors which are not generated by neural network based language models. Moreover, the dimension and number of the mapping vector can also be different in varying domains.\nFuture Work\nAs a future work, one could explore on a larger data. The dimension and number of mapping vector and data transformation can be different in varying domains. Moreover, word vectors can be generated by other neural network based language models.\nAcknowledgement\nAuthors would like to thank Ms. Aarti, Dr. Anusree, and other Symbiotic team members of Centre for Artificial Intelligence, Computer and Communication Sciences Department, Anna University for supporting with this work.\n\n[1] A. Abur, M. J. R. Fellbaum, and N. G. Cieri, 2011. A Computational Study of Linguistic Annotation: Analysis of Errors Made by People Doing Grammatical Labeling Tasks.\n\n[2] M. Abhishek Chandra, M. N. Reddy, N. P. Suryadevara, and M. Gopala Krishna, 2018. Detection of Cyberbullying through Text Analysis. arXiv preprint.\n\n[3] M. Abhishek Chandra, M. N. Reddy, M. Gopala Krishna, N. P. Suryadevara, and M. N. Sowmya, 2019. Exploring machine learning based cyberbullying detection for social media using social media. Journal of Communication & IT.\n\n[4] Y.-H. Yin, K. H. C. Chan, N. G. Cieri, M. J. R. Fellbaum, and A. B. S. Ram, 2013. Automatic Identification of Offensive Language in Twitter Sentences. In Proceedings of the Workshop on Annotated Corpora and Applications at ACL2013, pp. 73\u201381.\n\n[5] C. Schmidt, R. Wiegand, R. J. Berthold, and A. H. G. C. M. Veenstra, 2013. Automatic Hate Speech Detection. In Text and Social Media Mining: Advances in Natural Language Processing and Social Computing, pp. 113\u2013128.\n\n[6] K. D. Dadvar, O. K. Bender, P. Chen, J. H.",
    "3fff37b9f68697d080dbd9d9008a63907137644e": "\nAbout the Authors\nNamrata Gaur is currently pursuing her PhD in Computer Science from Maulana Azad National Technical University, Jaipur. She did BTech in Electronics and Communication from Amity University, Noida.\nShruti Chopra is pursuing her PhD in Computer Science from M.A.R.I.T., Pune. She did BTech in Electronics and Communication from Amity University, Noida.\nShashwita Tiwary is pursuing her PhD in Computer Science from IIT Kanpur. She did BTech in Electronics and Communication from Amity University, Noida.\n\nList of abbreviation\n\nBIBREF0:  \nBIBREF1:  \nBIBREF2:  \nBIBREF3:  \nBIBREF4:  \nBIBREF5:  \nBIBREF6:  \nBIBREF7:  \nBIBREF8:  \nBIBREF9:  \nBIBREF10:  \nBIBREF11:  \nBIBREF12:  \nBIBREF13:  \nBIBREF14:  \nBIBREF15:  \nBIBREF16:  \nBIBREF17:  \nBIBREF18:  \nBIBREF19:  \nBIBREF20:  \nBIBREF21:  \nBIBREF22:  \nBIBREF23:  \nBIBREF24:  \nBIBREF25:  \nBIBREF26:  \nBIBREF27:  \nBIBREF28:  \nBIBREF29:  \nBIBREF30:  \nBIBREF31:  \nBIBREF32:  \nTABREF0:  \nTABREF1:  \nTABREF2:  \nTABREF3:  \nTABREF4:  \nTABREF5:  \nTABREF6:  \nTABREF7:  \nTABREF8:  \nTABREF9:  \nTABREF10:  \nTABREF11:  \nTABREF12:  \nTABREF13:  \nTABREF14:  \nTABREF15:  \nTABREF16:  \nTABREF17:  \nTABREF18:  \nTABREF19:  \nTABREF20: \u2014 Offensive Language",
    "a778b8204a415b295f73b93623d09599f242f202": "\n\nAcknowledgements\n\nThe authors would like to thank Professor David Barberena for sharing the annotated tweets, and giving the initial motivation for this work.\n\nReferences\n* *\n\n[1] L. R. Barberena, D. Trguica, N. Afrati, J. Stoyanova, and H. Bjelke. \"Identifying and Categorizing Offensive Language in Social Media: Task Overview and Baseline Results for SemEval 2019\". In Proceedings of the 2018 SemEval Workshop. Association for Computational Linguistics (2019), [4]\u201343.\n\n[2] A. BERTOV, I. Y. Belkin, N. Chen and E. O. Smirnov. \"On the Efficiency of Word Embeddings and Its Implications for Deep Neural Network Architectures\". arXiv preprint arXiv:1805.06011 (2018).\n\n[3] H. Iida, R. Kitsuregawa, C. Liu and M. Tomita. \"Unsupervised Machine Learning for Offensive Language Detection on Online Social Networks\". The Fifth International Workshop on Language Resources and Evaluation (FREW), 2016. doi:10.4994/FREW2016.\n\n[4] J. M. Yin, S. Zhu, M. Li and L. Liu. \"Detecting Spam, Bullying and Harassment in Microblogs\". International Conference on Information and Knowledge Management (KCIKM), 2010.\n\n[5] F. Schmidt and A. Wiegand. \"An Overview of Automatic Hate Speech Detection Using NLP Methods\". Social Media and User Moderated Content: Understanding, Capturing, Analyzing (UCMCMM), 2016.\n\n[6] I. Dadvar, M. Kumar and J. Srikanchana. \"Coping with Cyber-Bullying on YouTube: New Approaches for Detection and Analysis.\" Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies.\n\n[7] B. Wiegand, M. Ochs, and A. Mueller. \"Aggression Identification in Social Media - Shared Task 2018: A Comparison of Approaches from NLP and Psychology Perspectives\". Proceedings of the North American Chapter of the Association of Computational Linguistics Conference, 2018.\n\n[8",
    "642e8cf1d39faa1cd985d16750cdc6696c52db2f": "\nReferences\n\nA. Dyer, M. A. Ermon, and B. C. Wharton. \"Building an English to Romanian neural machine translation system.\" In Proc. European NLP Workshop, pp. 84\u201391, 2008, http://ceur-ws.org/Vol-1139/qtm-2012-021/.\nG. Goyal, G. Hirst, M. Iyyer, I. Titov, D. Choi, S. Chen, I.-Y. Lee, D. Lee, and S M. Lee. 'Enabling Multilingual Machine Translation with Deep Learning for Neural Machine Translation,' NIPS 2015.\n\nS. Chopra, A. Garg, O. Girin, A. Goyal, N. Madaan, and S. Singh. \"Neural Machine Translation with Deep Bidirectional RNNs: Improving Synergies across Languages,\" arXiv:1510.05287, 2015.\n\nA. Gogate, H. Heister, T. Zhang, and N. M. N\u00f6rrle. \"The Effect of Dropout on Dropout-Based Neural Machine Translation,\" CoRR abs/1407.7343, 2014.\n\nK. Graff and J. K. Liu. \"Training a Bidirectional Language Model in the Tensorflow Neural Machine Translation Framework,\" CoRR abs/1503.08232, 2015.\n\nB. Soudry, M. G. Schuster, and L. G. Zueva. \"Building and Evaluating Neural Machine Translation,\" In Proc. ACL/IJCNLP Workshop on Statistical Machine Translation, June 2014.\n\nS. Edunov, Y. Kim, N. Pevzner, A. G. Bighash, and M. Auli. \"Neural Machine Translation using Unsupervised Word Alignment, In Proc. EuroSpeech 2013, pp. 1197\u20131201, 2013.\n\nX. Ma, T. Ngo, and T. H. Pham. \"Learning Phonologically Informed Deep Neural Network Transducer from Transcription in Statistical Machine Translation,\" In Proc. ACL/IJCNLP Workshop on Statistical Machine Translation, June 2013.\n\nE. S. W. Lee, J. Lafferty, and K. M. Cho. \"An Effective Approximation to",
    "493e971ee3f57a821ef1f67ef3cd47ade154e7c4": " We plan to extend the EqEmb model beyond the singleton word to make better use of the word-equation interaction context. We intend to do this by leveraging the language and NLP communities for new tasks such as semantic navigation of literature to improve search, as well as better support for writing and exploring scientific articles or knowledge bases of equations by using equation context to understand equation content and to extract meaningful insights from the collection.\n\nAcknowledgments\nWe thank David Ferrucci, Pauline Chen and all the anonymous members of our workshop reviewers from our paper submission to CHI 2016, as well as David Ferrucci, Yihan Chen and Yee Whye Teh from the Google Brain team for providing critical inputs.\n\n[1] S. Agarwal, J. Liu. A distributed representation of a word: combining context and content to capture semantic meaning, 2014.\n[2] C. D. Manning and M. P. W. Scha. Introduction to information retrieval. Cambridge University Press, 2008.\n[3] Z. Lai, W. Zhou. Exponential family neural networks: Deep probabilistic models efficiently learn relations among structured entities, 2015.\n[4] C. D. Manning, M. P. W. Scha. Character-level word representations. In Advances in neural information processing systems, pages 311\u2013323, 2016.\n[5] O. Vinyals, F. S. Chen, Q. Wu, C. Q. Zhu. Fast training of recurrent neural nets, 2014.\n[6] M. D. Le, P. Pilehvar, B. A. Raghavan, D. J. Dean. Continuous bag-of-words, 2012.\n[7] C. D. Manning, G. R. Manning, F. D. Ernst, C. T. Joachims, S. Deoras. Distributing continuous representations for efficient processing of large texts, 2014.\n[8] Y. Bengio. Learning word representations for semantic similarity search, 2003.\n[9] A. Kuznetsov, P. Gupta, J. Auer, M. Riedmiller, et al. Mathematical language understanding: from mathematical expression extraction to answer generation, 2016.\n[10] J. Auer, L. Gimpel, M. D. Lee, A. Kuznetsov, et al. Learning deep algebraic",
    "8dd8e5599fc56562f2acbc16dd8544689cddd938": " We also plan to apply these methods to help perform automatic reading comprehension.\nIn this paper we describe a deep learning method for developing semantically meaningful word and equation representations by embedding them under a non-parametric distribution. For each embedding there is a corresponding objective function. The objective functions are a probability distribution over all possible embedded features (e.g. vectors over discrete dimensions) where each feature represents a specific feature of the embedding. We apply our embedding models to automatically discover meaningful representations of mathematical equation units and demonstrate that they can discover meaningful relationships across the word and equation worlds.\nCite this paper\nG. Caragea, J. Weston, et al.: Semantic Representations of Equations. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing, Brussels, Belgium, 2019.\n\n\n\nBegin Reading\n\nTable of Contents\n\nAbout the Author\n\nCopyright Page\n\nThank you for buying this\n\nTom Doherty Associates ebook.\n\nTo receive special offers, bonus content,\n\nand info on new releases and other great reads,\n\nsign up for our newsletters.\n\nOr visit us online at\n\nus.macmillan.com/newslettersignup\n\nFor email updates on the author, click here.\nThe author and publisher have provided this e-book to you for your personal use only. You may not make this e-book publicly available in any way. Copyright infringement is against the law. If you believe the copy of this e-book you are reading infringes on the author's copyright, please notify the publisher at: us.macmillanusa.com/piracy.\nTo K.H. and J.H., my sisters.\n\nI love you both. This book is for you.\nPrologue\n\nTHE WIND CRIES. NOT BRAZILIAN CASHMERE this time but something raw and wild and untamed, as if there were only one tree in the world, and that one has a storm blowing through it.\n\nI take in a long breath of this cool spring air, smell the bitter perfume of the wind, and hear the voices of my children in my ears, calling me in hushed, uncertain tones that are so far away. If I listen closely I can still hear them, their tiny voices, in my head, as if they are in my mother's womb with me.",
    "abe2393415e533cb06311e74ed1c5674cff8571f": "\nReferences\n\nBIBREF0\n\n.\n\n. Vaalibotti, C., F. Gonon, A. Hevskopf, N. Rajhla, J. Miettinen.\n\nIce hockey statistics-based game news generation system.\n\nProc.\n\nCICLing\n\n2018\n\nBIBREF1\n\n. N. Rajhla, S. Salminen, A. Hevskopf.\n\nMachine learning-based template generation for Finnish sports news.\n\nProc.\n\nCOLING\n\n2018\n\nBIBREF2\n\n. T. Bannard, M. Baroni, S. J. Gomes, G. Vinyals.\n\nRotowire NLP Challenges 2019: Evaluating the NLG of Restaurant Dialogues.\n\nProc.\n\nEMNLP\n\n2019\n\nBIBREF3\n\n.\n\n.\n\n. V. S. Choi, Z. Zhang, J. Bhattacharya, G. Vinyals.\n\nThe Rotowire Game Recap Corpus and its Evaluation Metrics.\n\nACL\n\nBIBREF4\n\n.\n.\n\n. C. Heilman, V. Poria, F. J. Lepore, S. J. Gomes.\n\nEnd-to-End Spoken Dialogue Systems: What Has the AI-Assisted Generation of Restaurant Reviews Taught Us about the Future of Spoken Dialogue?\n\nProc.\n\nSIGDial\n\n2017\n\nBIBREF5\n\n.\n\n.\n.\n\n.\n\n.\n.\n.\n.\n.\n.\n, C. O. Marcos, F. G. Ranzato, D. Vuli\u0107evi\u0107, I. Tomioka.\n\nNeural Network-based Language Model for Data-Driven Spoken Language Translation Generation.\n\nProc.\n\nACL,\n\n2015\n\nBIBREF6\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\nF. Gonon, M. Rosti, L. Mourits, N. Rajhla, M. Turunen.\n\nImproving",
    "00c57e45ac6afbdfa67350a57e81b4fad0ed2885": "\nFigure 1. Average F1 performance changes at the top 10 percentile cutoff. Feature ablations are represented as the difference between average performance with (and hence, inclusion of) and without a particular feature group. This is calculated by holding features constant and performing F1 metrics on those groups that were or were not included in the given feature group.\nREFERENCE BIBLIOGRAPHY\n\nBayerl, M., & Pichler, M. (2013). Analyzing and Detecting Tweeters with Depression Using Semantic Features. In S. Zhang, C. Xu, & H. Huang (eds.), Language, Information, and Knowledge Engineering, Studies in Fuzziness and Soft Computing, Vol. 287. Springer Berlin Heidelberg.\n\nBIBREF0\n\nAlam-Farinasim, H., Goh, A. C., & Alabau, X. (2016). Eating Disorders in Spanish Language Twitter Data. In S. Deng, T. Zhang, & X. Du (eds.), Proceedings of the Eleventh International Conference on Cognitive Coaches. Springer, Singapore.\n\nBIBREF1\n\nFuentes, J. E., & Alam-Farinasim, H. H. (2015). Twitter Surveillance of Influenza Epidemic in United States. In S. Deng, T. Zhang, & X. Du (eds.), Proceedings of the Eleventh International Conference on Cognitive Coaches. Springer Singapore.\n\nBIBREF2\n\nViloria, A., Estevez, A., & Guti\u00e9rrez-Miguel, A. B. (2017). Social Media as Source of Information about Prescription Drug Use among US College Students. In S. Deng, T. Zhang, & X. Du (eds.), Proceedings of the Eleventh International Conference on Cognitive Coaches. Springer Singapore.\n\nBIBREF3\n\nFuentes, J. E., Alam-Farinasim, H. H., & Estevez, A. (2017). Online Risk Surveillance for Smoking and Alcohol in Adolescents Using Data Mining and Text Processing Techniques. In S. Deng, T. Zhang, & X. Du (eds.), Proceedings of the Eleventh International Conference on Cognitive Coaches. Springer Singapore.\n\nBIBREF4\n\nGuerrero, C., Guti\u00e9rrez-",
    "22714f6cad2d5c54c28823e7285dc85e8d6bc109": "\n\n1. Haug M, Smit JT, Gurevych V, et al. Depression, social media, and depression: a longitudinal analysis of Twitter. PLoS one. 2014;9(1):e89527.\n\n2. Smit JT, Haug M, Gurevych V. Twitter analytics for tracking depression-related behaviors. Journal of digital humanities. 2012;1(3):1-13.\n\n3. Haug M, Smit JT, Kulis AC, Gurevych V. Is Twitter a useful tool for early depression identification? Journal of Digital Forensic Services BIBREF17 (2014):1172-83.\n\n4. Haug M, Smit JT, Gurevych V, Kulis AC. Exploring the association between depression and mental healthcare terms in Spanish language online tweets with social media applications built on a big data analytics platform. PloS one BIBREF11 1 7 (2015):e903439.\n\n5. Smit JT, Haug M, Gurevych V, Kulis AC. Twitter analytics to detect early depression identification in Spanish Twitter mentions of antidepressants. PloS one BIBREF19 1 6 (2014):e861279.\n\n6. Moulin E, Gurevych V, Reber R. Detecting mental health disorders in Spanish language tweets using support vector machines. Information Processing & Management BIBREF18. (2015):1-13.\n\n7. Smit JT, Haug M, Gurevych V. Emotion identification in depression and related symptoms from Twitter: the influence of lexical features and user personality traits. Journal of Digital Forensic Services BIBREF20 2 1. (2014):1-10\n\n8. Smit JT, Gurevych V, Kulis AC. Quantifying emotional experience from unstructured tweets using sentiment: emotions are positively subjective and associated with self-awareness BIBREF21 (2015):1-16.\n\n9. Gurevych V, Haug M, Smit JT. Annotating symptoms of major depressive disorder in English language Twitter tweets to investigate their presence in public-private tweets. Journal of Digital Forensic Services BIBREF22 (2015):1-10.\n\n10. Haug M.",
    "82642d3111287abf736b781043d49536fe48c350": "\n \n#  \n\n**The Unlikely Demise of Jack Riff (A Puppy Named Mystery Case) and Her Boyfriend, Jimbo (A Friendship Named Rope-e) (A Mystery Case Mystery)**\n\n##  \n**by Anne Appleton**\n\n_To the memory of my very first dog_  \n_Holly, my beloved companion for almost 15 years_\n\n##\n\nThe snowy fields of the country are wonderful places in any weather. Dogs love snow, for it makes them feel lively and carefree. They never tire of rolling in it or burying their legs and tails in it or chewing and throwing it. If possible they even try to help make a snowman, but mostly they just lie down in the snow and keep themselves warm and comfortable. At least, that's the way things are when they have somewhere to go and things to do, and when they're having a good time in the fresh, brisk winter air. But that wasn't the way of Jack Riff as they lay in the snow of the empty field, and he was getting more unhappy with every moment that went by.\n\nIt was a bleak, wintry day. Far away in the distance the great white snow-tops of Blackmoor Hills shone, and the black, bare trees that stood here looked as cold, cold as Jack Riff began to feel.\n\nHe looked round, and noticed that the woods were empty as far as his eyes could reach. Their branches were stiff with the cold, and no bird sang as he had heard them do at home as he ran along there with his tail in front of him and always ready to jump up into the air and wave it. Instead there was a cold hush, as if a long period of frost had frozen the very air. For this is what Jack thought he and Fido were doing that morning when they were chasing each other about in the field\u2014just chasing each other, and it was a game to them because no matter how much they might hurt the other they loved each other and there was no other game in the world for them, but Fido was much further away now. Still, there was a path that Fido had followed, and that's what Jack decided to follow, even though he knew it would be hard work to get along it, even though he and Fido always had each other's",
    "5a81732d52f64e81f1f83e8fd3514251227efbc7": "\n\nThis is a work in progress and preliminary results may differ from the final version.\n\nReferences\n\nBIBREF0\n\nJ. Gonz\u00e1lez-Bail\u00f3n, J.J. P\u00e9rez-Ort\u00edn, J.L. P\u00e9rez-Calvo, A. Guerreiro Blanco, I. Guerreiro-Carbonell, J. Arbona-S\u00e1nchez, N. Hidalgo-Cid, M.L. del Angel, M.L. Alcal\u00e1, and F.L. Gonz\u00e1lez. \"Foods & Eating Disordered Speech on Twitter.\" In Proceedings of SIIW '14. ACM, 2014.\n\nBIBREF1\n\nGonz\u00e1lez-Bail\u00f3n, J.J.P\u00e9rez-Ort\u00edn, Guerreiro Blanco, J.L.P\u00e9rez-Calvo, Arbona-S\u00e1nchez, Guerreiro-Carbonell, and R.G. Carvalho. \"An Analysis of Tweets Relating to Influenza Symptoms: An Application of Linguistic Features to Detect Social Media Influenza Behavior.\" In Proceedings of the 18th International Conference on World Wide Web (WWW). ACM, 2015.\n\nBIBREF2\n\nC.D. S\u00e1nchez-Barrera, J.J. P\u00e9rez-Ort\u00edn, M.L. del Angel, I. Guerreiro Blanco, F.L. Gonz\u00e1lez, S. Alfaro, and N. Hidalgo-Cid. \"Exploring Prescription Drug Misuse Risk Perceptions in Social Media: Using Linguistic Features to Analyze Twitter Language and Behavior.\" In Proceedings of the 29th Conference of the International Association for Research in Internet Science (IARIS). ACM, 2019.\n\nBIBREF3\n\nJ.J. P\u00e9rez-Ort\u00edn, C.D.S\u00e1nchez-Barrera, F.L. Gonz\u00e1lez, J.L. P\u00e9rez-Calvo, and A. Guerreiro-Carbonell. \"An Analysis of Smoking & Tobacco Use Behavior on Twitter Using Linguistic Features to Monitor Social Media Behavior.\" In Proceedings of the 20th International Conference on World Wide Web (WWW). ACM, 2017.\n",
    "9a8b9ea3176d30da2453cac6e9347737c729a538": "\n\nReferences\n\nThe following is an annotated bibliography, including works cited in this project but also additional readings that provide useful information related to the given topic.\n\n[BIBREF1]\n\nW. Szekely, L. Chen, S. Dutta, W. Akyildiz, S. Golder, V. S. Narayanan, F. Alvarez-Melis.\n\nClinical concept extraction: first experience in the second sharc shared tasks for cross-linguistic named entity recognition in texts for diagnosis.\n\nIn Proceedings of ShARe@ACL 2013 Workshop, 2013.\n\n[BIBREF2]\n\nK. H. Huang, H. Zhang, Y. Zhang.\n\nNeural entity tagging for concept recognition for clinical natural language processing.\n\nComputers in Biology and Medicine, 71 (3), 797\u2013806, 2014.\n\nhttps://doi.org/10.1016/j.compbiom.2013.10.011.\n\n[BIBREF3]\n\nK. Lample, I. Singh, S. Yuille, Y. Li, J. Flaxman, C. L. Gimpel, J. Glickman.\n\nDeep learning neural networks for the clinical concept extraction task.\n\nIn Proceedings of the Conference on Empirical Methods in Natural Language Processing, 2015.\n\n[BIBREF4]\n\nK. H. Huang, H. Zhang, Y. Zhang.\n\nCross-validated bi-directional-LSTM neural entity recognition for clinical note analysis.\n\nIn Proceedings of the 6th Language Resources and Evaluation Conference, 2017.\n\n[BIBREF5]\n\nL. Huang, T. Tang, P. Nguyen, H. Zhang.\n\nLearning to reason from clinical notes using convolutional neural networks.\n\nIn Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 118\u2013128, 2015.\n\n[BIBREF6]\n\nL. Huang, T. Tang, P. Nguyen, H. Zhang.\n\nBiLSTMCRF with word2vec word representations for concept recognition for clinical natural language processing.\n\nIn Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, 2016.\n\n[BIBREF7]\n\nD. Tang, Y.",
    "4477bb513d56e57732fba126944073d414d1f75f": "\nAcknowledgement\n\nThis work was performed when Jialiang Huang was an undergraduate student at Hong Kong University of Science and Technology, a doctoral student at Carnegie Mellon University, where they have been awarded a full PhD fellowship, and where they have been awarded a graduate research assistanthip (GRA) by the department of computer science. The author would also like to thank the supervisor of the GRA, Dr. Mireille Hildebrandt, for their assistance in the project and a lot of encouragement. The author would also like to thank Dr. Mireille for giving them the opportunity to participate in a research project for the Department of Veterans Affairs at VA Palo Alto Healthcare System. Without their help, the work for the GRA would not have been completed. In addition, the author would like to thank his parents and his brother for their support. The content of this paper is solely their responsibility and does not reflect the views of those organizations.\nAcknowledgment\n\nThis work was performed when Jialiang Huang was an undergraduate student at HKUST, a doctoral student at CMU, and a GRIA at CMU. The author would like to thank Mireille Hildebrandt at CMU for her technical expertise in building up the project and Dr. Rolf A. Peters, Division Chief of Informatics, Department of Veterans Affairs Palo Alto Healthcare System, for funding the project. The author would also like to thank his parents and brother for their support. The contents of this paper are solely the author's responsibility and do not reflect the views of CMU, HKUST, or the VA Palo Alto Healthcare System.\nAcknowledgements\n\nWe thank the i2b2 Challenge Participants. Without them this project would not have been possible.\nAcknowledgment\n\nThis work was supported by the U.S. Food and Drug Administration, the Agency for Healthcare Research and Quality, and the Department of Veterans Affairs.\nAcknowledgments\n\nThe authors want to thank Dr. K. Ananth Challa, Director of the Center for Bioinformatics and Life Sciences at the University of Maryland, College Park, for sharing clinical data with us. Support on the NLP models has been provided by the U.S. Food and Drug Administration, the Agency for Healthcare Research and Quality, and the Department of Veterans Affairs, where one of them has been funded.\nAcknowledgments\n\nThe authors would like to thank Dr. Rolf A. Peters",
    "1b23c4535a6c10eb70bbc95313c465e4a547db5e": "\nReferences\n\n1. Graves, A., Schultz, S., Barghavae, C., Mikolov, T., Chen, K., Jaitly, A., and Bochman, S. (2014). Connectionist temporal classification for HMMs and neural nets. In: International Conference of the short-term working group on speech recognition, pp. 17-20. Cited by: \u00a7I.5.1; \u00a7I.5.1 [page ].\n\n2. Amodei, D.,  E.,  R., and  X. (2016).  \nAttention-based end-to-end speech recognition. In: Proceedings of INTERSPEECH, p. 1074\u201377.\n\n3. Sainath, P., R., Fathi, M., Garg, R.,  M., and Palaz, V. (2017).  \nDirect end-to-end speech recognition with CNN-TDNN-HMM and attention. In: Interspeech 2017, Posters & Workshops, Vancouver, Canada, 1\u20135 September 2017.\n\n4. Ghahremani, S., R., and  Gouraev, A. (2018).  \nInterspeech 2018, Oral Presentations,  \nBarcelona, Spain, 28\u20133 September 2018.\n\n5. Palaz, V., Sainath, P., Fathi, M., Ghoshal, S., K.,  M., and  R. (2018).  \nEnd-to-end raw waveform deep neural networks. In: Interspeech 2018, Oral Presentations, Barcelona, Spain, 28\u20133 September 2018.\n\n6. Graves, A.,  X.,  S.,  C., Chen, K., and Barghavae, C. (2014). Deep speech 2: End-to-end speech recognition with continuous duration neural networks. In: Workshop on Deep Learning for Acoustic Modeling and Speech Recognition, Interspeech, Geneva, Switzerland, 12\u201316 September 2016.\n\n7. Graves, A.,  S.,  C.,  A., and Chiang, B. E. (2016). Deep speech: Convolutional networks for efficient end-to-end speech recognition",
    "0a75a52450ed866df3a304077769e1725a995bb7": " We also acknowledge generous support for this work by the National Center for High-Performance Computing.\n\nReferences\n\n[1] M. Auli, Q. Geng, E. Hershey, and C. F. N. Jelinek, A New HMM-Inspired Continuous Speech Segmentation Scheme, Interspeech, 2010.\n\n[2] X. He, J. K. Q. D. T. Huang, A. Yu, and S.-G. Chew, Learning Vector Quantization for Robust Short-Term Speech Spectral-Line Estimation and Segmentation, Proceedings of the International Conference on Acoustics, Speech and Signal Processing, 2011.\n\n[3] S. R. Jhingan, D. J. Reiter, and M. A. P. Jastrzkebski, Speech Signal Analysis: Fundamentals and Applications, Kluwer Academic Publishers, 2010.\n\n[4] G. J. Palaz, A. B. Ng, S. Jajic, and B. W. K. Choy, CNN-TDNN Models for Large-Vocabulary Speech Recognition, Proceedings of the Conference of the Speech and Language Processing Association, 2016.\n\n[5] G. J. Palaz, A. B. Choi, R. Shyue, A. Zhang, K. Shim, J. Li, H. G. Chen, B. Lu, and C. F. N. Jelinek, CNN-Based Speech Recognition: Improving the Time-Delay Neural Network using a Jointly Trained Deep CNN-TDNN Model, Proceedings of the 2016 International Conference on Acoustics, Speech and Signal Processing, 2016.\n\n[6] C. Graves, R. Freeman, S. D. Ottenhof, and D. A. G. Stollmeyer, An Attention-based Neural Network Reader for Sequence Labeling Tasks, Advances in Neural Information Processing Systems, 24 (2010): 4034\u20134039.\n\n[7] C. C. Amodei, A. Dahlberg, H. Espejo, and L. M. N. T. S. T. Nguyen, Deep Speech (version 2), 2015.\n\n[8] S. Amodei, A. Dahlberg, H. Espejo,",
    "fd0a3e9c210163a55d3ed791e95ae3875184b8f8": "\nReferences\n\nAdey, O., M. Chen, and J. G. Harris. 2001. Deep multi-layer neural network acoustic models for continuous speech recognition. In InterSpeech 2001, 2:1563\u20131566, 2001.\n\nBarr\u00e9-Sinoussi, F., T. Mikolov, B. Carreira-Perpi\u00f1an, A. Karpathy, B. A. Osendorfer, A. Vyas, Y. Bengio, C. C. Wyse, R. Garnelo, and L. Bottou. 2016.\n\nMulti-task and transfer learning for speech with deep neural networks.\n\nIn Proceedings of the European Speech Communication and Technology Association (Interspeech 2016), 2016, September 16\u201319, Marseille, France.\n\nBengio, Y., M. T. Danihelka, P. C. Beutel, A. Dossal-Gharekhan, O. Vidal, J. L. Glass, W. Chang, J. Weston, A. Graves, G. Krizhevsky, C. C. Lample, M. A. Mueller, and M. Poibeau. 2013.\n\nDeep learning of speech representations for automatic speech recognition.\n\nMachine learning, 63(1):211\u2013232, 2013.\n\nBengio, Y., B. Ciotlon, E. M\u00e9ndez, D.-Y. Kang, S. S. Ihler, L. Bottou, and B. P. Bouayad-Agha. 2017.\n\nEnd to end speech recognition with the attention encoder- decoder.\n\nIn Proceedings of the Interspeech 2017 conference, 2017, September 21\u201324, Vancouver, Canada.\n\nBIBREF0\nA. M. Abdoul et al. 2016. End-to-end unsupervised speech recognition in the wild: a large scale approach.\n\nIn Proceedings of the 2017 International Conference on Machine Learning (ICML), Montreal, Canada.\n\nBIBREF1\nP. Palaz et al. 2016. Convolutional neural networks for speech recognition.\n\nIn Proceedings of the International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2016, January 25\u201330, New York, USA.\n\nBIBREF2\n\nJ",
    "c37f65c9f0d543a35c784263b79236ccf1c44fac": " We wish to thank the competition participants for sharing their code and baselines.\n\n[1]\n\nY. Xie, F. Zhao, Z. Li, K. Sridhar, and R. Carlucci, \"StoryGAN: Automatic Video Story Generation Based on Generating Adversarial Noise to Discourage Human Oversight.\"\n\nIn Proceedings of the Conference on Computer Vision and Pattern Recognition (CVPR 2017), pp. 844\u2013852.\n\n[2]\n\nY. Xie, F. Zhao, Z. Li, K. Sridhar, and R. Carlucci, \"StoryGAN: A Generative Adversarial Net for Video Story Generation.\"\n\nIn Proceedings of the Conference on Neural Information Processing Systems (NeurIPS 2017),\n\npp. 723\u2013732.\n\n[3]\n\nY. Xie, F. Zhao, Z. Li, K. Sridhar, and R. Carlucci, \"Multi-task Learning for Visual Storytelling: Joint Story Generation, Image Summarization, and Image Description.\"\n\nIn Proceedings of the Conference on Computer Vision and Pattern Recognition (CVPR 2018).\n\n[4]\n\nN. Gupta et al., \"The Vision and Language Grand Challenge: Visual Storytelling.\"\n\nIn Proceedings of the Conference on Computer Vision and Pattern Recognition (CVPR 2018), pp. 763\u2013772.\n\n[5]\n\nX. Bai, A. Karpathy, and D. Lin, \"Visual-to-text: Using CNNs to Generate Summaries, Stories, and Reports from Images.\"\n\nIn International Conference on Neural Networks (ICNN 2016).\n\n[6]\n\nY. Xie, F. Zhao, Z. Li, K. Sridhar, and R. Carlucci, \"A Visual Storytelling Framework for the NYC and Disney Datasets.\"\n\nArxiv preprint arxiv/1711.12397.\n\n[7]\n\nX. Wang et al., \"VST: A Visual Storytelling System for Disney and New Yorker.\"\n\nIn Neural Information Processing Systems (NeurIPS 2017).\n\n[8]\n\nG. Pennacchio et al., \"A Multi-task CNN for Visual Storytelling using Generative Adversarial Networks.\"\n\n",
    "584af673429c7f8621c6bf83362a37048daa0e5d": "\n[1]\n\nV. Chopra and A. Gupta, \"End-to-End learning of visual story for the web,\" in CVPR 2018, 2018, pp. 7077-7084.\n\n[2]\n\nA. Gupta and A. Venkatesh, \"BIBREFAttn: a neural end-to-end image and caption attention model for automatic text generation,\" in CVPR 2016.\n\n[3]\n\nA. Gupta and A. Venkatesh, \"Neural visual question answering,\" in CVPR 2017, 2017, pp. 1739-1746.\n\n[4]\n\nBIBREF4, \"Visual storyteller: Learning to tell stories with sequence-to-sequence models,\" in CVPR 2017.   \n[5]\n\nT. P. Lavelli and E. Lepetit, \"METEOR: A Method for Automatic Metric for Machine Translation,\" in ACL 2002.\n\n[6]\n\nS. Yu, X. Ma, X. Zhou, and N. L. Liu, \"Automatic image story generation using sentence-level semantic parsing and retrieval of visual concepts,\" in CVPR 2016, 2016, pp. 3351-3360.\n\n[7]\n\nA. Gupta and A. Venkatesh, \"Combining visual information for question answering,\" in CVPR 2016.\n\n[8]\n\nM. F. Ranzato, L. S. Chaurasia, O. Chum, E. H. Pfeiffer, and K. Q. Weinberger, \"Word2vec: Distributed Representations of words and phrases,\" in NIPS 2013, 2013, pp. 4010-4018.\n\n[9]\n\nM. F. Ranzato, L. S. Chaurasia, E. H. Pfeiffer, and K. Q. Weinberger, \"Learning distributed representations of images using context encoders,\" in CVPR 2015, 2015, pp. 2330-2338.\n\n[10]\n\nBIBREF12, \"Capturing the context: Visual story telling,\" in CVPR 2018.\n\n### Ike's Deep Learning for Visual Question Answering\n\nI. Ike\n\nINRIA Rennes, France\n",
    "1be54c5b3ea67d837ffba2290a40c1e720d9587f": "\n\n\\begin{itemize}\n\n\\item[Bibtex:]\n\n@Inproceedings{rinchesi2019,\n  author = {Rinchesi, D. and Franco-Mart\u00ednez, E. and Gonz\u00e1lez Rico, R. and L\u00f3pez-P\u00e9rez Zu\u00f1iga, D.},\n  title = {A deep neural network for visual storytelling},\n  booktitle = {Proc. International Conference on Learning Representations (ICLR), 2019},\n  year = {2019},\n  volume = _,\n  series =_,\n  address = {New Orleans, LA},\n  month = May,\n}\n\\item[Keywords:]\n\nVisual Storytelling, Generative Adversarial Networks, Context encoder, Inception V3, Recurrent Neural Network\n\\item[PDF:]\n\nhttps://openreview.net/pdf?id=H1v5vVg7qQ_\n\\item[PDF Notes:]\n\nhttp://web.cse.ohio-state.edu/\u02c9rinchesi/visual_stories.pdf\n\n\n_To Kip & Kynley, the best little brothers a girl could have_\n\n_\u2014B.K_\nPrologue\n\nIt was a clear sky night, the black of it spangled with stars, when Aria came down out of the mountains. She climbed from the mountains wearing a man's cloak, with only a black bag for her meager belongings and the knife she'd always been afraid she'd ever need. She'd been on her way into New Haven for three days and three nights, and when you were alone, that's a long time to be on the road. She'd seen a light burning like a candle far ahead in the town, and so she followed the road that would carry her to it. She'd seen the sign hanging over the road for New Haven, but she couldn't see the little town until she was close to it. She saw the little town spread out before her, its houses all crumbled and run-down.\n\nNew Hadens was the name of the town, although it was not what it once had been. People called it by a whole different name than New Hadens. No one talked about New Hadens except for old people, who said the name with a tinge of",
    "b08f88d1facefceb87e134ba2c1fa90035018e83": "\n\n[1]\n\nSajnog, P., Karayev, A. & Yu, F. Visual Storytelling: Towards Automatic Generation of Natural Language Stories. arXiv preprint, 2016.\n\n[2]\n\nHu, Z., Karayev, A. & Sajnog, P. Towards Large-scale Story Generation from Images with Neural Networks. Advances in Neural Information Processing Systems. (2016). Springer.\n\n[3]\n\nDhingra, S., Sajnog, P. & Yu, F. Text2image: Generating from Scratch, Generating from Text. arXiv preprint, 2017.\n\n[4]\n\nVu, T., Sajnog, P. & Yu, F. Neural Image Album Summarization with Attention and Convolutional Networks. arXiv preprint, 2016.\n\n[5]\n\nGao, J., Chen, W. R., Jaderberg, M., Kordjamshidi, P., Karayev, A. & Sajnog, P. Visual Storytelling from YouTube Video. arXiv preprint, 2018.\n\n[6]\n\nGao, J., Jaderberg, M., Kordjamshidi, P., Karayev, A., Sajnog, P. & Yu, F. Visual Storytelling Challenge at ICLR 2018. arXiv preprint, 2018.\n\n[7]\n\nGao, J., Jaderberg, M., Kordjamshidi, P., Karayev, A. & Sajnog, P. Visual Storytelling Challenge at ACL 2018. arXiv preprint, 2018.\n\n[8]\n\nMikolov, T., Zweig, G. & Zemel, R. Efficient Estimation Of Word Representations In Vector Spaces. International Conference on Machine Learning, 2013.\n\n[9]\n\nWan, Z., Sajnog, P., Karayev, A., Yatsenko, L., Yu, F. & Chen, W. Text2image: Generating from Scratch, Generating from Text. International Conference on Computational Linguistics, 2018.\n\n[10]\n\nSajnog, P. & Yu, F. Language and Vision. Towards",
    "b06512c17d99f9339ffdab12cedbc63501ff527e": " We hope that this work will spur further investigation into such knowledge graph representations and encourage further advances in the state-of-the-art.\nAcknowledgments\n\nWe would like to thank Dr. Mani Singh (Director: IDD) and Dr. Ehsan Khossa, (Distinguished Visiting Scholar) for helpful discussions and suggestions. We also acknowledge support from the Data Science and Engineering (DSE) Center at Indiana University Bloomington (IU) and the National Science Foundation (NSF) grant CNS-1640783.\n\nReferences\n\n[1] Bordes, A., Chiu, U. and West, J. (2013) Translating Knowledge Graphs with Translational Embeddings. In: Proceedings of the 18th Conference on Extending Database Technology, pp. 581\u2013591.\n\n[2] Chen, J., Huang, H., Lee, K. and Zhang, W. (2015) TransE: Transferring Embeddings for Entity and Relation Classification with a Hypergraph Network. In: International Conference on Knowledge Discovery and Data Mining.\n\n[3] Chopra, S., Farkas, L. et al. (2016) Deep and Cross-Model Embeddings for Relation Extraction. In: Proceedings of the 27th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 1379\u20131388. CSL-TR-1521. ACM, New York, NY. Also available\n\n[4]\n\n[5]\n\n[6]\n\n[7]\n\n[8]\n\n[9] Dettmers, A., Fidler, T. and Reimherr, R. (2013) Deep TransE: Joint Entity Matching and Relation Extraction Beyond Words in Semantic Graphs. In: Thirty-seventh AAAI Conference on Artificial Intelligence, pp. 1349\u20131355.\n\n[10]\n\n[11]\n\n[12]\n\n[13] Grail, M., Toutanova, T., Maier, P., and Nickel, M. (2016a) DistMult: Using Multiple Relational Triplets for Training Neural Entity Disambiguation. In: Proceedings of the 29th International Joint Conference on Artificial Intelligence, pp. 1058\u20131066.\n\n[14]\n\n[",
    "fd8e23947095fe2230ffe1a478945829b09c8c95": "\nAcknowledgments\n\nWe acknowledge support by a Google Faculty Research Award, a DARPA Grant and various other efforts like ETR.\n\nReferences\n\n[1] Y. Nickel, J. Tresp, C. Kriegel, Q. Yang, J. S. Boyd-Graber. Rescal: A fast recommender system using large-scale sparse matrices. ACM Transactions on Intelligent Systems, (TIS) 23(2):285\u2013299, 2012.\n  BIBREF1\n\n[2] T. Bordes, J. Weston, O. Chopra, A. Ng. Transforming continuous space representations of entities and relations into discrete ones. Machine Learning, (ICML) 54(3), 2013.\n  BIBREF2\n\n[3] C. M. Mohler, K. L. Graeber, T. P. Jansson, K. Lal, J. G. Fetaya, O. Chapelle, S. Chopra, C. K. I. Williams, T. P. Pedersen, O. Chapelle. A survey of relation extraction methods and evaluation metrics in knowledge bases. Data & Knowledge Engineering, (DEXA) 74:22\u201341, 2016.\n  BIBREF4\n\n[4] A. K. Grail, E. A. Ng, J. Choi, J. J. Keskar. Effective recommendation with deep relational network. In Proceedings of the 22nd International Conference on World Wide Web, 2015.\n  BIBREF6\n\n[5] M. Shchur, S. T. Choi, F. H. Iqbal, C. A. Guenther, H. S. Lee. Learning knowledge-graph relations with dense convolutional neural networks. In Proceedings of the 54th Annual meeting of the Association for Computational Linguistics, 2016.\n  BIBREF7\n\n[6] C. D. Palumbo, G. Zucca, R. Pfeiffer. An Efficient Knowledge Base with Deep Recontextualization. In Proceedings of the 32nd Conference on the Association for Computational Linguistics, 2017.\n  BIBREF8\n\n[7] C. A. Peters, B. Martins, S. Iyyer, K. Cho.  ",
    "8bf7f1f93d0a2816234d36395ab40c481be9a0e0": "\nSentence Embedding Model\nWe follow the procedure proposed in BIBREF40 to encode each sentence individually. Specifically, we use a bi-directional LSTM that takes the sentence and its reverse as input and pass them through three layers of fully connected layer. We have observed that word-level skip connections can cause the model to underfit, so we remove this layer. Then a fully connected layer that has 2048 units is used for projecting sentence vectors into a vector space. Finally we pass the matrix product of the last hidden vectors in both directions through the softmax function for calculating sentence similarity.\nAttentive Interaction Model\nWe employ word-level skip connections as in original paper BIBREF41 and also follow BIBREF42 to update the sentence order with a max pool for aggregation. The hidden size of Bi-LSTM in PWIM is 200 and 500 for all LSTM layers in different blocks. The feed-forward network has 500 hidden units, and the dropout rate is set to 0.1. We use the attention mechanism proposed by Bahdanau et al. bahdanau-EtAl:2015:natur to aggregate the vectors from other blocks, which consists of two steps: (i) first, every word from two sentences is paired with every other and has the soft alignment between them computed with softmax; then (ii) word pairs that are more likely to have semantic relationships than unlikely receive high attention weights and concatenated together for classification.\n\nDecomposable Attention Model\nFirst, we remove all the skip connections. Our model is similar to the original DecAtt model BIBREF10 but with a few modifications regarding to the feed-forward network: in the original paper, they use a two-layer architecture with 200 hidden units per layer, we use a single-layer feed-forward architecture with 300 hidden units per layer. We choose to train this model based on the Adam algorithm and set the initial learning rate following BIBREF43 recommendation: $lr=2\\cdot10 ^ {-6} $ with decaying learning rate as in the original paper.\n\nEnhanced Sequential Inference\n\nFirst, we choose to use LSTM to encode the context sentences: LSTM with 80 hidden units for encoding the first sentence and 40 hidden units for the second sentence according to BIBREF44 method. For the first sentence, we also include extra information of the second sentence as context. The",
    "3611a72f754de1e256fbd25b012197e1c24e8470": " This work is part of the research project of Department of Computer Science and Engineering, IIT Bhubaneswar.\nBollen, J.D.; Karahalios, H.I. (2016) Twitter and public mood: evidence for a causal link? Computational social science conference, p. 11-20. https://link.springer.com/chapter/10.1007/978-3-319-42375-3_2\n\nBing, X.; Lazar, J. (2013) Twitter-based sentiment analysis for financial trading: an application of fuzzy time series. SAC2013, p. 1435\u20131440. https://link.springer.com/chapter/10.1007/978-1-4799-7496-3_79\n\nChen, C.; Lazer, T. (2017) Twitter as predictive factor for financial trading: understanding investment strategies based on users' opinions. J. Adv. Comutat. Inf. Sci. 12, 634\u2013649. https://link.springer.com/chapter/10.1007/978-3-319-46192-0_35\n\nEiji, T.; Aikawa, S.; Wigoda, X. (2012) Twitter-based early flu-outbreak detection: application of stochastic graph to detect collective emotion. In proc. of the 12th international symposium on information technologies and applications, p. 1\u20136. http://www.witpress.org/journal/vol12/sista2012/sista2012-p8_4.htm\n\nGilbert, B.W., and Karahalios, H.I. (2009) Predicting the future of financial markets: a behavioral analysis using weblogs and social media. Computational social science 2011, LREC, p. 1773\u20131777. https://aclanthology.info/E73.pdf\n\nGupta, K., Goel, R., Goel, N., Srivastava, S., & Kaushik, K. (2013) Sentiment analysis and public mood prediction using twitter feeds. Int. Journal on Advances in Computing and Communication Systems, 1, 57\u201362.\n\nRuddigkeit, C., Cioffi, P., and Hahn, M. (2008) Prediction of stock price fluctuation: a time-",
    "4c07c33dfaf4f3e6db55e377da6fa69825d0ba15": " For the work in correlation we would like to thank our mentor, Prof. Sanjay Kumar Mishra for his guidance. We would also like to thank Twitter for helping us in extracting tweets from twitter\nReferences\n\n[1] Bollen, K., Gilbert, J., & Karahalios, J. (2009). Predicting stock market fluctuations via social media. Computers in Human Behavior, 25, 1229\u20131242.\n\n[2] Asur, B., & Huberman, B. (2009). Predicting the Opening Day Box Office Collection of Movies from Twitter. In Proceedings of the 2009 ACM SIGCSE Technical Symposium on Computer Science Education (SIGCSE '09). Association for Computing Machinery (ACM).\n\n[3] Zhu, H., He, Z., & Chai, H. (2009). Google flu: forecasting influenza outbreaks on the social Web. Paper presented at the Workshop on Information Reuse and Management (WAIR 2009), 2009.\n\n[4] Ruiz, C., Bordino, L., Cugnoni, F., & Grancea, A. (2015). Twitter-driven volatility. Journal of Derivatives and Risk Finance, 7, 843\u2013867.\n\n[5] Asur, B., & Huberman, B. (2007). Evaluating public interest in movies by mining Tweets. In Proceedings of the Seventh International Web and Human Communication Conference (Web-KDD '07). ACM.\n\n[6] Eiji, U., Kiyohara, F., Kikutani, K., Ohara, Y., & Shirata, M.\" Exploring twitter on flu: the impact of disease outbreaks and emotions on twitter\". In Proceedings of the 24th international conference on World Wide Web: Companion (ICW-Companion '10). ACM.\n\n[7] Ruiz, C., Bordino, L., Cugnoni, F., & Grancea, A. (2013). A stock market model driven by Twitter. In Proceedings of the 27th Annual International ACM SIGKDD Conference on Knowledge Discovery and Data Mining (SIGKDD '13). Association for Computing Machinery (ACM).\n\n[8] Bing, L., & Zhao, X. (2012). Investigating the connection between human emotion and stock price. Science China",
    "b1ce129678e37070e69f01332f1a8587e18e06b0": "\n[1] Bollen S.J.F., Wu A.I., Fertel, K.A. and Rao, R.H. (2010) Detecting public mood from twitter: Application to the stock market.\nProceedings of the 2010 international ACM SIGPLAN conference on Platform for open source software (POPOS), pp 1-8.   \n[2] Asur U.M. and Huberman B.E. (2012). Using tweets to predict the box office success of a film using sentiment metrics. ACM Transactions on Information Systems (TOIT), 30(2).  \n[3] Chen S., Lazer D. and Xu S. (2013). Exploring twitter to mine stock market investment knowledge.\nProceedings of the 28th Hawaii international conference on system sciences.  \n[4] Gilbert M. and Karahalios K.V. (2013). Predicting fluctuations in the stock market using social mood indicators. Information Systems 26(4):943-960.  \n[5] Ruiz E., Pueyo J., Alcala J.J & Tormes F. (2014). Analyzing twitter and stock market movements: A two-layered correlation graph. Data & Knowledge Engineering 84:68-79.  \n[6] Eiji T., Takaki Y. & Yanagi K. (2014). Detecting the flu from twitter. Journal of The Korea Information Society, 25(3):267-278.  \n[7] Bordino D., Pascarella L., Toma A., Brusco L., Di Palma F., D'Innazzo S. & Calafiore S. (2014). Is it true? Query volume, stock volume, and returns on the nasdaq-100 market index. Scientific reports 11(6):34.  \n[8] Bollen R., Fertel, K.A. & Rao R.H. (2011). Stock market prediction using twitter to gauge fluctuations: a study on the S & P 500 index. Journal of Knowledge Management 14(1):29-40.  \n[9] Gilbert M. and Karahalios K.V. (2011). Is there a link between twitter sentiment and the dow jones stock market index? Information Systems 25(2):243-255.  \n[10] B",
    "7fb27d8d5a8bb351f97236a1f6dcd8b2613b16f1": "\n\n\nTable of Contents\n\nTitle Page  \nTHE CHOSEN...  \nTHE SAVIOR...  \nTHE INHERITANCE...  \nTHE VISION...  \nTHE VAMPYRE'S REVENGE...  \nTHE BIRTHRIGHT...  \nTHE DEFEATER...  \nTHE CRUCIBLE  \nALSO BY ILLUSTRATED BY...  \nThe Chosen  \nThe Inheritance  \nThe Vision of Evar  \nThe Champion  \nThe Vampyre's Revenge\n\nThe Birthright  \nThe Defier  \nThe Crucible  \nThe Birthright, Second Edition  \nThe Defier, Second Edition\n\nThe Birthright, Third Edition  \nThe Crucible, Second Edition  \nThe Birthright, Fourth Edition\n\nTHE BIRTHRIGHT  \n\u00a92005 Wizards of the Coast LLC\n\nFORGOTTEN REALMS, WIZARDS OF THE COAST, DUNGEONS & DRAGONS, their respective logos, and TAMER OF TERRORS are trademarks of Wizards of the Coast LLC in the U.S.A. and/or other countries.\n\nAll characters in this book are fictitious. Any resemblance to actual persons, living or dead, is purely coincidental.\n\nThis book is protected under the copyright laws of the United States of America. Any reproduction or unauthorized use of the material or artwork contained herein is prohibited without the express written permission of Wizards of the Coast LLC.\n\nPublished by Wizards of the Coast LLC. Hasbro SA, represented by Hasbro Europe, Stockley Park, UB11 1AZ. UK.\n\nMap by Todd Gamble  \nCover art by J. P. Garcia  \nInterior art by Clyde Calwell\n\neISBN: 978-0-7869-6425-6  \n640-1318000-001-EN\n\nForgotton Realms setting: \u00a92003 Wizards of the Coast LLC\n\nAll Wizards of the Coast characters and their distinctive likenesses are property of Wizards of the Coast LLC.\n\nCover artist: J. P. Garcia\n\nLibrary of Congress Catalog Card Number: 2004939076\n\nFor customer service, contact:\n\nU.S., Canada,",
    "0689904db9b00a814e3109fb1698086370a28fa2": " MB and EM also hold Senior Fellowships of the National Institute for Health Research (NIHR) Imperial Patient Safety Translational Research Centre. All authors contributed to the design of the project and to the conception, writing and reviewing of this work.\n\nTable 1\n\nDoc2Vec training hyper-parameters, clustering performance, similarity with hand-coded categories.\nTable 2\n\nComparison of different clustering methods.\nReference\n\n1. BIBREF1.\n\nArora, N., Leskovec, J., Jaumard, A. The power of distributed context used in deep neural network language models. ArXiv preprint, ArXiv e-print ArXiv:1510, http://nidaarb.wordpress.com.\n\n2. BIBREF2.\n\nBletu, H., Jardin, S., Alahi, M. Neural Language Models and Clustering of High-Dimensional Data. ArXiv preprint, ArXiv e-print ArXiv:16, http://nidaarb.wordpress.com/papers/ arxiv1613/\n\n3. BIBREF3.\n\nLanchinetti, A., Machado, O., Lopes, C. Infomap: a community detection algorithm based on graph spectral analysis. Physiochem. Biol. Phys. 17, 1257\u20131265 (2013).\n\n4. BIBREF4.\n\nLanchinetti, A., Van Malderen, B., Fortunato, S. InfoMap: a network analysis method based on spectral embedding. Phys. Rev. E 75, 066130 (2006).\n\n5. BIBREF5.\n\nKohonen, T. Constructing feature spaces for unsupervised cluster analysis using the self-organising map. Psychometrik. 52, 179\u2013195 (2001).\n\n6. BIBREF6.\n\nKohonen, T. Learning vector quantization. Neural Comput. 12, 507\u2013533 (2000).\n\n7. BIBREF7.\n\nMikolov, T., Chen, K., Dean, J., Corrado, G., Lee, K., D. p. ht.p: /acl/14, https://ai.google/pubs/2016\u2013archive/629.pdf\n\n8. BIBREF8.\n\nPero",
    "cc354c952b5aaed2d4d1e932175e008ff2d801dd": " Box-plots are shown for gender pairs and for race pairs. They differ in the number of boxes, because there are more groups in the race plot than the gender plot. In Figure FIGREF33 we present the INLINEFORM5 \u2013spread across all 219 submissions. The boxes for each box plot represent the 25th to 75th percentiles of the INLINEFORM2 values predicted for the corresponding task.\nThe Appendix has two additional tables, Tables TABREF30 and TABREF31, which shows the results of performing only a gender analysis (with INLINEFORM2 = 0.03) and only a race analysis (with INLINEFORM2 = 0.04), respectively.\nFigure FIGREF25:\n\nScatter plot showing the difference between the scores predicted by each system on the tweets testing set (top) and the EEC (bottom), for the valence regression task. Each point ( \u25b2, \u25bc, \u25cf) on the plot corresponds to the difference between the scores predicted by the system on one sentence pair.\nFigure FIGREF28:\n\nScatter plot showing the difference between the scores predicted by each system on the tweets testing set (top) and the EEC (bottom), for the race sentence pairs.\nFigure (a):\n\nScatter plot showing the difference between the scores predicted by each system on the tweets testing set (top) and the EEC (bottom), for the anger intensity prediction task.\nFigure (b):\n\nScatter plot showing the difference between the scores predicted by each system on the tweets testing set (top) and the EEC (bottom), for the joy intensity prediction task.\nFigure (c):\n\nScatter plot showing the difference between the scores predicted by each system on the tweets testing set (top) and the EEC (bottom), for the sadness intensity prediction task.\nAverage score differences between (a) and (b).\nAverage score differences between (b) and (c).\nTable TABREF24:\n\nSummary results for gender bias score difference. Each submission is scored 0 to 1 according to the INLINEFORM1 \u2013spread values from different sources (e.g., paper INLINE4), INLINE5 = the mean of all the INLINE1 \u2013spread scores.\nTable TABREF26:\n\nSummary results for race bias score difference. Each submission is scored 0 to 1 according to the INLINEFERM2 = 0.",
    "0f12dc077fe8e5b95ca9163cea1dd17195c96929": " The INLINEFORM0 \u2013spreads for many systems are rather large, up to 0.57.\nReferences\nAbowd, A., Karahalios, K., Riedi, C. (2004) The sentiment in a text: an alternative way of determining whether it's positive or negative. In: Proceedings of the 40th annual meeting of the ACE Conference (American Association for Computational Linguistics). Association for Computational Linguistics, Dallas, USA.\n\nAhmadi, S.B., et al. (2014) Mining lexicalized opinion words and relations: a method for emotion and sentiment analysis of free text. In: Social & Empirical Methods in Natural Language Processing (SEM). Association for Computational Linguistics, Berlin. pp. 165\u2013172.\n\nCaliskan:2017 ( 2017) How do women feel about words? a word set analysis in English and ten other languages. In: Proceedings of the 13th Annual Conference of the European Association for Small Language (EASL), Stockholm, Sweden. Association for Computational Linguistics.\n\nChodrow, C.C., Jurgens, T. (2017) Discriminatory word association in sentiment and emotion analysis systems. Association for Computational Linguistics Publications (ACP), Association for Computational Linguistics, pp. 43\u201352.\n\nCurry, J., Gershman, SJ. (2015) Analyzing bias in Word2Vec: an evaluation of gender bias in English and German word vectors. In: Proceedings of the 12nd SIGKDD Symposium on Knowledge Discovery and Data Mining, London, United Kingdom. Association for the Advancement of Artificial Intelligence.\n\nDreyer, E., Hovy, E. ( 2016) Twitter sentimentality is a continuum: gender and emotion bias in sentiment analysis of free text. In: Proceedings of the 40th Conference on Computational Natural Language Learning. Association for the Advancement of Artificial Intelligence, Atlanta. pp. 1362\u20131370.\n\nEguchi, H., Gershman, S. J., Ie, S., Chodrow, C. C., Gunturkun, M., Jurgens, T., Sperberg-McQueen, S. ( 2017) Gender bias in human-written data: the case of the Web. In: Proceedings of the 40th Conference on Comput",
    "2ddb51b03163d309434ee403fef42d6b9aecc458": "\n\nAcknowledgments\nThanks to Zhiyuan Chen, Andrew Jaworski, Dan Tomashevky, and Sander Denes for their feedback and help with discussions of the paper. We thank our colleagues in the Audio Processing Group for their feedback and sharing of results in the early stages of research and our colleagues in the Deep Learning Group for their help in training experiments. Thanks to all of them, our research would not be possible without excellent facilities and collaboration within SLURM, Audio, and Vision.\n\nReferences\n\nBIBREF0 C. Y. A. Bahdanau, B. Saint-Hilaire, Y. LeCun, M. J. Schuster, and G. E. Hinton.\n\nHashed Transformer\n\nConvolutional Neural Networks for Audio\n\nBIBREF1 Y. Luchangco BIBREF\n\nT.\n\net al.\n\n\"Deep Convolutional Neural Networks for Hands-Free Speech Recognition in a Noisy\n\nEnvironments,\"\n\nin\nNeural Information Processing Systems\n\n(NeurIPS 2016), vol. 32, p. 8, 2016.\n\nBIBREF2 B. D. Ferreres, T. M. Schaul, X. Xiong, and B.\n\nPovey,\n\n\"Speech Recognition with Convolutional Neural\n\nNetworks using Deep Neural Networks,\"\n\nin\n\nInternational Conference on\n\nSpeech and Language\n\nProcessing (Interspeech 2016), 2016.\n\nBIBREF3 D. Chorowski, Y. Gagalova, W. J. Tran, K. M. Dosovitski, J. G. Neff, C. Reisz, and F. Lippman,\n\n\"Hierarchical Phoneme-Level End-to-End Recurrent Neural\n\nTransducer for Acoustic-Phonetic Speech Recognition,\"\n\nin\nProceedings of\n\nInternational Conference on Acoustics, Speech\n\nand Signal Processing (ICASSP 2016),\n\n2016.\n\nBIBREF4 I. Sennrich, H. Schwenk, O. Koehn, D. Bohnet, H.\n\nRusso, Y. Yasuni, and H. Ney,\n\n",
    "e587559f5ab6e42f7d981372ee34aebdc92b646e": "\nAcknowledgments\nWe thank the organizers of IARPA ASR 2018 for hosting a very useful and informative workshop. We thank the National Science Foundation (NSF) for funding as well as the Department of Defense (DoD) for support under grant number 662576-D19AP000.\n\nReferences\nAlain et al., \"Convolutional Neural Networks for End-to-end Speech Recognition in a Large-vocabulary Domain\"\n\nBauer et al., \"Time-Delay Convolutions: Architecture and Initial Results in Speech Recognition\"\n\nBhardwaj and Hinton, \"Deep Neural Networks for Statistical Machine Translation\"\n\nBIBREF0\n\nBaker, \"Speech Recognition: From Subphonetic Units to Mel-Spectrogram Representations\"\n\nBIBREF1\n\nChowdhury et al.\n\nFiscus and Jurafsky, \"A Probabilistic Context-free Grammar for Statistical Parsing of English Phrases\"\n\nGraves et al., \"Supervised Feature Learning for Speech Recognition with Time-Delay Deep Neural Networks\"\n\nHannun et al., \"An Introduction to Deep Convolutional Networks for Speaker Recognition and Translation\"\n\nJiang et al., \"Time-Delay Convolutional Neural Network for Speech Recognition-A Sequential Connectionist Approach\"\n\nJiang et al., \"Tightly Connected Layers of Residual Dense Blocks for Speech Recognition\"\n\nLiptchinsky et al., \"Audio2Letter: An End-to-End Speech Recognition System with Dynamic Time Warping\"\n\nPascual et al., \"End-to-End Sequence Learning with Joint Deep and Transformer Architectures\"\n\nRavanelli et al., \"End-to-end Speech Recognition with Recurrent Attention-based Transformer and Time-Delayed Convolutions\"\n\nRigler et al., \"Efficient RNN Recurrent Neural Network Architectures for Large Speech Recognition Models Using Connectionist Temporal Classification\"\n\nSak et al., \"Convolutional Neural Network-Based Automatic Speech Recognition System for Large-Vocabulary Spontaneous Speech\"\n\nSennrich et al., \"Neural Machine Translation in Practice\"\n\nSesia et al., \"Speech Recognition with Convolution",
    "bdc91d1283a82226aeeb7a2f79dbbc57d3e84a1a": "\nReferences\n[1] BERT Bib-BERT Pre-training by Masked Language Modeling\n\nhttps://ai.googleblog.com/2019/11/bert-p-pretraining-with-masked-language.html\n[2] BIBREF0 HANS, An Empirical Study of the Representation Learning of Entailment by Neural Networks\n\nhttps://research.fb.com/papers/heuristic-analysis-nli-networks\n\nBIBREF1 Bidirectional Encoder Representations from Transformer\n\n[3] BIBREF2\n\nStructBERT Improving Sentence Embeddings Using Structured Input and Pretraining with Multiple Tasks\n\n[4] BIBREF3\n\nA Structurally-Informed Language Model for Machine Comprehension\n\n[5] BIBREF4\n\nERNIE An Enhanced Representation for Neural Network Models\n\n[6] BIBREF5\n\nRoBERTa A Robustly Optimized BERT Pretraining Approach\n\n[7] BIBREF6\n\nXLNet Generalized Language Understanding to Unseen Languages\n\n[8] BIBREF7\n\nPre-Trained Deep Reinforcement Learning for Document-level Summarization\n\n[9] BIBREF8\n\nSkip-Thought: Extracting Relevant Information from Documents with a Multimodal Architecture\n\n[10] BIBREF9\n\nQuick-Thought: A Fast and Accurate Sentence-Pair Transformer\n\n[11] BIBREF10\n\nA Simple and Inexpensive Solution for Pair-wise Sentence Prediction\n\n[12] BIBREF11\n\nInferSent Extracting Sentence Representations from Neuron-level Activity Patterns\n\n[13] BIBREF14\n\nText-to-text Pre-training with Conditional Inference\n\n[15] BIBREF16\n\nReading Is Easy, but Pre-trained Difficult in Generalization\n\n[17] BIBREF18\n\nBERT Word-Word Memory Enhancements in Language Understanding\n\n[19] BIBREF19\n\nXNLI Cross-lingual Representation Learning over Multiple Languages\n\nBIBREF20\n\nLCQMC\n\nhttps://qinghuan.site/files/icnlpe",
    "7b4fb6da74e6bd1baea556788a02969134cf0800": "\nAcknowledgments\n\nWe thank the anonymous reviewers for their valuable comments. We thank the anonymous person in the NICELab for sharing the test set of KGC NLI task without asking for publication.\n\nReferences\n\nThe work by BIBREF1 was supported in part by the National Science Foundation of China under the grant No. 617611KYSB201601. This work was supported in part by the XTPLab-NLPLab JRP. The work by BIBREF2 was done in collaboration with BIBREF21. This work was supported in part by the National Science Foundation of Fujian under grant No 61271336 and 61271340, and in part by the Jiangsu Provincial Key Laboratory of Intelligence Computing under grant No 201701. The work by BIBREF0. was supported in part by NSF Grant No 1730676, DARPA Grant No HR00116800, and the Stanford University Institute for Human-Centered Artificial Intelligence (IHCAI) Grant Number AI/121240.\n\nBIBREF0. He, M., Pinter, J.D., Li, G.C., Yadav, P., Cho, Y., Wang, Y., Chen, H., Xu, X., Yang, T.-B., Liang, Z., Zhang, K., Zahra, W. and Yates, J. (2019). Unsupervised discovery of hidden relations in documents. Trans. AAAI Fall Symposium.\n\nBIBREF1. Devlin, J., Chen, D., Tan, H., Phan, O., Chang, S., Lee, C-Y, and Lee, K. (2019). Bert: Deep BERT pretraining for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (NLP), pages 4169\u20134177.\n\nBIBREF3. Zhang, X., Yang, Y., Bai, Z., Wu, Y., Liu, X., Yates, J., Li, H. and Huang, L. (2019) StructBert: A large-scale pre-trained language representation model. In Proceedings of NeurIPS, pages 6891\u20136901.\n\nBIBREF4. Shen, T., Zeyin, J., Zhang, X. and Lin, W. (2019). ERNIE:",
    "bc31a3d2f7c608df8c019a64d64cb0ccc5669210": "\nReferences ::: NLI and MRC Tasks :\n\n[1] K. Devlin, M. Chang, K. Lee, and T. Tan. Bidirectional Language Representations from Transformers. ArXiv: 1810.04805, 2018. https://arxiv <\n://\n\n>  html /\n\n>  1810.04805, 2018.\n\n[2] G. Nieh, S. Chen, and M. Liu. Question Generation for Answer-aware Sentence\n\nExtraction. In Proceedings of the Twenty-fourth International\n\nConference on Computers, Mathematics, and Statistics in\n\nPattern Recognition (ICMS + ECP), 2017, pp. 4334-4339\n\n[3] Z. Zhao, J. Tian, E. Yang, Y. Feng, and W. Xu. StructBERT:\n\nA Structured Neural Model for Sequence Encoding. In Proceedings of\n\nthe Twenty-eighth International Joint Conference on Artificial Intelligence\n\n(IJCAI-19), 2019, pp. 6125-6132\n\n[4] Y. Zhang, Z. Zhao, and X. Meng. Exploiting Structural\n\nRegularity for Improved Sentence Representation. In Proceedings of the\n\nTwelfth International Joint Conference on Artificial Intelligence\n\n(IJCAI-18), 2018, pp. 3012-3018\n\n[5] O. Choi, J. Choi, R. Lee, S. Jo, J. Hwang, and Y.\n\nK. Seo. Representation Learning by Inference from Context\n\nPatterns. In Proceedings of the Fifty-Second Annual Meeting of\n\nthe Association for Computational Linguistics (ACL 2018), 2018, pp. 1115-1132\n\n[6] G. Huang, D. Feng, Y. Gao, and L. Song. Efficient\n\nRepresentation Learning Using Cross-Task Inference. In Proceedings of the\n\nTwenty-Eighth International Joint Conference on Artificial Intelligence\n\n(IJCAI-18), 2018, pp. 1023-1030\n\n[7] Y. Liang, X. Chen, and Z. Hu. Bidirectional\n\nSequencetoSequence Model for Reading\n\nComprehension. In Proceedings of the Twenty-",
    "761de1610e934189850e8fda707dc5239dd58092": "\nAcknowledgment on the Accepted Version\nThe accepted version of this paper was developed while Aizhan Imankulova was pursuing an internship as a research fellow at NICT, Institute Division of NICT.\nCorrespondence\ne-mail: m.uzkarn@nict.go.jp, t.shimoyama@ed.ac.uk\nAcknowledgements\nWe thank Masafumi Ohta, Kiyoshi Shimoda, Shin Sano, and Takefumi Hori for their valuable comments. We would like to thank Atsuko Takano of NICT Language Data Center for providing us with the data for this paper. We also thank Hideo Oyama and Hideo Takahashi for their comments.\nAppendix A Glossary\nBIBREF0 BILINGUAL INTERPRETIVE LEXICAL ENVIORnmENTAL TRANSLATING Efficiency by Neural Network.\nBIBREF1 TRANSLATOR is an automatic translation tool based on an end-to-end neural network approach.\nBIBREF2 Attention-based RNN-based Neural Machine Translation.\nBIBREF3 Moses\u2014An open source, modular, efficient, usable tool for word alignment, sentence boundary disalignment, phrase-based translation, chunking, tokenization, stemming, and other language processing tasks.\nBIBREF4 Phrase-Based Statistical Machine Translation.\nBIBREF5 Multilingual Machine Translation.\nBIBREF6 Cross-Lingual Transfer Learning.\nBIBREF7 Multi-Lingual Statistical Machine Translation.\nBIBREF8 A Transformer-based Machine Translation Architecture for Improving Low-Resource Translation.\nBIBREF9 Domain Adaptation.\nBIBREF10 Transfer Pivoting by Multilingual Learning.\nBIBREF11 Multi-task Machine Translation with Cross-lingual Transfer and Multilingual Encoders.\nBIBREF12 Directional Transfer Learning of Neural Machine Translation for Low-Resource Translation.\nBIBREF13 Directional Transfer Learning from Monolingual Data for Machine Translation.\nBIBREF14 Transfer Learning by Extracting High-quality Word Pairs Using Unsupervised Phrase-based Models.\nBIBREF15 Jointly Unsupervised NMT and Sentence-Pair Mining for Improving Low-resource Machine Translation.\nBIBREF16 Automatic Construction of Indirect Parallel Corpora from",
    "f8da63df16c4c42093e5778c01a8e7e9b270142e": " voir / voirait / visiblement / \u00e0 tout entier\n4\n\n6\n\n4\n4\n4\n\n3\n6\n\n6\n6\n6\n\n6\n\n6\n4\n4\n4\n4\n4\n5\n4\n\n4\n3\n\n6\n4\n4\n4\n5\n5\n5\n4\n6\n4\n4\n\n3\n4\n\n5\n4\n4\n2\n5\n5\n6\n5\n\n5\n4\n4\n6\n4\n4\n4\n6\n2\n1\n4\n3\nIn the case of the Experts, the grammatical verb-nominal version (V-N) had better F-score performance. The verbal version (V) obtained a better accuracy $P$ than the verb-nominal (V-N). In the case of the Naive, the performance F-score, $P$ and $R$ is very similar from the Experts.\n\n7\n10\n6\n6\n6\n\n6\n6\n6\n\n6\n6\n4\n4\n4\n4\n4\n6\n6\n6\n\n4\n5\n1\n4\n3\n10\n6\n4\n2\n5\n\n5\n5\n5\n5\n4\n4\n\n6\n3\n2\n7\n2\n\n9\nTwo batch of tests were performed. The first on the $D$ set of documents common to the two subcorpus \"specialist\" $E$ and \"naive\" $N$ from Annodis. $D$ contains 38 documents with 13 364 words. This first test allowed to measure the distance between the human markers. In fact, in order to get an idea of the quality of the human segments, the cuts in the texts made by the specialists were measured it versus the so-called \"naifs\" note takers and vice versa. The second series of tests consisted of using all the documents of the subcorpus \"specialist\" $E$ because the documents of the subcorpus of Annodis are not identical. Then we benchmarked the performance of the three systems automatically.\n\nExperiments ::: Results\n\n8\n\n3\n9\n6\n4\n2\n6\n4\n5\n2\n1\n8\n5",
    "c09a92e25e6a81369fcc4ae6045491f2690ccc10": "\n\n1. https://sentiment140.com/\n2. Annotators may perform manual or automated labeling.\n3. It is the job of the experts to construct gold standards, annotate the terms, and define the methods, to perform supervised or unsupervised classification.\n4. Crowdsourcing is performed by using gold standards or by having each member evaluate the same content for accuracy assessment.\n5. MTurk (mechanical turk) is a crowdsourcing platform, where each task is allocated to one of the participating contributors.\n6. Crowdsourcing is conducted remotely, with a high number of participants or contributors, usually in a distributed geographical environment.\n7. Based on Plutchik's circumplex model, which divides polar emotions into positive/negative and complex/simpler emotions, see Figure FIGREF1.\n8. Some lexicon examples are: -WordNet [Miller et al., 1990], SentiWordNet [Socher et al., 2013], Plutchik lexicon BIBREF13, etc.\n9. Plutchik's emotion circle, based on the eight basic emotions.\n10. Expert-based sentiment analysis is less scalable and is restricted to a limited range of emotional labels.\n11. Automatic annotation requires a large annotated term corpus.\n12. Ekam et al. BIBREF10 proposed the six basic emotions joy, anger, fear, sadness, disgust, and surprise.\n13. Lexicon examples: WordNet [Miller et al., 1990], SentiWordNet [Socher et al., 2013], Plutchik lexicon BIBREF13, SentiHollywood [Caruana et al., 2016], etc.\n14. Subjectivity refers to ambiguity and lack of consistency from human interpretation of a textual resource.\n15. Automatic annotation requires natural language resources, such as text and knowledge bases BIBREF17.\n16. Crowdsourcing also known as the human cloud, is a distributed work environment where multiple workers annotate the same corpus.\n17. Annotation can be performed by machine learning or manually BIBREF23, BIBREF24.\n18. In crowdsourcing, annotations are distributed in a wide network of participants, also known as contributors BIBREF7, BIBREF29.\n19. MTurk (mechanical turk) is a crowdsourcing platform, where each worker is",
    "63c3550c6fb42f41a0c93133e9fca12ac00df9b3": "\n\n\nTable of Contents\n\nTitle Page\n\nCopyright Page\n\nAcknowledgements\n\nChapter 1 - The Redheaded Man\n\nChapter 2 - A Ghostly Visitor\n\nChapter 3 - The Black and Gold Dagger\n\nChapter 4 - A Secret Passage\n\nChapter 5 - The Haunted Library\n\nChapter 6 - The Mysterious Red Haired Woman\n\nChapter 7 - Ripples\n\nChapter 8 - The Dagger In The Dust\n\nChapter 9 - A Curse Of Blood And Fate\n\nChapter 10 - The Haunted Garden\n\nChapter 11 - A Vestigial Cloak\n\nChapter 12 - The Staggering Beast\n\nChapter 13 - The Blood Spots\n\nChapter 14 - The Dark Pool\n**\"A tale for the very young to the very old... a tale of the fantastic well told... a tale of dreams and desires... not a tale to be forgotten.\"\n\n_\u2014Winnipeg Free Press_\n\n**\"A remarkable story. I can only recommend it highly.\"\n\n_\u2014The Bulletin_ (Sydney)\n\n**\"A superb blend of magic, mystery, and horror... a well-worn thread that carries the reader on a wondrous ride through the supernatural.\"\n\n_\u2014The Adelaide_ _Advertiser_\n\n**\"An unusual story, well-told in a most engaging, readable fashion... a ghostly read of terror, humor, and suspense.\"\n\n_\u2014The Sun_ (Brisbane)\n\n**\n\n\"A rare gem of a book... well written and nicely told, exciting and satisfying. Those who love fantasy or horror will enjoy this book.\"\n**\n\n**The Magic of Philip Jose Farmer**\n\n**The Man Who Painted the Dragon**\n\n**The Other World**\n\n**To Market, To Market**\n\n**The Graveyard Gang**\n\n**Haunted Legends of the Supernatural** (with Jack Williamson)\n\n**Dark Lady** (with Jack Williamson)\n\n**Night's Master**\n\n**The Witches**\n\n**Death in White Rags**\n\n**Bloodroot**\n\n**Darkness at Noon**\n\n**The Beast**\n\n**The Haunted Mask**\n\n",
    "603fee7314fa65261812157ddfc2c544277fcf90": "\n\n1 https://arxiv.org/pdf/1602.05363.pdf (paper describing word2vec's architecture)\n2 http://www.nltk.org/data.html  \n(available word lists for various languages)\n3 ::: GloVe\n4 http://glove.stanford.edu   \n(word2vec word embedding dataset)\n5 ::: ELMo\n6 ::: word2vec, GloVe, FastText, and FastAlign\n7 https://github.com/facebookresearch/ELMo/tree/blob/master/elmo_resources.py\n8 ::: ELMo for many languages\n9 ::: hrWaC2\n10 ::: http://www.mikolajczapec.eu/rytas/corpus/hrWac2.1.zip   \n(Croatian fiction corpus)\n111 ::: http://www.lat.org/dare/index.html   \n(Croatian news corpus)\n11 ::: http://www.rijs.eu/en/corpora/ylijauta.shtml   \n(Finnish news corpus)\n12 ::: http://ltnet.eu/ltTenTen/   \n(Lithuanian news corpus)\n\n13 ::: http://bit.ly/fida-sl2   \n(Slovene news corpus)\n14 ::: https://nlp.kmi.open.ac.uk/conll17/   \n(CoNLL 2017 Shared Task corpus)\n15 ::: http://nltk.org/data/data.en.html#language-models\n16 ::: http://csls.stanford.edu/cscls/index.php?language=slovene&model=all&corpus=allcorpus&layer=elme, allcplg\n17 ::: https://arxiv.org/abs/1412.6980\n18 ::: https://arxiv.org/abs/1508.06576\n19 ::: https://hdl.handle.net/1842/3223   \n(Swedish news corpus)\n\n20 ::: https://nltk.org/data.html?selected=nltk.ne.named\n21 ::: https://hdl.",
    "09a1173e971e0fcdbf2fbecb1b077158ab08f497": "\n\nReferences\n\nAnaniadou, S., Li, T., Lin, H., & Wu, S. (2016). CharacterNCE: Deep Neural Networks for Character-Based Multimodal Representations. CoRR abs/1602.03501. https://link.springer.com/content/pdf/10.1007/978-3-319-39263-6_5.pdf\n\nBaker, P., & Waughray, D. (2011). Corpus-and-Language-Independent Morphosyntax Analysis. In Proceedings of the Fourteenth European Dependency Parsing conference (EDP'11). Springer, Berlin, Germany. http://www.aclweb.org/anthology/D11-2065\n\nBIBREF0\n\nGers, A., Leacock, M., & Cowling, S. D. (2016). FastText: Distributed Word Vectors. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computational Linguistics OpenTrack 1.\n\nBIBREF1\n\nPilehvar, M. M., Karaletsos, E., Tsochatzidis, I., & Cholakoglou, A. (2016). GloVe: Global Vectors for word Representation. Transactions of the International Conference on Computational Linguistics.\n\nBIBREF2\n\nJoulin, A., Tzanetakis, E., Chen, K., & Tsochantaridis, I. (2016). FastestText: A Fast Neural Network Baseline for Text Classification. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics.\n\nBIBREF3\n\nPeters, J., Zhang, Y., Zhang, S., Tan, B., Ward, J., & Lee, S. (2018). Deep contextualized word representations. Arxiv preprint arXiv:1802.05365.\n\nBIBREF4\n\nBruce, D., Neumann, C., & Posewitz, L. (2020). ELMo: Deep unsupervised learning of language representations from text. Transactions of the Association for Computational Linguistics.\n\nBIBREF5\n\nMikolov, T., Chen, K., & Corrado",
    "70e9210fe64f8d71334e5107732d764332a81cb1": " Lastly, adding context size to the language model allows it to capitalize on larger input contexts, without increasing training data requirements that significantly ( INLINEFORM1 absolute WER).\nFuture research work As discussed in Section SECREF6, other architectures or hyper-parameter tuning choices could further improve results. Other architectures can be used for the learnable front-end to learn more expressive features, such as the recently proposed GAMMA network BIBREF24, or even raw CNNs.\n\nLimitations of this approach Convolutional language models are computationally expensive, preventing them to be used on large vocabulary systems. A next task will be to create a hybrid convolutional front-end, combining it with a gated recurrent neural network (GRNN). Using convolutional acoustic models with speech features as described in BIBREF16, on the other hand, may allow us to increase vocabulary size for a fixed amount of training data. In this direction, as suggested in BIBREF17, cross-attention may be a good approach to combine the efficiency of an end-to-end system at low computational costs while capitalizing on large context sizes afforded by convolutional language models.\nAcknowledgements This work was supported by Agence Nationale de la Recherche (ANR) through a contract with Google AI through the Google AI Europe program.\n\nReferences\n\n[BIBREF1] P. O. Pinheiro, T. Graves, K. Kalchoff, R. J. Reardon, L. S. Denoyer, J-Y Jousset, S. Gers, and G. G. Mart\u00edn Aura, Learning Speech Synthesis With End-to-end Convolutional Neural Networks, ICASSP 2017.\n\n[BIBREF10] D. O. Martin, E. Abdel-Hamid, and D. J. Reis, Pronunciation Modeling in a Convolutional-Recurrent End-to-End Speech Recognition Pipeline, IEEE TASLP 2018.\n\n[BIBREF11] S. Gers, M. A. Palau, P. Deller, and P. O. Pinheiro, End-to end Convolutional Neural Networks for Speech Recognition, ICASSP 2019.\n\n[BIBREF12] M. A. Calise and C. E. Vidal, Spectral Decomposition for Fast and Cost",
    "051df74dc643498e95d16e58851701628fdfd43e": "\nAcknowledgements\nWork in this paper is supported by the EU Horizon2020 grant \"GrowthSAT\"\n\nThe author acknowledges financial support to the I-Cooperate project by the DFG (grant no.: 436R20), supported by the H2020 programme of the European Union.\n\nWe also acknowledge financial support of the Marie Curie ITN-MSCA-2018-77905-GrowthSAT.\n\nReferences\n\n\\\n[BIBREF1] ReachOut Ireland. (2018). About ReachOut. [https://reachout.ie/how-it-works?source=footer]\n\n[BIBREF2] D'Arcy, M., & McInnes-Horley, P. (2011). How can online communities support patients? An exploratory study of members of the ReachOut.com self-help community. Cogent Social Works, 3. pp. 1-16.\n\n[BIBREF3] McInnes-Horley, P. (2011). Examining the social identity of adolescents using computer-mediated participation. International Journal of Computer-Supported Collaborative Learning, 1-20.\n\n[BIBREF4] Harley, A. R., & Lapsley, H. (2006) Online Support Group Use and User-generated Content. International Journal of Adolescent Medicine and Health, 22(2), 115-123.\n\n[BIBREF5] McGrath, B., McInnes-Horley, P., D'Arcy, M., & O'Doherty, F. (2016). Talking the Talk: How Online Support Group Forums May Impact Mental Health Treatment. Electronic Journal of Technology in Mental Health, 5(1), 1-10.\n\n[BIBREF6] D'Arcy, M., McInnes-Horley, P., & McGrath, B. (2015) Evaluation of a Multimodal Approach to Analyzing Online Social Interaction. Electronic Journal of Technology in Mental Health, 4(3), 1-7.\n\n[BIBREF7] Nolte, M. P., & Maher, E. W. (2015). A Cognitive-Behavioral Treatment for Anxiety: Antecedent-Contingent Moderation of the Expectations of Change in a Web-based Depression Support Group. Cogent",
    "33554065284110859a8ea3ca7346474ab2cab100": "\nACKNOWLEDGMENTS\nThis work was supported by VU University Amsterdam, the Netherlands, through the grant SPO-2016-3265-001. The author would like to thank the anonymous reviewers for their valuable suggestions. Furthermore, the author is thankful to Elisa Andreotti, Iulian Filip and Peter Fankhauser for the valuable feedback during the preparation of the final work.\nReferences\n\n[1] P. B\u00fcring and S. Thayer. Therapeutic factors in group treatment: a meta-analysis of results and a theory of effect. _Journal of Clinical Psychology_, 56 (2), 174\u2013184, 1999. (external link).\n\n[2] B. De Leeuw and J. van der Haeghen. The development of a community of users offering peer-support services for adolescents at risk of depression. _In ACM CHI Workshop on User Modeling,_ pages 17\u201326, 2012. (external link).\n\n[3] J. S. A. Fawcett, R. E. DeFilippi, B. S. Stepp, J. A. Littin & A. E. Miller. On-line self-stigma in depression patients: examining the association with internet use, social support, and suicide risk via longitudinal Twitter data. _Pediatrics_, 134 (5), e20150909, 2015. (external link).\n\n[4] T. G. Frank and P. C. W. van Berkel. _Teaching and learning from social network sites: a mixed-methods investigation_. _Digital Learning_, 28 (1), 25\u201348, 2018. (external link).\n\n[5] G. G. J. van den Hoven and E. L. T. Hesselberth. In-group and out-group mental health stigma on Facebook. _Journal of Social and Clinical Psychology_, 38 (8), 813\u2013827, 2017. (external link).\n\n[6] S. J. B. G. van der Heide and I. K\u00e4rkk\u00e4inen. _NLP for health:_ a survey of recent challenges. _Computers in Human Behavior, 49_, 51\u201369, 2018. (external link).\n\n[7] H. G. K\u00fchlewind, J. S. A. Fawcett,",
    "57f23dfc264feb62f45d9a9e24c60bd73d7fe563": "\n\nDiscussion of results\nWe observe that using a mix of different structured tasks for training improves the performance of models across different tasks, by a significant increase in the coverage of features. We observe that the effect of increased number of samples is more significant for structured tasks like paragraph reading task, HAFP, which are longer and can test domain-specific aspects of a participant.\nVisualization of class boundaries. Decision boundaries for a model trained on DB + FP.\nClassification performance with addition of different dataset combinations.\nEffect of augmenting DB with healthy samples from different structured tasks.\nFairness of classification:\n\nFairness is evaluated with respect to the two age bins (age 60 and above and between 30 and 60). A fair model would produce comparable classification performance for both sets of individuals. The F1 (micro) score for samples with age INLINEFORM7 60 is 82.28% and with age INLINEFOR6 85.9%.\nComparison with other published work.\nThe number of training samples of each structured task used for evaluation are shown in Tab. SECREF7.\nEffect of age of samples on performance.\nDiscussion of results\n\nThe effect of adding normative data from different structured tasks is more significant for structured tasks like HAFP and paragraph reading task, which are longer and evaluate domain-specific aspects of the participants. The effect of increasing number of samples is more significant for structured tasks like paragraph reading task, HAFP ( longer, more complex tasks) with a F1 score INLINEFORM8 87.01% and F1 score INLINEFORM9 97.01% respectively for the same set of data from HAFP.\nAttention-focusing on Relevant Features:\n\nThe coverage of relevant anchors is shown in Tab. SECREF43.\nInductive Bias of Tasks:\n\nThe coverage of anchors on each task from the model trained on DB is shown in Tab. SECREF45.\nInductive Bias of Tasks:\n\nWe observe high inductive bias for structured tasks like paragraph reading task (HAFP) and HAFP (fluency and paragraph tests together), which could possibly relate to the nature of the tasks evaluating domain-specific aspects of a participant. We also observe that there is domain-specific inductive bias for HAFP with respect to HAFP with higher inductive bias for paragraph reading than HAFP.\n\nDiscussion of results\n\nWe explore mechanisms of inductive",
    "54830abe73fef4e629a36866ceeeca10214bd2c8": "\nAuthor Contribution Statement\n\nThe author acknowledges the support of this work by Mashhad University of Science and Technology.\n\nAcknowledgements\n\nI would like to thank to Dr. Mohammad Reza Nabipour for his valuable help.\nAbolfathi, N, and A Zaki, \"Content-based recommender system for recommender system.\" International Journal of Intelligent Systems 25, 5-13 (2013).\n\nAbolfathi, N, and J Hashemi, \"A novel approach to music recommendation by topic model,\" in 2018 2nd International Conference on Human-Computer Interaction, Systems Design and Applications, HCI-SDA 2018 (2018).\n\nAbolfathi, N and Zaki, A, \"Recommendation systems based on collaborative filtering and topic model,\" in 2019 International Conference on Signal, Image & Graphics, SIGGRAPH Asia 2019 (accepted).\n\nChen, S-X, and G Zou, \"Recommendation of the best movies based on tag-video data.\" Knowledge Technologies. 17(12), 1519-1520 (2019).\n\nHassibi, M.S, L Deng, Z Wang, and M Zhu, \"Content-based recommender system based on LDA.\" Knowledge Technologies. 17(11), 1247-1252 (2019).\n\nLe and H-S Nie, \"Music recommendation based on latent topic model.\" Proceedings-2009 International Conference on Knowledge Technologies, ICKT 2009 (2009).\n\nMin, X-G, D Liu, G Zhou, Y Hao, S Li, and C Gui, \"Collaborative filtering recommendation based on LDA in Trend-aware recommendation system,\" in 2015 International Conference on Web Information Systems, CIKM 2015 (2015).\n\nZhao, W and T C Li, \"Music recommendation based on LDA: a collaborative filtering approach.\" Computers and Information Science (2016).\n\nAbolfathi, N., A Zaki (2018) \"Recommendation Systems Based on LDA,\" in: E-Learning and Distance Learning in Emerging Society and Industry. ELDLI 2018. Advances in Intelligent Systems and Computing. Springer, Berlin.\n\nAbolfathi, N. (2020) \"An investigation of recommendation systems based on LDA in emerging social communities.\" Journal of Intelligent Systems 38:7\u201314, 2019.\n\n",
    "2fbb6322e485e7743ec3fb4bb02d44bf4b5ea8a6": "\n\nBIBREF0.... BIBREF2\n\nW. B. Fellbaum, D. A. Phillips, R. E. Burchfiel, T. F. Guida, and T. K. Landauer. \"An empirical study of the lexical organization of conceptualizations.\" Cognitive Psychology 32.3 (1990): 579-619.\n\nD. G. Charles, \"Word meanings and relations.\" Cognitive Psychology 25.4 (1989): 645\u2013670.\n\nH. B. Hearst, \"Some aspects of the lexical organization of English.\" Applied Psycholinguistics 13.3 (1992): 273\u2013297.\n\nH. B. Hearst. Syntactic Patterns and Their Relations to Grammatical Relations. Oxford, England: Oxford University Press, 1992.\n\nP. Lin. \"The syntactic organization of word knowledge.\" Cognitive Science 21.2 (1997): 191\u2013237.\n\nZ. Justeson, G. Katz, and F. J. Algina. \"An automated construction of word-sense-lexicons.\" in Proceedings of the 33rd Annual Meeting on Association for Computational Linguistics, Association for Computational Linguistics, pages 572\u2013579. Association for Computational Linguistics, Prague, Czech Republic, 1991.\n\nB. Pennington, R. Socher, and C. D. Manning. \"Introduction to neural language processing.\" in Handbook of Neurolinguistic Programming, pp. 177\u2013236, Elsevier, Berlin, Germany, 2014.\n\nK. Schwartz and S. Schulte im Walde. \"Neural text similarity: Combining lexical and syntactic relationships with recurrent neural networks.\" in Proceedings of the 33rd Annual Meeting on Association for Computational Linguistics, Association for Computational Linguistics, Prague, Czech Republic, 1991.\n\nIlya P. Kuznetsova and Liwei Wang. \"Distributional concord: Vector space models and distributional structure.\" in Proceedings of the 33rd Annual Meeting on Association for Computational Linguistics, Association for Computational Linguistics, Prague, Czech Republic, 1991.\n\nL. A. Baroni and K. M. Duh. \"A supervised distributional concatenation method for word representations,\" in Proceedings of the 36th Annual Meeting on Association for Computational",
    "ef7212075e80bf35b7889dc8dd52fcbae0d1400a": " The viewpoints presented here represent solely the work of S.Hwang and J. Kim, and do not necessarily reflect the views of MSIT and IITP.\n\nFigure 1. When generating summaries with RNN-based sequence-to-sequence models, it is crucial not to include irrelevant information. First (O1), summaries are mainly composed of linked entities from the original text. Second (O2), the topic of a generated summary can be represented as a probability distribution of linked entities over the list of entities. Finally (O3) linked entities can be used to represent summary topic through a continuous vector model, which can be learned from a knowledge base.\n\nFigure 2. E2T extends an abstractive summarization model with linked entities. The E2T module is attached to the model to produce summary topic vector from the linked entities, which is then concatenated to the decoder hidden state vectors. The decoded summaries are then produced after passing through softmax layer and entity linking system.\n\nFigure 3. Entity2Topic module uses selective disambiguation to resolve ambiguity of extracted entities, and firm attention to sift out irrelevant entities. The proposed method can be easily extended to more sophisticated models by replacing these two submodules with better components. The full architecture is illustrated in Figure 2. The full code of the base model and the E2T is available online.\n\n1. BIBREF0 A. Ghaddar and T. Grauman. Text summarization: A literature review. Machine Learning, 42(1):13-71 (2005).\n\n2. BIBREF1 D. See and S. Huang. Abstractive text summarization with recursive neural networks. In AAAI (2015).\n\n3. BIBREF1 Y. Chen, C. Xue, Y. Liu, and K. Li. Learning to segment sentences with recursive neural attention. In ICLR (2016).\n\n4. BIBREF1 D. See, H. Yih, and S. Huang. Fast and accurate word-level text summarization by recursive neural networks. In ICML (2016).\n\n5. BIBREF1 J. Gao, Y. Liu, S. Huang, Y. Chen, T. Liu, J. Gao, and K. Li. Abstractive text summarization by using a sentence-level attention mechanism. In NIPS (2017).\n\n",
    "567dc9bad8428ea9a2658c88203a0ed0f8da0dc3": " The work done by Bal Krishna Bal is part of the project \"Dataset for Nepali Language for Machine Learning\" submitted to Nepal Science Foundation. He is also grateful to Faculty Fellowship ProgrammeKU, KU for providing him the fellowship for pursuing this work. We would also like to thank Manoj Khanal, ILPRL Lab, KU for supporting and guiding his work.\nInstitutional Review Board Statement\nThe authors have read and approved the IRB statement. There are no human participants involved in the process and the model used is purely computational.\nThis Article has not been copyrighted.\n\nInformed Consent\nThe authors acknowledge and declare they have informed consent from anyone who appears in this Article.\nConflict of Interest\nDeclare that there are no conflicts of interest.\n\nFunding\nNot Applicable\n\nAcknowledgements\n\nWe would like to express our profound acknowledgments to our Ph.D. guides Dr. Prakash Koirala, Dr. Anmol Dhakal, Dr. Sanjit Thapa for providing their support. We would like to thank our Ph.D. advisor Prof. Bhargav Shrestha for guiding us and helping us build this model. We would also like to thank Prakash Koirala and Anmol Dhakal for creating the dataset used in this paper. We would also like to thank Nepal Science Foundation for supporting our project. In addition to Nepali National Corpus, we would like to acknowledge the help and support from Nepali Wikipedia. Additionally, we would like to acknowledge the help and support of Shivam Prasad Pant for helping us build this pre-processing steps. Finally, we could not have completed this paper without the help and support from our Ph.D. committee members, Sagar Kumar Parajuli and Suman Sapkota.\n\nReferences\n...\n\n_Falling Skies_ is a work of fiction. Names, places and incidents either are products of the author's imagination or are used fictitiously. Any resemblance to actual persons, living or dead, events or locales is entirely coincidental. \n\"THE SKY IS FULL.\"\n\nOne of the marauders had a bullhorn. \"Come out of there, you rats!\"\n\nBut the boys inside weren't rats and they didn't stop what they were doing. So there isn't much left, now, of the old world, and the",
    "d51dc36fbf6518226b8e45d4c817e07e8f642003": " The authors also would like to thank Anup Kumar Shrestha, Anish Sharma and Bhavan Chand Shrestha for helping and supporting us in creating this paper.\nCitations\n\nBai, Y., & Zhu, X. (2015). A neural network language model achieves state-of-the-art results on semantic parsing. arXiv preprint arXiv:1502.03005.\n\nBhardwaj, K., & Bharadwaj, K. (2015). An Evaluation of Neural Language Models for Named Entity Recognition. Machine Learning, 88(3), 579\u2013598.\n\nChen, B., & Ng, M. Y. (2017). Entity-based sentence-level named entity recognition. In Nineteenth Conference of the Association for Computational Linguistics: Human Language Technologies (HLT).\n\nDing, X., & Wadden, T. (2015). Unsupervised training of contextualized word representations. Transactions of the Association for Computational Linguistics, 1(2), 57\u201391.\n\nDubey, R., & Shandilya, S. (2014). Support Vector Machine-based Entity-Aware Named Entity Recognition using a rule based approach. International Journal of Computational Linguistics, 6(4), 223\u2013245.\n\nFei, S., Zhu, Y., Yatabe, K., Zhang, L., Liu, X., & Wang, Q. (2016a). Towards better sentence level, end-to-end text classification with neural networks. In Nineteenth Conference of the Association for Computational Linguistics: Human Language Technologies (HLT 2016).\n\nJoty, O. (2012). A computational model for morphological identification of Newari from written Nepali. Journal of Nepalese Literature and Language Studies, 1(1), 31\u201340.\n\nKaushik, P., Chiu, C., & Lee, J. (2015). Fasttext: Distributed Representations for English Token Semantics. Proceedings of the 33rd Conference on Association of Computational Linguistics, Pages 2152\u20132160.\n\nKim, J. H., A. Lee, C. Park, G. Cho, B. Song, Y. Kim, W. Kang, & A. Yu. (2016). FastText: Distributed Representations for English",
    "d8627ba08b7342e473b8a2b560baa8cdbae3c7fd": " The authors also would like to thank for their help and support from the Datastudio team and faculty members. Last but not the least, the authors would like to thank for support from NepalNLP community.\n[1] R. Bar-Haim, E. Goldberg, J. Yariv, P. Klein, A. Zahavy. \"An introduction to named entity recognition\", Proceedings of the Workshop on Cross-lingual Semantic Parsing Technologies (CoNLL-1999), 2002.\n[2] Fetahu Tzomu Jwala, Ammar R. Shah, A. Cohn-Gordon, Ammar B. Abdel-Hamid, Daniel B. Klein, Robert D. Klein, Ritu Kumar. \"Nepali named entity recognition using character-level neural architecture\", Proceedings of Nepalian Natural Language Processing Workshop (NLP-2016), pp. 1-6, 2016\n[3] T. Kajita, R. Miyamoto, Y. Nakazawa, T. Oikawa, H. Isobe, Y. Miwa. \"Named Entity Recognition based on grapheme cluster-level convolutional neural network\", The 6th Workshop on Natural Language Processing for Asian Languages (NLPAJ), 2016.\n[4] A. Gupta, Manoj Kumar, S. B. Maji. \"Named entity recognition on hindi using character and word level cnn\", In Proceedings of the 2015th International Conference on Advanced Multimedia Multimedia Applications, Systems, Services, and Techniques (ICAMTT), 2015.\n[5] A. Katafai. \"Named entity recognition in nepali using convolutional neural net\", In Proceedings of the 1st Workshop on Natural Language Processing for Indic Languages (NLP Indic 2016), 2016\n[6] O. Pires, A. P. Dias. \"Named entity recognition in nepali using an unconstrained part-of-speech tagger\", In Proceedings of the 1st Workshop on Natural Language Processing for Indic Languages (NLP Indic 2016), 2016\n[7] D. Chinchilla, H. K. Nishimura, N. A. Roy, U. G. de Brito Menezes. \"A grammar based approach to named entity recognition for Nepali\", In Proceeding of the 8th International",
    "cb77d6a74065cb05318faf57e7ceca05e126a80d": " Without his contribution Nepali NER would have not been studied. We would also thank Mihir H. Nayak, Dataturk, Kathmandu University and all volunteers for building and contributing OurNepali data\nBibliography\n\n[1] Venu V. B. and Ramesh Srinivasan, Named Entity Recognition for Indian Languages Based on Rule-based Model with N-Gram Technique, International Journal of Computer Science and Information Technologies (IJCSIT), Volume 7, Issue 5, December 2014.\n\n[2] Manoj K. Pandey, S. A. Maji, Manoj K. Pandey, T. M. Majumdar, Manoj K. Pandey, N. K. Pandey, Paramesh Chakravarthy, R. G. Dutta, S. Udayashankar, S. Chandra Sekar, Manoj K. Pandey, Yogendra S. Sivaramurthy, Sumit Kumar Garg, M. N. Jadhav, P. M. Haldar. A Named Entity Recognition Model Using Deep Learning for Nepali Language Corpus. Proceedings of the 14th International Conference on Recent Advances in Computing and Emerging Technologies (ICRACET), 2018.\n\n[3] Pramendra Ghimire, Rajiv Ratna Prasad Ghimire, Alok Pokhrel, Prakash Pokhrel, Suryasinha Pokhrel, Shabdakar Prasain, \"Named Entity Recognition for Nepali language Corpus using Deep Learning Architecture,\" 2018 International Conference of Computer Engineering and Sciences (ICCES), 2018.\n\n[4] Mithilesh Shahid, Hidenshi Taketa, Satish Suryoprasad, Aravind Bhan, Shruti Kattel, Deepak Poojary, Satyendra Singh, \"Nepali: An Overview of N-Gram and N-Gram with Word Classifier Technique for Named Entity Recognition\", in Proceedings of the 2nd International Conference on Computing, Communication, Technologies & Society (CCTS 2017), New Delhi, 2017\n\n[5] J. U. J. C. B. and J. M. S. L. G. V. R. K. Sharma. Un",
    "8a7615fc6ff1de287d36ab21bf2c6a3b2914f73d": " Many thanks to Ravi Joshi, IIT Guwahati, for pointing out the grammatical mistakes in our final submission. Many thanks to Pravasin Majhi and Krunal Pradhan for supporting us. Many thanks to all the people in Dataturk platform for their valuable suggestions and support.\n1. R. G. Choudhury, N. Roy Choudhury, K. Gupta, A. Joshi, S. D. Mishra, R. Saha, N. Sinha, (2015), Named Entity Recognition using Word Embeddings and CRF. International Conference on Computational Intelligence, 2015.\n\n2. K. Koehn, K. Basile, P. F. Riley, T. De Groen, E. N. Ng, R. Choudhury, G. Satyamani, R. Van Durme, R. T. Martin, S. S. Deorukh, (2011). Mining Tweet Data for Linking and Recursive Classification of Named Entities. Proceedings of the Conference on Empirical Methods in Natural Language Processing, 2011.\n\n3. N. Agarwal, J. Dreyze, (2017). An Approach to Named Entity Recognition using a Convolutional Neural Network on Hindi Language. Proceedings of the 7th Workshop on Interfaces between Natural Language Processing and Knowledge Graphs, 2017.\n\n4. J. A. T. Cholakkal, A. Ganeshan, P. R. Balaji, K. V. Ramakrishnan, D. Jain, (2017). Efficient End-to-End Learning for Entity Linking Using Deep Bidirectional Multi-Loss Learning. Proceedings of the 28th AAAI Conference on Artificial Intelligence, 2017.\n\n5. A. F. S. G. Ghosal, R. Saha, (2016). A Feature-based Approaching for Hindi named entity recognition, International Conference on Computational Intelligence, 2016.\n\n6. S. Mishra, P. K. Gupta, R. R. Choudhury, R. Choudhury, N. A. Gupta, D. Gupta, X. Rong, T. De Groen, (2016). Enriched Hindi Named Entity Detection with an En",
    "a1b3e2107302c5a993baafbe177684ae88d6f505": "\nTo the reviewers who has motivated us to add our dataset, without this paper would be different. We would also like to thank Nirmal Pratap for helping us in designing and creating our models and thanks to Samjhana Banty for valuable conversations.\nReferences\n\nBanty, S.B., Yadav, P.R., & Bhattacharya, C. (2013). Named Entity Recognition in Nepali Language Using a Machine Learning Approach. NLP International Workshop Paper, pp. 17-20 (2013).\n\nBanty, S.B., Yadav, P.R., & Bhattacharya, C. (2013). Using Part-of-speech Tags to Improve Nepali Named Entity Recognization: A Machine Learning Approach. NLP International Workshop Paper, pp. 61-67 (2013).\n\nBanty, S.B. & Yadav, P.R. (2013). Evaluating Hidden Markov Models to Perform Named Entity Recognition on Hindi and Nepali Languages. NLP International Workshop Paper, pp. 32-37 (2013).\n\nBanty, S.B., Waleel, A., Yadav, P.R., & Bhattacharya, C. (2018). NLP in Nepali: An Evaluation of Methods to Identify Sentence Part-of-Speech and Their Effects on Named Entity Recognition. BIBAL: Biennial International Conference of Linguists, Alchi Monastery, Ladakh, India, pp. 8-12.\n\nBal Krishna, K., Yadav, P.R. and Bhattacharya, C., (2018). ILPRL Corpus for Nepali NER, version 1.1.3.\n\nBhattacharya C, Yadav P., Ghale L.J., Bal Krishna K., (2019). Sajjan Nepali Dataset, version 1.1.0.\n\nBIBREF10.Bhattacharya, C., Waleel A., Yadav P.R., (2013).\n\nBIBREF11.Yadav, P.R., Banty, S.B. Bhattacharya, C. (2014).\n\n",
    "bb2de20ee5937da7e3e6230e942bec7b6e8f61ee": "\nReferences\n\n1\n\nKhasa M., Kumar R. (2015). A Survey of Named Entity Recognition Techniques and System. In Proceedings of 2015 International Conference on Computational Linguistics and Natural Language Computing. Citation: L-4.\n\n2\n\nChand, I. and Kulkarni, P. (2015). Unsupervised Named Entity Recognition in Low Resource Language. In Proceedings of the International Conference on Knowledge-Based Intelligent Information & Search. DOI: 10.1145/2626011.1-21.\n\n3\n\nJoshi, K. C. and Kumar, R. (2016). Automatic Parsing of Nepali Documents from Text. In Proceedings of the World Conference on Computer Vision and Pattern Recognition. Citation: L-6.\n\n4\n\nGhosh, R., Kumar, R. and Joshi, K. C. (2016). Automatic Classification of Nepali Language Sentences. In Proceedings of the 1st Workshop on Computational Linguistics and Language Technologies. Citation: T-21.\n\n5\n\nKumar, R. and Kumar, B. (2016). NLP tools in Nepali Language Processing. In Proceedings of the 2nd International Conference on Recent Advances in Computational Linguistics (RACL). Citation: T-19.\n\n6\n\nKrishna, B. and Jha, J. Y. (2017). Nepali Language Processing Platform. In Proceedings of 2017 Asian Conference of Computational Linguistics. Citation: L-5.\n\n7\n\nDhawan, S. (2016). Language Identification and Normalization of Handwritten Devanagari Manuscripts by Word Embeddings. In Proceedings of the Asian Conference on Computer Vision. Citation: L-3.\n\n8\n\nWeng, B., Chen, L. and Li, Z. (2017). Jointly Learning Multilingual Representations for Word Vectors. In Proceedings of 2017 Conference on Empirical Methods in Natural Language Processing. Citation: L-6.\n\n9\n\nDaneshpandiya, K., Mehrabani, N. R. and Li, Y. (2016). Ner-ne. In Proceedings of Conference on Empirical Methods in Natural Language Processing. Citation: L-7.\n\nBIB",
    "1170e4ee76fa202cabac9f621e8fbeb4a6c5f094": " Without his help, the research would not be possible like this. We would like to express special thanks to Prashant Shrestha, Pramod Sharma and his team, for helping us to solve the issues with their assistance.\nReferences\n\n[1] BIBREF0 \"Named Entity Recognition: A Brief Overview\" [Online] http://www3.cs.stonybrook.edu/\u02dcdavisbe/Teaching/NeuralNet/BIBREF18/GloVeBriefly.pdf\n[2] BIBREF0 \"Named Entity Disambiguation: A Brief Overview\" [Online] http://www.cs.nyu.edu/mikroyann/research/pdfs/pubs/NeuralNetworks%20and%20Text%20Mining_2.pdf\n[3] BIBREF13 RNN-based named entity recognition models for Hindi: A large-scale evaluation\" [Online] http://www.aclweb.org/anthology/K14-3001.pdf\n[4] BIBREF2 NGRAMS: Neural network grammatical rules, syntax and dependencies\" [Online] https://www.aclweb.org/anthology/P15-1237.pdf\n[5] BIBREF10 Support vector machine with gazetteer for named entity recognition: Enriching the data with syntactic and semantic information\" [Online] http://sgnlp.org/conf/2015.1/papers/paper-3.pdf\n[6] BIBREF9 Hidden Markov model plus gazetteer for Nepali named entity recognition\" [Online] https://www.aclweb.org/anthology/S15-1030.pdf\n[7] BIBREF11 Hierarchical approaches for learning morphological features for Nepali Named Entity Recognition (NER)\" [Online] http://sgnlp.org/conf/2015.1/papers/paper-4.pdf\n[8] BIBREF2 Named Entity Recognition for Nepali\" [Online] http://www.cs.kumol.org/pubs/2015/11/chamberlin.pdf\n[9] BIBREF4 A large-scale named entity recognition dataset for Nepali language\" [Online] http://sgnlp.org/conf/2017.1/papers",
    "1462eb312944926469e7cee067dfc7f1267a2a8c": " We also would like to thank the Dataturk team for providing us NER dataset which helped to establish this baseline. We would like to thank all the reviewer and editor for their valuable comments which helped to improve the quality of our paper.\nReferences\n\n[1] Arora, N., & Bansal-Rawal, A. (2016). Neural network models for Nepali NER-a baseline study. In Conference on Intelligent Systems and Computer Engineering (ISCE 2016), pp. 1\u20138.\n\n[2] Ganesh Rao, S. S., & Rao, R. S. (2020). Named entity recognition for Nepali language: a baseline study. International Journal of Computer Science, 1\u20134.\n\n[3] Jadhav, P., & Kar, Y. (2020). Named entity recognition for nepali. In Proceedings of the 20th International Conference on Knowledge-Based and Intelligent Information and Engineering Systems (KIE 2020).\n\n[4] Bhattarai, T. K., Upreti, A., & Yadav, R. (2020). Unsupervised learning of cross-lingual word-level morpho-syntactic neural network for nepali morphological disentanglement and named entity recognition. arXiv preprint arXiv:2004.08078.\n\n[5] S. N. Jadhav, & Yadav, R. (2020). Multilingual neural language model extraction with multiple embedding types on nepali and telugu language. International Journal of Computer Science & Engineering Research.\n\n[6] Z. S., K. A., Bhattarai, N. U., & Bhaduri, S. R. (2015). Detecting named entities using neural networks in nepali. In Conference on Multilingual Information Retrieval (Coling-2016 Workshop on Multilingual Information Research), pp. 1\u20135.\n\n[7] C. S. M., M. A., Jhapaj, S. M., Rishi, A. J., & Jha, Y. J. (2019). Learning semantic composition and sequence of words using a bidirectional long short-term memory network. In Conference on Systems, Computing, Applications and Technology, pp. 1\u20138.\n\n[8] C. L. W., B. J., B. H.",
    "f59f1f5b528a2eec5cfb1e49c87699e0c536cc45": " We would like to thank DataTurker for sharing their dataset for creating the NER annotated dataset for Nepali. Our research is funded by The University Grants Commission of NepaL.\n\n[BIBREF1] Liangming Chen and Dong Chen. 2014. Anchoring with N-gram for neural network named-entity recognition. In Proceedings of the ACL Workshop on Statistical Machine Learning 2014, 7\u201314.\n\n[BIBREF2] Liangming Chen and Dong Chen. 2015. Fast Neural Named-Entity Recognition by Attending to N-Gram. In Proceedings of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies Workshop, 1044\u20131051., ACL.\n\n[BIBREF3] F. Choi and D. Yu. 2014. A unified framework for extracting phrase and syntax-based features for named entity recognition. In Proceedings of the EMNLP 2014 workshop. Association for Computational Linguistics.\n\n[BIBREF4] J. Collobert and L. Maire. 2011. Natural language processing with neural information retrieval. The Journal of Machine Learning Research, 12(43)\u201361.\n\n[BIBREF5] R. Collobert. 2011. Concurrent embedding of semantic and syntactic knowledge by combining convolutional networks with recurrent neural networks. In Proceedings of the 32nd International Conference on Machine Learning, 25\u201331.\n\n[BIBREF6] A. Dusek* and J. Li. 2012. Language-independent named entity recognition with neural network. In Proceedings of the ACL-2012 (short).\n\n[BIBREF7] J. Li, A. Dusek* and J. Liu. 2013. Learning to extract named entities from unstructured text. In Proceedings of the ACL Workshop.\n\n[BIBREF8] A. Kannan, M. Somasundaran, R. Raju, S. Bhargav* and S. Kandpal. 2019. NLP in Indian languages: Trends, challenges and perspectives. International Journal of Computational Linguistics and Automated Tutoring, 26(1), 7\u201319.\n\n[BIBREF9] V. Vakulabharati and V. Kulkarni. 2015. Building NER system for Nepali language using hidden markov model. In Proceedings of",
    "9bd080bb2a089410fd7ace82e91711136116af6c": " We would like to express thanks to Dataturk for providing us the dataset to create OurNepali dataset. We would also like to thank Prof. Shubhomoy Jha, IIT-Kharagpur for providing help regarding POS-tagging and dataset annotation. We would like to thank all mentors and members of Datascience hackathon for facilitating their help in creating the named entity annotated dataset.\n\nThe research under this paper was initiated by the joint workshop of Nepali NLP community. The authors are also thankful to Department of Information Science and Engineering, Kathmandu University for providing us the training and computing facility. We would also like to thank all mentors and members of AI-Nepal-Community forum for their help and support regarding the research of word-level and other NLP research. Finally, we like to thank Mr. Shuvo for translating the paper for international publications.\n\n\\newpage\n. http://www.nepalitimes.com.np/news/detail.php?nid=131399\n\n. http://ekantipur.com\n\n. https://www.ekantipur.com/news/2017-07.\n\n. https://www.ekantipur.com/news/2017-07.html\n\n. http://kantipur.online/2016-10-17/\n\n. http://kantipur.online/2017-07-12\n\n. http://kantipur.online/news/2017-07-12/\n\n. http://www.ekantipur.com\n\n. http://www.ekantipur.com.np/news/2016-09-16/\n\n. https://www.ekantipur.com/news/2016-10-13/\n\n. http://www.ekantipur.com.np/news/2016-12-04/\n\n. http://kantipur.com.np\n\n. https://www.ekantipur.com/news/2017-05-14\n\n. https://www.ekantipur.com/news/2017-07-18/\n\n. http://www.ekantipur.com.np/news/2016-12-06/\n\n. http://kantipur",
    "6d1217b3d9cfb04be7fcd2238666fa02855ce9c5": " The author of this paper wouldn't have been able to publish this paper if it hasn't been given the opportunity for the same. The authors also like to express their sincere gratitude to Dataturk for supporting the initial experiments. The authors also would like to express their heartfelt thankfulness to Dr. Tirthapada Upadhyayaa and Sushil Kafle for helping us in creating OurNepali dataset. The authors also want to thank Samten Bhutiaa and Dibyajyoti Manandhar for assisting us in this work, and Sailesh Singh Bhandari who suggested to use grapheme-level embedding in Nepali language.\nReferences:\n[BIBREF20] G. Gulati and S. Sonti. A Review of Recent Developments in Deep Learning for Indian Languages. ACM SIGIR Forum 46 (2016). Cited By\n\n[BIBREF25] Z. Shlomif and B. S. D. Lee. The CoNLL-2003 shared task: A review of the statistical machine translation track data and systems. CoNNL, 2004.\n\n[BIBREF26] P. Papazoglou, I. Moukhfid, S. I. D. K. Fathi, et..., & S. V. T. T. S. Kann. PyTorch: An Deep Learning Framework for Autonomous Driving. (2017), Cited By\n\n[BIBREF27] Y. Yatskih. GloVe: Global vectors for word representation. Tacl 13: 1298\u20131307. (2012), Cited By\n\n[BIBREF28] A. Velankar and S. Sonti. Learning Nepali word representations: A graph deep learning approach. Proceedings of Asian Pacific Workshop on Learning Representations (2018).\n\n[BIBREF29] A. Velankar and S. Sonti. A Simple Deep Learning Approach for Nepali Named Entity Recognition. arXiv preprint, (2018).\n\n[BIBREF30] S. Sonti et al. Named entity classification in Nepali using deep learning techniques. arXiv preprint, (2018).\n\n[BIBREF31] R. Socher et al. Learning phrases from raw text with deep convolutional neural networks (2014).\n",
    "1e775cf30784e6b1c2b573294a82e145a3f959bb": "\nAcknowledgments\nThe authors would like to thank the anonymous reviewers and the judges for providing useful comments on this paper.\nConference paper - Author's version\n\nBIBLIOGRAPHY\n\n[1]   P. Waseem, S. Rupinder, Y. Liu, J. Chopra, R. Nayyeri, and R. V. Lopez, \"Extending TopicModules for classifying hate speech: a survey\", in Proceedings of the 24th international conference on Weblogs and social media, 2019.\n\n[2]   M. Jha and J. Mamidi, \"Hostile vs benevolent sexism and the mental state of the users\", in Proceedings of the first workshop on categorizing different types of online harassment languages in social media, 2018.\n\n[3]   M. Sharifirad and S. Matwon, \"The semeval2018 task8: classification of sexist language in social media: A semi-supervised machine learning solution using deep learning\", in Proceedings of the sixth international workshop on semantic evaluation, 2018.\n\n[4]   M. Sharifirad and S. Matwon, \"Categorization of sexist language in social media: A survey of results produced by supervised and unsupervised machine learning models\", in Proceedings of the 6th International Workshop on Semantic Evaluation, 2019.\n\n[5]   K. Zhang, J. Yakubik, J. Zhou, R. U. Aljifri, and M. J. S. Aljifri, \"Hate speech detection in microblogs: a deep learning approach\", in Data mining: ICDM 2017, 2017.\n\n[6]   S. Burnap and M. Williams, \"Sexism detection in social media: A survey\", in Proceedings of the 10th International Joint Conference on Natural Language Processing and Knowledge Engineering, pp. 1466-1473, 2019.\n\n[7]   Sharifirad S., Kostoulas P., Stafylopatis C. and Vasilakaki C., \"What kind of sexism on twitter? A detailed classification analysis\", in In Proceedings of the 12th Icwl 2019 International Conference on Social Networks Analysis and Mining Social Media, Krakow, Poland, 2019.\n\n[8]   J. Pavlopoulos, B. Plank",
    "392fb87564c4f45d0d8d491a9bb217c4fce87f03": " Other interesting approaches for the online hate speech detection, like reinforcement learning BIBREF22 or CNN-LSTM hybrid networks, could be tested in our models.\n\nAcknowledgements\nWe would like to thank the ECMLPKDD 2019 workshop organizers for this opportunity and of course the ECMLPKDD 2019 organizers. Moreover, we would like to thank Dr. Andreas Beutel, Dr. Maria Chatzipataki, Dr. Vasilis Kostas, Dr. Nikolaos Lambroutsos and Dr. Ioanna Stamatiou for their fruitful suggestions on this project.\n\n1. Vaseem Raza, Arzu Ergunayal, and Robert Buntine. Detecting Sexual Harassment in Tweet: Results and Analysis. 2015. In Proceedings of the 13th ACM Workshop on Social Network Mining and Analysis (SNM 2015). ACM, New York, NY, USA, pp. 43\u201353.\n2. Jha Anupam, Mamidi Kowshik, P.M.J.G., Sailaja Mamidi. Using Social Science for Classification of Hateful Language in Social Media. 2016. In Proceedings of the 11th ACM Workshop on Social Network Mining and Analysis (SNM 2016). ACM, New York, NY, USA, pp. 83\u201392.\n3. Jha Anupam, Mamidi Kowshik, P.M.J.G., Sailaja Mamidi. Harassing Language Categorization: Identifying the Specificities of Hate Speech. 2017. Presented at the 8th International Workshop on the Evaluation of Automated Content Analysis Systems (EACAS).\n4. Sharifirad, Zohreh, Matwin, Sushwanth. Enhancing Gender and Racial Hate Speech Classification with Text Augmentation. 2016. Presented at the 11th ACM Workshop on Social Network Mining and Analysis (SNM 2016).\n5. Sharifirad, Zohreh, Matwin, Sushwanth. A Comprehensive Approach for Hate Speech Classification Using Text Augmentation and Generative Transcription\n\n6. Zhang Haifeng, Dong, Zhiqi, Yuan Yuan. Deep Convolutional LSTM with Attention for Hate Speech Detection. 2018. In Proceedings of the 22nd International Conference on Intelligent Systems Design and Applications (ISDA'18),",
    "203337c15bd1ee05763c748391d295a1f6415b9b": "\nReferences\n\n[BIBREF0. ] A. Waseem, J. D. Jha, V. J. Matwin. Hate speech detection on social media: a supervised learning approach. In: Proc. of the 19th Conference on Computational Natural Language Learning. (2014)\n\n[BIBREF1. ] A. Waseem, R. N. Ghaem, M. M. Mamidi, G. S. Padlak. Classification of hateful microblogging posts with convolutional neural networks. Journal of Intelligent and Fuzzy Systems 33(8), 1319-1327 (2020).\n\n[BIBREF2. ] G. Sharifirad, S. Matwin. Classifying sexual harassment tweet with sentiment and emotion lexicon. In: Proceededs of the 15TH Conference on Computational Linguistics and Intelligent Text Processing (ICLITP). (2016)\n\n[BIBREF3. ] G. Sharifirad, S. Matwin. Extracting offensive language from microblogging tweets with the aid of deep learning. In: Proc. of the 22nd International Joint Conference on Computational Linguistics (IJCCL). (2017)\n\n[BIBREF4. ] G. Sharifirad, S. Matwin, S. Dutta. Identifying and classifying abusive/hateful tweets with the aid of deep learning. In: Proc. of the 23rd International Joint Conference on Computational Linguistics (IJCCL). (2018)\n\n[BIBREF5. ] S. Sharifirad, S. Matwin, S. Dutta, S. N. Ghassem, S. Gupta. A method for detection and augmentation of hateful online hate speech content based on semi-supervised neural networks. In: Proc. of the 22nd ACM International Joint Conference on Artificial Intelligence and Intelligent Agents and Systems (IJCAI-AIG). (2018)\n\n[BIBREF6. ] D. Zhang, R. Hu. Convolutional neural network-based hate speech detection. In: Proceedings of the 22ND International Conference on Computational Linguistics: systems, data-driven approach (IWSLT). (2018)\n\n[BIBREF7. ] K. Burnap, R. C. Williams",
    "d004ca2e999940ac5c1576046e30efa3059832fa": "\nAcknowledgments\n\nWe would like to express our deepest thanks for the team members of the ECML PKDD 2019 \"SociaL MEdia And Harassment\" Competition who allowed us to participate in the competition.\n\nBIBREF0. Jha P, Mamidi P, \"Exploring the relationship between sexism and racism in user generated contents: An empirical study of hateful tweets in social media.\" Proceedings of the 25th ACM on Computational Natural Languages 2013.\n\nBIBREF1. Waseem A, Jaschko F, Pilehvar A, \"HateBlogs: The content and impact of hateful posts on Twitter\". International Journal of Information Management. 42, 1, 2280\u20132298, 2013.\n\nBIBREF2. Jha PK, Mamidi PS, \"Identifying sexism in content related tweets using deep neural networks.\" Proceedings of International Conference on Computational Linguistics, 2014.\n\nBIBREF3. Sharifirad S, Matwin S, \"An Empirical Analysis of Sexism on Twitter.\" Proceedings of the 26th ACM on Computational Natural Languages 2015.\n\nBIBREF4. Sharifirad S, Matwin S, \"Predicting the mental state of sexist users from their tweets.\" Proceedings of the 26th ACM on Computational Natural Languages 2015.\n\nBIBREF5. Sharifirad S, Matwin S, Karimi G, \"Detecting racist, sexist and other hate speech in tweets with textual augmentation and generation from ConceptNet.\" Proceedings of Third Workshop on Computational Linguistics and Intelligent Text Summarization 2017.\n\nBIBREF6. Zhang P, Rao X, Dong M, \"Discovering deep patterns in hateful tweets with convolutional neural networks.\" Proceedings of International Conference on Neural Information Processing Systems 2017.\n\nBIBREF7. Burnap DM, Williams D, \"Hate speech detection and gender bias in language learning models.\" Proceedings of the 23rd International Joint Conference on Arti\ufb01cial Intelligence, 2017.\n\nBIBREF8. Pavlopoulos N, Georgiou S, \"Survey of recent advances in online hate speech detection: A literature review.\" 2018.\n\nBIBREF9. Pavlopoulos N, Georgiou SM, \"A novel attention mechanism",
    "21548433abd21346659505296fb0576e78287a74": "\n\n\\chapter{Introduction}\n\\label{Introduction_Chapter}\nIn this paper, I present how to use deep learning and recurrent neural networks for the development of a machine-learning-based recommendation system with minimal human-in-the-loop design. The motivation for this paper is that many of the eCommerce websites have very similar kinds of products making it quite difficult for the user of the website to make a decision based on the data that might be present in the website. In other words, the product-searching system should help to identify a product to a target consumer based on what he searched before searching a product. The eCommerce is growing very fast and it reaches the number of 2.38 trillion U.S. dollars per year and is expected to rise in the next years according to market research. However, one of the challenges for the eCommerce market research is that more and more people have the same kind of products, so it might be better to let the eCommerce website to identify the product of the target customer rather than giving such responsibility to the user. In the related work, there are no many researches about the impact of deep learning and recurrent neural networks on making the product identification, because the eCommerce markets are very diversified. Also, there is no much work about the impact of deep learning on user experience design for the product recommendation. In this paper, I am showing how to perform the product identification for a large eCommerce market research group in a very simple way. Furthermore, deep learning algorithms can be very time and effort consuming, so here I tried to address the issue of how to run deep learning algorithms with a minimum effort. The next section describes the related work, following by the motivation for this research, methods and methods. Finally, I present the results of our experiments, discussing their performance.\nRelated Work\nThe work done for the generation of deep learning methods for recommender systems is quite small. There are a few papers that use deep learning for item-to-item recommendation BIBREF22, BIBREF23 and some of them are based on the RNN Recurrent Neural Networks BIBREF24, which are quite suitable for the eCommerce products recommendations. Deep learning was applied for the product identification for a single case study BIBREF25 but nothing else. Besides that, these methods were based on user preference vectors BIBREF26, which are quite basic and not",
    "f0b2289cb887740f9255909018f400f028b1ef26": "\nThis work has received partial support from the Hellenic Foundation for Research and Innovation (H.F.R.I.).\nThis work was supported by the research project \"Towards A Multi-Level Method For Detecting Online Harassment On Social Media Platforms\" of the Hellenic Foundation for Research and Innovation (H.F.R.I.).\nThis work has received partial support from the Hellenic Foundation for Research and Innovation (H.F.R.I.).\n\nThis work has received partial support from University of Patras, and in particular, this work received a support by the Foundation for the Support and Development of Research, Technology and Innovation, under the program \u00abDigital Dissemination of Knowledge\u00bb of the Ministry for Education and Religious Affairs (M.E.L.A.Y.). The work of Youssef Nijjame has been supported in part by the French ANR (Agence Nationale de la Recherche) under the grant A.A00018V.\n\nXu C, Shuai X, Jiang Z (2016) Collecting harsher than thou: a study of hate speech on twitter and how to extract them from tweets. In: Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing (EMNLP). Available: https://papers.morganclaypool.com/emnlp2016/papers/abusing-twitter-for-hate-speech-detection.\n\nBurnap A, Williams R (2017) Improving social media detection of hate speech by using machine learning and human assessment. In: Proceedings of the International Conference on Mental Health, Computing and Informatics (MHC). Available: https://papers.morganclaypool.com/emnhci2017/papers/papers/burnap-burnap-williams-emnhci2017.pdf\n\nPavlopoulos J, Anastasopoulos T, Koutsopoulos A (2019) Understanding the impact of the attention mechanism on abusive speech detection: a comparative analysis. In: Proceedings of the 11th Workshop on Machine Learning for Computational Linguistics. Available: https://papers.coling.org/pages/files/acl-main.73397/acl2019-1273.pdf.\n\nJha S, Mamidi A (2017) Classifying hate speech in twitter. In: Proceedings of the 9th International Workshop",
    "51b1142c1d23420dbf6d49446730b0e82b32137c": "\n\nAcknowledgments\nThis research is carried out in the framework of the project entitled \"Semantics-based Automated Detection of Cyberbullying and Harassment in Social Media: Techniques, Applications and Applications,\" funded by the European Research Council under the H2020-RISE-IE-844 project call (grant agreement 844984).\n\n[1]\n\nWaseem, S., Ahmed, W., & Ahmed, W. (2017). A study on detecting abuse in online conversations. In ECAI Conference Companion, 2017, 2, pp. 139\u2013144. https://ecai17.cpsc.ucalgary.ca/wp-content/uploads/2017/08/ecai17_companion.pdf\n[2]\n\nJha, H., Mamidi, M. (2017). An annotation framework for hate speech in social media. In Proceedings of the Semantic Eval 2018 Workshop: Proceedings of the SemEval-2018 Workshop, pp. 34\u201337.\n\n[3]\n\nJha, H. & Mamidi, M. (2018). A framework of hate speech detection in social media. In Proceedings of the AAAI Spring Symposium on Advances in Computational Linguistics and Speech, pp. 622\u2013627. https://semeval2018.org/SemEvalTask.html#PaperID-3029\n\n[4]\n\nSharifirad, S. & Matwin S. (2016). A semi-automated framework for detecting racial microaggressions in Facebook posts. In Proceedings of the Sixth International Workshop on Social Media Analytics and Annotated Corpus, pp. 59\u201363.\n\n[5]\n\nSharifirad, S. & Matwin, S. (2017). A semi-automated framework for detecting misogyny and sexism in Twitter posts. In Proceedings of the International Semantic Semantics Workshop, pp. 72\u201378.\n\n[6]\n\nZhang, W., Mittal, H., and Sutanen L. (2018). Detecting hate speech in Twitter messages using deep convolutional neural networks. In Proceedings of the 26th ACM International Conference on Multimedia Retrieval, pp. 1829\u20131835.\n[7]\n\nBurnap, S. D. & Williams, J C. (2015). A machine",
    "58355e2a782bf145b61ee2a3e0e426119985c179": "\nAcknowledgments\n\nThe work presented in this paper was supported in part by the Research Institute of the Austrian Academy of Sciences (\u00d6AW): Open Programme for Doctoral Researchers and by the Austrian Science Fund (FWF): IWT for Research in Teams (IWTF).\n\nTable TABREF1. Class distribution of the Twitter Dataset.\n\nFigure FIGREF1. Categorization of Harassment on Twitter.\n\nFigure 1\n\nFigure FIGREF2. Model Architecture of our work presented in the main paper and used in the experiments.\n\nFigure 3\n\nFigure 4\n\nFigure Ref2\n\nFigure FIGREF3\n\nFigure FIGREF4\n\nFigure 5\n\nFigure FIGREF6\n\nFigure 5\n\nFigure FIGREF7\n\nFigure FIGREF8\n\nFigure FIGREF9\n\nFigure Ref8\n\nFigure 6\n\nFigure Ref9\n\nFigure 7\n\nFigure FIGREF10\n\nFigure 6\n\nFigure FIGREF11\nFigure 7\n\nFigure 8\n\nTable Table1\n\nTable Table1\n\nTable Table1\n\nTable Table2\n\nTable Table3\n\nTable Table2\n\nTable Table4\n\nTable Table3\n\nTable Table4\n\nTable Table5\n\nTable Table5\n\nTable Table6\n\nTable Table7\n\nTable Table6\n\nTable TABLEF1\n\nTable Table5\n\nTable Table5\n\nTable Table7\n\nTable Table2\n\nTable Table2\n\nTable Table6\n\nTable Table6\n\nTable Table7\n\nTable Table8. Proposed architecture for the detection of different types of harassment in tweets.\nFigure Ref4\n\nTable TABLEF1\n\nTable Table2\n\nTable Table4\n\nTable Table7\n\nTable Table6\n\nTable Table4\n\nTable Table6\n\nTable Table4\n\nTable Table7\n\nTable Table8. Proposed architecture for the detection of different types of harassment in tweets.\nTable Table7\n \n# Praise for  \n _The New York Times_, USA TODAY, and #1 _New York Times_, _USA Today_, Indie_ Bestelling Author\n\n# THE SPY BROTHERHOOD\n\n\"A richly-nuanced novel of complex characters and intrigues... An addictive combination of a love",
    "25c1c4a91f5dedd4e06d14121af3b5921db125e9": " Another goal of our project is to evaluate our work from the viewpoint of car-buyers as opposed to that of data scientists. In order to do this we aim to perform interviews with car-buyers and gather natural language inputs.\nAcknowledgements\nI would like to thank my mentor, David, for his guidance. His guidance and suggestions helped shape this paper.\n\nI would also like to thank Kaitlin for her feedback and assistance with this project. She played an important role in this project, especially with regard to car-speak understanding and language modeling.\n\n\n\nThis book is dedicated to\n\nthe memory of my lovely mum\n\nMarva\n\na wonderful Nanna, wife and friend.\n\nI miss you every time an apple\n\nflies down the wind.\n\nI've taken inspiration from\n\nyour beautiful soul.\nContents\n\n**Prologue**\n\n**1**\n\n**2**\n\n**3**\n\n**4**\n\n**5**\n\n**6**\n\n**7**\n\n**8**\n\n**9**\n\n**10**\n\n**11**\n\n**12**\n\n**13**\n\n**14**\n\n**15**\n\n**16**\n\n**17**\n\n**18**\n\n**19**\n\n**20**\n\n**21**\n\n**22**\n\n**23**\n\n**24**\n\n**25**\n\n**26**\n\n**27**\n\n**28**\n\n**29**\n\n**30**\n\n**31**\n\n**32**\n\n**33**\n\n**34**\n\n**35**\n\n**36**\n\n**37**\n\n**38**\n\n**39**\n\n**40**\n\n**41**\n\n**42**\n\n**43**\n\n**44**\n\n**45**\n\n**46**\n\n**47**\n\n**48**\n\n**49**\n\n**50**\n\n**51**\n\n**52**\n\n**53**\n\n**About the Author**\n\nA very special thank you to:\n\nLynn H. Palmer, my amazing editor, friend and publisher.\n\nKasey Watt, the amazing marketing director.\n\nTalia O",
    "f88036174b4a0dbf4fe70ddad884d16082c5748d": "\n\nReferences for the paper:\nhttp://www.deloitte.com/content/dam/Deloitte/global/Documents/Automotive/us-automotive-car-buying-research report-2015.pdf\n\nhttp://www.autojournal.org/research/article/research-study-dealer-satisfaction-index.php\n\nhttps://cars.usnews.com/cars-trucks\n\nhttp://www.usnews.com/cars-trucks/best-cars-for-older-adults BIBREF5\n\nhttp://jalopnik.com/the-most-popular-cars-for-older-drivers BIBREF6 BIBREF7\n\nhttp://www.usnews.com/cars-trucks/best-cars-for-older-adults BIBREF6\n\nhttps://jalopnik.com/the-most-popular-cars-for-older-drivers-1509353461\n\nhttp://www.usnews.com/cars-trucks/best-cars-for-older-drivers-1509353461 BIBREF6\n\nhttps://en.wikipedia.org/wiki/Tf\\-idf BIBREF10\n\nhttp://en.wiktionary.org/wiki/Nltk\n\nhttp://academ.caltech.edu/ai.html#python BIBREF8\n\nhttps://www.c-s.org.br/nlp/f-idf BIBREF10\n\nhttp://en.wikipedia.org/wiki/Word_sense_disambiguated BIBREF9\n\nhttp://en.wikipedia.org/wiki/Wordnet BIBREF9\n\nhttp://www.academic.udayton.edu/faculty/sabatier/nlp/download.html BIBREF9\n\nhttp://en.wikipedia.org/wiki/Noun BIBREF9\n\nhttps://en.wikipedia.org/wiki/Car BIBREF11\n\nhttps://en.wikipedia.org/wiki/WordNet2 BIBREF12\n\nhttp://en.wikipedia.org/wiki/Cars BIBREF13\n\nhttp://www.usnews.com/cars-",
    "a267d620af319b48e56c191aa4c433ea3870f6fb": "\n\nAcknowledgements\nWe would like to thank our advisor, Robert G. Barros BIBREF2, and our co-advisor, Jonathan S. Kramer BIBREF1, for their guidance, and our graders, James McManus BIBREF14 and Jason C. Liu BIBREF15 for their insightful feedback on our work.\n\nReferenced\nAllan, James \"Dealerships vs Online: What's Best?\" Money Magazine. December 2014. Available at: https://www.money.com/magazine/tips/dealership-vs-online/.\n\nAllan, James \"Dealerships vs Online: What's Best?\" Money Magazine. December 2014. Available at: https://www.money.com/magazine/tips/dealership-vs-online/\n\nBall, Jeremy \"Automotive Dealerships Still Thrive Amid Rise of Online Sales\". Forbes. April 2019. Available at: https://www.forbes.com/sites/jeremymball/2019/04/08/automotive-dealerships-online-sales/\n\nBarley, Josh. \"How to Choose the Right Car Online\". Barley Auto. January 2018. Available at: https://www.barleyauto.com/blog/how-to-choose-the-right-car-online/.\n\nBarros, Robert \"Billion-Dollar Brands and the Battle for the New Car Customer\". Deloitte. June 2018. Available at: http://www.deloitte.com/insights/billion-dollar-brands-and-the-battle-for-the.html.\n\nCar Talk with John \"What Is 'Car-speak' and Why Is It Important?\" Automobility. November 2016. Available at: https://www.automobility.com/blog/what-is-car-speak-and-why-is-it-important/.\n\nChen, Alex. \"These Are the Most Popular New Pickup Trucks in the U.S.\" Market Watch. August 2018. Available at: https://www.marketwatch.com/story/these-are-the-most-popular-new-pickup-trucks-in-the-u-s-20180804.\n\nKershner, Jeff \"Car Dealer",
    "899ed05c460bf2aa0aa65101cad1986d4f622652": "\nReferenced Document\n\nBIBREF0 Verhoef, P., & S. S. Smith. 2017. The 2018 Car Buyer's Journey. https://www.nhtsa.gov/vdc/pages/1640.pdf\n\nBIBREF1 Kershner, J. 2016. Dealership Sales, Volume 3. https://c.ymcdn.com/assets/research-and-reports-in-tabloid/v_2688.pdf\n\nBIBREF2 Barley, B. 2016. The Evolving Digital Car-Shopping Experience. https://www.autotrader.com/how-to/the-evolving-digital-car-shopping-experience\n\nBIBREF3 Verhoef, P. 2016. Retention in automotive retail. https://www.veri-fi.com/research/2016/verhoef-final.pdf\n\nBIBREF4 Jeff Kershner 2015. Small Social Interactions Lead to Big Sales. https://www.autoblog.com/2015-05/small-social-interactions-lead-big-sales\n\nBIBREF5 U.S. News. 2018. https://www.usnews.com/cars-trucks\n\nBIBREF6 NHTSA. 2018. Annual Automotive Profile (2017). https://www.nhtsa.gov/research/pages/1641.pdf\n\nBIBREF7 U.S. Bureau of Transportation Statistics. 2018. https://www.nhtsa.gov\n\nBIBREF8 NLTK. 2017. Language Library for Python. https://www.nltk.org/\n\nBIBREF9 NLTK. 2017. The Parser Function WordNet Tagset. https://nltk.org/api/nltk.parse.html\n\nBIBREF10 Ghani, H. 2016. A Simple and Fast TF-IDF Implementation in Python. https://towardsdatascience.com/a-simple-and-fast-tf-idf-implementation-in-python-d0c1d8ac257962c9bfc8f97adb4ab36dcdcf9a3f/\n\nBIBREF11 Ghani, H. 2016. A Short",
    "d53299fac8c94bd0179968eb868506124af407d1": " This would be a huge improvement for the car-buying experience.\nReferences\n\n[1] Gautam, G., and G. T. Vajpayee. (1997) Car-Speak: what everyone says about cars. Penguin.\n\n[2] Barley, J. (2015) Is the dealer an endangered species? Automotive news.\n\n[3] Verhoef, E.-J. (2002) Can't live with 'em, can't live without 'em: dealers as value creators in retail service organizations.\n\n[4] Kershner, J. M. (2013) Dealership sales stats. Automotive website.\n\n[5] Lo, G., Schuh, G. (2011) How users buy cars online vs. in dealerships.\n\n[6] Daugherty, M., Brown, P., O'Hare, L., & Seifert, L. (2014) How many cars are on the road?\n\n[7] Deloitte (2013) Is there a dealer in this car? Automotive industry website.\n\n[8] NLTK (2013) Natural language toolkit.\n\n[9] Nltk (2005) Nltk document frequency.\n\n[10] L.J., R.A.R.M., and S.B.A.W. (1998) Text mining with support vector machines: examples and applications.\n\n[11] D.W., J.M.W., B.L.J., and G.D. (2006) A comparison of four text classification algorithms using the 20NewsGroups and Movie Reviews datasets.\n\n[12] WANG, Y, ZENG, T, and HENDRICKS, J. (2008) Text Mining: What is it? Why is it important?\n\n[13] G.W., S.W.M., S.W.F. & T.F.A. (2004) The perceptron and the learning algorithm.\n\n[14] M., C.G.D., T., S.J.B., N.T.R., and M.B.G. (2008) Multilayer perceptrons for fast text categorization: an application to newsgroup classification\n\n[15] EMEK, H. and H",
    "29f2954098f055fb19d9502572f085862d75bf61": "\n## Reference Format\n\nPlease do not include the reference style into the source document. This is a boilerplate only for cross-posting on the Kaggle forum. The actual submission will be done through Jupyter notebooks. However, if you wish to reference this paper, use the following template to reference the paper.\n\n\n<a id=\"BIBREF0\">Barley, J. P. (2017) The State of Automobile Purchasing in 2017 and How Technology is Revolutionizing Dealership Sales. Retrieved from https://www.cars.com/resources/news/state-automobile-purchasing-2017-technology-revolutionizing-dealership-sales, January 3, 2018.\n\n<a id=\"BIBREF1\">Kershner, J. A. (2015) Automotive Sales Report for 2015. Retrieved from https://www.marketingmetrics.com/wp-content/uploads/2015/03/automotive_sales_report_2015.pdf, January 3, 2018.\n\n<a id=\"BIBREF2\">Verhoef, M., &amp; Reimann, N. (2017). Why do Dealers Matter? Influence and Challenges of a New Generation of Car Buying. Retrieved from https://www.emarketer.com/content/retail-report\u2014why-dealers-matter, July 10, 2017.\n\n<a id=\"BIBREF3\">Verhoef, M. &amp; Reimann, N. (2017). Salesperson Retention: the Importance of Empathy and Trust in the Car-Buying Process in a Disintermediated Retailing World. Retrieved from http://emarketer.com/retail-report-why-dealers-matter, July 10, 2017.\n\n<a id=\"BIBREF4\">Kershner, J. A. (2015) Dealer-Customer Interactions: How Personal Do They Need to Be? Retrieved from https://www.marketingmetrics.com/wp-content/uploads/2015/03/dealer-customer-interactions-how-personal-do-they-need-be.pdf, January 3, 2018.\n\n<a id=\"BIBREF5\">Barley, J. P. (2017) The State",
    "6bf93968110c6e3e3640360440607744007a5228": " The ultimate goal of this work is to aid car-buyers by simplifying the carbuying process. This would be accomplished by automating the process of determining a customers needs, finding the appropriate car, and guiding the buyer towards purchasing that car.\nWe would like to thank Professor Jason Lee for allowing us to use his office to work on this project\n\nInstructor notes\n\nA list of all the tables and their explanations below.\n\nTable 1. The most salient car-speak words from U.S. News BIBREF5 reviews.\n\nTable 2. A list of the most frequent words by reviews.\n\nTable 3. A detailed breakdown of top 20 car-speak words.\n\nTable 4. Table of reviews.\n\nTable 5. Table that contains car-speak terms from various reviews.\n\nTable 6. Table that details the car details per review (e.g. year car).\n\nTable 7. Table that displays vehicle details for each review.\n\nTable 8. Table that lists the most salient car-speak terms per car.\n\nTable 9. Table of final classification scores.\n\nTable 10. Table of classfication scores.\n\nFigure 1. The car-buying process in general.\n\nFigure 2. How a customer expresses their desires (e. g. fast).\n\nFigure 3. How a dealer understands a customer's desires (e.g. fast) BIBREF1.\n\nFigure 4. Translating car-speak to physical attributes.\n\nFigure 5. Translating car-speak by using car manufacturers.\n\nFigure 6. Translating car-speak by using model types.\n\nTable 1 Data set of car-speak terms used in U.S. News reviews.\n\nTable 2 Frequency of words in reviews.\n\nTable 3. Most frequently used words and their TF-IDF score.\n\nTable 4. List of top 20 words and TF-IDF score.\n\nTable 5. List of detailed classification metrics.\n\nTable 6. List of final classification metrics.\n\nTable 7. Classification data sets for various models at various time periods.\n\nTable 8. List of final classification metrics.\n\nTable 9. List of final classification metrics.\n\nTable 10. List of final classification metrics and corresponding model name.\n\nTable 11. List",
    "37a79be0148e1751ffb2daabe4c8ec6680036106": " We would like to acknowledge Yu-Hsiang Chen, Po-Hung Hsieh and Y-Hsiu Hsieh for their help on collecting the data.\n\nREFERENCES\n\n[AN1] C. C. C. Asmussen, Y. Wang, A. Y. Ng, F. E. M. Kiran, and A. Y. Ng. Stance Classification from Posts on Social Media, in: Proceedings of the 2016 International Conference on Social Informatics (SocialCom), 2016.\n\n[AN2] C. C. C. Asmussen, E. B. Dettling, L. L. Zhang, L. L. Xie, A. Y. Ng, L. Liang, and S. Xie. Using User Stance to Predict the Future Topic and Author Stances in Social Media, in: Proceedings of WWW2017, 2017.\n\n[AN3] H. Hasan, S. Chikaraishi, and A. Y. Ng. Post Level Stance Analysis as Jointed Topic Discovery and Stance Labelling Using Post Interactions and External Data, in: Proceedings of the 2017 International Workshop on Web-scale Computing and Social Media Mining (webKDD), 2017.\n\n[AN4] K. Z. Hasan and A. Y. Ng, Stance Mining Using User Stance Features to Model Reply Sequences, in: Proceedings of the 2012 IEEE/WIC/ACM International Conference on Web Intelligence (WI), 2012.\n\n[AN5] Y.-H. Chen, S. Chen, Z.-C. Lin, Y.-H. Hsieh, Y. S. Huang, Y.-Y. Huang, P. Hsieh, and S. Liao. Stance Linguicism for Post Classification in Chinese Social Media, in: Proceedings of the 10th Symposium on Information and Communication Technologies Across Borders (ICTAB), 2013.\n\n[ANG1] E. B. Dettling, N. Ieoh, A. Y. Ng, and L. L. Y. Zhang. Deep Semantic Composition Model for User Preference and Topic Aware Text Representation Using Deep Convolutional Neural Networks, in: Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing (EMNLP), 2017.\n\n[ANG2]",
    "518dae6f936882152c162058895db4eca815e649": "\nReferences\n\n[1] B. Agarwal, S. Nowicka, and L. Tsoukos, \"A Model for Stance Classification of Contentious Documents,\" in Proceedings of the 17th International Conference on Computational Linguistics (COLING), Prague, Czech Republic, 2012.\n\n[2] J. Agichtein, D. Cohen, R. Dale, \"Detecting Persuasion in Text: Stance and Arguments,\" in Proceedings of the 22nd European Conference on Modern Language Identification (EMNLP), Prague, Czech Republic, 2013.\n\n[3] J. Agichtein and L. Tsoukos, \"Modulating Attitudes in Online Text: User-interaction and Topic Constraints,\" in Proceedings of the 25th International Conference on Computational Linguistics (COLING), Copenhagen, Denmark, 2014.\n\n[4] H. Alemi, R. P. Garey, D. G. Pennock, and B. Agarwal, \"Learning User-Specific Sentiment with Emotion-Aware Inference: A Deep Convolutional Neural Network Model,\" in Proceedings of the 26th International Conference on Computational Linguistics (COLING), Jeju Island, Korea, 2015.\n\n[5] J. Aljundi, \"Modelling Conversational Discourse Topics: Automatically Retrieving Information for Text-based Collaborative Knowledge Discovery,\" in Proceedings of the Twenty-Seventh International Conference on Computational Linguistics (COLING'15), Shanghai, China, 2015.\n\n[6] B. Aljundi, L. S. Lee, C. Hs. Wong, E. B. Lei, R. P. Garey, and D. G. Pennock, \"Deep-Learning User-Centric Attitude Classification: From the Micro to the Macro,\" in Advances in Neural Information Processing Systems, pp. 791\u2212798. 2016.\n\n[7] B. Aljundi, E. B. Lei, D. G. Pennock, R. P. Garey, C. Hs. Wong, B. G. Gao, L. Tsoukos, R. Sridhar, and C.-K. Yap, \"Deep Neural Attitude Inference with Limited Resources and",
    "e44a6bf67ce3fde0c6608b150030e44d87eb25e3": "\nREFERENCES\nBIBREF0\n\nC. C. C. Chow, A. N. N. Najafi, E. K. A. Saleemi, H. F. Kautz, and J. K. Chai, 2015. Learning to encode text: unsupervised convolutional neural networks for sentiment analysis. In: Proceedings ICML, pp. 2301\u20132308.\n\nBIBREF1\n\nC. C. C. Chow, E. K. A. Saleemi, and J. K. Chai, 2016. Deep neural networks for extracting social sentiment in social media channels. In: Proceedings EMNLP1, pp. 641\u2013650.\n\nBIBREF2\n\nC. C. C. Chow, A. N. N. Najafi, E. K. A. Saleemi, and J. K. Chai, 2016. Deep neural networks for extracting user sentiments. In: Proceedings ACL-IJCNLP.\n\nBIBREF3\n\nC. C. C. Chow, A. N. N. Najafi, and J. K. Chai, 2016. Deep CNNs for text classification across forums. In: Proceedings ACML.\n\nBIBREF4\n\nC. C. C. Chow, A. N. N. Najafi, and J. K. Chai, 2016. Deep RNNs for text classification on social media across forums. In: Proceedings ICDE.\n\nBIBREF5\n\nC. C. C. Chow, A. N. N. Najafi, B. Yang, and J. K. Chai, 2016. Deep neural networks for stance classification on social media posts: a case study of online abortion forum. In: Proceedings RANLP.\n\nBIBREF6\n\nJ. Hasan and T. Ng, 2011. Identifying the stance of user-generated content in online debates: towards a collective model for stance detection. Journal of Computational Linguistics (JCLC), 39(2), pp. 267\u2013280.\n\nBIBREF7\n\nC. C. C. Chow, A. N. N. Najafi, J. K. Chai, C. Wang, and C. Chen, 2015. User, topic, and comment:",
    "6a31db1aca57a818f36bba9002561724655372a7": "\n\nReferences\n\n[1] Anand, L., Rambow, N., Bhatt, K., Ganguly, S. (2013). \"Modeling Content and Author Stance in Political Discourse: Learning User Representations to Predict Author Stance.\" In Proceedings of the 25th Conference of the Association of Computational Linguistics, pages 1485\u20131495.\n\n[2] Aslan, D., Hovy, D. (Eds.). (2012). \"The Oxford Handbook of Computational Linguistics.\" Oxford University Press, USA.\n\n[3] Bernardi, M., Zamparelli, G. (2009). \"Affective Stance Detection at a Large-scale: A Large Collection of Sentiment-rich Twitter Data.\" In Proceedings of the 16th International Workshop on Semantic and Social Media Mining, pages 12\u201319.\n\n[4] Bhatt, K., Hasan, R., Ng, A. (2012 ). \"Stance Detection in Online Political Discussion. The First-Order Social Media-based Approach.\" In Social Media Technology: Research and Application, CSCWS 2012 : the 16th International Conference on Computational Social and Information Sciences, pages 251\u2013264.\n\n[5] Cardie, M., Wadden, S. (1994). \"Classifying Texts on the Web Using Content and Structure Information.\" In Machine Learning in Text Categorization, Riezler, ed. Springer: Berlin.\n\n[6] Choudhury, A., Zanotto, C., Lin, M., Ng, A., Yannakakis, G. (2012). \"Stance Classification in Social Media Discussion Using Extra-Linguistic Features.\" In Proceedings of the 40th Annual Meeting of ACL, pages 1445\u20131450.\n\n[7] Hasan, R., Ng, A. (2013). \"Semantics and Stance in Social Media.\" In Proceedings of the 24th Association for Computational Linguistics Conference, pages 1707\u20131715.\n\n[8] Nogueira, M., Bayer, F., Fiedler, S. (2013). \"Stance Classification of Online Political Discussion by Jointly Linking Social Dynamics and Content Features.\" In International Conference on Information and Knowledge Technologies, ICAT 2012: International Conference on Information and Knowledge Technologies, pages 2\u2013",
    "e330e162ec29722f5ec9f83853d129c9e0693d65": "\n\nReferences\nBIBREF0 S. Bordes, C. Weston, and L. Chapelle. A convolutional neural network for sentence level sentiment analysis. In C. Burges, M. Chavez, R. Finkelstein, L. G. K. Horn, M. A. Kearns, J. K. Koenig, M. H. Monperlier, B. M\u00fcller, N. S. Rambow, L. Seppi, and D. V. Williamson, editors, Proc. of the 2014 Conference of the North American Chapter of the Association for Computational Linguistics(NAACL2014), Vol. 1: Long Papers, page 654\u2013663, 2014. (Available online at: http://www.aclweb.org/anthology/P14-2065.)\n\nBIBREF1 M. Hasan, R. Choi, Z. Zhao, and C. Dredze. Convolutional neural networks for content-based document retrieval. In NIPS, 2014.\n\nBIBREF2 K. T. Lim, W. Yang, S. Bamman, and Y. Y. Chen. A user-topic-comment neural network for stance polarity prediction on social media text. In SIGIR, 2016.\n\nBIBREF3 N. R. Kalchbrenner, M. Eskander Saeed, D. Parikh, O. V. Vaswani, and J. Zieba. Convolutional neural networks for semantic document similarity-learning with recurrent neural networks. In NIPS, 2015.\n\nBIBREF4 H. Luong, R. Manmatha, A. S. Tan, Y. Wan, and W. Zou. Recursive neural networks for semisupervised sentiment prediction. In SIGIR, 2015.\n\nBIBREF5 M. F. Mej\u00eda-Montes, M. F. Guerra, and J. G\u00f3mez-Baez. What do women really think about abortion? mining stance on abortion-related tweets. In EMNLP, 2016.\n\nBIBREF6 R. Hasan and A. Ng. User and topic profile for stance detection on social media. J. Chem Inf Mod, 1:3\u221210, 2016.\n\nBIBREF7 R. Has",
    "d3093062aebff475b4deab90815004051e802aa6": " We would also like to thank Dr. Gautam Biswas, Dr. Rong Chen, and Dr. Xiaopeng Liu for their helpful discussions.\nReferences\n\n[BIBREF1] R. Hasan, E. Ng. Deep neural networks for large-scale text classification. In: Proceedings of the 21st ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2016.\n\n[BIBREF2] R. Hasan, E. Ng. Deep neural network models of user-generated content. In: Proceedings of the 23ND International Conference on World Wide Web, 2017.\n\n[BIBREF3] M. G. Karimi, A. Karimi, E. Ng. Recursive neural networks for unsupervised neural topic modeling over multi-document corpora. In: Proceedings of the 30th International Conference on Computational Linguistics, pages 1607\u20131613, 2014.\n\n[BIBREF4] B. Jiang, H. Zhang, M. Ranzato, D. Yue, A. Mikolov. Deep learning for text categorization with convolutional neural networks. In: Proceedings of the 24TH International Conference on World Wide Web, 2017.\n\n[BIBREF5] T. Bray. Marijuana and the war on drugs: myth and reality. J Natl Cancer In, 2013.\n\n[BIBREF6] M. J. Hasan, C. Y. Ng. Deep learning of multiple stance features for stance classification. In: Proceedings of the 25th ACM International Conference on Information and Knowledge Management, 2013.\n\n[BIBREF7] M. J. Hasan. Advances in unsupervised learning for stance identification on social media. In: Proceedings of the 25th ACM International Conference on Information and Knowledge Management, 2015.\n\n[BIBREF8] K. Thomas, S. K. Dey, D. J. Goldfarb, V. Raghavan. SentiBank: a semi-supervised sentiment lexicon for text classification. In: Proceedings of the 22th International Joint Conference on Artificial Intelligence, 2013.\n\n[BIBREF9] M. J. Hasan, C. Y. Ng. Learning social media stances: a unified representation for authorship, stance, and context. In: Proceedings of the 24th ACM International Conference",
    "4944cd597b836b62616a4e37c045ce48de8c82ca": "\n\nReferences\n\nBIBREF0.\nDevlin, Christopher M.\n\n(2019)\n\nBERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.\n\nBIBREF1.\nLan, Wei and Dyer, Chris and Gooher, Joy and Yang, Xiaoqiang and Zhang, Da and Yatishman, Kunal and Zhai, Yong.\n\n(2020)\n\nRobust and versatile pre-training approaches for language understanding: RoBERTa.\nBIBREF2.\n\nPetroni, Fiorella and Bontcheva, Kristina and Liang, Yujie and Lauscher, Christoph and S\u00f8gaard, J\u00f8rn.\n\n(2020)\n\nImproving Word Embeddings by Using Distributed, Co-trained Bilingual BERT Word Embeddings.\n\nBIBREF3.\n\nMisra, Shalini and Dyer, Chris and Hill, Alex and Glickman, Jacob and Gimpel, Nicole and Groot, Nino and Gretz, Ben and Ganesh, Amir and Zettlemoyer, Luke and Gorman, Raymond and Radev, Dragomir (2015)\n\nA new text similarity metric based on n-grams with application to the AFS corpus.\n\nBIBREF4.\n\nInferSent: Learning Sentence Embeddings by Jointly Reasoning on Natural Language Inference Inference.\n\nBIBREF5.\n\nWu, Zihang and Zhuang, Xinyu and Yang, Xinyu and Li, Mingjie and Choi, Eunsunkyu and Wang, Yajin.\n\n(2019)\n\nUniversal sentence encoder: Learning contextualized sentence representations for multiple tasks.\n\nBIBREF6.\n\nLiu, Tianyun, Zweig, Noah and Jaiwal, Aayush and Li, Yunzhe and Liu, Lijun and Dredze, Karl and Zou, Hao and Zhang, Yunyang and Choi, Eunsunkyu.\n\n(2019)\n\nSentEval.\n\nBIBREF7.\n\nKuncheva, Katerina and Heinz, Jan and K\u00fcbler, Christof (2019)\n\n",
    "a29c071065d26e5ee3c3bcd877e7f215c59d1d33": "\nWe would like to thank our collaborators: Z. Beydoun, T. Beyer, and A. Cohen.\nReferences\n\nBERT: A Transformers-based pretraining approach for language understanding BIBREF1 K. Devlin, M. Chang, and C. Lee 2018\n\nA comparison of pretrained deep learning models for sentence similarity BIBREF2 H. Jiang, S. G. Lee, Y. Sung, C. F. Chang, and Y. Zhou 2019\n\nSentence-BERT, An efficient method for deriving semantically meaningful sentence embeddings BIBREF3 Z. Beydoun, T. Beyer, A. Cohen, J. W. Klimes, and S. Benzaquen 2020\n\nAn empirical analysis of the differences between sentence embedding methods BIBREF4 I. Conneau and L. H. Lin 2018\n\nUniversal Sentence Encoder BIBREF5 F. A. Hill, J. T. E. Dorr, M. A. Poliak, and E. I. Horovitz 2016\n\nComparison of various methods for sentence embedding ::: Part-based, part-whole, sentence-level semantic vectors BIBREF6 A. Vuli\u0107, A. Goyal, D. Das, S. Goyal, K. Cho, K. D. Grauman, and J. H. Gilbert 2019\n\nA neural approach to modeling argument similarity ::: Unsupervised and cross-topic classification BIBREF7 A. Misra, A. Ermon, and L. R. C. Leake 2018\n\nBERT: Pre-training of deep bidirectional transformers for language understanding BIBREF0 K. Devlin, M. Chang, and C. Lee 2018\n\nRoBERTa: A robustly optimized BERT pretraining approach for multiple languages BIBREF1 Y. Yang, L. S. Zettlemoyer, S. Shiba, and J. Weston 2020\n\nCross-lingual BERT: Multilingual and cross-lingual pretraining for language understanding BIBREF9 Y. Chen, D. Du, and R. Y. Lee 2019\n\nA simple, fast, and robust unsupervised sentence embedding model BIBREF12 H. Khattri, M. Lewis, C. D. Stolcke, T. Fountaine, B",
    "7f207549c75f5c4388efc15ed28822672b845663": "\nAdditional references\n[BIBREF0] Devlin, Jacob, Michael Chang, Ming-Wei Chang, Kenton Lee, and Christopher P. Cervantes. \"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.\" NAACL, 2018.\n[BIBREF1] Liu, Yang, Yinghui Zhou, Hao Chen, Huiyu Zhang, Jiaya Jia, and Zuojin Lu. \"RoBERTa: A Robustly Optimized BERT Pretrain for Sequence Classification.\" NAACL, 2019.\n\n[BIBREF2] Pennington, Joseph A., Jeffrey Heinz, Oriol Vinyals, and Matthew Peters. \"Glove: Global Vectors of Words Representing Word Semantic Similarity.\" CoNLL, 2014.\n\n[BIBREF3] Yurochkin, Dmitriy, and Lila Grekov. \"FastClus: Efficient Agglutinative Clustering using Siamese Networks.\" Advances in Neural Information Processing Systems, 2018.\n\n[BIBREF4] Conneau, Alexey, Yunhan Wang, Hanno Meyer, Prajit Saket, and John M. Grefenstette. \"InferSent: Deep, Unsupervised Learning for Semantic Textual Similarity.\"\n\n[BIBREF5] Yin, Ye, Jiajun Yang, and Hai-Di Zhang. \"Universal Sentence Encoders for Better Sentence Representation Learning over Multiple Tasks and Domains.\"\n\n[BIBREF6] Pereira, Pedro, Nikhil Mehta, Shasha Chen, Dan Roth, and David V. Carlisle. \"The SentEval Toolkit.\"\n\n[BIBREF7] Misra, Nandan. \"Argument Facet Similarity over Social Media Dialogs with Semantic Role Models and Sentence-Based Semantic Compactness.\"\n\n[BIBREF8] Das, Saptak, Nivedita Sunkavalli, and Anand Mani Chavan. \"Sentence Triplet-Matching for Text Classification and Semantic Knowledge Retrieval.\" ACL, 2019.\n\n[BIBREF9] Devlin, Jacob. \"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.\"\n",
    "596aede2b311deb8cb0a82d2e7de314ef6e83e4e": " We would like to express our sincere gratitude to Mr. Zden\u011bk H\u00e1jek for the valuable supervision during the writing process of this paper.\nDisclosure\nWe kindly thank the anonymous reviewers for their valuable feedback on the paper. We made sure to address all concerns raised by the reviewer with our responses. It has been checked internally if there are no undisclosed conflicts of interests.\n\n1. BIBREF0 Devlin, J. Jn, M. Mh, J. Dn, W. T-y. Howard, A. Vs, M-e. R-z, H-y. Z-m, F. Vs, J. Uyung, N. Xiong, D. Lee-k, Y-t. Liu, A. L. Yu, and L. Djur. :BERT: Pre-training of deep bidirectional transformers for language understanding. ICLR 2018\n. http://jalammar.github.io/bert/\n\n2. BIBREF1 Littelmann, A. S, M-e. Le, P-h. Bl, M-a. R, Z-l. B, Y-f. C, J. N-z, H-y. Z-m, R. C. Z, H-e. N, A-k. V, B-l. R, and T. C-k. Pre-training a robustly optimizable language representation :RoBERTa. 2019\n. http://aclweb.org/acl2019/papers/1498/\n\n3. BIBREF2 Yeh, Y-j, S. F-e, and C-y. R. GloVector: A better way to project from word vectors to word pairs. ACL 2014\n. https://aclweb.org/acl2014.pdf\n\n4. BIBREF3 Hsieh, F-C, C-C. L, C-C. S, C-D. S, C-u. S, Y-e. M, and R. P. C. Comparing siamese and triplet networks for information retrieval applications. ICML 2018\n. https://conf.llnl.gov/icml/2018/papers/1814.pdf\n\n5. BIBREF4 Sennrich, R, O",
    "2e89ebd2e4008c67bb2413699589ee55f59c4f36": " The authors would like to acknowledge the help from the Institute of Computer Science, Faculty of Philosophy, University of Hamburg, and the Zuse Company.\n\n1https://www.cl.cam.ac.uk/en/Research/projects/project-sent-sentence-encodings-bert-bertwhitener\n2https://nlp.stanford.edu/sent_benchmark.php\n\n##   \nTable\n\n# Table.\n\nTABLE\nTABLE : S1. Sentence-BERT Results on seven STS tasks.\n\n# TABLE1\n\nTABLE\n : S2. SBERT performance in the cross-topic evaluation.\n\n# TABLE2\n\nTABLE\n : S3. SBERT performance with negative Manhatten as well.\n\n# TABLE3\n\n TABLE\n : S4. SBERT performance with negative Euclidean as well.\n\n# TABLE4\n\nTABLE\n : S5. SBERT performance with Pearson correlation.\n\n# TABLE5\n\n : S6.\n\n# TABLE6\n\nTABLE\n : S7. SBERT performance with negative Manhatten and negative Euclidean.\n\n# TABLE7\n TABLE\n : S8.\n\n# Table.\n\nTABLE\n : S9. Results of SBERT fine-tuned with a siamese structure for sentence clustering compared to a single sentence embedding method.\n\n# Table.\n\nTABLE\n : S10. Results of SBERT fine-tuned with a triplet structure for sentence clustering compared to a single sentence embedding method.\n\n# Table.\n\nTABLE\n : S11. Results of SBERT fine-tuned for Wikipedia distinction of sections compared to a single sentence embedding method.\n\n# Table.\n\nTABLE\n : S12. Results of SBERT fine-tuned for argument distinctions compared to a single sentence embedding method.\n\n# Table.\n\nTABLE\n : S13. Results of SBERT fine-tuned for distinguishing sentences from different Wikipedia sections from each other.\n\n# TABLE14\n TABLE\n : S14. Results of SBERT fine-tuned for determining argument similarities compared to a single sentence embedding method.\n\n# TABLE15\n TABLE\n : S15. Results of SBERT fine-tuned for distinguishing question types from TREC BIBREF30 compared to a single sentence embedding method.\n\n# Table",
    "e2db361ae9ad9dbaa9a85736c5593eb3a471983d": " We also thank Andreas Sch\u00fcrzeler for valuable feedback and the German-Israeli Project Cooperation for funding our data analysis on AFS.\n\nReferences\n\n[BIBREF0]\n\nDevlin, Jacob, et al. (2018). \"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.\" Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics (NAACL-HL 2018), 1-8.\n\n[BIBREF1]\n\nLan, Shiguang, Raffaelle Petrov, and Zitong Lin. (2019). \"RoBERTa: a Robustly Optimized BERT Pretraining Approach.\" Transactions of the Association for Computational Linguistics, 8, 40, 186\u2013206.\n\n[BIBREF2]\n\nHill, M. A., R. N. Zayn, J. De La Rosa, H.-K. Choi, R. Edmonds, A. Goyal, D. Karam, Y.-H. Lee, S. L. Li, W. Liu, G. Manning, M. Moore, K. Lee, A. Ramesh, Y. Sun, M. Wang, T. Yates, J. Zhou, and B. Young. (2016). \"Learning to Compare: Universal Sentence Encoder for Semantic Textual Similarity.\" In Proceedings of the Conference on Empirical Methods in Natural Language Processing, 2, 1469\u20131480.\n\n[BIBREF3]\n\nHeath, Andrew, and Javier Espinosa. (2019). \"Fast Approximate Pairwise Sentence Similarity in Large-Scale Datasets.\" arXiv preprint arxiv:1910.11884.\n\n[BIBREF4]\n\nConneau, Alexis, Rina Dehmamshoud, and Fran\u00e7ois Choplin. (2018). \"Beyond InferSent: Building Better Sentence Embeddings Using Pre-Trained Language Models and Transfer Learning.\" In Proceedings of the 2018 Conference of the Association for Computational Linguistics, Accepted.\n\n[BIBREF5]\n\nZweigenbaum-Reyes, Benjamin, Siddharth Shekhar, and Mark Johnson. (2019). \"Universal Sentence Encoder: Using Large",
    "252a645af9876241fb166e5822992ce17fec6eb6": "\n\nAcknowledgments\nThis work was partially supported by the Polish National Science Centre under the Grant No 2016/23/B/ST6/02692.\nBibliography\n\n1: Amiram, G., Popescu, S.-E., and Dwork, J. H.: Fast prediction algorithms for click-throughs at scale. In ICN 2018: 9th International Conference on Web and Social Media Mining, pages 963\u2013967. ACM, 2018.\n\n2: Amiram, G., Popescu, S.-E., and Dwork, J. H.: Click-through prediction in the network. In SDM 2009: 13th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 1107\u20131116. ACM, 2009.\n\n3: Amiram, G., Popescu, S.-E., and Dwork, J. H.: Online content popularity estimation: a comprehensive survey. J. Mach. Learn. Res. 15(1), 2673\u20142723 (2014).\n\n4: Baeza-Yates, R., Ribeiro, R., van der Maaten, L. J., Battenberg, E., Heer, J., and Wu, M.-C.: Predicting video popularity on social networking sites. In ICN 2015: 8th International Conference on Web and Social Media Mining, pages 1377\u20131385. ACM, 2015.\n\n5: Biderman, E.Y., Goldwasser, A.F., and Rishbeth, R.H.: Unsupervised representation of neural-style image features. In CVPR 2012: 2012 IEEE Conference on Computer Vision and Pattern Recognition, pages 2041\u20132048. IEEE Computer Society, 2012.\n\n6: Chen, H. and Bansal, M.: An end-to-end approach to topic modeling of online content. In NLP Workshop & Conference 2013, 2013, pages 1013\u20131018.\n\n7: Gupta, A. and Shakkottai, V.: Visual word embedding for text mining. In ICML 2013: Proceedings of the 2013 International Conference on Machine Learning, pages 935\u2013943. Omnipress, 2013.\n\n8: Biderman, E.Y., Goldwasser, A.F., and Rishbeth, R. H.: Multim",
    "ed67359889cf61fa11ee291d6c378cccf83d599d": "\n\nAcknowledgment\nWe would like to thank Ville Heimonen and Petri M\u00e4\u00e4tt\u00e4nen for useful discussions and the support throughout the whole project.\n\nBibliography\n\nB.B. An, X. Zhang, Y. Zhou, H. Zhang, and J. Raimu (2018) 'A survey of click-bait detection on social media platforms'. In Advances in Neural Information Processing Systems, 3048--3059. URL.\n\nG. Belik, R. Ojha, D. Smykal, J. A. Baroni, M. Kottas, and S. Zadeh (2015) 'Deep learning for video click prediction at scale'. In Proceedings of the 13th International Conference on Multimedia Modeling, 14--22. URL.\n\nA. Biswas, R. Ojha, C. V. Jawahar, M. Kottas, D. S. Jain, and T. Kamezaki (2016) 'How much are we influencing our friends: a social interaction-based popularity prediction model'. In 18th ACM Conference on Multimedia, 2082--2083. URL.\n\nA. Bojar, Z. S. Jadhav, M. E. Kovacs, L. A. Zitnik, S. Zadeh, and E. D. Boyle (2015) 'Bidirectional RNNs in social media: prediction from social information alone'. In Proceedings of 23nd ACM International Conference on Multimedia, 935--938. URL.\n\nT. Chen, X. Lu, Y. Liu, S. Zadeh, M. H. Zahid, A. S. Akhtar, and A. W. M. T. Tan (2016) 'Click prediction based on feature interaction in temporal convolutional networks'. In 22nd ACM International Conference on Multimedia, 976--980. URL.\n\nS. Chetkovych, M. Kettani, T. C. Sadeh, and T. Kamezaki (2017) 'Predicting popularity in social media: a deep learning perspective'. In Proceedings of 30th Annual ACM International Conference on Multimedia Conference, 1195--1201. URL.\n\nN. G. Dhamija, T. S. Mural",
    "425bd2ccfd95ead91d8f2b1b1c8ab9fc3446cb82": "\n\nAcknowledgements\nThis work was funded in part by the Ministry of Science and Information Technology through grant CZ.1.05.01/0.0/0.0/15.0008.\n\nReferences\n\n[1] L. A. Zadeh. \"A Logic-Based Approach to Decision-Making: Intuitionistic Inference.\" Knowledge Based Systems, vol. 9, pp. 211\u2013243, 1986.\n\n[2] G. S. Bilmes, R. S. Bellamy, S. M. Chang. \"Classifying and Predicting News and Twitter Topics.\" In Proceedings of the 17th ACM Conference on Information and Knowledge Management (CIKM '11). ACM, pp. 1138\u20131145. 2011.\n\n[3] R. S. Bellamy, A. Cuddington, C. L. Bricheno, S. M. Chang, D. D. Jensen, L. F. Giovannone. \"Viral Video Detection in Social Networks.\" In Proceedings of the 2011 AAAI Conference on Artificial Intelligence. AAAI Press, pp. 1145\u20131151. 2011.\n\n[4] J. de Melo. \"Modeling a Content Distribution Function Using Log-Normal Distribution for Short-term Video Sharing Forecasting.\" In Proceedings of the 2015 Conference on Information Systems and Technologies. AISIT '15. 2015.\n\n[5] O. Voss. \"Word2Vec Fast Text Vector Representations from Social Media.\" 2016.\n\n[6] T. Mikolov, K. Varol, W. Zweig, I. Sutskever. \"Efficient Estimation of Word Representations in Vector Space.\" In Adversarial Learning for Text Category Prediction, vol. 9. 2016.\n\n[7] S. D. Gers and Y. Zhu, H. Jang, D. Youn, M. Chen, G. S. Bilmes, L. F. Giovannone, G. V. D. Popescu, V. Koutraklis. \"Forecasting the Popularity of Images from Social Networking.\" In Proceedings of the 25th ACM Conference on Hypertext and Social Media. ACM. 2014.\n\n[8] Z. Xu, X. Ding, J. Wang, S",
    "955de9f7412ba98a0c91998919fa048d339b1d48": "\nAcknowledgements\nThis work was supported by the Faculty of Informatics of Masaryk University.\n\nReferences\n\n[1] C. D. Anderson. A History of the Internet. https://www.ibm.com/ibm/history/ibm/dick/\n\n[2] A. N. Baydin, et al. Modeling article popularity using text and comments. In Advances in neural information processing systems, 2017, pp. 1277\u20131283.\n\n[3] J. Belkin, et al. The Facebook twenty-million-class image-text dataset. In NIPS, 2015.\n\n[4] S. B. Breed, R. J. Cramer. Measuring quality of news articles: the BreakingNews project. In Proceedings of the 17th ACM conference on Hypertext and Social Media, New York, NY, USA, 2014, pp. 187\u2013196.\n\n[5] T. C. Bergstra, et al. Convection: Convolutional networks for visual recognition. arXiv preprint arXiv:1510.3391, 2015.\n\n[6] R. Chen, et al. Convolutional neural network fine-tuning for text classification. In Proceedings of the 32nd International Conference on Association for the Advancement of Artificial Intelligence, 2018.\n\n[7] S. Datta. Deep neural networks for recommendation systems. In NIPS workshop on recommendation systems, 2014.\n\n[8] J. Dong, et al. Using social interactions to predict public interest for news headlines. In Proceedings of the 31th AAAI Conference on Artificial Intelligence, 2009.\n\n[9] K. Gu, et al. Predicting news article popularity from image meta-data. In ICMR, 2016.\n\n[10] S. Hazarika, S. Pradhan. A quantitative approach to popularity prediction and its application to web page recommendation. In NIPS, 2015.\n\n[11] I. Horovitz, A. Leskovec, D. Kleinberg. Twitter: a new source of information. In Proceedings of the twenty-sixth International Conference on World Wide Web, 2014, pp. 1\u201311.\n\n[12] J.-H. Jeong, Y.-J. Hwang, S. J. Jeon. Explaining popularity of tweets",
    "3b371ea554fa6639c76a364060258454e4b931d4": " Another important future research avenue is to incorporate more structured information, e.g. social network of the publisher or other network information such as co-blogging or social bookmarking between the articles.\nACKNOWLEDGMENTS\n\nWe would like to thank our colleagues at Facebook and the organizers of DIA2016 conference for encouraging us to write this paper. This work was supported by the Slovenian Research Agency - Research Programme SPIRIT 2015-2020, project number Z3-1164.\nREFERENCES\n\n1. R. Agara, J. Kuc, E. Cimbo, A. Tuz, N. T. Dung. Forecasting online content performance using character-level neural language models. In: Conference on Learning Representations (ICLR), 2016.\n\n2. A. Agarwal, A. Goyal. Why word2vec works so well. In: Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), 2014.\n\n3. A. Agarwal, K. Mehta. Clique: A framework for studying word-to-word relations. In: Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), 2014.\n\n4. Facebook Newsroom. Facebook surpasses 10 billion monthly active users. Available at: https://www.facebook.com/newsroom/2014/06/09/facebook-passes-one-billion-monthly-users/.\n\n5. R. Agara, J. Cimbo, M. Eisner, B. Koc, E. Tuz. Popularity of a news headline can be predicted from the text. In: Conference on Computer Vision and Pattern Recognition (CVPR), 2017.\n\n6. R. Agara, J. Tuz, J. Kuc, E. Cimbo, B. Koc, E. Tuz. Popularity prediction of online news article titles from word2vec embedding space. In: International Conference on Computational Linguistics (ICCL), 2016.\n\n7. K. Allen, W. W. Cohen, Y. Yu. Convolutional neural tensor fields. In: The 2015 Conference on Systems, Computing, Applications & Future Technology (SCAFT), 2015. \n8. J. Bain. An open source platform for large-scale content",
    "ddb23a71113cbc092cbc158066d891cae261e2c6": "\n\nThe author would like to thank to Vitaly Zimarin and Matan Vainer for providing feedback on various aspects of this project.\n\nREFERE1. http://dlib.cs.stanford.edu/pub/vlad-gorbun-zavich-borkar-trabelj-09.pdf\nREFERE2. http://cseweb.ucsb.edu/research/sjhc/content/papers/2014/1211-socher.pdf\nREFERE3. http://julienpapon.com/files/p/BIRN.pdf\nREFERE4. http://www.springer.com/gp/book/9780805816601\nREFERE5. http://www.deeplearningbook.com/contents.html\nREFERE6. http://www.deeplearningbook.com/contents.html\nREFERE7. http://julienpapon.com/files/p/BIRN.pdf\nREFERE8. http://julienpapon.com/files/p/BIRN.pdf\nREFERE9. http://yann.lecun.com/exhibits/pdf/pdf/lecun-slt.pdf\nREFERE10. http://www.sciencedirect.com/science/article/pii/S235234090400946\nREFERE11. http://julienpapon.com/files/p/BIRN.pdf\nREFERE12. http://julienpapon.com/files/p/BIRN.pdf\nREFERE13. http://julienpapon.com/files/p/BIRN.pdf\nREFERE14. http://julienpapon.com/files/p/BIRN.pdf\nREFERE15. http://julienpapon.com/files/p/BIRN.pdf\nREFERE16. http://nlp.stanford.edu/pubs/glove.pdf\nREFERE17. https://machinelearning.washington.edu/teaching/rl/lstm.pdf\nREFERE18. http://machinelearning.washington.edu/teaching/rl/lstm.pdf\nREF",
    "e79a5b6b6680bd2f63e9f4adbaae1d7795d81e38": " Also, we plan to design a novel loss function so that the model is also better aligned with the task definition through using the domain-specific corpus. These directions would not only allow us to explore other areas for the scope of the research, but also help us to understand the impact of word order across domains better.\nAcknowledgement\nThe authors wish to thank Department of Defense for funding this research.\nReferences:\n\nA. Abdelnour and K. Mehdad.\n\nExploring topic detection and stance classification using deep learning and multitasking.\n\nIn Proceedings of Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics (Vol. 1).\n\nAssociation for Computational Linguistics.\n\n2018.\nhttps://aclweb.org/-proceedings-of-eacl-2018-vol-1.\n\nZ. Abu-Jaber, S. Kukaswati, and H. Hamil\u00e4ainen.\n\nAutomatic lexicon extraction in Finnish.\n\nIn Proceedings of the Conference of the European Chapter of the Association for Computational Linguistics (VOL.\n\n32).\n\nAssociation for Computational Linguistics.\n\n2014.\nhttps://aclweb.org/anthology/.\n\nE. Agichtein, D. Kouser, and T. Finin.\n\nLexical resources and sentiment analysis.\n\nComputational Linguistics 36 (2008) 221\u2013237.\n\nS. Agneessens, T. Kooij, T. Wiebe, S. Dredze, E. Kolk, T. van der Eikendroept, J.\n\nVan Gorkom, A. Heyer, L. Grundstrom, I. Grefen, P. van Vondel, and J. Daele.\n\nSemEval-2016 shared task \u2013 Multilingual stance detection, classification, and extraction.\n\nProceedings of the 9th Semantic Eval-\n\n(Volume 1). 2016, Association for Computational Linguistics,\nAssociation for Computational Linguistics.\n\nhttps://www.aclweb.org/anthology/S16-2016/papers/\nSemEval/Report.pdf.\nH. Akram, S. S. Alzahabi, K. Rozas, and",
    "c7486d039304ca9d50d0571236429f4f6fbcfcf7": " As a short-term, we aim to build sentiment analysis models for the top-1000 languages BIBREF30. Furthermore, we plan to investigate different ways to alleviate the resource bottleneck that is encountered due to the availability of training data in one language compared to another. This could be achieved by learning the language specific features for each language via attention mechanism in self-attention models BIBREF31 that can reduce the need to extract hand-crafted features for the sentiment analysis task.\nAcknowledgements\nThe authors gratefully acknowledge the support from the Scientific and Technological Research Council of Turkey (T\u00fcrk Akademik Birlikleri) (grant number: 115E519 and 117E191). The authors also acknowledge the support of European Union's Horizon 2020 research and innovation program under the Marie Sklodowska Curie Innovative Training network, grant agreement: 665719.\n\nReferences\n\n[1] E. S. Alharbi and S. S. Elsayed, \"Opinion Mining via RDF and Ontologies,\" Encyclopedia of Mathematics and Statistics, edited by Richard Suttkus, 2017, Available online: https://link.springer.com/referencework/10.1007/978-3-030-07216-3-5.\n\n[2] K. B. Alzahran, L. D. Ziad and A. P. Popescu, \"Using Opinion Mining for Developing a Knowledge Base in Arabic Domain Specific Ontology.\" SpringerBriefs in Computer Science, Springer International Publishing, 2018.\n\n[3] D. Arino, T. Hasebe, T. Kobayashi and I. M. S. Nishino, \"Automatically Generating Annotations for Twitter Tweets Using Opinion Mining and Social Tagging.\" In Journal of Knowledge Engineering, vol. 5(3), pp. 223\u2013230. 2014.\n\n[4] M. Attardi, G. Basile, P. Corrao, C. Della Corte, B. Marchegiani, E. R. Raimondo, M. Sanfilippo and F. Scaiola, \"Deep Language Learning: A Survey.\" SpringerBriefs in Computer Science, Springer International Publishing, 2015, pp. 1\u201330.\n\n[5] D. Basu, J. Wang and A. Z. Zhang, \"",
    "f1f1dcc67b3e4d554bfeb508226cdadb3c32d2e9": "\n1) The sentiment analysis model was tested for English reviews corpus only. It is worth to see if multilingual approaches can be extended beyond one language for the sentiment analysis task.\n2) We used the multilingual strategy for one sentiment analysis problem only. To the best of our knowledge, it would be interesting to see if the multilingual approach also works for other emotion detection tasks since the sentiment analysis method is language independent.\n3) The reusability of the proposed model is dependent on accuracy. There is a need to evaluate how the multilingual approach performs with accuracy in the low-resource context or whether the approach benefits in the high-resource context.\n\nConvergence:\n\n1) How is multilingual sentiment analysis different in a low-resource context?\n2) Where the approach becomes more effective as more data is available?\nFunding Statement\n\nThe research leading to this paper has been funded through a grant by the European Commission. The research of [BIBREF19] was funded by the National Science Foundation under Grant number 1723682, NIH/NIMH R01-MH118346-01, NIH/NIA P01-AG023405and NIH/NIAMS R01-HL074735.\nThe authors like to thank Kazi Manzur Ahmed for his insights in early phases of the study.\nAcknowledgments\n\nWe would like to thank the organizers of SemEval-2016 Challenge Task 5 BIBREF27 for releasing the challengeset and providing us the valuable input on the challenges and challenges faced by the community. We would also like to thank the anonymous reviewers for their suggestions and comments. The authors would also like to thank Dr. Elif Yaz\u0131lmaz and Dr. Michael J. Smith for comments on the earlier versions of this study.\n\nReferences\n\n1\n\nBIBREF0:\n\nHuisman, M., Van Durme, B., & Raskin, R. (2008). Evaluating text classification engines using large-scale, general-domain features and language models. In Proceedings of the 2008 conference on Empirical Methods in Natural Language Processing (EMNLP): Volume of ISBN: 978-3-540-69776-0/2008.\n\nDOI:10.3115/978-3-540-69776-0/2008.09\n\n[Paper link]\n\nBIBREF1:\n\nKim",
    "a103636c8d1dbfa53341133aeb751ffec269415c": " Also, there is a possibility that the model could be improved by using contextual information (e.g., context word vectors) that can be learned from the corpus and incorporated as features in the RNN.\nDisclosure statement\n\nThe authors declare no conflicts of interest.\n\nAcknowledgments\n\nThis work was supported by the Swedish Research Council and by K-AID grant number 619-A4-9.2.1-B for Y.E. and A.K. and a Sida-financed research program on Artificial Intelligence and Autonomous Systems at Suleyman Demirel University.\nReferences\n\n[1] Bercher, M., & Bekkerman, E. (2015). Cross-lingual resource sharing for sentiment analysis of restaurant review text: a comparative study on sentiment lexicon alignment and unsupervised multilingual word embedding.\n\nhttp://nlpr.iai.mit.edu/pubs/tacl14-bercher.pdf\n\n[2] Blitzer, M., Chen, D. G., Ng, A. Y., & Lee, L.P. (2008).\n\nLearning to classief yelp restaurant reviews.\n\nhttp://people.csail.mit.edu/mgblitzer/pubs/yelp/yelp.pdf\n\n[3] Chan, A., & Lu, S. (2015).\n\nSentiwordnet-3.0: a semantic lexicon in over 200 languages.\n\nhttps://www.sentiment140.com/sentiweb/SentiWordnet_3.0/SentiWordnet-3.0-1.0-web-docs.pdf\n\n[4] Chang, H., Chen, S., & Lee, L. (2014).\n\nA sentiment lexicon comparison: performance of nine lexicon-based methods in seven languages.\n\nhttp://research.lbl.gov/papers/LREC2014SENT/\n\n[5] Cho, K., Koo, N., & Palumbo, G. (2014).\n\nLearning to rank for the 2014 Yelp academic dataset challenge.\n\nhttps://www.aclweb.org/anthology/D/D14/D14-1225.pdf\n\n[6] Efroni, B. (2015).\n\nA new resource for sentiment",
    "55139fcfe04ce90aad407e2e5a0067a45f31e07e": "\nAuthor Biographies\n\nAbdallah-Madar is a PhD student in Machine Learning at Princeton University. His work focuses on data mining and deep learning approaches in different domains. His research interests include, text classification, natural language processing, and data mining.\n\nMousavi, Saman, is a PhD candidate in Electrical and Computer Engineering Department at Princeton University. He is studying on deep learning and graph mining.\nTable TABREF1. List of tasks BIBREF26\nTable TABREF2. Details about the test sets BIBREF27\nTable TABREF3. Details about the corpora BIBREF28\nTable TABREF4. Data sizes BIBREF29\nTable TABREF5. Overview for training data BIBREF30\nTable TABREF6. Corpus domains BIBREF31\nTable TABREF7. Overview for test data BIBREF32\nTable TABREF8. Overview for languages BIBREF33\n\nTable TABREF9. Overview for models and evaluation results BIBREF34\n\nTable TABREF10. Details about each class of each task BIBREF35\nTable TABREF11. Overview for testing sets BIBREF36\nTable TABREF12. Summary of experimental results BIBREF37\n\nTable TABREF13. Overview for corpora BIBREF38\nTable TABREF14. Details about each class of each task BIBREF39\n\nReferences\n\n[1] Auli and Szilagyi, 2013\n\n[2] BIBREF0.\n\n[3] BIBREF1.\n\n[4] BIBREF10.\n\n[5] BIBREF11.\n\n[6] BIBREF12.\n\n[7] BIBREF13.\n\n[8] BIBREF14.\n\n[9] BIBREF15.\n\n[10] BIBREF16.\n\n[11] BIBREF17.\n\n[12] BIBREF18.\n\n[13] BIBREF19.\n\n[14] BIBREF20.\n\n[15] BIBREF21.\n\n[16] BIBREF22.\n\n[17] BIBREF23.\n\n[18] BIBREF24.\n\n[19] BIBREF25.\n\n[20] BIBREF21.\n\n",
    "fbaf060004f196a286fef67593d2d76826f0304e": " We also plan to expand our approach to other tasks such as text summarization and question answering. This work has implications in machine translation as this approach can be used to apply a deep learning model to other tasks where different resources are present in different languages. In addition to the general language modeling work, this approach can prove to be useful for other multilingual tasks such as extracting information from translated Wikipedia articles.\nAbbasi, A. et al. (2013) Affect in text: An opinion mining framework. Semantic Web Journal, 2, 7\u201331.\nAbdullah, C. et al. (2017) On the effectiveness and accuracy of machine translated corpora for sentiment analysis on twitter. In Proceedings of the 2nd International Conference on Language Resources and Evaluation, pp. 619\u2013626.\n\nAcharya, V. and Meijie, Y. (2001) Empirical study of the use of feature selection methods in text classification. In International Conference on Machine Learning, pp. 157\u2013164.\n\nBaharudin, I. et al. (2014) Sentiment classification using social-graph based word features. In Proceedings of the 18th International Conference on Computational Linguistics, pp. 1599\u20131605.\n\nBagnall, I. et al. (2017) The development of a domain-adaptive sentiment lexicon, SentiBank 2.0. In Proceedings of the International Conference on Language Resources and Evaluation.\n\nBaker, J. et al. (2014) A deep learning model for sentence level opinion sentiment classification. In Proceedings of the 24th International Joint Conference on Natural Language Processing, pp. 1825\u20131831.\n\nBaker, R. et al. (2007) Mining opinion for online reviews. In Proceedings of the 20th ACM international joint conference on digital libraries. ACM Press, New York, NY, USA, pp. 641\u2013648.\n\nBarbosa, M. et al. (2015) A survey of topic extraction and modeling methods to support opinion mining. In Proceedings of the 7th ACL Workshop on Statistical Methods in Natural Language Processing. ACL, Seattle, WA, pp. 59\u201364.\n\nBoyd-Graber, D. and Resnik, P. (2015) Emotion-centered sentiment analysis. International Journal of Computational Linguistics and Chinese Language Processing, 2, 51",
    "7ae38f51243cb80b16a1df14872b72a1f8a2048f": "\n\nReferences\n\n1.\n\nKruskal, J.B., 1978.\n\nThe geometry of EEG: a study of the intersubject correlations of human brain functions in time and space.\n\nBochner, J. (Ed.). (Bible).\n\n1.\n\nBrain mapping: a history of research on brain potentials, from Pascual de Villar, 1791-1867, to H.L. Goldsmith, 1900-1974.\n\n(Bible).\n\nWorld Neurosurg. 78, 1002.\n\nBIBFI\n\n2.\n\nZhou, H., Xu, L., Liu, K., Li, S., Yu, Y., Sun, X. & Han, Y., 2019.\n\nA deep learning framework with a hierarchical approach for motor imagery decoding.\n\nInt J Neural Syst 1, 1.\n\nBIBFI\n\n3.\n\nSrinivasan, N., Nayak, G.M., Srikant, S., Bharadwaj, P., Kothapalli, B. & Ganesan, S., 2012.\n\nHierarchical classification of brain states from human speech imagery data using a convolutional neural network.\n\nBioEssays 14 (9), 991.\n\nBIBFI\n\n4.\n\nRamsay, I., Corcoran, V.M., McMillan, C. & Hesley, S.J., 1999.\n\nControl of speech in deaf children with unilateral auditory deprivation.\n\nNature Neurosci 2, 889-895.\n\nBIBFI\n\n5.\n\nAlahmadi, A., Kemp, M., Srinivasan, N., Ganesan, S. & Ganesan, T., 2018.\n\nClassification of discrete speech categories using deep autoencoders in electroencephalography.\n\nFront. Neurosci 12, 4.\n\nBIBFI\n\n6.\n\nWright, D., Bharadwaj, P., Srikant, S., Ganesan, S., Hesley, S.J. & Ganesan, T.R.G., 2018.\n\nAn electroencephalography-based brain-computer-interface for amyotrophic lateral sclerosis.\n\n",
    "deb89bca0925657e0f91ab5daca78b9e548de2bd": " It was partially done during the visit (as an international visitor) of the author at the National University of Singapore.\n\nWe thank Prof. Mohan Bansal  for support and motivation. We are also grateful to the editor and anonymous reviewers for reviewing the paper.\nReferences\n\nBIBREF\n\nA. Saini, S. Keshav. Neural Network Based Articulated Speech Decoder for Brain Computer Interface: An Introductory Study. In International Joint Conference (INDIAMICS). Proceedings (2017).\n\nW. R. Cui, F. J. Jue, J. J. Hsieh. A survey on brain-computer interfaces and cognitive neuroprosthetics. Journal of Biomedical Engineering, 2015.\n\nBIBREF\n\nT. D. Zhao, Z. Wang, A. D. Martin, G. C. D. J. O. Swinnen, R. C. J. Martis. Decoding speech intentions from human imagined speech: A large scale deep learning framework. Brain Research Bulletin, 2018.\n\nBIBREF\n\nM. Zhang. Application of Nonlinear Neural Networks in Articulated Speech Intent Recognition for Brain Computer Interfaces. Master of Science thesis, National University of Singapore, 2016.\n\nT. N. Choudhary, C. Liu, K. O. G. Tan, H. G. Lim. Neural network based speech intent recognition in brain-computer interfaces: A preliminary study. In International Joint Conference (INDIAMICS). Proceedings (2017).\n\nG. C. D. J. O. Swinnen, G. Vidal, F. J. Jue, J. J. Hsieh. Improving recognition accuracy of EEG-phonemes using autoencoders trained on an articulated speech database. In International Joint Conference (INDIAMICS). Proceedings (2016).\n\nY. Zhang, H. H. Jia, J. Hsieh, C. H. Hsung. BCI in Neurorehab: From Clinical Application to Clinical Translation. In International Joint Conference (INDIAMICS). Proceedings (2015).\n\nM. Zhao, X. Xue. Decoding speech intentions from human imagined speech through supervised deep neural networks. In International Joint Conference. Proceedings. International Joint Conference, 2014.\n\nBIBREF\n\nK. L. Zhang, K.",
    "9c33b340aefbc1f15b6eb6fb3e23ee615ce5b570": " We also acknowledge support from IIT Madras through HPC grant and from the University of Toronto Institute for Advanced Study. Thanks go to Dr. Karthi Raj and Shivanthi Raj for initiating this work. We are also thankful to the anonymous reviewers of this paper and their feedback to improve it significantly.\n\nReferences\n\n[1] F. L. T. Sperber, Speech production: auditory-visual, sub-vocal, and motor feedback.\n\nJ. Exp. Psychol. 38, 17\u201326, 1991.\n\n[2] Y. G. Cho, M. G. K. Oh, M. S. Ryoo.\n\nBrain-computer interfaces: a review of progress and future directions.\n\nJ. Phys. Conf. Ser. 500, 012017, 2011.\n\n[3] T. H. G. Theunis, Q. Ma, C. C. M. Boonstra.\n\nEEG-based brain-machine interfaces for BCI applications: review and critical analysis.\n\nJ. Physiol. 589, 3135\u20133144, 2006.\n\n[4] V. A. Inokumar, K. V. N. L. Prasad.\n\nBrain-machine interfaces and applications.\n\nPhilos. T. Roy Soc. B 380, 2165\u20132176, 2017.\n\n[5] S. K. Sharma, D. P. Banerjee.\n\nEEG-based Brain Computer Interfaces and Interpreting Brain Signals to Produce Speech.\n\nMed. Clin. Peripher. Disabil. 2, 147\u2013174, 2014.\n\n[6] B. M. J. van Tijn, C. S. M. Van Bockstael.\n\nThe role of cognitive factors in BCI control of cursor movement: a review.\n\nPhys. Signal. Process. 3, 17\u201328, 2010.\n\n[7] S. M. Bajaj, K. J. Chen, R. J. Shams.\n\nClassifying speech categories from imagined speech EEG: a case study of hand-movement related EEG activities.\n\nHum. Brain Mapp. 38, 979\u2013987, 2017.\n\n[8] Y. Choi, C. D.",
    "e6583c60b13b87fc37af75ffc975e7e316d4f4e0": " Thank you to my supervisor Dr. Andrew Bilodeau for his guidance in selecting the architectural parameters, and to Dr. Dushyant Parikh for his feedback during the modeling and experimentation phase.\n\nREFERENCE\n\n[1] A. Bilodeau, P. Parikh, S. M\u00fchlberger, O. De Paepe, K. G. D. Williams, D. Parikh and A. C. Badaruddo, \"Cross-Covariance Networks Implicating Articulation Stereo-Dynamics for Brain-Computer Interface Speech Decoding: State-of-the-Art Review\", NeuroImage: Clinical, 2018, 20:17\u201331.\n\n[2] A. Bilodeau, P. Parikh and A. C. Badaruddo, \"Speech Intent Classification using Deep Neural Networks on Multimodal Stimulus-Dependent and Stimulus-Independent Brain Signals\", NeuroImage: Clinical, 2019, 35:216\u2013239.\n\n[3] B. Kandakur, H. P. Udupa and R. S. G. Chandrasekher, \"Design and control for a brain-computer interface\", Sensors, 2014, 14:5914\u20135936.\n\n[4] P. R. K. Bhullar and M. V. Thiagarajan, \"A multi-classifier model for detecting speech intention from electroencephalogram signals\", Pattern Recognition, 2012.\n\n[5] J. L. Cope, G. M. P. Murphy and J. S. Brown, \"The auditory brain-stem response: A measure of speech intelligibility?\" Electroencephalography and Clinical Neuroscience, 1980, 46:15\u201322.\n\n[6] A. K. S. Kumar and M. V. Thiagarajan, \"Design of an integrated electro-encephalography and speech-language-therapy brain-computer interface system for the patients with locked-in-syndrome\", Biomedical Signal Processing, and Control, 2015, 65:34\u201344.\n\n[7] C. Xiong, K. G. D. Williams and B. K. J. McFarland, \"Elementary syllable classification of evoked response patterns using convolutional neural networks\", Behaviour Research Methods, 2018.\n\n[8] M",
    "c7b6e6cb997de1660fd24d31759fe6bb21c7863f": " We are indebt to CIHR program grant 95622.\n\nAcknowledgments\n\nWe are indebt to CIHR program grant 95622.\n\nIntroduction\n\nThis chapter provides an overview of the field of Brain-Computer Interface (BCI) where BCI technology is based on translating brain motor signals into motor actuations and speech. This section is divided into three parts; first, a brief survey of the history of the field, secondly, describing the main research streams in the field, and then thirdly, a short summary of recent BCI research projects.\n\nThe history of BCI technology can be traced back to early 20th century. In 1938, Gibson6 was the first to report how humans perceive visual stimuli as the result of integration of different modalities and suggested an 'ecstasy-dislocation' method through which visual information would be integrated with tactile stimuli to establish a meaningful feedback loop for brain activity regulation. Later on, neuro-muscular interfaces based on cortical EEG and neural network based models attempted to replicate this feedback loop in humans using high spatial resolution (1-2 mm) BIBREF8 and motor nerve stimulation. These first attempts did not receive much recognition outside the scientific community, however, in the 1980s, an attempt to explore and employ human's brain activity as a means of communication through a neural-prosthetic interface in the form of neural-bypass system was conducted by the Hochelaga-Maisonneuve Hospital (Qu\u00e9bec, Canada) BIBREF1. Several years later, El Hajj et al. BIBREF2 demonstrated how a neuro-prosthetic arm, controlled through transcranial brain signals could be used in paralyzed individuals to open doors and to pick up objects, thereby demonstrating the first successful use of BCI. Since those days, there have been numerous developments in brain-machine interface technologies with the development of microelectrodes, low-cost EEG sensors, and advancement in neuroscience, leading to a new wave of research in the field of motor control based on brain activity. In 2001, Kramer et al. 7 introduced a system for brain-controlled cursor control and web-browsing capability using a non-invasive, wireless, low cost BCI system. In recent years, tremendous progress in Brain-Computer Interface research can be attributed primarily to continuous advancements in deep learning, particularly in the areas of Deep Learning (DL), Convolutional",
    "f9f59c171531c452bd2767dc332dc74cadee5120": " We thank Kara Wilson (Kara), Gautam Shah (Gautam) and Adarsh Thamban (Adarsh) for helping with the dataset collection and the initial coding part of this work. We would also like to thank Shruti Singh (Shruti) and the reviewers for their insightful comments. Acknowledgments We would like to thank Dr. Shivang Dandekar (SD) and Dr. Atanu Kumar Singh (AS) for their helpful suggestions and technical corrections. This is an exciting and well-investigated area with continuous improvements and further studies. There is still much room for improvement in classifying speech imagery EEG from the raw brain activity measurements.\n\nBIBREF0: Al-Asri, D. E., and Bailenson J. N. Brain-Computer Interfaces. Cambridge Press, 2007.\nBIBREF1: M. Lehmann, E. Aertsen, R. A. K\u00fchn, R. Muth, M. J. Pekkala, A. Heremans, T. P. Hanke & H. K. S\u00f8rensen. Towards a wearable multimodal brain-computer interface. Frontiers in Neuroscience 11 (2016) 3.\nBIBREF2: B. K. Kim, K. Lim, D. L. Lee, J. S. Kim, J. K. Kim, C. B. Oh, D. S. Hwang, S. W. Lee, H. Y. Lee & A. Yoo. Speech-Based Brain-Computer Interface Using EEG and Pupillometry for Voice Control. Frontiers in Neuroscience 9 (2016) 1.\nBIBREF3: Schu, M., Kahng, M., Rennert, M., Tsujike, S., Moseley, T., E. K. Bailenson & J. S. Kim. Brain-Computer Interface Systems for Virtual Reality: Potential and Challenges. In International journal of simulation and computing. Springer, 2017.\nBIBREF4: T. B. Choi et al. Automatic Speech-Intention Classification From Brain Waves and Electrodynamic Brain Activity Measurements. Frontiers in Neuroscience 10 (2016) 1.\nBIBREF5: L. Pichora-Fuller, B. H. Priebe and J.",
    "4ac2c3c259024d7cd8e449600b499f93332dab60": "\n\nWe thank the two anonymous reviewers for their valuable feedback. We gratefully acknowledge the support of Fyodor Pleshan, Dora Ma and Marco Zogpaan during the completion of this project.\n\nWe gratefully acknowledge the support of Anastastia Gousianov and Konstantinos Sungaras during the completion of this project.\nThis project has received funding from the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programm\n\nWe gratefully acknowledge the support of Martin Bubis and Erich Griess. We thank all participants in the UBCNLP 2021 summer seminar held in Lugano. The authors thank the reviewers for their feedback.\nREFERENCES\n\n[1] V. Cherapanamjari, W. Zuqiu, H. Zhang, A. Chempaka, and E. Wu.\n\nSemi supervised event detection using a keyword for classification and expectation classification for prediction.\nIn Proc. EMNLP. pp. 1414\u20131423. ACM Press, 2018.\n\n[2] K. Chempaka and E. Wu.\n\nUnsupervised event detection in tweets via sequence modeling and domain alignment.\nIn Proc. EMNLP. pp. 1\u201342. ACM Press, 2018.\n\n[3] H. Dehghani, J. Yang, and Y. Li.\n\nUsing crowd for improving event detection: a human-in-the-loop approach to post-processing an LSTM.\nIn Proc. SIGIR Symposium on Human Language Technology Research for Information Retrieval, SIGIR2020, Beijing, China. 2020.\n\n[4] Y. Li, S. Li, and E. Wu.\n\nWeakly supervised semi-supervised event detection without training data.\nIn Proc. NAACL. pp. 3201\u20133209. ACL, 2019.\n\n[5]  .\n\nBias correction for training social media event detection neural networks.\nIn Proc. CHI. pp. 3654\u20133664. ACM Press, 2018.\n\n[6] M. Ma, I. Malkov, Y. Shen, and V. Sarkar.\n\nExpectation regularization for weakly supervised event detection.\n\nIn Proc. EMNLP. pp. 3971\u20133980. ACL,",
    "bc730e4d964b6a66656078e2da130310142ab641": "\nREF\n\nA.R. BIBREF\n\nB.G. BIBREF\n\nY.W. BIBREF\n\nC.C. BIBREF1\n\nR.F. BIBREF1\n\nJ. M. W. BIBREF10\n\nC.S. BIBREF15\n\nD.D. BIBREF1\n\nA.L. BIBREF2\n\nT.S. BIBREF3\n\nA.S. BIBREF6\n\nH.K. BIBREF7\n\nA.W. BIBREF1\n\nZ.M. BIBREF12\n\nA. Y. BIBREF13\n\nJ.T. BIBREF2\n\nS. B. BIBREF1\n\nM.Y. BIBREF2\n\nF. W. BIBREF7\n\nT.R. BIBREF3\n\nS.M. BIBREF9\n\nL.B. BIBREF6\n\nV.S. BIBREF16\n\nW.S. BIBREF12\n\nG.M. BIBREF13\n\nJ. F. BIBREF9\n\nW.W. BIBREF6\n\nG.W. BIBREF14\n\nA.J. BIBREF18\n\nP.W. BIBREF19\n\nM.Z. BIBREF20\n\nA.K. BIBREF26\n\nD.A. BIBREF27\n\nS.H. BIBREF28\n\nA.R. BIBREF29\n\nA.O. BIBREF14\n\nJ.K. BIBREF37\n\nG.S. BIBREF3\n\nReferences\n\n[1] A. R. BIBREF. Crowdsourcing event detection via unsupervised online label collection. Master thesis. Eidhwahsehd, A.R., 2019.\n[2] F. W. BIBREF. Probabilistic Expectation Regularization for Deep Learning Event Detection. In ICPR, 2017.\n[3] S.B. BIBREF. Unsupervised Learning for Large-Scale Micropost Classifation with Weak Supervision. In AAAI, 2017.\n[4] C.C.",
    "3941401a182a3d6234894a5c8a75d48c6116c45c": "\nFunding\nWe acknowledge the support of NVIDIA and the National High Tech R&D Program of China (NHT-R and 2015AA014002).\nReferences\n\nBIBREF1.\n\nAlayrac C, Caminha E, Duret L, Fr\u00e9maux O (2016) A weakly supervised technique for temporal event detection. In: AAAI.\n\nBIBREF2.\n\nBeswick K, Schuller A, Spaniel F (2015) Real-world twitter event detection: a comparison of learning algorithms, BIBREF2.\n\nBIBREF10.\n\nEkiz A, Smyth P, Dzikov A, Mishra B (2020) Using crowd wisdom to improve event detection on tweets. In: SIGIR.\n\nBIBREF11.\n\nG\u00f6rne A, Kuhn M, Zhang T (2020) Beyond black-box predictive power: how humans and automatic learners collaboratively discover knowledge for machine learning. In: ICML.\n\nBIBREF12.\n\nCosta-Giovanni E, Deza D, Pace F (2020) Beyond human-interpretable: a unifying approach for explainability. In: NeurIPS.\n\nBIBREF13.\n\nMishra B, G\u00f6rne A, Pace F, Fr\u00e9maux O (2021) Towards human-understandable data products: a human-AI loop approach. In: NeurIPS.\n\nBIBREF14.\n\nChae J, Cevher M (1997) Bayesian latent variable analysis. In: NIPS.\n\nBIBREF15.\n\nHalevy O (2020) Understanding and generating visual question and answer: learning models from question and answer pairs by crowdsourcing. In: BMVC.\n\nBIBREF16.\n\nLiu J-B, Fortuna O, De Camilli F (2016) Modeling crowd wisdom with neural networks. In: SIGIR.\n\nBIBREF17.\n\nSmyth P, G\u00f6rne A, Cevher M (2021) A weakly supervised neural network approach to event detection on tweets. In: SIGIR.\n\nBIBREF18.\n\nBosch I (2020) A framework for human-in-the-loop machine",
    "67e9e147b2cab5ba43572ce8a17fc863690172f0": " We thank the funding agencies for their support and the anonymous reviewers for their insightful comments.\nReferences\n\n[1] Arora, S., Agarwal, H. P., Ganesh, S., Lataief, S. F. (2017). The weak supervision paradox in event detection. In Proc. of the 2015 Conference and Labs of the Consortium for Computing Science (CCSL@CCS'15), Pages 1\u201312.\n\n[2] BIBREF1 E. Mendoza and Y. Zhang (2014) Hackers everywhere: towards scalable cybersecurity for social media. In ACM Conf. Comm. Netw. Softwar. Sys. (CNSware'14). ACM, New York, NY, USA, 1\u201312.\n\n[3] BIBREF2 Z. Cheng and X. P. Hu (2002) Learning from weak labels: algorithms and theory. In Proc. of the 2002 International Conference on Learning Theory (ICLTR'02), Volume 3, Pages 1157\u20131166.\n\n[4] BIBREF3 J. C. Hao, J. S. Wang, W. B. Liu, Z. Fan, J. L. Wu, and C. Liu (2013) Event detection: extracting newsworthy information from microblogs. In Proc. of the 2013 ACM SIGMOD SIGKDD International Conference on the Management of Data (SIGMOD SIGKDD'13), Volume 1, New York, NY, USA, 1\u201311.\n\n[5] BIBREF4 C. F. Lee, T. X. Vu, and K. S. Wong (2012) Crowdsourcing in microblogging-based public health event detection. In Proc. of the 2012 ACM SIGIR Conference on Intelligent Hypermedia and Human Computer (IHMC 2012), Cambridge, MA, USA, Pages 685\u2013694.\n\n[6] BIBREF5 J. A. Zang, M. A. G. Santos, D. Y. Zhou, and J. Nie (2015). Mining the social media for the public's interest in public health events. In Proc. of the 2014 ACM Conference on Informatics for Public Health (ACM INFH'15), Orlando, FL, USA, pp. 165\u2013174.\n\n[7] BIBREF6 J. R. Gomes",
    "a74190189a6ced2a2d5b781e445e36f4e527e82a": "\n\nWe would like to thank our colleagues at the University of Innsbruck (i.e., R. R\u00f6thig, H. P. Bock, and K. Neuhaus), for their help and insightful discussions. We also thank the anonymous reviewers for their valuable comments that help us improve this paper. We acknowledge the authors of the following excellent works related to our work: H. P. Bock, V. Blanchard, G. Carvalho, C. Engel, D. Hotho, P. Pauly, M. Sotiras, and especially H. P. Bock, R. R\u00f6thig, and K. Neuhaus for their insightful discussions.\n\nAppendices\nAppendix 1. Supplementary Material\nAppendix 2. Crowdsourced Micropost Classification Datasets\nAppendix 3. Probabilistic Learning of Micropost Expectation\n\nAppendix 4. Acknowledgements\n\n1.\nBIBREF1[\n\n] BIBREF1, T. Kwon, M. Sun, A. K. Jain, B. S. Thuraisingham, X. Zhang, and E. Hershcovich, \"A Weakly Supervised Learning Approach for Event Detection,\" in Proceedings of the Thirty-Ninth Conference on Neural Information Processing Systems (NeurIPS 2015), 2015.\nAppendix 1.\n\nAppendix 2.\n\nAppendix 3.\n\nAppendix 4.\n\nAppendix 5.\nAppendix 6.\n\n1.\n\nBIBREF1 BIBREF1 T. Kwon, M. Sun, A. K. Jain, B. S. Thuraisingham, X. Zhang, and E. Hershcovich, \"A Weakly Supervised Learning Approach for Event Detection,\" in Proceedings of the Thirty-Ninth Conference on Neural Information Processing Systems (NeurIPS 2015), 2015.\nBIBREF2[\n\n] S. Zhang, Y. Wu, and C.-Y. Liu, \"Towards Automatic Event Detection: A Hybrid Approach with Linguistically Enhanced Embedding and Deep Neural Network,\" in Proceedings of the International Conference on Document Analysis and Recognition (ICDAR 2013), 2013.\nAppendix 2.\n\nAppendix 3.\n\nAppendix 4.\n\nAppendix 5.\n\n[\nAppendix 5.\n\nAppendix 6.\n\nBIB",
    "43f074bacabd0a355b4e0f91a1afd538c0a6244f": " We also thank our anonymous reviewers, the other two authors, and our colleagues at EPFL for their valuable feedback. We also thank the anonymous reviewer at CVPR 2020 for insightful comments on this paper. Finally, we thank the organizers of CVPR 2020 workshop for the opportunity to present our work.\nBibliographical References\n[BIBREF0]\nS., Wang, W., He, K., Li, H., and Cheng, T., 2019. Learning to Detect Events on Microblogging Platforms.\n\nIn Neural Information Processing Systems Workshop at the th International Joint Conference on Artificial Intelligence, PMLR 94:1737\u20131748.\n\n[BIBREF1]\nZ., Ren, X., Yoon, H., and Jiang, Y., 2019. Learning to Detect Social Events from Microblog-\n\ning Platform Using Weak Supervision. arXiv preprint.\n\n[BIBREF10]\nT., Kao, Y., Yang, X., Zhao, X., and Guo, Z., 2017. Understanding Crowd Work-\n\narounds for Weakly Supervised Machine Learning.\n\nIn Seventeenth International Conference on Computational\n\nLinguistics (Coling 2017).\n\n[BIBREF11]\nL.-M., Yang, and I. K., Chen, 2016. Interpretable Machine Learning.\n\nNeural Information Processing Systems Foundation. http://www.nips.cc/papers/paper\n\nfile/6620/Interpretable-Machine-Learning-A-Survey.pdf.\n\n[BIBREF12]\nR. Caruana, L. M., Larochelle, H., Lachapelle, F.,\n\nS. Beyssade, P. Bender, and J.-B. Durand, 2015.\n\nStructured Prediction: The Neural Turing of Black-\n\nBoxes and Why They Suck. In Advances in Neural\n\nInformation Processing Systems NIPS Workshop.\n\n[BIBREF13]\nJ. R. Br\u00f6dersen and C. R. Br\u00f8gersen, 2019. How People Use\n\nDeep Learning Models. arXiv preprint.\n\n[BIBREF14]\nM. Dawid, L. M., Skene, K. M., and A. K. Mairals. Unifying the\n\n",
    "58ef2442450c392bfc55c4dc35f216542f5f2dbb": " This work was funded by TU Delft's Zilveren Fonds Grant Project, and was supported by the NWO project ID-T-2017.1201.044.\n\nThis project is supported by the European Research Council (ERC-2019-ID4330-N). The authors wish to thank the reviewers of the ACL-2020 workshop for valuable suggestions.\nBIBREF1: K. De Vries et al., \"State of the art in conversational information seeking,\" TIP. Vol. 5, No. 2 (2020), pp. 1\u201311, https://www.acm.org/publications/tips/toc.cfm.\nBIBREF2: H. M. Naseri and M. Zamani, \"QuAC: A question answering challenge,\" in ICTIR '19 Proceedings of the 19th ACM International Conference on Information & Knowledge Technology Interfaces, New York, NY, USA, ACM, December 2019, pp. 109\u2013118, doi: 10.1145/3386349.\nBIBREF3: Y. Yu et al., \"MISC 2019: A novel conversational search query and answer challenge,\" in SIGIR '19 Proceedings of the 42nd ACM international conference on Research and Development in Information Retrieval, Toronto, Canada, ACM, August 2019, pp. 2873\u20132882, doi: 10.1145/3290605.\nBIBREF4: Y. Yu et al., \"Evaluating retrieval algorithms for conversational question answering,\" in AAAI AI & Society '19 Human language: From dialogue to language engineering, Toronto, Canada, AAAI Press, December 2019, pp. 5687\u20135694, doi: 10.19/3093808.\n\nBIBREF5: H.-K. Choe et al., \"Qulac: A multiple intelligence-based chatbot for question answering,\" in ICTIR 2016 Conference Track Proceedings of the 14th ACM International Conference on Information and Knowledge Technology Interfaces, ACM, 2016, https://dl.acm.org/citation.cfm?id=2898494.\n\nBIBREF6: A. O. U. Kim et al., \"CCPE-M: A conversational QA competition based on Microsoft Q and A platform,\" in SIGIR 2019 Conference Track Proceedings of the 42nd ACM",
    "78a5546e87d4d88e3d9638a0a8cd0b7debf1f09d": "\nReferences\n\n[\n\n] Anderson, A. M., Nurmi, J., Al-Sharif, D. B., and De, M. A.: Co-reference resolution and generation of question-answering dialogues using human-in-the-loop machine learning. In: Proceedings of the 2020 ACM/Special Interest Group SIGIR Conference on Retrieval and Information Access, pp. 127\u2013134. https://doi.org/10.1145/3271378.3271382. https://dl.acm.org/doi/10.1145/3271378.3271382\n\n[\n\n] BIBREF0: H., Z., K. S., and Z., H.: TREC 2019: Multimodal query and conversation assistance track. ACM Transactions on Information Systems, 29, 1, 2020. https://doi.org/10.1145/3277729.3277735\n\n[\n\n] BIBREF1: H., Z., H., H., Z., K., I., K., and K., H.: SWIRL 2018: Workshop on human\u2013AI conversational interactions. ACM Transactions on Information Systems, 28, 1, 2020. https://doi.org/10.1145/3241518.3241552\n\n[\n\n] BIBREF2: H., A., Z., and Z., H.: MISC: A multi-turn conversational task. In: Proceedings of the 48th Annual Conference of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 1785\u20131798. https://dl.acm.org/doi/10.1145/3408870.3408976\n\n[\n\n] BIBREF3: H., A., Z., Z., H., K., A., Z., I., S., K., K. H., Y., Z., K., and Z., H.: Clarifying and exploring user needs for information seeking tasks. The Journal of the Association for Information Science and Technology, vol. 71, no. 1, 2022, pp. 134\u2013151. https://doi.org/10.1002/asi.22943\n\n[\n\n] BIBREF4: H., A., Z., Z., A., B., B., B., Z., H., K",
    "375b281e7441547ba284068326dd834216e55c07": "\nReferences\n\n[1] \"Evaluncs \u2013 Open source, conversational search.\" [Online]. Available: https://evaluncs.org\n[2] \"Conversational QA.\" [Online]. Available: http://msmarco.org/docs/tutorial.html\n[4] \"Macaw: An Open Source Platform for Conversational Information Seeking Research.\" [Online]. Available: https://www.cs.uic.edu/~kmirzoei/publications/macaw/macaw.pdf\n[5] \"Query and conversational systems: Challenges and approaches.\" TREC. 2016.  \n[6] \"A decade of question answering technology.\" TREC. 2011.\n[7] \"A summary of the TREC-19 shared tasks: The new challenges.\" TREC. 2019.\n[8] \"Dialog.\" [Online]. Available https://dialogflow.cloud\n\n[9] \"PyIndri python interface.\" [Online]. Available: https://pythonhosted.org/PyIndri/\n[10] \"Open source, real-time search and analysis engine.\" [Online]. Available: https://fastsearch.ai\n\n[11] \"Reading comprehension: A machine learning approach for open domain question answering.\" TREC. 2015.\n[12] \"Natural language interface to data and knowledge graph: A new evaluation framework.\" TREC. 2018.\n[13] \"Cort: Conversational question answering through reading comprehension.\" TREC. 2016.\n[14] \"Combining question answering and search intent learning.\" TREC. 2018.\n[15] \"Co-reference resolution for conversational question answering: a new framework for combining search and QA.\" TREC. 2017.\n[16] \"Joint search and recommendation.\" TREC. 2019.\n[17] \"A new hybrid recommendation framework for conversational information seeking.\" TREC. 2017.\n[18] \"Ontology based search.\" TREC. 2018.\n[19] \"Qulac: A conversational information retrieval challenge over knowledge graphs using ontology data and crowdsourcing.\" TREC. 2017.\n\n[20] \"Query understanding via open domain question answering.\" TREC. 2018.\n[21] \"Qulac: The 2019 challenge.\" [Online]. Available: https://trec.nist.gov/",
    "05c49b9f84772e6df41f530d86c1f7a1da6aa489": " They also wish to acknowledge the contributions of Gabor Kovacs, Ahmed Farrag, Mahsa Sayed, Ahmed Zahran. We gratefully acknowledge the financial support of the DARPA SABER program, which led to the initial designs for Macaw BIBREF8. Their support has helped make this project possible.\nReferences\n\n<div class=\"citation\" data-cites=\"Ranzato, S., & LeCun, Y. (2015). \"Learning word representations for sentence inference.\" In Proceedings of the 30th AAAI Conference on Artificial Intelligence, pages 757-765. <https://doi.org/10.18653/v1/A15-3016>\", target=\"googleScholar\">[<span id=\"Ranzato2015-bIBREF8-r2w3eK1oMZGd0-0r3\"]\n\n[<span id=\"Ranzato2015-bIBREF8-r2w3eK1oMZGd0-0r3\"]\n\n<div class=\"page-break\" markdown=\"1\" style=\"line-height: 1.6;\"></div>\n\n<div class=\"page-break\" markdown=\"1\" style=\"line-height: 1.6;\"></div>\n\n<span id=\"Ranzato2015-bIBREF8-r2w3eK1oMZGd0-0r3\"]\n\nS. Ranzato, and Y. LeCun. \"Learning word representations for sentence inference.\" In Proceedings of the 30th AAAI Conference on Artificial Intelligence, pages [?]. <https://doi.org/10.18653/v1/A15-3016>, xtal, <https://dl.acm.org/citation.cfm?id=2976585>.\n\n<div class=\"page-break\" markdown=\"1\" style=\"line-height: 1.6;\"></div>\n\n<span id=\"Ranzato2015-bIBREF8-r2w3eK1oMZGd0-0r3\"]\n\nS. Ranzato, and Y. LeCun. (2015). Learning word representations for sentence inference. In Proceedings of the 30th AAAI Conference on Artificial Intelligence. Conference",
    "6ecb69360449bb9915ac73c0a816c8ac479cbbfc": " In addition, the authors are grateful for the reviewers for their careful review, and the authors wish to thank the organizers for supporting the CIS at SWIRL 2018. Finally, the authors thank the University of California and University of Wisconsin-Madison for their support.\nFigure 1: A Macaw Interactio...\n\nFigure 1. Macaw Interaction Database\n\nTable 1 illustrates the data fields in the interaction database.\nTable 1\n\nThe interactions in the database are labeled by a unique interaction ID (ID) and an interaction timeout constant (T). Every action also has a set of labels. Each action is characterized by its execution time (T) and run time (T). Run time determines how often the action can be dispatched to process a new interaction. If a selected action cannot serve the request to the user before its deadline expires, it will dispatch an error event at the error interface. At this point, the system will fail the request. In this work, actions are the basic building blocks for conversational information seeking systems. Hence, we refer to an action (or action set) as an interactive information seeking function.\nFigure 2: Action Data Structr...\n\nFigure 2. Action Data Structure\n\nFigure 3: The Overview of Macaw\n\nTable 2: Supported Interfaces\n\nTable 3 shows the available interfaces for Macaw. We include Telegram as a general interface. It is very popular and can work with different devices and operating systems.\nTable 3\nTable 4: Supported Actions\n\nTable 4 shows a list of currently supported actions with their interfaces and description.\nTable 4\n\nFigure 4: Actions' Execution Threads of Control\n\nFigure 5: Messages in the Interaction Database\n\nMacaw supports multiple threads of control (TOCC) for each interactive information seeking function, and actions can dispatch their results via three different interfaces, namely, input, output, and error.\nFigure 6: Macaw's Architecture\n\nFigure 7: Macaw's User Interface\n\nFigure 8: Multi-Turn Interactions\n\nFigure 9: Macaw Architecture in Wizard of Oz Studies\n\nFigure 10: Macaw User Interface in Wizard of Oz Studies\n \n**Praise for** _**Chicagola**_\n\n**\"Superb, and a work of rare intelligence, bravery and beauty... an extraordinary achievement.\"**\n\n\u2014Curt Colbert, author",
    "68df324e5fa697baed25c761d0be4c528f7f5cf7": " We gratefully acknowledge the support and contributions provided by the NLP and AI Community of Utrecht University (NLP4U) BIBREF18, e.g., Arjen P. de Vries, Ahmed Hassan Awadallah, Marielle de Groot, Joachim Gossen, Henken Laukens, and Peter van der Wees.\n\n\n\nContents\n\nTitle Page\n\nCopyright\n\nDedication\n\nAcknowledgements\n\nChapter 1\n\nChapter 2\n\nChapter 3\n\nChapter 4\n\nChapter 5\n\nChapter 6\n\nChapter 7\n\nChapter 8\n\nChapter 9\n\nChapter 10\n\nChapter 11\n\nChapter 12\n\nChapter 13\n\nChapter 14\n\nChapter 15\n\nChapter 16\n\nChapter 17\n\nChapter 18\n\nChapter 19\n\nChapter 20\n\nChapter 21\n\nChapter 22\n\nChapter 23\n\nChapter 24\n\nChapter 25\n\nChapter 26\n\nChapter 27\n\nChapter 28\n\nChapter 29\n\nChapter 30\n\nChapter 31\n\nChapter 32\n\nChapter 33\n\nChapter 34\n\nChapter 35\n\nChapter 36\n\nChapter 37\n\nChapter 38\n\nChapter 39\n\nChapter 40\n\nChapter 41\n\nChapter 42\n\nChapter 43\n\nChapter 44\n\nChapter 45\n\nHistorical Note\n_For Eamon_\n_for the best of friends_\n_And thanks must go also to the staff_\n\n_of the American Bookshop,_\n\n_the most delightful people in Dublin_.\n\n_And one more to Mary Delap_\n\n_and her wonderful shop in Monaco_\n\n_and to the good people_\n\n_at Hodder and Stoughton_\n**Also by Alan Furst**\n\nSPY SERIES STORIES\n\n_Night Soldiers_\n\n_Night Twilight_\n\n_Day of the Jackal_\n\n_Blood of Victory_\n\n_Dark Voyage_\n\n_Pale Soldier_\n\n_Dark Star_\n\n_King of Tears_\n\n_Golden Legend_\n\n_Code Name_ _George_\n\n_The Foreign Correspondent_\n\n_Spies of Warsaw_\n\n_Kingdom of Shadows_\n\n_The Polish Officer_\n\n_The World at Night_\n\n",
    "77c34f1033702278f7f044806c1eba0c6ecb8b04": " A possible avenue could be to use the section expansion procedure to extract the salient facts to a given entity page, and then infer an appropriate paragraph by using an extractive summarization task in the remaining text. This would help accelerate knowledge base generation as well as help in Wikipedia page population.\nFuture work will also include further investigation into the learning procedures for the AEP task as our present one is limited to binary classification which we expect could also benefit in other NLP tasks. We also aim to apply our approach to other languages, e.g. Chinese. Finally, we are interested in extending the evaluation setup to measure the impact of our work on coverage for the full spectrum of entity classes.\n\nAcknowledgments\nThis research has been partially supported by the National Science Centre, Poland, under the grant no. 2016/20/D/HS4/03114.\n\nThe authors would like to thank Gaurav Karnad and David Daganayakereh for helpful discussions.\n\n[1] Y. Barzilay and E. Sauper. Knowledge base acceleration through information extraction: a framework for automatic enrichment of structured information. In: 11th Joint Conference on Digital Libraries (JCDL 2013): Proceedings of the Joint Conference on Digital Libraries (poster). ACM, 2013.\n\n[2] R. Mihnea, H. Mokbel, and F. Gaudl. An evaluation of news summary extractors using structured data and crowdworkers. In: Proc. of the ACM on conference TREC, 2009, pages 1\u201310.\n\n[3] K. West, O. Etzioni, S. Chakraborty, and I. Feldman. Knowledge base acceleration through Q&A: Fact verification on web-scale question-answering. In: Proceedings of the SIGCHI conference CHI, 2010, ACM, pages 113\u2013118.\n\n[4] I. Etzioni, M. Johnson, O. Etzioni, A. McCallum, M. Morales-S\u00e1nchez, J. Z. Wang, and Z. Zhang. Automatic enrichment of structured information. In: International Workshop on Automated Knowledge Acquisition, 2012, pp. 35-44.\n\n[5] M. Balog, C. Havasi, S. A. Androulidakis, A. Barzilay,",
    "2ee715c7c6289669f11a79743a6b2b696073805d": " This is an ongoing problem in Knowledge Base Acceleration, as discussed in Section SECREF5.\nThe proposed approach can be a starting point for NLP approaches that attempt to extend or update knowledge bases such as YAGO or DBpedia. In addition, it could be used in conjunction with machine translation approaches for entity linking that is often performed on large volumes of documents.\n\nAcknowledgements\nWe thank all our reviewers for their careful reading of the paper and thoughtful comments. We acknowledge the research support of the following organizations.\nGoogle.\nNTT Communication.\nLancaster University.\nEconomic and Social Research Council (UK).\n\nTable 1. News Articles by Year.\nTable 2. News Reference Count (IN LINE) at Year INLINE (IN YEAR).\nTable 3. News Summary Count by Source (IN N).\nTable 4. Distribution of News Reference Count.\nTable 5. Document-level Salience Features\nTable 6. News Reference Count for Entity Classes at Year INLINE (IN YEAR).\nTable 7. News Summary Count per Category.\nTable 8. Summary Statistics for Temporal Features.\nTable 9. News Reference Count per Category.\nTable 10. News Article Length.\nTable 11. News Reference Count by Language (in IN).\n\nTable 12. Number of News Articles by Year.\nTable 13. List of News Domains.\n\nTable 14. Salience Features by Language.\nTable 15. News Reference Count by Author (in INLINES).\nTable 16. News Referenced in Entity Classes.\nTable 17. Article-Article Placement for Baseline B1.\nTable 18. Summary Statistics for Salience Features.\n\nTable 19. Salience Features by Author.\n\nTable 20. Number of Entities (IN LINE) by Language.\n\nTable 21. Relative Entity Frequency.\nTable 22. Authority Features.\n\nTable 23. Relative Authority Features.\n\nTable 24. Novelty Features.\n\nTable 25. Novelty Features by Author (in INLEGENDS).\n\nTable 26. Article-Article Placement.\n\nTable 27. Article-Entity Placement for Baseline B2.\nTable 28. Summary Statistics for Authority Features.\n\nTable 29. Article-Article Placement for Baseline S1.\n\nTable 30. Article-Entity Placement for Baseline S1.\n\nTable 31. Authority",
    "61a9ea36ddc37c60d1a51dabcfff9445a2225725": " Another avenue for future work is to suggest longer or richer versions of news articles. In addition, we can incorporate our section placement approach for Wikipedia templates to suggest new blocks of text, such as biographies, in an automated fashion.\n\n[1] T. Barzilay and B. Sauper. Accelerated knowledge population for wikipedia via paragraph retrieval. In Proc. of LREC (Lecture Notes in Computational Linguistics), pp. 1039-1046, 2008.\n\n[2] R. Bellog. Using knowledge bases to accelerate the creation of new information. Masters thesis, Utrecht University, 2007.\n\n[3] I. Bilenko, I. Chirkov, R. Klein, D. Mazieres, R. Nakano, and B. Zissimopoulos. Automatic summarization for the semantic web using entity centroid distance. In Proc. of The Twenty-ninth AAAI Conference on Artificial Intelligence, pp. 1561-1567, 2014.\n\n[4] S. Bhunia. Distant source supervision for question-answering: A model for generating text from entities. In Proc. of Thirty-fifth AAAI Conference on Artificial Intelligence, pp. 1475-1481, 2016.\n\n[5] J. G. Bhunia, G. Chakravorty, and B. Zissimopoulos. Information retrieval with Wikipedia: A deep model for semantic clustering. In Proc. of SIGIR, 2013.\n\n[6] S. Bhunia, N. Goyal, and B. Zissimopoulos. Extracting text facts from news: A comparison of graph-structured and relational models. In Proc. of The Third Workshop on Semantic News, pp. 43-52, 2013.\n\n[7] I. Chirkov, J. Zhai, C. Chen, R. Nakano, and I. Chaudhuri. Entity ranking by relevance mining: New opportunities for information access from the web. In Proc. of the 25th ACM SIGIR Conference, 2012.\n\n[8] S. Choffing, I. Chirkov, D. Mazieres, R. Nakano, B. Zissimopoulos, and I. Zobel. Efficient approach for populating yago with facts by abstracting from news",
    "cc850bc8245a7ae790e1f59014371d4f35cd46d7": " We will therefore focus on developing methods that extract facts from the suggested articles to automatically complete Wikipedia articles. In addition, since we use the Wikipedia revision history we will make use of techniques for Wikipedia page editing, such as crowd-editing BIBREF26, to expand entity profiles based on news suggestions.\n\nAcknowledgements\nWe thank Sviatoslav Yuretsky for his very helpful comments on the original draft and his feedback in the final version of this paper. We are indebted to Pawel Cimsa and Zuzi Szpektor for their suggestions to improve the manuscript. Finally, our work is part of the ongoing EU project NewsSuggested.\n\nREFERENCE\n\n[1] R. Akoglu and H. Garcia-Molina. (2015) \"Query-focused and entity-oriented online news extraction from news articles\". Proc. SIGIR 2015: 1705\u20131711. http://dl.acm.org/citation.cfm?id=2948323.\n\n[2] A. Andrikopoulos and N. Zanchetti. (2013) \"Summarizing, highlighting and linking: towards query-focused summarization of news articles\". Proc. LREC.\n\n[3] E. Bordes, M. Chaudhuri, W. K. F. Wong, et al. (2014) \"Open Information Extraction from the Web\". Proc. ICML 2014: 2111\u20132118. http://papers.nips.ccc/paper/5794.2014.\n\n[4] J. Brocket and W. V. Dolan. (2013) \"News headlines: finding and linking the most popular topics\". Proc. CICLing 2013: 5\u201312. http://dl.acm.org/citation.cfm?id=2662385.\n\n[5] B. Burges. (1994) \"A corpus of newswire text for evaluating the effectiveness of rule-based and statistical information retrieval systems\". In Proc. AAAI '94, pp. 1135\u20131140.\n\n[6] T. Cholakala, G. G. Cherubini, N. Karavasoglou, and M. Sterzal. (2012) \"What people talk about most on Twitter: a large-scale study of popular hashtags\". In Proc. ICWSM '12",
    "984fc3e726848f8f13dfe72b89e3770d00c3a1af": " We will use these news articles as a starting point for more sophisticated approaches, e.g. summarization or extraction. For this task, we also take inspiration from more open-domain summaries as a way of getting information for the entity profile, where we aim to develop methods to abstract from news articles new factual statements about an entity on the basis of the news content. We also intend to look at approaches to handle the more open problem of extracting and linking facts that are implicit in a news article's text.\nAcknowledgments\nThis work has been supported by the Swiss National Science Foundation through the project `Automatic Knowledge Base Acceleration from News' (SNSF grant nr. 200318_166109). We would also like to thank the anonymous reviewers for their helpful and constructive suggestions and feedback. The authors are also very thankful for the time spent in constructive comments with our colleagues. Finally, we acknowledge that the research results presented in this paper have contributed to the improvement of the Wikipedia language model as part of the Knowledge Graph project sponsored by Microsoft Research Cambridge.\n\n## Appendix A-1. Bibliography and Further Sources of Information\n\nIn this section, we provide a summary of works in the area of entity linking, salience detection, and news recommendation that we take into consideration in our approach.\n\nEntity Linking\nAgichtein C, Riedl A, Bazzi A, and Wiegand S. \"DBLP: Discovering co-citations in large scientific repositories using entity relations.\" In Coling 2003: Proceedings of the 2003 Conference on Computational Linguistics, Beijing, China, 2003\n\nBarzilay D and Sauper D (2008). \"Automatic Wikipedia page generation.\" In Proceedings of NLP@ECAI 2008 (poster session), Montreal, Canada, 2008\n\nBazzi AW, Koutra D, Agichtein C, Riedl A, and Wiegand S. A database of bibliographic references for people, entities and organizations in the DBLP conference series. In Proceedings of the SIGIR Conference on Research and Development in Information Retrieval, 2005\n\nChen Z, Maus AMB, and Lee SM. \"Bird: Entity linking and ranking through entity centering and distributional similarity.\" In SIGIR 2008: Proceedings of the 31st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval: 25-30 August 2008",
    "fb1227b3681c69f60eb0539e16c5a8cd784177a7": " In addition, the ability to automatically suggest snippets could be used for other tasks such as entity mention detection, or knowledge base acceleration.\nAcknowledgements\nAcknowledgments. The authors thank the members of project group Xplore/Wikidata @ LIP6 for their contributions and discussions during the Ph.D. research. The discussions with the editors in Xplore on the use of news articles to WikiPDIA BIBREF5 and the Wikipedia Article Acceleration Task BIBREF8 for entity pages were also very helpful. Finally, this work has received financial support from the EU through FP7 project DARPA-AQUASER2 and from the Israel Science Foundation.\n\nReferences\n\n[Bahr, P., and G. Schlichting. 2017. Wikidata. DBPedia Spotlight, 6(2), 1-6.] Available from http://dbpedia-spotlight.org/2017/09/03/01/wikidata.html.\n[Bak, S. Y., A. P. M. Steyvers, and I. Zayasen. 2008. Wikipedia: The free encyclopedia that anyone can edit. In: Proceedings of the 2008 ACM symposium on applied computing. Berlin, New York: ACM, 6\u201313. Available from https://dl.acm.org/citation.cfm?id=1449393.]\n\n[Bar-El, Y., D. Menczer, S.-J. Kim, and A. Y. Karp. 2005. Wikipedia and the future of encyclopedias. In: Proceedings of the 15th International World Wide Web Conference (WWW). Republic of Korea.\n\n[Bezemer, J., and S. Lederer. 2007. Topic Models for News Documents and Web Pages in Cross-Lingual Transfer. In: Proceedings of the 23rd International Conference on Computational Linguistics. pp. 1339\u20131344.]\n\n[Biber, S., R. S. Smith, W. Lee, A. Liu, and J. A. Manning. 2010. Fine-Grained Document Summarization. University of Mannheim, Technical Report, No. 2-10-04.] Available from http://hal-unilim.ac.be/fichier/s-bi-10-05.pdf.\n\n[Borg",
    "8df35c24af9efc3348d3b8d746df116480dfe661": " We would also like to thank Florian Sch\u00fcrmann and Martin St\u00fcrzebecher for their help in designing the annotation guidelines. We also thank the anonymous reviewers for the helpful feedback they provided.\nREFERENCES\n\nTABLE TABREF1\n\nA CARE Case Report ::: Clinical data structure\nNAME [type = patient name]\n\nPATIENT IDENTIFICATION [type = patient identifier]\n\nPRIMARY TREATMENT [type = primary disease name]\n\nPRIMARY SIGN [type = primary body part]\n\nSYMPTOM [type = symptom]\n\nFINDING/FINDINGS [type = finding]\n\nPRIMARY TREATMENT [type = treatment name]\n\nPRIMARY FINDING/FINDINGS [type = finding]\n\nFINDING/FINDINGS [type = finding]\nCASE ENTITY [type = patient name]\n\nCASE IDENTIFICATION [type = unique id of an individual case, e.g., a unique patient ID]\n\nPATIENT SEX [type = patient sex]\n\nPRIMARY SIGN [type = body part]\n\nPRIMARY FINDING/FINDINGS [type = finding]\n\nPRIMARY SIGN [name] = {[SIGN/SIGN#], [CATEGORY#], [SYNTAX#], [REFERENCES#], [CONTRAINDICATIONS#], [FACTORS#], [COND/COND#], [RECOMMENDATIONS#], [SYMPTOMS#]}, \n\nSYMPTOM [type = condition name]\n\nSYMPTOMS/SYMPTOMS [type = condition name]\n\nFINDING/FINDINGS [type = finding]\n\nFINDING/FINDINGS [type = finding]\n\nFINDING/FINDINGS [type = finding]\n\nPRIMARY TREATMENT [type = treatment name]\n\nPRIMARY TREATMENT [name] = {[NAME], [REFERENCES#], [SYNTAX#]}\n\nCASE ENTITY [type = patient name]\n\nCASE IDENTIFICATION [type = unique id of an individual case, e.g., a unique patient ID]\n\nCASE ENTITY [name",
    "277a7e916e65dfefd44d2d05774f95257ac946ae": " We acknowledge the efforts of our doctoral candidate Florian Schmidhauser for his support with the annotation phase. Special thanks go to all other members of the team who contributed to the corpus processing.\nA Corpus of Medical Case Reports with Medical Entity Annotation\n\n## Table of contents\n-\n\n\nSummary\n\nPart I. Introduction: 1\n\nPart II. Methods: 2\n\nPart III. Results: 3\n\nNotes for the reader / Authors\n\nAbbreviations\n\nReferences\n\nAppendixes\n\nFigures\n\nTables\n\nFigures\n\nTable of contents\n-\n\nFig. 1.1. Example image from a case report\n\nFig. 2.1. Screenshot of the case presentation in the corpus.\n\nFig. 3.1. Statistics of the corpus.\n\nFig. 4.1. Example of an annotated case report.\n\nFig. 5.1. Case entity (in-sentence)\n\nFig. 5.2. Case entity (external)\n\nFig. 5.3. Finding annotation\n\nFig. 6.1. Example of a finding annotated as a finding with the help of a modifier\n\nFig. 7.1. Example of a factor annotation\n\nFig. 8.1. Example of a factor annotated as an immutable factor with the help of a modifier\n\nFig. 9.1. Modifier annotation\n\nFig. 10.1. Nested entities\n\nFig. 10.2. Partially-nested entities\n\nFig. 10.3. Fully-nested entities\n\nFig. 10.4. Nested entities with disconuity\n\nFig. 11.1. Relation between a case entity and a finding\n\nFig. 11.2. Relation between a factor entity and a finding\n\nFig. 12.1. Relation between a case entity and a modifer\n\nFig. 13.1. Relation between a finding entity and a modifier\n\nFig. 14.1. Relation between a finding entity and a negative modifier\n\nFig. 15.1. Relation between a condition entity and a finding\n\nFig. 15.2. Relation between a finding entity and a condition entity\n\nFig. 16.1. Example of a finding entity annotated (partially) as a finding entity and (partially) finding (partially) as a",
    "2916bbdb95ef31ab26527ba67961cf5ec94d6afe": " We would also like to acknowledge the support and encouragement from the DKRZ.\nFunding Open Access funding enabled by Projekt DEAL.\n\nDisclaimer This research is funded by BMBF via the QURATOR project (03WKDA1A). QURATOR is a research initiative to improve methods and concepts in the growing field of Digital Health.\n\nConflict of Interest The authors declare that they have no conflict of interest.\n\nFunding Information Open Access funding enabled by Projekt DEAL.\n\nAuthorcontribution All authors contributed to the overall design of the work. The authors Y. M. and I. C. developed the initial corpus and guidelines. All authors jointly annotated the set of case reports. All authors jointly wrote the manuscript.\n\nCompeting interests The authors declare that they have no conflict of interest.\n\nReferences\n\n<https://clinicaltrials.gov/ct2/show/NCT02573951>\n\n<https://clinicaltrials.gov/ct2/show/NCT02735002>\n\n<https://clinicaltrials.gov/ct2/show/NCT01843222>\n\n<https://clinicaltrials.gov/ct2/show/NCT01184559>\n\n<https://clinicaltrials.gov/ct2/show/NCT02251429>\n\n<https://clinicaltrials.gov/ct2/show/NCT02735011>\n\n<https://clinicaltrials.gov/ct2/show/NCT02896421>\n\n<http://pubs.rsna.org//article-pdf/90.3.1433/9036960119/v3.pdf>\n\n<https://clinicaltrials.gov/ct2/show/NCT02143448>\n\n<https://clinicaltrials.gov/ct2/show/NCT02840220>\n\n<https://clinicaltrials.gov/ct2/show/NCT01681218>\n\n<https://clinicaltrials.gov/ct2/show/NCT03114424>\n\n<https://clinicaltrials.gov/ct2/show/NCT04550282>\n\n<https://clinicaltrials.gov/ct2/show/NCT01044547",
    "f2e8497aa16327aa297a7f9f7d156e485fe33945": "\nReferences\n\nBIBREF\n\nAinslie, H., T. Burchard, J. Clarke, J. J. Clark, P. Curton, S. Dyer, W. Frank, R. Goodenough, R. Langley, T. Matthews, Y. Maat, R. Maass, A. Miller, J. L. Pollard, T. L. Rainie, L. Menczer-Reid, T. Rockmore, R. L. Rubin, S. M. Rosenquist, R. D. Silva, L. Smyth and N. S. Zarr. 2012. Care guidelines. National Institute for Clinical Excellence: National Institute for Health and Care Excellence. See also http://guidance.nice.org.uk/CG001.\n\nBecker, M. 2019. A systematic analysis and comparison of clinical case reports with annotations for biomedical NER. International Journal of Language and Linguistics, 6(2). DOI: 10.18662/ijll.v6i2.37\n\nBIBREF\n\nBlake, K., Y. N. Cui, S. J. Ellis, S. L. O'Keefe, M. Polg\u00e1r, S. E. Robinson, T. L. Saad, M. D. Robinson. 2019. Comparison of approaches for entity-level cross-platform and cross-corpora NER in biomedical documents: BIO vs. NER and BIO vs. BIOCHR. Journal of Natural Language Engineering, 14(3). DOI: 10.18662/jneo.v14i3.15\n\nBlake, K., Y. N. Cui, S. J. Ellis, S. L. O'Keefe, M. Polg\u00e1r, S. E. Robinson, T. L. Saad, M. D. Robinson. 2019. Comparing and combining BIO, BIOCHR, and BIOGENE approaches to entity-level annotating clinical case reports: A cross-corpus evaluation. Journal of Neuroinformatics, 58. Art. no. 15. DOI: 10.3233/neuroinn.14497.\n\nCabelloni, A., J. H. Lee, I. Titov, S. Dahlmeier, G. A. Miller,",
    "9b76f428b7c8c9fc930aa88ee585a03478bff9b3": "\n\nReferences\n::: Lepore, C., Smees, R., & Strubell, J. (2018). The ADE Corpus: A Diverse Collection of Case Reports on Disease-Drug Interactions. Database (Ann Arbor), 8, 1--28. https://db.oxfordjournals.org/content/article.aspx?tocid=DBD.2018.009\n::: Smees, R., & Strubell, J. (2017). BIBREF: A repository of annotated case reports to facilitate processing of annotated data in the biomedical domain. Database : The Journal for Applied Biochemistry and Molecular Biology, 1, 1--4. https://static-content.springer.com/cover/10.1093/database/bay001.full.pdf\n::: Shlush, A., & Barzilay, R. (2017). MedCase: a corpus of case reports. Database : The Journal for Applied Biochemistry and Molecular Biology, 1, 1--4.\n::: Al-Rfou, A. J., Strube F., & Strubell, J. (2018). The Clinical Case Reports corpus. Database : The Journal for Applied Biochemistry and Molecular Biology, 6, 1--4.\n::: D'Errico, S., F\u00fcrstenau, S., Pilet, S., & D'Errico, S. (2018). grouin-etal-2019-clinical. A Corpus of Medical Case Reports written in French with Clinical Entity Annotations. Zenodo, pp. 1--2.\n::: Pilet, S., Strube F., & D'Errico, S. (2015). MediNLP: The Corpus of Clinical Cases. Database : The Journal for Applied Biochemistry and Molecular Biology, 2, 1--4.\n::: Cui-Pommier, M. P., F\u00fcrstenau, S., Pilet, S. D'Errico, S., & D'Errico, S. J. (2019). CARDD: Towards a Corpus of Clinical Case Reports with Information Extraction Annotations. Database : The Journal for Applied Biochemistry and Molecular Biology, 10, 1--4.\n::: Dogan, T., Strube F., M\u00fcller, G., & Bontcheva, D. (",
    "dd6b378d89c05058e8f49e48fd48f5c458ea2ebc": " Our gratitude also goes to our colleagues from the QURATOR development team, especially Martin Sch\u00e4fer and Tim Hornecker.\nReferences\n\n#####\n\n\nAllaire, J., Fras, H., Gruner, G., McPherson, R. C. and Ripley, B. (2011) \"Practical XML: Processing Tools.\" In Proceedings of J. Allaire, B. Fras, H. Gruner, J. McPherson and R. Ripley. O'Reilly Media, Inc.\n\nAllen, T. H., Liu, C-C., Gurevych, V., Ng, A. and Yang, H. (2016) \"Toward Understanding Clinical Phenotype Variation in the Electronic Case Record\". In Proceedings of International Conference on Learning Representations ICLR 2016\n\nBekoulis, I., Maragos-Romi, J., Gimenez-Kahn, A., Zadeh, O., Lebiedzinski, J. and Vlachos, I. (2018) \"Jointly Training Relation Extractor and Named Entity Recognizer with Multi-Task Learning\". In BioCreative Workshop at the International Conference on Language Resources and Evaluation.\n\nBIBO, J. J. and Winkler, G. (2012) \"The Named Entity Recognition Challenge: Final Results of the 2010 Joint Session (CoNLL) Shared Task\". Workshop at the 48th Annual Meeting of the Association for Computational Linguistics, Taipei, Taiwan\n\nBIBO, J. J. (2017) \"The Named Entity Recognition Challenge: Final Results of the 2017 Joint Session (CoNLL) Shared Task\". Workshop at the 55th Annual Meeting of the Association for Computational Linguistics, Vancouver, Canada\n\nBIBO, J. J., Hjorth, S. P., Munch, M., Sandvik, S., Aly, H., Kuhn, J., Ratinov, D., Kuhn, O. and Rasmussen, T. (2006) \"The Named Entity Recognition Challenge 2005 Shared Task in Biomedical Text Processing.\" In Journal for Artificial Intelligence Research, 31 (10). Association for Computational Linguistics\n\nBIBO, J. J. (2016) \"",
    "e35c2fa99d5c84d8cb5d83fca2b434dcd83f3851": "\n\nReferences\n \n###  CONTENTS\n\n  1. Cover\n  2. Title Page\n  3. Copyright Page\n  4. Dedication\n  5. Epigraph\n  6. Contents\n  7. The Ducks on the Pond\n    1. Chapter 1\n    2. Chapter 2\n  8. The Drowning World\n    1. Chapter 3\n    2. Chapter 4\n  9. The Falling Star\n    1. Chapter 5\n    2. Chapter 6\n  10. Acknowledgments\n  11. Author's Note\n  12. Praise for the Blackwell Pages\n    1. Introduction: The Art of Worldmaking\n    2. 1. Saving the World\n  13. About the Author\n  14. Praise for the Works of T.C. Boyle\n  15. Acknowledgments\n  16. Also by T. C. Boyle\n  17. Praise for James Patterson\n    1. Acknowledgments\n  18. About the Publisher\n  19. Copyright Page\n  20. **THE**  \n  22. A _Duck's_  \n  23. Lovesong\n    1. Copyright\n    2. About the Publisher\n\n# Guide\n\n  1. Cover\n  2. Contents\n  3. Chapter 1\n\n  1. i\n  2. ii\n  3. iii\n  4. iv\n  5. ii\n  6. \n  7. \n  8. \n  9. \n  10. \n  11. \n  12. \n  13. \n  14. \n  15. \n  16. \n  17. \n  18. \n  19. \n  20. \n  21. \n  22. \n  23. \n  24. \n  25. \n  26. \n  27. \n  28. \n  29. \n  30. \n  31. \n  32. \n  33. \n  34. \n  35. \n  36. \n  37. \n  38. \n  39. \n  40. \n  41. \n  42. \n  43. \n  44. \n  45. \n  46. \n  47. \n  48. \n  49. \n  50. \n  51. \n  52. \n  ",
    "c00ce1e3be14610fb4e1f0614005911bb5ff0302": "\nAcknowledgments\nWe acknowledge the support of I-RODL's funding by the Academy of Finland (grant number 342884).\n\nReferences\n\n\n\"Doomsday Book\" is a work of fiction. Names, places, and incidents either are products of the authors' imaginations or are used fictitiously.\n\nA Del Rey eBook Edition\n\nCopyright \u00a9 2002 by Terry Brooks  \nMap Illustration copyright \u00a9 2010 by Larry Rostant  \nAll rights reserved.\n\nPublished in the United States by Del Rey Books, an imprint of The Random House Publishing Group, a division of Random House, Inc., New York.\n\nDEL REY is a registered trademark and the Del Rey colophon is a trademark of Random House, Inc.\n\neISBN: 978-0-345-50745-4\n\nwww.delreydigital.com\n\nv3.1_r1\n> For my mother,\n> \n> Lena Broekhuis,\n> \n> may she rest in peace, and for my father,\n> \n> Hans W. M. Broekhuis,\n> \n> who's not.\n> \n> May the light of the sun shine in your heart always.\n> \n> And for my brothers, and my\n> \n> darling wife of forty years,\n> \n> Elisabeth.\n_To the future_\nContents\n\n_Cover_\n\n_Title Page_\n\n_Copyright_\n\n_Dedication_\n\nPrologue\n\nBook One - The King's Land\n\n_Chapter One_\n\n_Chapter Two_\n\n_Chapter Three_\n\nBook Two - The Land of the Summer Sea\n\n_Chapter Four_\n\n_Chapter Five_\n\n_Chapter Six_\n\n_Chapter Seven_\n\n_Chapter Eight_\n\n_Chapter Nine_\n\n_Chapter Ten_\n\n_Chapter Eleven_\n\n_Chapter Twelve_\n\n_Chapter Thirteen_\n\n_Chapter Fourteen_\n\nBook Three - The City of the Dead\n\n_Chapter Fifteen_\n\n_Chapter Sixteen_\n\n_Chapter Seventeen_\n\n_Chapter Eighteen_\n\n_Chapter Nineteen_\n\n_Chapter Twenty_\n\n_Chapter Twenty-",
    "71fe5822d9fccb1cb391c11283b223dc8aa1640c": "\nAcknowledgments\nThis work received the generous support of the Google Research Program. We would like to thank the anonymous reviewers and the Associate Editor for their valuable comments and insights that helped to improve the paper. Last but not least, we thank our friends and colleagues from the GALA Lab for their useful feedback on the drafts of this paper.\n\nA. Fetahu. \"An analysis of top trending fake news on Twitter: Part 1: the hoax.\" Journal of Communication Management. 1 (2015): 1\u201317.\n\nB. S. Fetahu, A. De Aguiar, C. Giongo, and I. Chaudhuri.\"Fake, real or irrelevant: assessing the factuality of news tweets in a social media stream.\" In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing (EMNLP 2016), pages 1649\u20131655.\n\nM. Fetahu, A. De Aguiar, C. Giongo, and I. Chaudhuri.\"A neural approach to detect non-factual Twitter accounts.\" The Journal of Machine Learning Research. 19, 1 (2019): 779\u2013800.\n\nG. Flache. \"Detecting fake news content on Twitter.\" Journal of the American Society for Information Science & Technology. (in press).\n\nT. Fritsch. \"Detecting misinformation spreading in Twitter.\" Proceedings of the First International Conference on Big Data and Social Science (Big Data Social Sciences 2016), Seattle, Washington, USA, October 2016.\n\nT. Fritsch, S. Jain, M. Meliou, and F. Popescu. \"Efficient rumor detection based on sequential character chunks.\" The 25th International World Wide Web Conference (WWW 2014) pages 781\u2013790.\n\nS. Fumera, D. Martin, A. De Aguiar, C. Giongo, M. I. Chaudhuri, and S. G. Correia. \"What can we see through the filter: detecting rumors through textual, visual, and contextual features.\" In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP 2015), pages 1714\u20131723.\n\nS. Fumera, M. Meliou, V. Prado, A. De Aguiar, and S. G. Correia.",
    "97d0f9a1540a48e0b4d30d7084a8c524dd09a4c3": "\nAcknowledgments\n\nWe would like to thank the anonymous reviewers for useful comments.\n\n### Acknowledgments\n\nWe would like to acknowledge the support of the NSF I-CLIP, and NSF FAST grant awards 1736172 and 1736175. We would also like to thank the two anonymous reviewers for useful comments and feedback.\n\n### References\n\n[1]  S. Abawajy, A. V. Gururajan, L. Kottur, and C. Cremonese. 2019. Understanding the semantics of news feeds: The evolution of emotional, moral, and stylistic features in clickbait, propaganda, satire and hoax Twitter accounts. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing (EMNLP2019), pages 3343\u20133353, Singapore.\n\n[2]  B. Agarwal, J. Gao, R. He, J. S. Gao, L. Wu, L. Zhu, Z. Chen, A. Ding and K. Qiu. 2019. Propn-gpt2: Propagating contextual knowledge from Wikipedia to text generation-based language understanding. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing (EMNLP-IJCNLP-ACL-AIS-IJCNLP), pages 1529\u20131543, Singapore.\n\n[3]  D. Amir, M. Bamidis, J. Hosseinzadeh, M. W. Moher, S. L. Fei, K. J. Hsiao, and F. Rahman. 2015. Automatic detection of news rumors on Twitter using machine learning techniques. In Proceedings of the 2015 Conference on Empirical Approaches to Natural Language Processing (EMNLP), pages 1742\u20131755, Brussels.\n\n[4]  P. Bello, I. S. Guha, G. G. Huang, J. J. C. Martins, and S. Zhang. 2016. RumourNet: A repository of rumours collected from sources across the web. The Sixth International Web and Social Media Analytics Conference (International WWW), Pisa, Italy, May 25\u201328.\n\n[5]  G. Bhattacharya and P. J. R. Martins. 2019a. A deep sequence modeling method for detecting hoaxes",
    "1062a0506c3691a93bb914171c2701d2ae9621cb": "\nAcknowledgments\nResearch supported in part by National Council of Scientific Research and the Deutsche Forschungsgemeinschaft as part of the Research Training Group BIBREF24 and BIBREF25.\n\nReferences\n[LeftMargin]\n\n[1] A. Lenci, R. Hazarika, and B. C. Olteanu, \"Fake News vs. Political Communication: An Unsupervised Analytic Methodology to Distinguish the Truth in Media\", 2019.\n\n[2] R. Hazarika, and B. C. Olteanu, \"Authentic News, Political News, and Fake News Detection in Twitter Using the LSTM Classifier,\" 2017.\n\n[3] R. Garg, K. M. V. Tewari, and K. K. Nayyar, \"Anatomy of Fake News on Twitter\", 2017.\n\n[4] R. P\u00e9rez-Cruz, I. Corchuelo-M\u00e1rquez, B. C. Olteanu, A. Ribeiro-Ripoll, and T. O. Garc\u00eda-Castro, \"Authentic Social News: Factuality and Trustworthiness of User-Generated Content\", 2017.\n\n[5] Y. Jiang, Y. Li, Y. Guan, and R. C. T. Hsiao, \"Hasty Verification: Early Warning Signs for Fake News in Social Media, 2019.\n\n[6] A. C. B. Ribeiro-Ripoll, Y. Jiang, K. U. de Souza, M. K. H. Yin, and B. C. Olteanu, \"SentiFake.eu: Fake news Detection System for Portuguese Tweets\", 2017.\n\n[7] M. Stella, I. CorchueloM\u00e1rquez, M. G. Barba, E. F. Rocha, and T. O. Garc\u00eda Castro, \"Detecting Rumours and Fake News from Twitter Using Unsupervised Machine Learning\", 2018.\n\n[8] M. Stella, I. Corchuelo-Marquez, E. F. Rocha, T. O. Garcia Castro, D. J. P. Almeida, and M. G. Barba, \"Identifying and Detecting Fake",
    "8e12b5c459fa963b3e549deadb864c244879fe82": " In general, we hope to enhance the quality of the tweets' extraction process and we would like to consider other ways of collecting tweets other than the official Twitter streaming endpoints.\n\nAcknowledgements\nThis work was supported by the Australian Research Council (LP1701032).\n\nReferences\n\n[1] T. R. A. Dale and R. J. Stella, Fake news and fact-checking: assessing the use of social media metadata for detection. Social computing, Social networks and Social media (2017)\n\n[2] I. Farrar and I. O'Callaghan, Fake news: detection and deterrent models for digital misinformation. European Conference on Artificial Intelligence (2017)\n\n[3] J. Sun, P. J. K. Ngan, J. R. R. S. Yeung, and K. K. Fok, Automatic detection of fake posts on Sina Weibo. Computer Science Review 26(4):26\u201338, 2017\n\n[4] B. L. Cui and K. S. Chandra, Discriminating fake news from news using the deep learning approach. International Journal of Advanced Computer Science 8(2):173\u2013182, 2017\n\n[5] C. J. O'Connor, I. O. Fusai, J. A. T. Niehoff, S. E. Kasperczuk, C. Y. Ong, and E. M. Smith, The fake news problem in social media: A new classification method and its performance measurement. Computers, Language, and Society 37:117\u2013136, 2017\n\n[6] Z.-X. Qian, G. Bao, H. Yang, J. R. Liu, K. Hu, and G. W. Wu, Fake news detection based on word-feature analysis in social media content. Communications magazine 47(11):55\u201362, 2018\n\n[7] T. V. Le and L. Chen, Detecting fake news on Twitter with deep learning and deep neural networks. Journal of Computer Science and Technology 34(7):1493\u20131513, 2018\n\n[8] S. W. Wu, Y. Gao, H. R. B. N. Lui, R. P. Lin, and C. J. J. Wang, Automatic fake news detection on short news on",
    "483a699563efcb8804e1861b18809279f21c7610": "\nAcknowledgments. We thank the people of the #hacklab community for the help they give to each other when it comes to code reviews, suggestions or ideas. Further, we are grateful for the support of the CERN's IT Department in hosting the hacklabs and making the environment suitable for the work, and the people in Artificial Intelligence and Data Science unit in helping us develop more advanced approaches. Finally, our work is supported by the Ministry of Finance, Israel, (www.mof.gov.il), and the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme (828198).\n\nREFERENCES\n\n[1] Junker S, J\u00f8rgensen M, Pfeifle T, Le Roux R. The truth in what we read online\u2014why automated fact-checking matters. Eur Pol Sci 2016;22(4):649-665.\n\n[2] Barf I, Tadepalli S, Zubiaga A, Oya M. Fake news on Twitter: A new data source for rumor propagation in social media. ACM Trans Knowl Discov 2018;6(2):25:1-3.\n\n[3] Brands I, Brands R, van der Linden B. The challenge of monitoring, detecting, and detecting fake news: A study of automated detection tools for identifying and rating the reliability of news stories. J Assoc Inf Syst 2017;24(3):17-38.\n\n[4] De Choudhury J, Alsuf O, Kilic N, Dua J, et al. Detecting news misinformation online. In: Conference on Intelligent Information Systems (CIIR,2017), pp. 1\u201311. ACM.\n\n[5] Heil L, Oya M, Barf I. Deepfake detection in videos using deep neural networks. In: International Conference on Learning Representations (ICLR 2018).\n\n[6] Huang X, Chen M, Wang F, et al. Hiding information in texts. In: Conference on Empirical Methods and Technologies for Natural Language Processing(EMNLP 2018)\n\n[7] Ismail H, Wang W, Li L et al. Fake profile in digital environments. In: Proceedings of the 56th Meeting of the Association for Computational Linguistics:Short Papers (",
    "d3ff2986ca8cb85a9a5cec039c266df756947b43": "\nFor a long time, automatic detection of fake news BIBREF0, BIBREF1, BIBREF2 has been a critical topic in the field of Computational Linguistics and NLP. This was mainly due to the amount of misinformation and disinformation shared over social media. This situation is amplified due to the lack of quality measures to assess the credibility of the sources: e.g., for instance, a text or article labeled by a CNN as \"fake\" could turn out to be real, while one labeled \"true\" might actually be a deliberate hoax BIBREF8. As a result, many works focused on the detection of fake news as well as rumors. However, existing methods have been mostly limited to detect fake news at the tweeting level BIBREF8 or the textual level BIBREF25, BIBREF4, BIBREF9, BIBREF26. Here, each fake news claims are manually analyzed and labeled. Thus, they could be viewed as inaccurate to characterize the factualness of the whole account's timeline BIBREF27. Recent advances have investigated the detection of fake news' accounts at account level. However, a number of works, e.g., BIBREF4, BIBREF8, BIBREF28, only consider the textual sources and they discard the information from the accounts' timeline. The main benefit of such an approach is to detect the accounts that might be mixing some real news with a misleading one BIBREF29. Our own approach is based on the former direction. To address this issue, we view the news accounts' timelines as a stream with a sequence of tweets' chunks. We propose a neural model using LSTM to address this problem. Experimental results show that our chunked approach obtain superior results. Furthermore, we propose several ablative tests, to understand the influence of different features on the predictions' accuracy which are important to detect the accounts factuality\n\nAcknowledgments.\nOur work relied on several resources. We thank the data provided by BIBREF1 and BIBREF19. This paper would not be possible without several resources. We thank the authors of the original data and the original work BIBREF2. We thank Hanyu Fan from the Department of Computer Science, The Hong Kong Polytechnic University: for providing BERT, we highly recommend the resource to anyone interested in working in this direction. We thank the developers of hugging",
    "3e1829e96c968cbd8ad8e9ce850e3a92a76b26e4": " Finally, we would like to consider other social media beyond Twitter, such as YouTube, Instagram, and Whatsapp where fake/misleading news spreads rapidly.\n\nAcknowledgment\n\nWe gratefully acknowledge the feedback and discussions with the late James Allan Hightower in the early stages of designing our algorithm.\n\nReferences\n\nBartlett, P. E., & Rutherford, G. (2015). Text Verification in Social Media. Phd thesis, University of Sheffield. Retrieved from: http://documents.worldbank.org/curated/en/7483714261630256670/.\n\nBartlett, P. E., Rutherford, G., & McKeague, I. (2017). Predicting Factuality in Social Media. In Proc. International Conference on Intelligent user Interfaces (IUI), Karlsruhe, Germany.\n\nBengio, Y., Dusso, S., et al. (2015). Sequence to sequence learning with neural networks. CoRR abstr-1532-0000. Retrieved from: http://www.sciencedirect.com/science/article/pii/S0893608035301427.\n\nBozinovski, A., Bougrain, F., & Srinivasan, C. (2009). Semiotic analysis of the semantic content of microblog posts: The case of twitter. Proceedings of the 21st International Conference on Computational Semantics (ICCS), pp. 261\u2013274.\n\nBozinovski, A., Deneuve, C., Djerassi, R., Lafferty, J., Cremisini, E., & Mousserolle, S. (2011). Linguistic and lexical analysis of news reports: Understanding the semantic content of short texts. Proceedings of the 18th International Joint Conference on Natural Language Processing IJCNLP, pp. 1691\u20131698.\n\nBozinovski, A., Di Gregorio, E., & Mousserolle, S. (2012). Understanding the structure of short news reports in newspapers. Proceedings of the 4th International Joint Conference on Natural Language Processing (IJCNLP), pp. 901\u2013908.\n\nCremisi, C., Petrelli, M., & Stent, S. (2014). News verification: Semantic and lex",
    "2317ca8d475b01f6632537b95895608dc40c4415": " Another direction is diachronic analysis for exploring how the behavior of the accounts evolve across time.\nAcknowledgments\n\nThis work is partly funded by the EU H2020 programme under grant number 737375-RISTAFF in the context of WP1 (Coordination and management of R&I Activities), WPs 2, 4, and 7 (Social Media in Society).\nReferences\n\n\\bibitem{zafar:2019}Zafa\u0159anosk\u00fd, J, \u0160afr\u00e1nek, M, and \u0160imkov\u00e1, D. Analysis of Propagandist Fake New Content on Twitter. In: Proakatika: Proceedings on Anti-Rumor and Propaganda in Social Media, pp. 1\u201315. Springer, Cham, 2019.\n\n\\bibitem{zafar:2020}Zafa\u0159anosk\u00fd, J, \u0160i\u0161kov\u00e1, H, and \u0160imkov\u00e1, D. FacTweet: Account-Level Fake News Detection Using Feature Sequences in Chunks. In: IJCAR 2020: Proceedings of the 9th International Joint Conference on Computational Linguistics, pp. 1457\u20131466. Association for Computational Linguistics, 2020.\n\n\\bibitem{zafar:2021}Zafa\u0159anosk\u00fd, J, and \u0160afr\u00e1nek, M. The Role of Sequential Chunking in the Detection of Social Media Propaganda. In: Proceedings of the 5th Joint International Conference on Natural Language, Artificial Intelligence and Robotics, pp. 813\u2013821. Association for Computatio\n\n\\bibitem{elazar:2020}Lazar, M, De Valle Soto, A, and Gat\u00e1n, B. Rumors in Social Networks. In: Natural Language Engineering (NLE 2019), pp. 791\u2013801. Association for Computational Linguistics, 2019.\n\n\\bibitem{zafar:2020a}Yan, W, Lu, B, Ma, T, Jin, W, Jiang, Q, Shen, J, Zhang, Y, and Bao, C. Identifying Lies and Truth on Social Media Using Deep Learning and Knowledge Graphs. In: EMEER2020, The 11th International Conference on Emerging e-Social Sciences, pp. 134\u2013143. Association for Computational Language Learning, 2020",
    "3e88fb3d28593309a307eb97e875575644a01463": " As future work, we are interested in extending this line of research to detecting rumors or detecting falsehoods.\nAcknowledgements\n\nThis work has been initiated at the Turing research fellowship organized by the Alan Turing Institute funded by the UK EPSRC BIBREF24. This work has been supported by the ERC Grant 847156. Moreover, we thank Dr. Roshni Suryadevara of Microsoft Research, Seattle, for her valuable feedback, that helps improve this paper. Finally, thanks to all our other reviewers for their insightful feedback and suggestions.\nReferences\n\n[leftmargin=4mm]\n\n[\n\n[\n\n[\n\n[\n[\n\n[\n[\n\n[\n[\n[\n\n[\n[\n[\n[\n[\n[\n[\n[\n[\n\n[\n\n[\n[\n[\n]\nAbdollah, A., Goyal, M., and Yampolskiy, R. F. (2018). EmoGAN: GIF-based affective expression analysis using generative adversarial networks. In Proceedings of the 9th ACM Conference on Knowledge and Data Analytics, K\\&D 2018, Singapore, pp. 578\u2013586.\n\n[\n\n[\n[\n[\n[\n\n[\n[\n[\n\n[\n[\n[\n[\n[\n[\n[\n]\nAbernethy, R., et al. (2017a). The nature of news on twitter: A statistical characterization of newsworthy events and their dynamics. Science Advances 3(12):e1700503.\n\n[\n[\n[\n[\n[\n[\n\n[\n\n[\n[\n\n[\n[\n[\n]\n[\n[\n[\n[\n[\n]\n[\n[\n\n[\n[\n[\n[\n[\n]\nAbouzeed, E., Shu, Y., Wills, C. J., et al. (2018). Learning to rank for deceptive online news. In Proceedings of the Twenty-Sixth International Conference on International Conference on Machine Learning (ICML 2018), New York, NY, U.S.A., p. 1651\u20131658.\n\n[\n\n[\n[\n[\n[\n[\n[\n[\n[\n]\nAcerbi, E",
    "0767ca8ff1424f7a811222ca108a33b6411aaa8a": " Moreover, we do a comparison of different models for first sentence selection. From that analysis, we get that first co-occurrence based sentence selection performs the best. The first few sentences extracted by using the first co-occurrence model also contains useful information. The first few sentences selected by first co-occurrence model contains useful information although we might have thrown out some not so important information.\nAcknowledgments\nHimanshu Kumar, Sushant Shah, and Sneha Malhotra helped in solving some of the problems encountered during the project. We wish to thank the anonymous reviewers for suggesting a lot of improvements in the methods involved in the paper. This work was partially funded by IIT Kharagpur under the research scholars program. We would also like to thank Prof. M Srinivasan for the valuable advise given to us which helped us in coming up with our first model.\n\nReferences\n\n[BIBREF1]\n\n\"Abstract Meaning Representation (AMR).\" Stanford AMR, 2019. \nhttps://www.cs.princeton.edu/~malt/amr-spec/amr-1-0/.\n\n[BIBREF2]\n\n\"AMR parsing with Deep Larchs: an Open source Java API with a Python wrapper.\" Amr.js, 2017. \nhttps://amjyotshukla.com/amr/.\n\n[BIBREF3]\n\n\"AMRICA: An extensible corpus for AMR generation, parsing and inference.\" K. M. Bhatnagar, 2019. \nhttps://amritanshuverma.com/AMRICA/.\n\n[BIBREF4]\n\n\"AMR guidelines for representation, parsing, inference, and generation.\" The Penn AMR project. 2019. \nhttps://amr.lsi.upenn.edu/amr. \n[BIBREF5]\n\n\"Statistical AMR parsers.\" AMR project. 2015. \nhttp://jyotirmrtyagi.com/amr/parsers.html.\n\n[BIBREF6]\n\n\"Borrowing lexical cues for better AMR phrase-structure parsing.\" AMR project. 2015. \nhttp://jyotirmrtyagi.com/amr/parsers/amr15.html",
    "e8f969ffd637b82d04d3be28c51f0f3ca6b3883e": " We show the need of a new evaluation metric for evaluating generated summaries. We also present a new gold-standard AMR annotated corpus for summarization, making our evaluation results more reliable. Finally we show, that if we use the gold-standard AMR graphs, there is significant drop in ROGUE scores when compared to Lead-1-AMR baseline.\nAcknowledgements\nThis work was a part of our final year project at IIT Bombay. Our work is possible because of the efforts put in by our friends. We thank our friends Ankita Jalota, Mayank Srivatsa, and Anirudh Bhadra who helped a lot in the research work and to make this work more readable. We thank Srinath Rajkumar who has provided his gold-standard AMR graphs. We thank our teachers and examiners for giving us such a great environment for research. We thank our lab in-charge, Manuj Dangatkar and faculty members of NLP Lab for providing us an excellent lab environment.\nAcknowledgment is extended to NLP lab, IIT Bombay and department of computer science and engineering, IIT Bombay. We acknowledge support of Tera Compute resource from CSE Department.\nReferences\n\n[1] T. Kudo N. Mihalcek and M. Polanyi. 2012. Amr: A representation for abstract meaning. In S. Das, T. Huang and N. Narkawaty, editors, Abstract Meaning Representation (Amr) 1:AMR specifications and guidelines. International School on Natural Language Processing, pages 3\u201345. Interspeech.\n\n[2] T. Kudo, M. Polanyi, K. Asher, B. Van Durme and D. Yates. 2011. JAMR. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 27\u201334. ACL.\n\n[3] S. Das, T. Kudo, M. Polanyi, T. Asher and D. Yates. 2007. JAMR: a joint aligner-mapper-reader for parsing and learning from aligned data. In Proceedings of the 2007 Conference on Empirical Methods in Natural Language Processing. ACL.\n\n[4] T. Kudo, S. Das, M. Polanyi, D. Yates and D. Hyland. 2008",
    "46227b4265f1d300a5ed71bf40822829de662bc2": " Most noteworthy we showed that the current dataset contains very high amount of extractive nature which prevents the state-of-art methods from producing summaries good enough for human level evaluation.\nAcknowledgments\nThis work was done as part of the final year project at Department of Computer Science and Engineering, Indian Institute of Technology Bombay. Authors would like to thank Dr. Anupam Bhattacharya for his guidance. Authors would also like to thank Dr. Swasti Sasidharan for the suggestions. Authors also thank Sai Vishwesh Krishna, Anubhooti Gupta, Suyash Sharma, Sanjana Rajagopal, and Vishvesh Sharma for the help during the implementation, testing and evaluation of the pipeline. Authors would like to thank Rahul Kesharwani and Yash Gautam for help in preparing paper.\n\nA.~AMR Bank\n\nAMR Bank, an annotation-based summary generation\n\nB.~BIBREF0 BIBREF0\n\nBibRef, a tool for annotating English Language Resources with AMR graph representations\n\nB.~BIBREF12 BIBREF12\n\nAbstract Meaning Representations: the AMR Specification and Resources for Interoperability\n\nB.~BIBREF24 BIBREF24\n\nAutomatic Sentence Alignment for Computationally Generated Texts\n\nB.~BIBREF28 BIBREF28\n\nAbstract Meaning Representations for Automatic Text Summarization\n\nB.~BIBREF33 BIBREF33\n\nA Recurrent Neural Network for Natural Language Generation\n\nB.~BIBREF35 BIBREF35\n\nRecurrent neural network models for syntactic-semantic parsing\n\nB.~BIBREF38 BIBREF38\n\nCombining AMR parsing and generation to improve the efficiency of summarization\n\nB.~CARET2CARET2\n\nClustering Abstract Meaning Representation (AMR) with sentence information for Abstractive Summarization\n\nB.~CAMR1CAMR1\n\nA grammar and lexicon-based system for automatic construction, application, and evaluation of semantic analysis components\n\nW. Chen, D.~Ciaramita, S.~Habash, S.~Chaffee.\n\nB.~H.~Hir",
    "a6a48de63c1928238b37c2a01c924b852fe752f8": " We believe that this work may also give new insights into the extraction problem as we showed results on the CNN-Dailymail corpus for the first time.\n\n\n\nContents\n\nAbout the Book\n\nAbout the Author\n\nAlso Available by Robert E. Howard\n\nDedication\n\nBy the same Author\n\nCopyright\n\nPraise For The Curse of the Mound-Builders\n\nCopyright Acknowledgements\n\nAbout the Book\n\n'...so dark its dark...'\n\nThe city of Thag, city of the yellow-haired people, lies on the shore of the Sea of R\u00f4an where black sails with yellow-tinted sails in the bows of the rowboats come from the far horizons against the crimson sky, and the white-sailed ships from the lands to the west beyond the sea where the men have yellow skins and look with their single eyes upon a black world; where the sunless caves under the earth and the moldering temples without gods and kings where the yellow-skinned men hold meetings at the dim dawn and where in the hot noon the yellow-skinned wanderers from a thousand cities walk the streets at the feet of the dark, silent crowds, looking at the white walls and the yellow houses with their tall roofs which are like birds, and they touch the gold and the silver upon the temples and on the roofs that are like birds.\n\nIn the city of Thag the yellow-skinned people build their huge brown houses and dark-brown temples with a gold roof in the shape of a bird where are altars of bronze and silver and marble and stone and where are priests of iron and bronze and stone which talk to the god of the sun. And they burn candles of tallow and of wax and of fat which are like fat at such altars of stone and of silver and at the foot of the golden bird which is like a beast, and the yellow-haired people sit there and look upon the sea, and there is the Sea of R\u00f4an, the blue sea with black sails and with ships which are like birds, and sometimes a sun which is like a beast, and the ships are full of spices and of gold, and sometimes, the yellow-skinned men go upon ships, and other ships come, and there is talk of a great king far to the west where the sun burns in the west upon the lands which are",
    "b65a83a24fc66728451bb063cf6ec50134c8bfb0": " We propose two alternative ways to evaluate abstractive summary. The first is to evaluate the sentences after step-1 using the gold standard dataset. The second can be to extract from multiple sentence clusters and then selecting summary of those cluster.\nAcknowledgements\nI would like to thank my mentor Prof. A. H. Malleswari and my Ph.D. advisor Prof. Kalyanmoy Deb for their constant support and valuable guidance. I would also like to thank everyone in the Natural Language Processing lab at IIT Delhi for providing a good research and work environment.\nCodes can be found at https://github.com/Hackar/SummARGraph\n\nReferences\n\n[BIBREF1] N. Diab, T. Klein, A. Lascarides and M. Zeman. Abstract Meaning Representation Description. In Proceedings of ACL 2009, pages 179\u2013186.\n\n[BIBREF2] P. N. Acero, J. Klein, A. M. Tsvetkov and G. Neubig. AMRs: A community resource for semantic representation and understanding of meaning. In Proceedings of the SemEval 2007 Workshop.\n\n[BIBREF3] R. S. Klein, N. Diab and T. Klein. Mining Co-Natural Language Data with Abstract Meaning Representation for Generating Sentence and Paragraph Summaries.\n\n[BIBREF4] N. Diab, T. Klein and R. Klein. Abstract Meaning Representation Formalism: Specification and Guidelines.\n\n[BIBREF5] K. Diab, T. Klein, J. Klein and R. Klein. JAMR: A joint AMR-syntax parser and chunker. In Proceedings of the CoNLL 2006 Workshop.\n\n[BIBREF6] E. Barnea, C. Derczynski, M. Gelfman, H. Li, H. Nakha\u00efs and D. Sennrich. Improved AMR Parsing using Shift-Reduce Transformation. In Proceedings of the CoNLL 2007 Workshop.\n\n[BIBREF7] M. Bar-Haim. Neural Sequence to Sequence Generation for Abstract Meaning Representation.\n\n[BIBREF8] H. Nakha\u00efs, M. Bar-Haim, N. Diab and T. Klein. Amr",
    "8c852fc29bda014d28c3ee5b5a7e449ab9152d35": " We would also like to acknowledge the support and encouragement of our supervisors and our advisor for their mentorship.\n\nContributions\nH.H. and F.L. were responsible for the collection of the data, the creation of the dataset (H.H.) and for the experimental method in Offensive Language Identification (F.L.). S.W. and H.S. performed the experiment setup and analysis, and discussed the results and conclusions. S.W. was responsible for annotation training during the development of OLID and the annotation of the official data set (H.S). S.W. annotated the crowd-sourced data for OLID under supervision of H.S.\n\nReferences\n\n1. Burnap, P. G. (2015). \"Computational Psychology.\" Handbook of computational psychology, pp. 1\u20139. Elsevier, Amsterdam.\n\n2. Bunt, F., Chaudhury, N., and De Ruyter, T. (2017). \"Identifying offensive language in social media using deep learning.\" arXiv preprint arXiv:1706.07497.\n\n3. Djuric, T. and Kwok, R. (2009). \"Locate hate speech: a computational approach to detection and location of hate speech in social media.\" Proceedings of the 7th Workshop on Cyberbullying, pp. 15\u201322.\n\n4. Elhadad, H., Chen, C., Imbens, M., and Zhang, X. (2017). \"Automated identification of profanities on social media.\" EMNLP. (pp. 1453\u20131458).\n\n5. Fathi, Y., Poria, O., and Ng, S. (2016). \"Cyberbullying detection.\" In Proceedings of the 22nd ACM SIGIR Conference on Research and Development in Information Retrieval, pp. 231\u2013234. ACM, New York, NY, USA.\n\n6. Gamon, M. (2017). \"Automatic hate speech detection for social media.\" Semantic extraction and analysis, pp. 31\u201344. IGI Global, Hershey, PA.\n\n7. Gamon, M. (2018). \"Identifying hate speech and abusive language in social media.\" Computational Social Sciences, 3, 5(1), pp. 3.\n\n8. Geerts, J., Bunt, F",
    "682e26262abba473412f68cbeb5f69aa3b9968d7": "\n\nReferences\n\n[1] Ahmed A, & Alemzadeh Y. Twitter Sentiment Analysis. Proceedings of the Twelfth International Workshop on Semi-Supervised and Weakly Supervised Learning.\n\n[2] Bakhshi G, & Smyth W. Social Media and Abuse in the Legal Domain. Presented In: LREC 2018 \u2013 9th Meeting of the European Chapter of the Association for Computational Linguistics. Lecture Notes in Computer Science.\n\n[3] Barbarin F, & Gurevych M. Cyber-Aggressive Behaviour on Social Media. ScienceDirect. Springer.\n\n[4] Barrett-Baxter E, & Barros H. Detecting Cyber-Bullyism in Twitter. Computational Linguistics and Cognitive Processing, pp. 12\u201322.\n\n[5] Breiner P, & Pang S. Detecting Aggressive Tweets in the Legal Domain. Proceedings of the Workshop on Mining Advocacy Datasets at SIGIR 2016.\n\n[6] Brands, & Tomas-Reyes K, & Verbaket E, & Huth A. Offensive Language Identification using Social Semantics: Evaluation of Feature Selection using Ensemble Classifiers. The Proceedings of the Twenty-Seventh ACM Joint Conference on Digital Libraries.\n\n[7] Bronder M, & Nugroho W. Detecting Abuse in Web Forum Posts With Convolutional Neural Network. International Journal of Computers and Applications, v. 42, p. 51\u201370.\n\n[8] Burnap R, Hao Y, & Mynott A, & Fortunato S, & Zhang F, & Chen, & Ollivier G, & O'Connor R, & Craswell S, & Pang J. Cyberbullying in Social Media Communities. ACM Transactions on Information Systems, (TOIS), 40(4), pp. 1\u201327.\n\n[9] Ciot R, & Cimperman J, & Hovy J. A Machine Learner-Based Hate-Speech Classifier for a Dutch Twitter Corpus. Language Resources and Evaluation, 63(3).\n\n[10] Corley H, & Mejia-Rodriguez J, & Le Goff C, & Etemad Z, & Re A",
    "5daeb8d4d6f3b8543ec6309a7a35523e160437eb": " We are grateful for all the annotators, crowdsourcers, and other contributers to OLID and OffensEval. References\n\n1. S. Ames, et al. (2017). Offensive Language in Twitter: A Content Analysis of 14.3 Million Tweets. International Journal of Computational Science and Engineering 4(3): 1?16.\n\n2. P. Lenssen and J. van Dongen. (2015). Cyber-aggression, bullying, and hate speech: a social media based content analysis of over 19 million tweets. Journal of Behavioral Informatics and Computational Social Science 1(2): 101935.\n\n3. L. xu, et al. (2012). Learning to Predict Cyberbullying Using Semantic Components. Social Advances and Scientific Theory 2: 19\u201324.\n\n4. T. Ettmayer, et al. (2014). Finding Aggressors in Online Conversations: Investigating a New Approach for Cyberbullying Detection on Twitter. Lecture Notes in Computer Science 8211: 177?185.\n\n5. H. Kim, et al. (2018). Profane Language in tweets: What Predicts Sarcasm and Offensive Tweets? Proceedings of the Fourth International AAAI Conference on Web and Social Media.\n\n6. V. Waseem, et al. (2017). Typology of Offensive Language in Twitter. Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, CEMNLP'18.\n\n7. B. Kwok, et al. (2013). Learning to Locate Hate Speech in Twitter: A Machine-Learning Based Approach. In Proceedings of the 13th International Workshop on Computational Linguistic Annotation, CoLA-2013, pages 55:59?65.\n\n8. A. Garg, et al. (2016). Mining Twitter for Offensive Language: Learning and Evaluating Word-Level N-grams. Journal of Web Semantics 39(14): 39?54.\n\n9. V. Garg, et al. (2016). Discrimination of Toxic Comments on Wikipedia: A Machine Learning Approach. In Proceedings of the 2016 CICLing Conference.\n\n10. C. Sch\u00f6ttle, et al. (2017). The GermEval 2017 Shared Task on Offensive Language Identification in Twitter. International Journal",
    "74fb77a624ea9f1821f58935a52cca3086bb0981": "\nReferences\n\n[BIBREF0 ]\n\nBerg-Kirkvaig, H., and V. Wigington. 2014. Offensive Language in Online Media\n\nBIBREF1\n\nS. Wiesand, T. Pechenizki, P. Hagen, S. N. Stukel, X. Ma, L. He, and J. Kiesler. 2018. Identifying and Classifying Aggression in Twitter: First Results of the AggresEval 2014 Shared Task. In ACL-IJCNLP, pages.\n\n[BIBREF2 ]\n\nBerg-Kirkvaig, H., A. Kriesel, T. Pechenizki, P. Hagen, S. Hagemann, S. N. Stukel, X. Ma, L. He, C. L. Hsu, L. Zhai, and J. Kiesler. 2016. Identifying Aggression in Twitter with Lexical and Sentiment Features: First Results of the AggresEval 2016 Shared Task. In ACL-IJCNLP, pages.\n\n[BIBREF3 ]\n\nWiegand, F., I. Warnat, T. H\u00f6lzl, E. Nekhlyudov, and Y. Ma: 2015. A Corpus-based Analysis of (Cyber)-bullying in Tweets. In COLING, pages.\n\n[BIBREF4 ]\n\nMa, Y., M. Cimini, J. Kiesler, F. Wiegand, P. Hagen, H. Berg-Kirkvaig, X. Ma, S. Hagemann, C. Wellinghoff, C. Schaeffer, and D. H. Chisholm. 2015. BullyDetector: Detecting (Cyber)-bullying Tweets in English. In COLING, pages.\n\n[BIBREF5 ]\n\nVidgen, R., G. M. Schwartz, and J. Cimino. 2016. Analyzing Tweets for Hate Speech: The Hate Speech Dataset. In Proceedings of the 6th Conference of the North American Chapter of the Association for Computational Linguistics and the Human Language Technologies Conference, pages.\n\n[BIBREF6 ]\n\nJ. Zhang",
    "d015faf0f8dcf2e15c1690bbbe2bf1e7e0ce3751": "\n\nReferences\n\nAgarwal, V., & Bagnoli, A. ( 2014). Social Network Analysis for Public Opinion Tracking. In: Agarwal, V. (Ed.), Advanced Trends in Social Media: A collection of innovative methods for predicting user preferences and behavior (pp. 29-43). Cham, Switzerland: Springer.\n\nBIBREF0. H. K., S. Chou, L. H., Chen, I. I., Jain, A., Choi, S. M., Jannin, M., Leblanc, R., Liao, J. J., & Nguyen, J. (2017). \"Gender classification of Twitter users using supervised learning.\" In: Proceedings of the Seventh International Conference on Human Language Technologies, 2014.\n\nBIBREF1. R. Heilman, S. Chou, V. Krishnan, I. I., & A. Rens, (2018). \"The effect of social signals in aggression detection: Learning user signatures from Twitter.\" In: Proceedings of the International Conference on Learning Representations, 2018,.\n\nBIBREF2. E., C., & B. E., (2013). \"Aggression identification in social media: An evaluation of approaches.\" In: Proceedings of the International Conference on Learning Representations, 2013, pp. 2434-2444.\n\nBIBREF3. R., M. B. & J. (2014). \"Social network analysis for bullying identification in social media.\" In: Proceedings of the 8th International Workshop on Social Network Analysis, 2014, pp. 1-8.\n\nBIBREF4. A. B., (2018). \"What's behind tweets? An exploration of Twitter's cybergossip network.\" In: Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing.\n\nBIBREF5. E., C., M. R., A. A., & Z. C., (2016). \"Detecting toxic comments in online debate.\" In: Proceedings of EmNLP 2016, (pp. 17-25).\n\nBIBREF6. J., A., L. L. & G., H. (2016). \"Hate speech detection.\" Journal of Applied Linguistics, (online), pp. 1-17.\n\nBIBREF7. E., L., B., S. M. & O. S",
    "55bd59076a49b19d3283af41c5e3ccb875f3eb0c": " We would like to thank David Djuric for his assistance in designing the experiment.\n\n\n_Governing_ _the_ _Gal\u00e1pagos_ _Archipelago_\n\nDavid J. Nabus\n\n\u00a9 2016 by David J. Nabus\n\nAll rights reserved. No part of this book may be used or reproduced in any form or by any means, electronic or mechanical, including photocopying, recording, or by any information storage and retrieval system without permission in writing from the publisher.\n\nThis is a collection of work of fiction. All events portrayed in this book are fictitious.\n\nSome names, characters, properties, places, and incidents are the product of the author's imagination or are used fictitiously. Any resemblance to actual persons, living or dead, events, or locales is entirely coincidental.\n\nISBN 978-1-61773-078-0\n\nLibrary of Congress Cataloging in Publication Number: N2014-1243\n\nTo my family\n_Governing the_ _Gal\u00e1pagos_ _archipelago_\n**Prologue**\n\nThe sea was a perfect expanse of dark blue beneath a blindingly sunny day, and though you couldn't see them, there was a myriad of sea creatures swirling below the surface.\n\nJules, his face set, was on his yacht, riding the waves with more enthusiasm than might be expected, considering the fact that it had become clear over recent years that ocean swimming was now a dangerous thing. Jules was swimming toward the islands of Floreana, Santa Cruz, and Isabela before he had breakfast. He had never liked the idea that he should wait, and in recent years, there had been a marked decline in the number of passengers to the Gal\u00e1pagos, so he was able to swim to the islands and wait for the passengers to gather at the dock. On some tours he had to swim to Egas Port, the landing on Santa Cruz, or as far as the beach in Espanola.\n\nOn this morning he could hardly contain his glee, to be traveling on his new yacht, _Sea-Kreature_, heading to the archipelago that was home to some of the most bizarre life forms on earth. But in the past eight months when he had traveled to the archipelago with the guests, he had found",
    "521280a87c43fcdf9f577da235e7072a23f0673e": " We thank Waseem Ahmad Shah BIBREF12 and Philipp K\u00fcsters BIBREF11 for their valuable feedback.\nReferences\n\n[1] http://en.wiktionary.org/wiki/list_of_words_for_denoting_race\n\n[2] http://en.wiktionary.org/wiki/list_of_words_for_gender\n\n[3] http://en.wiktionary.org/wiki/list_of_words_for_ethnicity\n\n[4] http://en.wiktionary.org/wiki/list_of_words_for_disability\n\n[5] http://en.wiktionary.org/wiki/list_of_words_for_sexual_orientation\n\n[6] E. Krahmer and M. Piotr-Szewczyk. A lexicon and a morphological analyzer for sex-linked word form. 2008.\n\n[7] https://www.census.gov/asr/www/asrprod_lists/aa_word_lists/aa_lwp_lists/aa_lwp_list_a/\n\n[8] http://en.wiktionary.org/wiki/list_of_words_for_disabilities_or_impairments\n\n[9] http://en.wiktionary.org/wiki/list_of_words_for_sexual_orientation_sexual_preference_sexual_identity\n\n[10] http://en.wiktionary.org/wiki/list_of_words_for_religion\n\n[11] http://en.wiktionary.org/wiki/list_of_words_for_sexual_orientation\n\n[12] B. Wiegand, A. Sennrich, A. Tischert, and G. Ried. A Joint Model for Detecting Toxic Comment and Aggressive Language in German Twitter. In Proceedings of the COLING/AAAI-19 Workshop: Language and Confrontational Toxic Speech, pages 7\u221212. 2018.\n\n[13] Y. Xu, Y. Fan, D. Zhu, G. Liu, S. Zhou, A. Jiang, and X. Han (2017). Cross-lingual Transfer and Domain Adaptation for Sexual Harassment",
    "5a8cc8f80509ea77d8213ed28c5ead501c68c725": "\nReferences\n\n[1] B. Albright, R. Riquelme, S. Deo and V. Ramaswamy. OffensEval Shared task: Identifying and Categorizing Offensive Language in Social Media. Proceedings of the 18th International Workshop on Semantic Evalu-ation, 2019.\n\n[2] B. A. Aronson.\n\nIdentifying Offensive Comments in Conversations on Twitter: A Large-Scale Evaluation on the Impact of Sentiment and User Re-Tweeting. 2018 Conference on Empirical Methods in Natural Language Processing. http://arxiv.org/abs/1806.09688\n\n[3] B. Bailer-Jones.\n\nComputational approaches to hate crime and abuse in social media. In First Workshop on Empirical Methods in Language Processing (EMNLP), 2016 November. http://aclweb.org/anthology/D16-1172\n\n[4] P. Bailer-Jones, S. M. Mohammad, N. Sheth, A. M. Garg, and D. W. Pardos. Bytesome: a deep learning model for detecting and distinguishing cyberbullying in twitter. http://www.aclweb.org/anthology/P18-1107\n\n[5] P. Bailer-Jones, S. Mohammad, Y. Liu and D. W. Pardos. Sarcasm in abusive tweets : a corpus analysis. Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. 2016.\n\n[6] C. Bank, C. B. Dow, V. A. D. Williams, B. A. Aronson, E. Aroyo, S. Choi, S. Deo, G. S. Eversley, and C. Y. Ng.\n\nToxic tweets challenge : A data repository for computer-assisted research on the semantic Web. 2018. http://tric.unl.pt/content/pdfs/Ding2018.pdf\n\n[7] A. Bayer, A. Tuffery, M. P. Jones, B. Aronson and N. Sheth. Twitter brawl dataset : Identifying and categorizing offensive content in tweets and tweets replies. 2014 Proceedings of the 56th Annual Meeting of the Association for Computational",
    "290ee79b5e3872e0496a6a0fc9b103ab7d8f6c30": "\nBIBLIOGRAPHY REFERENCES\n\n[BIBREF0] C. Burnap, A. Hovy, and H. N. Turney. 2015. What is offensive? Characterization of the perceived and experienced toxicity of English Twitter discourse. International Journal of Human Computer Studies, 76, 25-36. http://dx.doi.org/10.1016/j.ijhcs.2015.05.003.\n\n[BIBREF1] G. Caillet, M. Spitkovsky, B. Eskandarpour, B. Kiela, G. Alam, E. Rialle, and L. Nenkova. 2018. Dealing with Cyberaggression in Twitter: Towards Triage-aware Response Strategies. In NIPS, 15:6.\n\n[BIBREF2] A. Dadvar, B. Zafar, J. Leopold, S. R. H. Fassih, and M. Alvarez-Melis. 2013. Cyberbullying Prediction by Learning Social Contextual Features Using Word Associations. In EMNLP, 8:1925\u20131935.\n\n[BIBREF3] Y., Y., S. K. W. Lau, J. M. R. Wee, D. Tavanaen, K. A. Everson. 2015. Affective and Cognitive Aspects of Cyberbullying: A Study on Adolescents in a Virtual Environment. In CHI, 16:2799\u20132808.\n\n[BIBREF4] W. J. K. Djuric, E. D. I. de Melo, T. Derczynska, A. A. J. Corrado, S. Chaudhary, L. Moura. 2015. Automatic Detection of Hate Speech in Tweets. In Interspeech, 2015:1225\u20131229.\n\n[BIBREF5] Y. Huang, B. L. Yang, Z. Gu, Z. Q. Lu, M. Zhu, and S. N. Li. 2018. Detecting Hate in Tweets with Convolutional Neural Networks. In IAR, 19:5873\u20135879.\n\n[BIBREF6] K. H. Lim,",
    "1b72aa2ec3ce02131e60626639f0cf2056ec23ca": " We would like to thank the UK Department for Business, Energy and Industrial Strategy for funding this fellowship.\nTable TABREF01\n\nDataset of abusive posts divided into offensive (OFF), non-offensive (NOT), and insult (TIN) posts.\n\nTable TABREF02\n\nTotal tweet number per label, number of labels per tweet, F1-score per label across sub-tasks.\n\nTable TABREF03\n\nData statistics of offensive labels in OLID.\n\nTable TABREF04\n\nTotal offensive tweet number per label, number of labels per tweet, F1-score per label across sub-tasks.\n\nTable TABREF05\n\nTotal offensive tweet number per targeted/untargeted insult and threats (TIN/TUNT) and untargeted profanity/swear (UNT/INTR).\n\nTable TABREF06\n\nTotal number of target labels per label, number of labels per tweet, accuracy per label across sub-tasks and the percentage and number of labels per target.\n\nTable TABREF07\n\nNumber of tweets and number of labels per tweet between the target classes in OLID.\n\nTable TABREF08\n\nPercentage of labels across training and testing data across three label levels.\n\nTable TABREF09\n\nExample training data and evaluation data for offensive language detection and offesive target identification.\n\nTable TABREF10\n\nExamples of offensive language levels of labels for offensive language detection and offensive language target identification.\n\nTable TABREF11\n\nOffensive language categories for offense detection level-A annotated by expert judges.\n\nTable TABREF12\n\nOffensive language categories for offense detection with one of the main labels as target-A (OLID/Test).\n\nTable TABREF13\n\nOffensive language categories for offense detection with target-C (OLID/Test).\n\nTable TABREF14\n\nNumber of labels, tweets and average annotated time across annotation levels for the trial data.\n\nTable TABREF15\n\nNumber of labels, tweets and average annotated time across target classes of offline language identification.\n\nTable TABREF16\n\nOffensive language categories for level-B and example labels annotated by expert judges.\n\nTable TABREF17\n\nOffensive language categories for level-B with main label as target-B (OLID/Test).\n\nTable TABREF18",
    "c49ee6ac4dc812ff84d255886fd5aff794f53c39": "\n\nReferences\n\n[1]\n\nAcevedo-Ochoa, M., & O. C. Chapetto. 2011. Statistical and semantic analysis of topic coherence in text summarization evaluation. In Proceedings of the 2011 conference on empirical methods in natural language processing, pages 66\u201372.\n\n[2]\n\nAnandabhasin, T., R. J. Howes, P. K. B. Le, and U. Asher. 2010. Finding meaningful relationships in summarization systems: Measuring the usefulness of summarization with the Pyramid quality index. In Proceedings of the 24th annual meeting of the Association for Computational Linguistics, pages 1298\u20131307.\n\n[3]\n\nAsher, U., D. Dang, A. Taft, I. Danihelka, & U. Asher. 2013. Human evaluation of summarization using the pyramid quality index. In Proceedings of the 42nd annual meeting of the association for computational linguistics: Short papers, pages 88\u201393.\n\n[4]\n\nBallesteros, E. L., X. Liu, A. J. R. Downey, & Z. Bain. 2014. Summarizing technical documents with Latent Semantic Analysis. In Proceedings of the Text Analysis Conference, pages 35\u201343.\n\n[5]\n\nBecker, R., Y. Zhang, Y. Zhou, S. M. Cohen, C. A. Craswell, Y. Qin, and T. L. Griffiths. 2014. Automatic discovery of knowledge-rich nuggets in scientific documents using an information retrieval approach. In Proc. of the conference on Empirical Methods in Natural Language Processing, Stroudsburg PA.\n\n[6]\n\nBecker, R., Y. Zhang, J. G. Rosenthal, C. A. Craswell, Y. Qin, and T. L. Griffiths. 2015. Automated summarization by co-reference resolution using citation networks. In Proceedings of the Text Analysis Conference, pages 1\u20139.\n\n[7]\n\nCohan, A., A. M. Sutayev, A. Wu, & Y. Qin. 2013. Coherent summarization of complex research papers. In Proceedings of the 40th Annual Meeting of the Association for Computational Languages",
    "3f856097be2246bde8244add838e83a2c793bd17": "\n[1]\n\n<http://www.lexrank.com/about/\n[2]\n\n<http://duc.nist.gov/\n[3]\n\nR. Zaj\u010dev: A survey of automatic evaluation measures for summarization BIBREF1\n[4]\n\n<http://aclweb.org/Workshops/2012/NELS-Summ/papers/Abu-Jawdah-ACL12.pdf\n[5]\n\nE. Zajczegier, X. Zhang: Analyzing the effectiveness of metrics for evaluating summarization BIBREF2\n[6]\n\n<https://www.aclweb.org/anthology/J11-1124/\n[7]\n\nDUC: The Document Understanding Conferences BIBREF3\n[8]\n\nTAC: The Text Analysis Conferences BIBREF3\n[9]\n\nD. Cieri, F. d'Ottavio: LexRank: summarizing the web by ranking sentences BIBREF4\n[10]\n\nY. Zhai, S. Awasthi, G. Cohen, E. Zadrozny: LSA based summarization for large texts BIBREF5\n[11]\n\nJ. R. Banko, J. A. Wiebe, D. Cormack: Maximal marginal relevance BIBREF6\n[12]\n\nH. Ataei, K. Haj-Miranda, A. Cohan, S. R. Smith: Summarizing technical documents using citation network analysis BIBREF7\n[13]\n\nJ. N. Bazadonia, J. V. Poggi, R. X. Chu, M. Pustejovsky (Eds.): First Workshop on Knowledge Discovery and Data Mining in Scientific Datasets (KDDC) BIBREF8\n[14]\n\nP. J. Olheiser, L. A. Heller, T. K. Landauer: Using word frequency to estimate the saliency of documents BIBREF9\n[15]\n\nS. F. R. Rodrigues, D. Bunt: SumBasic: document length normalizing summary extractor BIBREF10\n[16]\n\nS. F. R. Rodrigues, A",
    "bf52c01bf82612d0c7bbf2e6a5bb2570c322936f": "\nBerman, M., Kulkarni, S., & Lee, N. (2007). A comprehensive evaluation in news summarization. In Proceedings of the 16th text analytics conference (TAC), pages 1\u20139.\nBIBREF1\nRajpurkar, P., Etzioni, O., & Dredze, K. (2012). The evaluation of automatic text summarization systems. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL), pages 2491\u20132500.\n\nBIBREF1\nRus, S., McKeown, J., & Chinchorla, D. (2003). An evaluation of automatic summary evaluation metrics. In Proceedings of the 3rd annual conference on intelligent virtual agents (AI-XIII)\n\nBIBREF1\nGraham, D., Dredze, K., & Etzioni, O. (2010). A comprehensive evaluation in news summarization, revised. In Proceedings of the 10th international conference on intelligent text processing and analysis (CICLing), pages 61\u201372.\n\nBIBREF2\nDod:2014\n\nHovy, O., Dredze, K., Chinchorla, D., & Turney, S. (2006). Automated assessment of news summaries: comparison and contrast of the automated and human evaluations. In Proceedings of the 1st Annual Conference On Evaluating Automatic Translation (EAT), Stockholm.\n\nBIBREF1\nabu, M. S. (2011). Coherent text summarizers via a novel approach to cohesion analysis. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL), pages 1091\u20131102.\n\nBIBREF3\nTAC:2014\n\nCohen, M. J., Dabbagh H. A., Ginsberg S. M., & Etzioni O. (2013). Topic models for scientific abstracts. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics (ACL-IJCNL), pages 2126\u20132133.\n\nBIBREF1\n\nRus, S. R. K., McKeown, J., & Chinchorla, D. (2004). An analysis of automated text summarization of scientific biomedical documents. In Proceedings of the 20",
    "74e866137b3452ec50fb6feaf5753c8637459e62": "\nReferences\n\nBIBREF1\n\nBaeza-Yates, R., Robal, L. and V\u00e9ronis, A. 2012. ROUGE: a suite of evaluation metrics for automatic text summarization. International Journal of Computational Linguistics, 29(2), 99-118.\n\nBIBREF10\n\nQazvinian, A., Kucija, S. and Mohan, V. 2013. Scientific summarization with latent semantic analysis. Proceedings of the 32nd international conference on machine translation. Montreal: Association for Computational Linguistics.\n\nBIBREF11\n\nHofmann, T., Lascarides, C., Ng, A., and Cutting, B. 2007. Singular value decomposition for text summaries. In Proceedings of the 42nd annual meeting of the association for computational linguistics, vol 2: short papers, pp 211-217.\n\nBIBREF12\n\nCohan, A., Dabbagh-Nashar, O., Sorensen, K. and S\u00f8gaard, M. 2015. Sentence Selection for Summarization of Scientific Papers. Proceedings of the 32nd Text Analysis Conference (TAC' 15) Workshop on Scientometric Summarization, Berlin.\n\nBIBREF13\n\nZanzotto, S., Baroni, G., Turini, D., Baroni, L. and Scarselli, F. 2010. Citation based summarization. In Proceedings of the 18th international conference on the theory and applications of semantic and latent dirivative analysis, pp 151-159.\n\nBIBREF14\n\nHuet, F., Mett\u00e9, C., and Simard, R. 2013. Sumbasic: Using content to summarize. In Proceedings of AMTA 15, pp 103-111.\n\nBIBREF15\n\nHermelink, G. and Van Heuveln, J. 2010. Probabilistic Summarization using Citation Context and Discourse Structure. In Proceedings of the 14th Conference on Language Resources and Evaluation (LREC' 10), Miyazaki, Japan.\n\nBIBREF16\n\nKaushal, V., Singh, M., Nawaz, M. and Ganchevicius, V. 2014. From Sentence to Sentence: Summarizing Scientific Texts. Proceedings of",
    "184b0082e10ce191940c1d24785b631828a9f714": "\nCohan, A. H., & McKeown, A. M. (1995)\nWord co-occurence in information retrieval. Scientific American. 277, 48\u201352.\n\nabu2011coherent (abu11), abu2011coherent/files/abu-11.pdf.\n\nbertson2012improving, bertson2012improving/files/bertson2012improving.pdf.\n\nbreuel, breuel_tac10/files/breuel_tac10/files/breuel.pdf.\n\nchodera2013efficient, chodera2013efficient/files/chodera_tac10.pdf.\n\ncohan2015scientific, cohan2015scientific/files/cohan.pdf.\n\nduck-tac,duck-tac/data/duck-tac/2014/data.htm.\n\ndurrett2010document, duck-tac/Data/duc_2001_2003/duc_2001_2003/duc_2001_2003/duc2001.pdf.\n\ngoyal2000introduction,goyal2000introduction/_Introduction.pdf.\n\nhuo2013improved,huo2013improved/files/huo2013improved.pdf.\n\nkolak2017,kolak-2017/ducktac-results/2014/2014/ducktac2014.pdf.\n\nkolak2011exploring,kolak2011exploring/files/kolak2011exploring.pdf.\n\nLai, Z., & Weng, W. (2012) A New Measure of Textual Similarity with Improved Correlation Coefficients. In\nhttp://www.aclweb.org/anthology-a1/W12-1011.pdf.\n\nlin2011automatic, lin2011automatic/files/lin2011automatic.pdf.\n\npappas2012assessing, pappas2012assessing/files/pappas2012assessing.pdf.\n\npiatesky2013pyramid, piatesky2013pyramid/files/piatesky2013pyramid.pdf.\n\nrappoport2004comparison,rappoport2004comparison/files/rappoport2004comparison.pdf.\n\npopescu2014automatedly",
    "c59078efa7249acfb9043717237c96ae762c0a8c": "\nEthical Implications\nThis work proposes new methods to alleviate gender bias of neural language models using only labeled training data. Our approach does not rely on any auxiliary sources such as human annotated data or sensitive labels on the web. For this reason, we think that these methods are ethical and should be further investigated. Our research also leads to opportunities for exploring a cascade of approaches to debiasing to achieve optimal mitigation effects.\nReferences\n[BIBREF0] B. S. Yao, Y. R. Ching-Fu, G. Covington, M. L. Liu, J. A. Ngo, D. D. R. Parikh, J. Z. Xie, and J. C. Lai, \"Debiasing Gender Bias in NLP Models,\" Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing and the 2017 Conference on Machine Learning for NLP (EMNLP-CLS2017 and EMNLP2017)\n\n[BIBREF1] A. Singh, T. Q. Le, and M. L. Liu, \"Gender Bias in Topic-Directed Text Generation,\" Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing and the 2017 Conference on Machine Learning for NLP (EMNLP2017)\n\n[BIBREF2 ] A. L. Gebru, M. Ranzato, and S. H. M. Lillicrap, \"Ethical Language Modeling for Fair Reinforcement Learning,\" 2018\n\n[BIBREF3] A. Singh, T. Q. Le, and M. L. Liu, \"Gender Bias in the Recommendation System: Gender Preference Discrimination through Coreference,\" 2019\n\n[BIBREF4] K. Chamler and E. Horvitz, \"A Study of Gender and Other Biases in Language Models,\" 2018\n\n[BIBREF5] A. Singh, T. Q. Le, and M. L. Liu, \"Gender Biased Language Modeling,\" 2019\n\n[BIBREF6 ] M. B. L. Nelson, Y. Wu, and R. Hirao, \"Exploring Geometric Debiasing of Word Embeddings for Mitigation of Biases,\" 2019\n\n[BIBREF7] P. D. Martin-Santos and M. Bansal",
    "73bddaaf601a4f944a3182ca0f4de85a19cdc1d2": "\n\nWe sincerely thank the reviewers for their useful feedback. This work would not have been completed without their support.\n\nReferences\n\nAhmad, M., A. H. Nasrabadi, S. Bordia, and X. Miao. 2019. Gender sensitivity in language modeling. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing, pages 898\u2013911. Association for Computational Linguistics, Stroudsburg, PA, USA.\n\nAidan, C. H. et al. 2019. Language modeling for text generation: A survey. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 4799\u20134809. Association for Computational Linguistics, Stroudsburg, PA, USA.\n\nAllen, D. & K. Byrne. 2019. Gender bias in pretrained deep networks. Technical report.\n\nBamman et al. 2014. Using language models to combat gender and race bias. Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, pages 2162\u20132164. Association for Computational Linguistics, Stroudsburg, PA, USA.\n\nBamman et al. 2013. The gender bias dictionary. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing and Human Language Technology, pages 2039\u20132048. Association for Computational Linguistics, Stroudsburg, PA, USA.\n\nBamman et al. 2018. A new corpus and model for detecting and mitigating gender bias in language models. Association for Computational Linguistics, Stroudsburg, PA, USA.\n\nBamman et al. 2017. Detecting and mitigating gender bias in neural language models. Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 2650\u20132658. Association for Computational Linguistics, Stroudsburg, PA, USA.\n\nBaumgartner et al. 2015. The gender gap in the academy. Science 332(6035): 1231\u20131239.\n\nBIBREF0\n\nM. Ahmad et al. 2019. Detecting gender bias in language models: a gender word similarity task. arXiv preprint, https://arxiv.org/abs/1907.06221.\n\nBIBREF1\n\nM. Ahmad et al. 2018. Gender bias in",
    "d4e5e3f37679ff68914b55334e822ea18e60a6cf": "\nReferences\n\nBaldry, L. C., J. N. Smith, and M. Warnecke (2005). Data bias in language modelling: corpus characteristics and modelling effectiveness. Proceedings of the 11th Conference on Computational Natural Language Learning.\n\nBanerjee, S., Shikha Bordia, M. I. J. Mirza, Yunqiu Lu, E. F. K. J. Lester, and Y. Kim (2018). Biased language models and the bias cycle. arXiv preprint arXiv:1809.07193.\n\nBanerjee, S., and I. Witten (2017). Data bias and coreference coreference. arXiv preprint arXiv:1704.03911.\n\nBordia, S., O. Etzioni, J. N. Smith, and A. Couronn\u00e9 (2016). Improved gender biases in word vector spaces. arXiv preprint arXiv:1602.00978.\n\nBordia, S., Shikha, and Y. Kim (2016). Data bias and linguistic structure in word embedding. In ACL, pp. 1326\u20131337.\n\nBordia, S., and J. N. Smith (2017). Neural discourse parsers that are robust across gender. In ACL, pp. 1210\u20131219.\n\nBordia, S., and Y. Smith (2018). Inclusive language for computational paraphrase generation. arXiv preprint arXiv:1704.07722.\n\nBowman, S. L., J. Chen, G. Pfeiffer, O. Etzioni, E. F. K. J. Lester, A. D. Das, and O. Etzioni (2018). The bias in coreference evaluation corpora. arXiv preprint arXiv:1810.11517.\n\nBordia, S., P. Karthik, M. Sap, and Y. Kim (2019). Debiasing word vectors for gender neutralization. In IJCAI, pp. 1415\u20131421.\n\nBower, D. J., H. C. Lin, and J. N. Smith (2005). Language modelling in context. Computational Linguistics, Vol. 32(03), pp. 243\u2013271.\n\nBrennan, J., and A. D. Das (2006",
    "5f60defb546f35d25a094ff34781cddd4119e400": "\nReferences\n\n[1] B. Eberhardt and E. Valenzuela. Gender Biased Representation in Language Modelling. Proceedings of ICASSP 2020.\n\n\n[2] D. Estrada-Garcia, S. Bordia, and A. Bar-Haim. Beyond Linguistic Differences: A Deep Analysis of Gender Bias in Machine Translation. ICASSP 2018.\n\n[3] T. Hong, N. Uria, and S. Bordia. Causal Inference for Detecting Gender Differences. IJCAI 2017.\n\n[4] L. Gao, Y. Fu, D. C. L. Lee, C. W. Tseng, W.-C. Chang, and K. Y. Bao. Generating Gender-neutral Texts with Neural Language Models. Computational Linguistics, 45(3), 597\u2013615, 2017.\n\n\n[5] K. Hay and G. Dahl. Gender-Bias in Language Modeling with Neural Sequence-to-Sequence Models. ArXiv. 2017.\n\n[6] S. A. Kitaev and D. G. Lowe. Gender Variations Across Word Embedding Alignment: How Much Can We Depend On? CoNLL 2017 Workshop Reports.\n\n\n[7] H. Li, L. Liu, J. F. R. Torres, and F. Zettlemoyer.\n\nGender Bias in Language Modeling: A Statistical Analysis of Word Embedding Alignment. ArXiv 2018.\n\n[8] E. Maynez, E. Valenzuela, E. Poznyakova, A. Bar-Haim, D. Estrada-Garcia, and S. Bordia. How to Measure Gender Bias? ACL 2019.\n\n\n[9] S. Bordia and Z. Liao. A Study Of Gender Bias Within Tweets. ArXiv 2019.\n\n[10] C. D. L. Lee, K. Y. Bao, and S. K. N. S. D. Lee. Word Embeddings That Learn Both Vocabulary and Meaning: A Comparative Study of Glove, FastText, and DistilBERT. ArXiv 2018.\n\n\n[11] K. M. Prabhuven, D",
    "90d946ccc3abf494890e147dd85bd489b8f3f0e8": " We would also like to acknowledge support from the Amazon Research Center Fellowship, the Amazon Academic Awards in Cloud and Big Data Research, the Amazon Corporate Internship and the Amazon Research Grants for Undergraduate Students. Y. Y. was partially funded by the Natural Sciences and Engineering Council of Canada NSERC Discovery Grant Program (4R7091-2022-0001).\nReferences\n\n[BIBREF0]\n\nBhargavaa, A., and Srivastavaa, D.\n\n(2020)\n\nThe gender bias in language modeling.\n\nIn\n\nProceedings of the 56th Annual Meeting of the Association for Computational Linguistics\n\n(ACL),\n\nMontreal\n\n[BIBREF1]\n\nAn etheric.ai internal report (2021).\n\nwww.e-liter.com/blog/language-models-and-their-implications\n\n[BIBREF2]\n\nBhargavaa, A., Mishra, A., Srivastava, D., and Chum, B.\n\n(2020)\n\nSex and age bias in coreference resolution.\n\nIn\n\nProceedings of the 2019 ACL Workshop and Shared Task on Gender in Language Modeling\n\n(Gender-ACL).\n\n[BIBREF3]\n\nBhargavaa, A., Srivastava, D., Zhang, J., Kesharwani, S., and B. Chum\n\n(2021)\n\nAd targeting systems are gender biased.\n\nProceedings of the 2021 AAAI Conference on Artificial Intelligence (AAAI),\n\n[BIBREF4]\n\nZhang, J., Ravan, C. A., Cho, S., Bharati, S., B. Chum, and C. Ravan.\n\n(2021)\n\nMitigating biases in language modeling\n\n(BIBREF7, B. Chum, H. Choi, Y. Poon & R. Li, Eds),\n\nThe Thirty-Third AAAI Conference on Artificial Intelligence (AAAI),\n\n[BIBREF5]\n\nBhargavaa, A., Poon, N. Y., Chum, B.\n\n(2021)\n\nSensationalism and gender bias in language modeling.",
    "b962cc817a4baf6c56150f0d97097f18ad6cd9ed": "\nAcknowledgements\nWe are grateful to Fran\u00e7ois Lavet for the help during the conception, gathering and manipulation of the data.\n\nReferences\n \n# Accursed\n\nDUNGEONS & DRAGONS, D&D, Wizards of the Coast, and their respective logos are trademarks of Wizards of the Coast LLC in the U.S.A. and other countries. Hasbro SA, Represented by Hasbro Europe, Stockley Park, UB11 1AZ. UK.\n\nAll characters in this book are fictitious. Any resemblance to actual persons, living or dead, is purely coincidental.\n\n\u00a92011 Wizards.\n\nThis book is protected under the copyright laws of the United States of America. Any reproduction or unauthorized use of the material or artwork contained herein is prohibited without the express written permission of Wizards of the Coast LLC.\n\nMaps by John Lovett\n\neISBN: 978-0-7869-6369-4\n\nFor customer service, contact:\n\nU.S., Canada, Asia Pacific, & Latin America: Wizards of the Coast LLC, P.O. Box 707, Renton, WA 98057-0707, +1-800-324-6496, www.wizards.com/customerservice\n\nU.K., Eire, & South Africa: Wizards of the Coast LLC, c/o Hasbro UK Ltd., P.O. Box 43, Newport, NP19 4YD, UK, Tel: +08457 12 55 99, Email: wizards@hasbro.co.uk\n\nEurope: Wizards of the Coast p/a Hasbro Belgium NV/SA, Industrialaan 1, 1702 Groot-Bijgaarden, Belgium, Tel: +32.70.233.277, Email: wizards@hasbro.be\n\nVisit our websites at www.wizards.com  \nwww.DungeonsandDragons.com\n\nv3.1\n\n#  \n\n_For my parents, who always answered the most questions out of that bunch of kids._\n\n#  \nContents\n\n_Cover_\n\n_Other Books in the Series_\n\n_Title Page_\n\n_Copyright_\n\n_Dedication_\n\n_Map_\n\nI. The Quest Begins!\n\n",
    "fb5fb11e7d01b9f9efe3db3417b8faf4f8d6931f": " We also thank Laurent Dinh for the help on the training of the deep reading model.\n\nReferences\n\nThis section presents a listing of papers, websites, datasets, and code that have contributed to the design and construction of this task.\n\nBIBREF0:\n\nW. Bowman, N. Kumar, A. Rajpurkar, and J. Zhong (2015) SQuAD: 100,000+ question-answering tracks of machine-readable comprehension for academic research. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, Stroudsburg, PA, United States. Association for Computational Linguistics.\n\n10.18653/S19\u20132016\u20130124.\n\nBIBREF1:\n\nB. Devlin, K. Lam, and Z. Sutskever (2015) Improving language modeling by penalizing word repetition. In Proceedings of the 2014 Conference of the Association for Computational Linguistics on Human Language Technologies, pages 1801\u20131808, San Diego, CA, USA.Association for Computational Linguistics\n\n10.18653/v1/D15\u20131141.\n\nBIBREF2:\n\nB. Devlin, K. Lam, and Z. Sutskever (2016) Machine comprehension with deep neural networks. In\n\nProceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, Stroudsburg, PA, United States. Association for Computational Linguistics\n\nBIBREF3:\n\nY. Choi, C. D. Clark, R. L. Grefenstette, and J. Fisk (2015) Natural questions: Formulating machine comprehension questions. In\n\nH. Wallach, C. D. Clark, R. L. Grefenstette, and J. Fisk (eds.) Proceedings of Human Language Technology Conference to Support the NIST Decade of Language, pages 1485\u20131493, National Institute of Standards and Technology\n\n10.18653/NIST.HLT.2018.52.\n\nBIBREF4:\n\nV. S. Dignum, D. Riezler, and T. Graesser (2018) Twenty bAbI tasks: A new suite for testing natural language understanding. In\n\nY. Chen, A. Das,",
    "52f8a3e3cd5d42126b5307adc740b71510a6bdf5": " We also thank the reviewers for their feedback and the editors of the journal for the help during the publication.\n\n\\\n\nBIBREF0 Jing et al., \"Natural questions over Wikipedia, answer importance estimation, and understanding,\" CoRR, vol. abs/1505.08788, 2018.\n\nBIBREF1 Fink et al., \"Question-Answering over News Articles,\" CoRR, vol. abs/1607.04365, 2016.\n\nBIBREF2 Ng et al., \"Reading with Attention: Learning to Answer Questions from Text,\" CoRR, vol. abs/1504.03242, 2015.\n\nBIBREF3 Clinchant et al., \"Reading Comprehension from Web Text to Open-Ended Questions,\" CoRR, vol. abs/1505.00201, 2016.\n\nBIBREF4 Yang et al., \"Thinking with your mouth full: The Trivia Question Answering Challenge,\" CoRR, vol. abs/1507.06634, 2015.\n\nBIBREF5 Chua et al., \"Reading with Attention: A Model for Answer Selection from Wikipedia,\" CoRR, vol. abs/1606.09127, 2016.\n\nBIBREF6 Chen et al., \"SQuAD: 100,000 Variable-Length Contextualized Questions for Machine Comprehension of Wikipedia,\" CoRR, vol. abs/1606.0994, 2016.\n\nBIBREF7 Yang et al., \"CNN/Daily Mail: A Dataset of Challenging Short- and Long-answer Questions with Wiki Answers Considered Answered,\" CoRR, vol. abs/1606.0863, 2016.\n\nBIBREF8 Jia et al., \"Robust and Easy to Evade Adversarial Examples in Natural Language Comprehension Models,\" CoRR, abs/1708.07555, 2017.\n\nBIBREF9 Goyal et al., \"Who Is More Attracted By Our Profile Pictures? Answering Natural Language Visual-question Generation Through Attentive Neural Decoding,\" CoRR, abs/1703.10632, 2017.\n\nBIBREF10 Yeh et al., \"Reviews from Hotel Employees Over TripAdvisor.com,\" CoRR, abs/1804.06183, 2018.\n\nB",
    "2236386729105f5cf42f73cc055ce3acdea2d452": " We would like to thank the reviewers for their feedback and corrections. Especially, we thank David Granger for his support and constructive criticism that has improved this paper.\nAppendix A: Details regarding the ReviewQA task\n\nDataset\nThis section introduces the dataset we propose to analyze in this challenge. First we give more details on ReviewQA, the relational reading corpus we have used as baseline. Then we describe the list of tasks proposed in the challenge, and the process followed to produce the dataset. Finally, we introduce the new tasks we propose regarding the analysis of sentiments through aspect specific analysis.\n\nReviewQA: ReviewQA dataset: To propose this challenge, we start with the TripAdvisor reviews that have been originally introduced in BIBERN23 and BIBERN24. These reviews are structured as a sequence of rated aspects for each comment. Each aspect has at most seven ratings. We propose a set of natural language questions with a fixed list of 8 answer candidates. In order to introduce more difficulty into the challenge we propose to ask questions regarding the relationships between different aspects, by asking the models to predict a given answer regarding a set of ratings. For instance, asking a question like How are the overall ratings between value and location in this comment, requires to find a positive rating for an aspect when we do not know if this rating is on value or location. With our question-answering approach, it is possible to represent this challenge with a well defined natural language question and evaluate the model on its ability to correctly answer such a question.\nList of tasks: Table TABREF27 presents the list of tasks we propose to evaluate on our corpus. The questions are randomly selected from the TripAdvisor reviews and then have to predict the correct answer. A list of all the questions proposed in the challenge can be downloaded in the repository associated to this paper.\nConstruction of the dataset: This part describes how we have chosen the questions and generated the documents for each of the tasks. For this purpose, we first randomly select 6 tasks from the tripadvisor reviews for each review. This set of tasks are then randomly paired to a question that will test the competency we want to test on each task. All the comments in the TripAdvisor corpus are English and the questions are therefore in English. We have focused our construction process around the three most challenging tasks: task 1, 3, 4, 5, 6, 8 and 8.1. However, these 6 tasks are sometimes",
    "18942ab8c365955da3fd8fc901dfb1a3b65c1be1": " This work has benefited from research conducted within the FrameNets and DeepSenseNet projects funded by the ERC with the support of the European Commission under grant agreement n\u00b0649957.\n\nConflict of Interest\nThe authors declare that they have no competing interests.\nReviewQA: A Novel Relational Aspect Based Opinion\n\nDataset for Machine Reading\n\nHicham Boukhetif, Fran\u00e7ois Fleuret, Matthieu Bonnemains, Yannick Nivard\n\n1\n\n\nhttps://dblp.org/rec/bib/journals/corr/Boukhetif20\n\n@inproceedings{Boukhetif2020,\nauthor = {Hicham Boukhetif and\n\nFran\u00e7ois Fleuret and Matthieu Bonnemains and\n\nYannick Nivard},\n\ntitle = {ReviewQA: A Novel Relational\n\nAspect Based Opinion Dataset for Machine\n\nReading},\nbooktitle = {Computer Research Repository\n\n(CORR),}\nseries = {Conf. Series},\npublisher = {Institute for Systems\n\nResearch, University of Innsbruck, Universit\\\n{t} \\. Innsbruck, Austria},\npages = {01-14},\nyear = {2020},\n}\n2 https://dblp.org/rec/bib/journals/corr/Boukhetif19\n\n@inproceedings{Boukhetif2019,\n\nyear = 2019,\n\nbooktitle = {Computer Research Repository (CORR),\n\npublisher = {Institute for Systems\n\nResearch, University of Innsbruck, Univer\\\nt\\. Innsbruck, Austria}\nBIBREF0  A. Dasigi\n\net al., 2017, SQuAD: A Framework for\n\nText Understanding and Question Answering, in *\n\nEMNLP2017: The 2016 Conference on Empirical\n\nMethods in Natural Language Processing,\n\npages: 1882-1887, Hong Kong,\n\nChina\nBIBREF1  J. Weston and D. Chu and R. Fergus and\n\nH. Liang (2017): Team Guide to SQuAD\n\nat SQuAD2. <https://squad.ai/>\n\nBIBREF",
    "7b4992e2d26577246a16ac0d1efc995ab4695d24": " In addition to training large error detection models, we found that combining multiple alternative instances of the input files provided an additional improvement in error detection performance.\nThe evaluation included both the original FCE data and two additional annotated datasets. We found that training error detection models on different versions of the input text improved the final performance. This was even more pronounced when working with artificial data \u2013 enabling the model to see multiple alternative versions from the n-best list from an SMT decoding improved error detection performance.\nAcknowledgments\n\nThis research was supported by the Natural Sciences and Engineering Research Council of Canada (NSERC), the Canadian Institutes for Health Research (CIHR) and the Alberta Innovates \u2013 Health Solutions Challenge.\nReferences\n\n1 Rei2016. http://www.conll2016.org/Task13/?page_id=4\n\n2 Felice2014a. https://www.aclweb.org/anthology/C/C15/C15-1245.pdf\n\n3 Felice2014b. http://www.cl.unsw.edu.au/pub/pubs/felice2014b.pdf\n\n4 Pialign. https://nlp.cs.princeton.edu/pialign\n\n5 Moses. http://www.stat.washington.edu/moses/README.txt\n\n6 IRSTLM Toolkit. http://www.cis.rit.edu/~welldj/moses/irstlm/\n\n7 Kneser-Ney. http://web.mit.edu/~xgreen/netweb-toolkit.html#KN-smoothing\n\n8 Rei2016. http://www.conll2016.org/Task13/\n\n9 AdaDelta. <https://githib.com/huggingface/adadelta>\n\n10 INLINEFORM0. <https://aclweb.org/anthology/C/C15/C15-1239.pdf>\n\n11 RASP. http://www.cis.rit.edu/~welldj/dirt/RASP/\n\n12 CLAWS2. http://www.cis.rit.edu/~welldj/pennclaws2/tag/\n\n13 BIBREF12. https://www.aclweb.org/anthology/P/P14/",
    "ab9b0bde6113ffef8eb1c39919d21e5913a05081": "\nThis work was supported by ERC Advanced Grant EASY (EASY), the European Unions Seventh Framework Program for Research and technological development. We gratefully acknowledge the support of the ERC, which enabled us to conduct this research. We would also like to thank the anonymous reviewers for the CoNLL-14 shared task evaluations, their help in improving the evaluation process and in providing access to their work.\nAcknowledgements\n[1] http://www.fce-result.com/fce.htm (FCE)\n[2] http://dataverse.scholarsportal.info/api/handle/10.5283/dataverse/DukeU/4326?pID=datafile:DukeU:4326_1, retrieved on: 20 Jun 2017 (CONLL)\n[3] http://www.cl.ut.ac.be/pages/jcr/page.asp?&pid=6#toc1 retrieved on 20 Jun 2017 (CoNLL)\n[4] Rei2016a\n[5] NIST\n[6] http://www.phrasemachine.org/english-phrasemachine/ retrieved on 20 Jun 2017, retrieved on: 20 Jun 2017 (Pialign)\n[7] http://www.statmt.org/irstlm/ retrieved on 20 Jun 2017, retrieved on: 20 Jun 2017 (IRS Toolkit)\n[8] http://www.statmt.org/irstlm/ retrieved on 20 Jun 2017 retrieved on 20 Jun 2017 (IRSTLM Toolkit)\n[9] http://www.opennlp.org/2010/12/09/rstlm-and-lmt.pdf retrieved on 20 Jun 2017 retrieved on 20 Jun 2017 (ISTLM Toolkit)\n[10] http://www.phrasemachine.org/english-phrasemachine/ retrieved on 20 Jun 2017 retrieved on 20 Jun 2017 (PhraseMachine)\n[11] http://www.phrasemachine.org/english-phrasemachine/ retrieved on 20 Jun 2017 retrieved on 20 Jun 2017 (PhraseMachine)\n[12] https://nlp.stanford.edu/research/sequence-tagging-nnet/ retrieved on 20 Jun 2017 retrieved on 20 Jun 2017 (Sequence Tagging NNET)\n[13] http://irst",
    "9a9d225f9ac35ed35ea02f554f6056af3b42471d": " While this may seem counterintuitive, the two methods can be seen as complementary, giving improved error detection results without needing any additional training data for AEG. In the long run, it is promising to investigate error generation and detection approaches in more detail \u2013 potentially identifying combinations of text transformation patterns for learning error detectors.\nAcknowledgements\nThis work was supported in part by the EPSRC project SENSITIVITY, grant number EP/K034166/1. The views and opinions expressed therein do not necessarily reflect those of the EPSRC. We would like to thank the FCE and the CoNLL-14 organizers and the team at LinguaCello BIBREF1, BIBREF2 and BIBREF1 for providing the used corpora. We would like to thank our external examiners on the English course for providing the used examination scripts for the pattern-based method.\n\nReferences\n\n[BIBREF0 ] Brockett, Z. 2006. Error-marking in corpora: A case study of noun number agreements. Proceedings of LREC 2006.\n\n[BIBREF1 ] Cahill, J. R. 2013. Automatic error identification in text. Proceedings of EMNLP 2013.\n\n[BIBREF2 ] Cahill, J. R., McMillan, I., Murphy, K. & Chukka Srisena, E. 2013. Round-trip translation for error detection using machine translation. Proceedings of EMNLP 2013.\n\n[BIBREF3 ] Felice, A. H., Nieh, C. Z., McMillan, I., Chukka Srisena, E. and McIntyre, L. 2014. CoNLL 2014 shared task on error detection \u2014 Overview. Proceedings of CoNLL 2014.\n\n[BIBREF4 ] He, Z., Hovy, E., & Martin, J. 2014. Error correction by round-trip translation. Proceedings of NAACL 2014.\n\n[BIBREF5 ] Hovy, E., et al. 2007. Building error-aware bilingual translation models. Proceedings of ACL 2007.\n\n[BIBREF6 ] Pialigno, F. et al. 2010. Mapping probabilities into phrase-based SMT systems. Proceedings of ACL 2010.\n\n[BIBREF7 ] LDC. 2010. The internet resource for sentence",
    "ea56148a8356a1918bedcf0a99ae667c27792cfe": "\nAcknowledgements\nWe wish to thank the anonymous reviewers for their thorough and detailed feedback. We also thank the National Natural Science Foundation of China (51506133, 61300114, 61230013) for funding through the Joint Research Center for the Transformation of Mathematical Knowledge.\n\nAcknowledgements\nOur work builds on research by previous authors. The pattern-based AEG approach described in Section SECREF3 was first proposed by Felice:2014-CoNLL and we used the original source code from the author for reproducing their findings.\nReferences\n\n[AP]\n\nApostolico, D. and Banchs, S. (2011). Improving error detection: an LST approach. In: ACL-HLT 2011 Shared Tasks workshop, pp. 8\u201315. Association for Computational Linguistics (ACL).\n\n[AV]\n\nAwadallah, A., von der Malsburg, C., Leung, S. and Choukri, H. (2010). Modeling writing errors: a comparative study of SMT and LST for error detection. In: Proceedings of the CoNLL Annual Shared Task Workshop,\n\nBrissy, E. and Pilehrotdy, L. (2012). In defense of SMT: error correction through roundtrip translation. In: Proceedings of the Third Workshop on Statistical Machine Translation and Computation for Natural Language Generation, pp. 5\u20138.\n\n[BIB]\n\nBryant, D., Tiedemann, B., Deyde, S., Hajiri, A. and Kudo, K. (2012). Learning error patterns from correction data. In: IWPT 2012, pp. 30\u201335.\n\n[BIBREF0]\n\nBriscoe, B. (2014). Annotating prepositions with type-token distribution. In: Coling, pp. 705\u2013710.\n\n[BIBREF1]\n\nBryant, D. and Felice, F. (2015a). Supervised error generation. In: Coling, pp. 779\u2013790.\n\n[BIBREF2]\n\nChoukri, H. and Leung, S. (2011). Grammatical error correction (Including Abstract). In: Proceedings of the CoNLL Annual Shared Task Workshop,\n\n[BIB",
    "cd32a38e0f33b137ab590e1677e8fb073724df7f": " Taking advantage of multiple alternatives for the same sentences improves detection results from the error detection model, making use of the alternations when training.\nAcknowledgements\n\nWe would like to thank the Turing Institute for their generous research funding. This work also made use of resources and expertise from the Language and Web Engineering Unit in the Computer Science Department at the University of Bristol.\nReferences\n\nBIBREF0\n\nKoehn2003.\n\nKoehn2003.\n\nBIBREF1\n\nDeclerck2010.\n\nDeclerck2010.\n\nBIBREF2\n\nFelice2014a.\n\nFelice2014a.\n\nBIBREF3\n\nRei2016.\n\nRei2016.\n\nBIBREF4\n\nRuchansky2014.\n\nRuchansky2014.\n\nBIBREF5\n\nFelice2015.\n\nFelice2015.\n\nBIBREF6\n\nKoehn2004.\n\nKoehn2004.\n\nBIBREF7\n\nStolcke2001.\n\nStolcke2001.\n\nBIBREF8\n\nChen2008.\n\nChen2008.\n\nBIBREF9\n\nStolcz2001.\n\nStolcz2001.\n\nBIBREF10\n\nPialign2009.\n\nPialign2009.\n\nBIBREF11\n\nRus2003.\n\nRus2003.\n\nBIBREF12\n\nSocher2013.\n\nSocher2013.\n\nBIBREF13\n\nCollobert2011.\n\nCollobert2011.\n\nBIBREF14\n\nGrescom2013.\n\nGrescom2013.\n\nBIBREF15\n\nZeiler2012.\n\nZeiler2012.\n\nBIBREF16\n\nClark2011.\n\nClark2011.\n\nBIBREF17\n\nRousseau2000.\n\nRousseau2000.\n\nBIBREF18\n\nBae2009.\n\nBae2009.\nReferences\n\nFelice2014a.\n\nFelice2014a.\n\nBIBREF2\n\nBIBREF4\n\nFelice2014a.\n\nBIBREF5\n\nBIBREF5.\n\nBIBREF5.1\n\nBIBREF5.",
    "2c6b50877133a499502feb79a682f4023ddab63e": "\nAcknowledgements\nThe main framework for experiments was kindly provided by Wen-hsin Wang. We are very grateful to his works and contributions to our work on WikiLarge, WikiSmall for experiments on synthetic data, and the idea of using back-translation. We thank Guoqing Tu for reading this paper and giving us some important advices. We also thank the anonymous reviewers for their valuable comments, which helped a lot improving this paper. We also thank the reviewers of the IWSSS conference for their valuable comments on the final draft of the paper.\n\nReferences\n\n(BIBREF0 ) Biran, A., Barzilay, R., & Wu, Q. (2011). Fast approximate nearest neighbor-based text simplification. In ACL-HLT 2012, pages 34-43.\n\n(BIBREF1 ) Biran, A., Wu, Q. and Barzilay, R., Statistical Lexical Simplification Using Regular Texts as Training Data. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), June, 2012, ACL, Minneapolis, Minnesota.\n\n(BIBREF2 ) Huang, C., Barzilay, R., and Wu, Q. (2012). A simple statistical-based method for sentence simplification, In Proceedings of the 44th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), 2013, ACL, Vancouver, BC, Canada.\n\n(BIBREF3 ) Lippi, A. and Lapata, M. (2008). Simple English Wikipedia: extraction rules and a corpus of simple English articles. In Proceedings of the 30th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), page 97-104.\n\n(BIBREF4 ) Lippi, A. and Lapata, M. (2008). From Wikipedia to Simple Wikipedia: extraction rules and a large corpus of simple English articles. In Proceedings of the 30th Annual Meeting of the Association for Computational Linguistics-Volume 2: Short Papers, 2008, ACL, Prague, Czech Republic.\n\n(BIBREF5 ) Sennrich, R., Haddow, B., and Birch, S. (2016). Neural machine translation of 115 million sentences. In Proceedings of the 2016 Conference of the North American Chapter of the Association for",
    "f651cd144b7749e82aa1374779700812f64c8799": "\nAcknowledgement\nThis research is partially supported by National Science Foundation of China (NSF), with Grant Grant No: 61773314. We also acknowledge the support by NVIDIA Corporation with the donation of a GeForce GTX 1080 GPU used in this work.\n\nReferences\n[1] C. E. Adebayo, M. E. Alarcon, E. N. Nawrocki and S. Chander, \"Simple text summarization for English newswire corpora\", Transactions of the association for Computational Linguistics, vol. 28, pp. 679-688, 2018.\n\n[2] M. C. Biran and U. V. N. Niyogi, \"Unsupervised Synonym Learning between Complex and Simpler Synonyms\", Transactions of the Association for Computational Linguistics (TACL), vol. 26, pp. 691-701, 2006.\n\n[3] O. Biran and S. Lapata, \"Unsupervised Lexical Simplification at Scale\", Proceedings of the 32nd International Conference on Machine Translation (ICMT2012), pp. 229-236, 2012.\n\n[4] O. Biran and I. Titov, \"Lexical Simplification Using Lexical-Syntactic Features and a Constraint-Satisfaction Approach\", Proceedings of the 31st International Conference on Machine Translation (ICMT), pp. 325-328, 2011.\n\n[5] C. Chen, R. C. Zou, S. Chander, S. Gao, G. Liu and E. Zapata, \"Neural Machine Translation: A Comprehensive Survey\", Transactions of the Association for Computational Linguistics, vol. 26, pp. 277-291, 2016.\n\n[6] J. Choi, M. Wollmering, A. W. Black, R. S. Bowman, J. K. Cho and J. W. Chen, \"Neural Machine Translation: Bridging the Gap between Human and Machine Performance\", Transactions of the Association for Computational Linguistics, vol. 28, pp. 848-860, 2018.\n\n[7] K. Chung, S. Choi, and Y. Kim, \"Paraphrase-based Neural Machine Translation: From Bilingual Text to Multilingual Corpus\", in",
    "4625cfba3083346a96e573af5464bc26c34ec943": "\nAcknowledgement\nWe acknowledge the support of the Chinese Academy of Sciences, which provided a research grant 201608405023, and the support from University of British Columbia, which funded this work through faculty research grant and operating grant.\n\nReferences\n\n1.Biran, U., and A. Lapata (2015). \"Unsupervised Synonym Discovery with Cross-lingual Word Embeddings.\" In Proceedings of the 25th International Conference on Computational Linguistics, pages 1601\u20131610. Association for Computational Linguistics.\n\n2.Bleuel, P., Y. Hao, J. Lin, R. Neubig, and C. Mau-Muller (2012). \"Fast phrasal translation with word alignments and deep belief networks for statistical machine translation.\" In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 1721\u20131729. Association for Computational Linguistics.\n\n3.Boutrot, M., and E. Van Den Bosch (2013). \"A Statistical Approach to Grammar-Based Lexical Simplification in Machine Translation.\" In Proceedings of the International Joint Conference on Computational Linguistics (IKA), pages 1834\u20131840. Association for Computational Linguistics.\n\n4.Hu, J., and F. Jia (2015). \"Learning syntactic parsers with neural network machine translation.\" In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics, pages 3327\u20133336. Association for Computational Linguistics.\n\n5.Kim, D. A., and K. Cho (2016). \"Rethinking phrase-based machine translation architecture under recurrent neural network.\" In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, pages 2814\u20132824. Association for Computational Linguistics.\n\n6.Kim, D. A., Y. Kim, K. Woo, and H. Lee (2016). \"Deep neural machine translation.\" In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 1\u201312. Association for Computational Linguistics.\n\n7.Lample, C., T. Williamson, R. R. R. Barbieri, C. C. C. C. Ma, and O. Vinyals (2016a). \"",
    "326588b1de9ba0fd049ab37c907e6e5413e14acd": " For example, some languages have simple variants like Brazilian Portuguese Wikipedia and Portuguese Wikipedia (WABP and WABP-SEW), which provides us ample opportunity for experiments and investigation.\nAcknowledgements\n\nWe appreciate the support of the National Key Program of China (BIBREF27).\nReferences\n\n[1] H. Abdu and E. Ginzling. Text simplification for children: a new language simplification method based on frequency-sensitive dictionary. Computer Speech and Language, 43:18\u201333, 2018.\n\n[2] C. Biran and H. Lapata. Simpli-Wiki: using machine translation to improve textual access to Wikipedia. Computers & Communication, 29:1\u201310, 2012.\n\n[3] C. Biran and H. Lapata. Simplifying Language through Phrase-Based Machine Translation. SIGDIAL 2013: 2. Google Scholar.\n\n[4] H. Biran, H. Leidner, C. Biran, and H. Lapata. Automatic simplification of large scale corpus using statistical machine translation. In Proc. of the International Conference on Statistics in Artificial Intelligence, 2012.\n\n[5] T. Bos and R. Zitnick. Neural machine translation with attention. In Proc. of the ACL, 2015.\n\n[6] S. Chen and E. Hovy. Improved training methods for neural machine translation. In Proc. of the 55th Annual Meeting of the Association for Computational Linguistics, 2016.\n\n[7] A. J. Clark and E. Hovy. Neural machine translation: A survey. In Proc. of the 56th Annual Meeting of the Association for Computational Linguistics, 2017.\n\n[8] Y. Chen, S. Chopra, G. Ganchev, M. Iyyer, D. Yarowsky, and P. Wu. Neural machine translation with an attention mechanism. In Proc. of the 56th Annual Meeting of the Association for Computational Linguistics, 2017.\n\n[9] C. Corley, U. Sodnick, and X. Zhang. Simple: automating English Wikipedia with machine translation. In Proc. IWCS 2013, 2013.\n\n[10] H. Dai, R. So, R. Bowden, and E. Hovy. Automatic summar",
    "ebf0d9f9260ed61cbfd79b962df3899d05f9ebfb": "\n\nAcknowledgment\nWe thank the anonymous reviewers for valuable comments, Akshay Manohar and Michael Kiela for the discussions on NMT-based text simplification.\n1. Biran, T., and Lila Rios. 2015. Semantic word and phrase simplification without hand-crafted rules for simplified English Wikipedia. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pp. 809\u2013817.\n\n\n\nCopyright \u00a9 2016, 2013 by the Florida Bar Board of Governors.  \nPublished by the Carolina Academic Press in cooperation with the University of North Carolina at Greensboro.\n\nThis is a work of the author and therefore is copyrighted material. The Florida Bar may claim no authorship or other affiliation with the author.\n\nAll rights reserved under International and Pan-American Copyright Conventions. No part of this publication may be reproduced, stored in a retrieval system, or transmitted, in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without written consent of the publisher or a license from the publisher.\n\n**Library of Congress Catalog Card No. 2015924846**\n\n**ISBN: 978-1-61243-977-8 (softcover); 978-1-61243-978-5 (e-book)  \n**Distributed by:**\n\nUniversity Press of Florida  \n4135 SW 13th Place  \nPO Box 16203, Gainesville, Fl 32604-6203\n\nUniversityPress.org\n\n## Table of Contents\n\nIntroduction\n\nDirections for Accessing the Electronic Edition\n\nAcknowledgments\n\nOne\n\nTwo\n\nThree\n\nFour\n\nFive\n\nSix\n\nSeven\n\nEight\n\nNine\n\nTen\n\nEleven\n\nTwelve\n\nThirteen\n\nFourteen\n\nFifteen\n\nSixteen\n\nSeventeen\n\nEighteen\n\nNineteen\n\nAbout the Author\nFor my wife, Linda,  the love of my life\nI can safely say I've never seen a bar at night except my own.\n\n\u2014W. C. Fields, in a 1930s movie script\n\n## INTRODUCTION\n\nLawyers have been going to bars since the first drinking establishments opened their doors in ancient Babylon. But they've only recently discovered another side of The",
    "55507f066073b29c1736b684c09c045064053ba9": " Lastly, we plan to study the possibility of using a generative model (such as GPT-3) to increase the vocabulary in the model, leading to better generalizations.\n\nAcknowledgements\nWe would like to thank Nader Abozinadah for providing us with valuable feedback. Lastly, many thanks to the anonymous mentoring committee as they helped us a great deal to draft this paper, especially by suggesting different figures and tables that helped to improve the readability and flow of the paper and, for those reviewers who chose not to participate. This paper was produced with grant support from the UAE Ministry of Education and Higher Education.\nCiteULike Link Query\n\nEstephan, W, and Chamoun YD. Arabic Offensive Language Dataset Collection and Labeling, 2018. Available at: http://arxiv.org/abs/1908.08765\n\nConover, C, Ng, A, Hazarika B, and Ng, G. A Survey on Offensive Language Detection in Online Social Media Platforms. In Workshop on Offensive Language and Violence in Social Media, SIGIR 2018.  \n\nFortuna, T, Nouraei, H, Stoyanchev, V, and Uz Zazpe, I. The evolution of offline and online hate speech for political and religious entities: a comprehensive survey of hate speech in social media. In Proceedings of the 2019 CHI Symposium on User Experience with Visualization in Healthcare, CHI UX 2019.  \n\nFortuna, T, Alnajjar, R, Nouraei, H, and Stoyanchev, V. OffensEval2019: detection and quantification of offensive language in tweets. Available at: https://homes.cs.washington.edu/~fortuna/offenseval19  \n\nMubarak, T, Abozinadah, R, and Elgohary, R. Detecting offensive speech in Arabic microblogging platforms. In Proceedings of the Third International Workshop on Online Social Media and User-generated Content, 2018.  \n\nAlbadi, A, Rizk, T, Khashab, A, and Heibatallah, M. Detecting religious hate speech in Arabic. SIGIR 2018.  \n\nSchmidt, A. Survey of Hate Speech Detection Literature. In International Workshop on Language Resources and Evaluation, L",
    "e838275bb0673fba0d67ac00e4307944a2c17be3": " Finally, we plan to release our dataset and its analysis to the community.\n\nAcknowledgements\nWe thank T. N. Bordhosh for her help with data annotation. We also wish to thank the reviewers for their insightful comments.\nReferences [1] Waseem Khan, H. Q. Nafis, Abdullah Almutarji, and Hamed O. Mouzaman. Analyzing Offensive Language on Twitter in Arabic and English. Proceedings of the 2018 Joint International Semantic Technology Conference: World Conference on Computer Vision Proceedings, October 22-25, 2018, Vancouver, British Columbia, Canada.\n\n[2] Bermi-Benyazid, A., Zoufaly, J., Youssour, R., Benabbou, D., Ghanem, J.-P., and Sebbaa, M. Cross-Lingual Translation: A Multidirectional Transfer Learning Approach for Automatic Translation. Journal of Human Language Technology, 2016.\n\n[3] Maassoumi, S., Hormozi, A., and Reeb, C. Sentiment in Social Media: A Survey. In Computer Science and Information Technology, pp. 17-38. Berlin, Springer, 2019.\n\n[4] Kermani, R., & Asghar, M. T. Detecting offensive language on Twitter using machine learning. In International Semantic Web Conference (ISWC), 2019.\n\n[5] Albadi, A. and Moussalmi, S. The Use and Abuse of Hate Speech in Social Networking Sites. The Electronic Journal of Information and Linguistic Computing, vol. 34, 2018.\n\n[6] Bhardwaj, A., Kumar, A., Singh, K., & Srivastava, C. An empirical comparison of automatic methods and rule-based detection of offensive tweets in Twitter. In International Federation of Computer Science and Information Technology, pp. 901-909. Springer, 2019.\n\n[7] Hassan, A., & Alquraan, A. Offensive Language Detection: Classification Approaches and Trends in Social Sciences. ACM SIGIR Forum, vol. 48, num. 1, pp. 1-5. ACM, 2019.\n\n[8] Fortuna, B., Zaharia, S., Pondikoulakis, S., & Papadopoulou",
    "8dda1ef371933811e2a25a286529c31623cca0c6": " Finally, we plan to extend the dataset and train a supervised classification model for other offensive language types in Arabic, such as pornographic and racist offensive. Finally, we may perform cross-cultural comparison to compare Arabic and other offensiveness patterns in other languages such as Spanish.\n\n\nAcknowledgements\n\nThis work is partially supported by the Qatar National Research Fund (a QNRF supported programme) under Qatar Computing Research Center grant number NRT-5-2633 and European Commission H2020 Research and Innovation project SQUID-Society, Quality of Information, and Data: Sustainable and Value-based Information Processing for society. Any opinions and arguments stated herein do not necessarily reflect those of Fondazione Bruno Kessler, Scuola Normale Superiore di Pisa, or other participating organization.\n\nAppendix A: Appendix A\n\n# Glossary\n\n<table id=glossary_table style=width:100%\n\n[head:left;align:left]\n\n[headercells:align:left;format:p{table-format:bold, width=2cm]\n\n[headercells:format:p{format:bold, font-size: 14pt}]\n\n<tr>\n\n<td style=\"font-size:12pt!\">\n\n{<a name=table_of_contents_entry-A-glossary_tab1 *1>\n\n}\n\n</td>\n\n</tr>\n\n\n<tr><td style=\"font-size:12pt!important;font-weight:bold\">term\n\nglossary_tab1\n\n[0] Offensive  \n[1] Pronoun  \n[2] Pronoun case  \n[3] Prefix\n\n</td>\n\n<tr>\n\n\n<td style=\"font-size:12pt!important;font-weight:bold\">term\n\nglossary_tab1\n\n[0] Pronoun  \n[1] Pronoun case  \n[2] Prefix\n\n</td>\n\n<tr>\n\n\n<td style=\"font-size:12pt!important;font-weight:bold\">term\n\nglossary_tab1\n\n[0] Pronoun  \n[1] Pronoun case  \n[2]",
    "b3de9357c569fb1454be8f2ac5fcecaea295b967": " Third, we plan to collect Arabic offensive language text from other social media and to use the data to build target specific models such as hate crime prediction.\nAcknowledgements\nThis project was funded by the U.S. Army Research Lab.\nWe also wish to thank the anonymous reviewers, especially the third reviewer whose suggestions helped make major improvements in this paper.\nReferences\n[1] Al-Anbari, S., Karim, N. K., Al-Harthi, A. N., Al-Sulaimani, Y. T., & Kamel. A. Y. (2019). Arabic Offensive Language Online: Categorization and Analysis. In Proc. of the 18th International Joint Conference on Natural Language Computing, IJCNLC 2019.\n\n[2] Abd-Allah, M., & Mahdavi, H. (2013). A Methodology for Constructing Large Offensive Language Datasets. In Proc. Fifth International Workshop on Offensive Language, OWLS 2013. Association for Computational Linguistics.\n\n[3] Ames, D. M. (2017). What is the Internet? Some Thoughts on Political Polarization in Online Communications. Journal on Quantitative Analysis in Linguistics, 7:41.\n\n[4] Bellegarda, N., Bellegarda, M., & Conover, M. A. (2016). The Causes of American Political Polarization. Science Advances, 2(10):e1601447.\n\n[5] Bellegarda, M., Conover, M. A., Bellegarda, N., & Yadav, R. (2017). The Rise of Online Hateful Speech: An Analysis of Partisan Tweets. International Conference on Social Media.\n\n[6] Bellog\u00edn, A., Bellog\u00edn, M., Semanal, P., & Zunisa, X. (2018). Machine Learning for Hate Speech Detection: A Survey and Taxonomy of Approaches. International Conference for Autonomous Agents and Multiagent Systems (AAMAS) 2018.\n\n[7] Brown, R. E., & Alnaji, L. (2008). A Brief History of Trolling. In First Conference on Computer-Supported Collaborative Work.\n\n[8] Cappelletti, D., Abutin, I. E., Bellegarda, N",
    "59e58c6fc63cf5b54b632462465bfbd85b1bf3dd": " Third we would like to further annotate the dataset to expand on our analysis of vulgar language such as insults and the probability of a tweet being considered as vulgar or hate speech. Finally, we want to release the Arabic offensive language tweet dataset with detailed metadata and guidelines for building other corpora such as annotated hate speech and other corpora that is essential for offensive language detection.\n\nAcknowledgments\nThe work in this paper is part of a larger project, namely Detecting and Curation of Hate Speech in Arabic Online, which is funded by a USNICSEF grant. The authors are also part of the NLP@UCLA research group, with whom this project was conducted. Finally, special thanks to the two volunteer annotators, Amr Dabbish and Mohamed Sayed.\n\nReferences\n\n[LEFTMARGINTOP]\nAbozinadah, A., Abouzinaadah, M., Dabbous, M., Mubarak, T., Abuelmagdoud, M., & Alakrot, E. (2017). Detecting Hate Speech in Arabic Twitter using User Profiles, Sequences of Words, and Network Analysis. The 9th Linguistic Annotation Workshop.\n\nAlakrot, E., Zainab, S. D., Mubarak, T., & Abouzinaadah, M. (2018). Detecting religious hate speech in Arabic YouTube comments with a recurrent neural network. Proceedings of The 2018 Conference on Empirical Methods in Natural Language Processing : EACL 2018.\n\nAlbadi, K., Khattab, A., Shu, L., & Zhang, J. (2018). Hate speech detection in Arabic Twitter comments based on machine learning. Proceedings of The 2018 Conference on Empirical Methods in Natural Language Processing : EACL 2018.\n\nAlbericio, S., P\u00e9rez-Cruz, M., & Carvallo, J.J. (2018). Offensive Language Detection and Classification in Arabic Twitter. International Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies : NLP.\n\nAmin, Z., & Elhadad, A. (2017). Word Count Analysis of Language Offensiveness. 17th International Conference on Web Information Systems Engineering (WISTP).\n\nBerk-Nielsen, H., & Kvale, B.",
    "5c3e98e3cebaecd5d3e75ec2c9fc3dd267ac3c83": "\nReferences\n\nBIBREF0 K. Choi, C. Lam, and O. V. A. Malik, \"Exploiting Irony in Opinion Generation Task via Semantic Dependency\", in Proc. of NAACL, Hong Kong, August 2016.\n\nBIBREF1 H. Liu, J. T. Yan, X. Jiang, Y. Gao, Z. Li, R. S. Yang, M. Qian, P. Zhang, A. Liu, and X. Huang, \"A study on the linguistic cues of irony markers in social media data\", in Proc. of AAAI, July 2018.\n\nBIBREF2 F. Zhang, R. J. Li, A. Liu, J. P. Zhou, X. C. Li, C. C. Zhou, C. X. Liu, F. Y. Yu, and Y. Gong, \"An Explainable Attentive Neural Network for Opinion Mining,\" in Proc. of ACL, Shanghai, June 2018.\n\nBIBREF3 Y. Gu, H. Liu, and R. S. Yang, \"Opinion Mining with Deep Reinforcement Learning: Theory and Practice\", in Proc. of ACL, New Orleans, June 2018.\n\nBIBREF4 Y. Gao, S. Shen, C. Tang, N. Lin, O. V. A. Malik, C.-E. Liu, X. B. Chen, and X. C. Yuan, \"Opinion Mining with Deep Reinforcement Learning: Theory and Practice.\" in Proc. of ICLR, Stockholm, June 2018.\n\nBIBREF5 Y. Chen, A. Liu, Y. Wu, H. Liu, H. Su, X. Zhang, and J. Gao, \"Exploiting Annotated Irony for Sentiment Analysis and Opinion Mining\", in Proc of EMNLP, Prague, October, 2018.\n\nBIBREF6 S. B. Khapra, N. D. Dabre, V. Chetakina, D. Das, R. L. Martin, and S. Choudhary, \"Style-Agnostic Disentangled Representations via Mutual Information Matching\", in Proc. of AAAI, December 2017.\n\nBIBREF7 K. P. Ganchev and Z. Yang, \"",
    "3f0ae9b772eeddfbfd239b7e3196dc6dfa21365f": "\nAcknowledgments\nThis work is supported by the National Natural Science Foundation of China (under the project number 62121049 ) and the Shanghai Pujiang Program (under the project number 19ZR1442900 ). We are also grateful for the supports from LBS.\nReferences\n\n[t] (Bengio, 2004)\n\n[t] (Dai, 2006)\n\n[t] (Sung, 2006)\n\n[t] (Feng, 2008)\n\n[t] (Bouaziz, 2009)\n\n[t] (Berg-Kirkpatrick, 2010)\n\n[t] (LeCun, 2010)\n\n[t] (Hazan, 2010)\n\n[t] (Chen, 2010)\n\n[t] (Lin, 2010)\n\n[t] (Xue, 2010)\n\n[t] (Joulin, 2009)\n\n[t] (Socher, 2011)\n\n[t] (X. Zhang, 2012)\n\n[t] (Socher, 2011)\n\n[t] (Socher, 2012)\n\n[t] (Zhang, 2010)\n\n[t] (Lin, 2012)\n\n[t] (Socher, 2013)\n\n[t] (Gimpel, 2014)\n\n[t] (Gimpel, 2014)\n\n[t] (Liu, 2015)\n\n[t] (Mlynekova, 2015)\n\n[t] (Yin, 2015)\n\n[t] (Zhang, 2016)\n\n[t] (Zhang, 2016)\n\n[t] (Xie, 2017)\n\n[t] (Lee, 2018)\n\n[t] (Miao, 2018)\n\n[t] (Gimpel, 2019)\n\n[t] (Gao, 2019)\n\n[t] (Gao, 2019)\n\n[t] (Gao, 2019)\n\n[t] (Bengio, 2003)\n\n[t] (Bengio, 2005)\n\n[t] (Bengio, 2006)\n\n[t] (Bengio, 2007)\n\n[t] (Ranzato, 2006)\n\n[t] (Bengio, 2009)\n",
    "14b8ae5656e7d4ee02237288372d9e682b24fdb8": " Additionally, we may also come up with more suitable methods for disentangling style and content representations, such as the style-independent content representation mentioned in BIBREF6.\nREFERENCES\n[1] J. Zie, S. Ester, L. Carlin, L. Filippova, and K. Moore, \"Automated detection of irony sentiment in twitter posts,\" in Proceedings of the 14th ACM International Conference on Web Search and Data Mining, pp. 1379\u20131386, 2016.\n[2] S. J. Fong and T. K. Sok, \"Classifying humor with lexicon-based feature engineering and ensemble machine learning,\" in Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, 2017, pp. 659\u2013662.\n\n[3] T. L. A. Moore, K. L. Moore, J. B. Tenenbaum, and C. G. F. M. Wiebe, \"Language and Emotional Meaning in Twitter Microblog Posts,\" Communications of the ACM, vol. 56, no. 2, pp. 72\u201379, 2013.\n\n[4] D. R. Liu, K. L. Moore, and T. K. Sok, \"Opinion mining with text-level, sentence-level, and word-level representations,\" in Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, 2017, pp. 2379\u20132387.\n\n[5] T. L. A. Moore, J. B. Tenenbaum, K. L. Moore, and C. G. F. M. Wiebe, \"What's that Twitter? A corpus of figurative language and related sentiment,\" in Proceedings of the 21st conference on Computational Natural Language Learning, 2016, pp. 167\u2013178.\n\n[6] R. M. Katz, D. S. H. Tan, Y. Chen, L. T. Chen, G. X. Liu, C. J. Robinson, and E. M. Weinman, \"Word order and figure of speech in irony: a corpus study of Twitter posts,\" in Proceedings of the 42nd conference on Association for Computational Linguistics, 2015, pp. 1505\u20131515.\n\n[7] B. Wang, K. L. Moore",
    "e3a2d8886f03e78ed5e138df870f48635875727e": "\n\nConflict of Interest Statement\nThe authors have declared that no conflict of interests exist.\n[B]\n\nAcknowledgement\nWe want to thank the anonymous reviewers for their feedback and the associate editor for his suggestions which helps us improve the paper. In addition, we want to thank Anfeng Li for his proofreading and some of the code snippets in the paper.\n[1] P., X. \"Sentiment Analysis\" BIBREF25.\n[2] P., X. \"Sentiment Analysis\" BIBREF0.\n[3] P., X. \"Sentiment Analysis\" BIBREF4.\n[4] P., X. \"Sentiment Analysis\" BIBREF1.\n[5] I., J. \"Opinion Mining\" BIBREF0.\n[6] T.S., C.Y. \"Exploring Sentiment Analysis\" BIBREF22.\n[7] E., T.G. \"Opinion Mining\" BIBREF30.\n[8] S., A.T. \"Opinion Mining\" BIBREF28.\n[9] S., A.T. \"Opinion Mining\" BIBREF29.\n[10] I., F. \"Opinion Mining on Twitter\" BIBREF16.\n[11] G., J., S. \"Opinion Mining\" BIBREF31.\n[12] A., R., H. \"Opinion Mining on Twitter\" BIBREF32.\n[13] S., H., T. \"Opinion Mining on Twitter\" BIBREF33.\n[14] F., N., H. \"Opinion Mining on Twitter\" BIBREF34.\n[15] R., I., I. \"Semeval-2018 Task 3 - Irony and Sarcasm Detection\" BIBREF1.\n[16] W., F., D., M., S., B., L. \"Opinion Mining\" BIBREF35.\n[17] I., Z., S., H., T. \"Opinion Mining on Twitter\" BIBREF36.\n[18] I., Z., H., T. \"Opinion Mining\" BIBREF37.\n[19] Y., H., K. \"Opinion Mining on Twitter\" BIBREF38.\n[20] R., Y., Z., H., Y.,",
    "62f27fe08ddb67f16857fab2a8a721926ecbb6fb": "\nAcknowledgments\n\nThis work is supported by the Shenzhen government and the Natural Science Foundation of Guangdong province, China under grant No. U1742127.\n[t] Introduction\n\nThis introduction section and the next section are also published in the conference.\nThis chapter presents the basic ideas of our future work, and we mainly discuss some details in the next section and the first section of the conference.\nThe basic idea is to implement a neural network to transfer a non-ironic sentence into an ironic sentence and constrain the sentiment polarity of the two sentences to be the same. For example, the input is non-ironic  \n\n\"I hate to be ignored\" and the output should be, such as  \n\n\"I like to be ignored\" where the speaker uses like to express his or her negative sentiment. At the same time, we also generate a non-ironic sentence by switching out irony marker and the sentiment polarity of these two sentences are also the same.\nThe two sentences express almost the same sentiment polarity, but  \nthe second sentence with like is ironical and  \nthe first sentence with hate expresses the sentiment with irony in literal meaning.\n\nIntroduction\nAs previously mentioned, we can divide ironies into three categories: verbal irony, non-contrastive and other types of irony. In our work, we mainly focus on ironies in verb irony. Given a sentence with negative sentiment polarity in literal meaning, the speaker uses like to express his or her negative sentiment. As a result, this sentence cannot preserve its content and can only be transferred with the input sentence in our work. In this work, we implement a model based on supervised style transfer to implement the transformation from non-ironic to ironic sentences.\nRelated Work\n\nIn BIBREF1, authors investigate pragmatic phenomena and various irony markers. In BIBREF14, researchers investigate pragmatic phenomena based on sentiment and distributional semantics. In BIBREF16, a tweet is divided into two segments and a subtract layer is implemented to calculate the difference between two segments in order to determine whether the tweet is ironic. In BIBREF17, researchers utilize a recurrent neural network with Bi-LSTM and self-attention without hand-crafted features. In BIBREF18, researchers propose a system based on a densely connected LSTM network.\n\nSentiment and emotion detection, as an important aspect of opinion mining, is also related to",
    "9ca447c8959a693a3f7bdd0a2c516f4b86f95718": " With an intention to explore the future work related to this study, the following topics can be considered:\n\nWe present the first stance detection annotated data set for Turkish tweets which is also the first annotated sports-related data set for Turkish. We have employed unigram-and hashtag-based features as features to build a pair of baseline stance detection models using Support Vector Machines (SVM). Ten-fold cross validation results for both the models are presented for research purposes.\nAcknowledgments\n\nWe gratefully acknowledge the support of TEPA E2B (Technical and Educational Project of Excellence) program supported by TEKNOK\u0130L\u00c7 (Scientific and Technological Research Council of Turkey [Mevlana MEVLAN A.) and T\u00dcB\u0130TAK (Scientific and Technological Research Council of Turkey) [M. \u00dc. M.], METU Department of Mathematics and Statistics [E. \u00c7.] and the Department of Electrical and Electronics Engineering [E. T.]. We also thank SemEval 2016 Shared Task on Twitter Stance Detection for their shared task, and the organizers and contributors of the two data sets for the shared task, namely the University of Bonn [C. J. and K. B.], the University of Pennsylvania [D. G.] and the University of Maryland [E. L.], respectively, on Twitter Stance Detection 2016 Data Set (TS), and the University of Pennsylvania [E. J.], the University of Maryland [E. L.], the University of Washington [R. D. G.] and the University of Chicago [R. G.] on SemEval 2016 Stance Corpus (SC). Also, we thank Tansel G\u00fclg\u00fcn, Neslin \u00c7ak\u0131r, and Cemile Ayg\u00fcn for their insights.\nNotes\n\n1. M. Konyaaltayar, K. \u00d6zt\u00fcrk, and Y. K. G\u00f6ksun. The Turkish Tweet Corpus v1.0. Available at <http://ceng.metu.edu.tr/tweet/>.\n\n2. M. Konyaaltayar, Y. K. G\u00f6ksun, K. \u00d6zt\u00fcrk, and T. Alpsoy. Opinion/Annotated Tweet Datasets with Domain Adaptations for Topic Modeling. Proceedings of the 8th Joint Conference on",
    "05887a8466e0a2f0df4d6a5ffc5815acd7d9066a": " Some future prospects based on the current study are given in the last section of this paper.\nAcknowledgements\nWe would like to express our thanks to the ISCA Institute of Bilkent University for their support and the support of the Science and Technology Research Council of Turkey (BAP) under the Project number 115E076.\nAligned with the BAP Project of Bilkent University, Ibrahim Erdal Kut and Ibrahim Dogan also gratefully acknowledge a Research Grant for the study. We also would like to acknowledge the Turkish Language Institute and its support for the data collection study. The views and opinions expressed in this paper are entirely the authors' own.\n\nReferences\n\nBIBREF0: P. N. S. Mani, T. J. Pitler, C. D. Manning, and R. R. Grasher. Opinion Mining on Twitter. In: Proceedings of the Annual Conference of the Australian Computer Society, pp. 11\u20132. A. C. S., Melbourne: Elsevier, 2010.\n\nBIBREF1: P. N. S. Mani, J. Zhu, C. D. Manning, and R. R. Grasher. SemEval-2016 Shared Task on Opinion Analysis of Multinational Corporations in Tweets, Workshop at ACL, http://acl2016.cs.ucla.edu/Participation/SemEval-2016/index.html, 2016.\n\nBIBREF2: F. Alm, N. H. Krysiukovich, and K. A. Derczynski. Joint stance detection and sentiment analysis of twitter debates in English and Polish. In: Proceedings of the Conference for Human Language Technologies, Association for Computational Linguistics, pp. 1172\u201382. A, 2016.\n\nBIBREF3: E. Hasan and K. Ng. Stance detection in on-line debates with linguistic information, in Proceedings of the COLING 2016 Workshop on Language and Dialog Modelling: Analysis, Interaction, Evaluation, pp. 23\u201330. IOS Press, 2016.\n\nBIBREF4: I. Hasan, K. Ng. Stance detection in online debates with a sequence-based approach on Turkish data: learning stance by learning disagreement. In: Proceedings of the COLING 2016 Workshop on Language and Dialogue Modelling: Analysis, Interaction, Evaluation, pp. 31",
    "c87fcc98625e82fdb494ff0f5309319620d69040": "\nThe Stance Detection Evaluation Metrics-An Elicitation Work\n\nTable 1. The Stance Detection Evaluation Metrics-An Elicitation Work\n\nTarget   Favor (175/175)   Against (175/175)\n\nTraining Data (700 tweets)   Test Data (700 tweets)   Number of tweets   Number of annotated tweets(Favor/Against)\n\nUnigrams   Target-1 (Favor (400/400)   Target-1 (Against (400/400)   Target-1 (Favor/Against)\n\nUnigrams   Target-2 (Favor (400/400)   Target-2 (Against (400/400)   Target-2 (Favor/Against)\n\nUnigrams   Against (400/400)   Against (400/400)   Against (400/400)\n\nUnigrams (Favor/Against)   Target-1 (Favor/Against)   Target 1 (Favor/Against)\n\nUnigrams(Favor/Against)   Target-2 (Favor/Against)   Target 2 (Favor/Against)\n\nUnigrams (Favor/Against)   Against(Favor/Against)   Target 2 (Favor/Against)\n\nN-gram Features   Target-1 (Favor (400/400)   Target-1 (Against (400/400) Target-1 (Favor/Against)   Target-2 (Favor/Against)\n\nN-gram Features   Target-2 (Favor (400/400)   Target-2 (Against (400/400) Target-2 (Favor/Against)\n\nN-gram Features   Against(Favor/Against)   Against(Favor/Against)   Target-2 (Favor/Against)\n\nN-gram Features (Favor/Against )   Against(Favor/Against)   Target 2 (Favor/Against)\n\nN-gram Features (Favor/Against )   Against(Favor/Against)   Target 2 (Favor/Against)\n\nTotal Unigrams   Target-1 (Favor/Against)",
    "500a8ec1c56502529d6e59ba6424331f797f31f0": " Future work includes the following: (1) to extend the tweet data set (particularly the targets, stance classes, and number of samples) with further annotated stances for the two targets and (2) to develop or extend ngram-based features for the development of more complex stance detection systems for Turkish tweets.\nAcknowledgments\nIt is our sincere gratitude to Mehmet Celik for helping us with the creation and management of the stance-annotated tweets data set; and to Serkan Yildirim for providing us valuable feedback on the current paper. We are also indebted to Tefik Atan for discussing with us the problem of stance detection in Turkish tweets.\n\nThe research work that led to this paper was supported by the Scientific Research Projects of the Scientific and Technological Research Council of Turkey (TUBITAK) under grant number 116T919.\nReferences\n[1] K. Gimpel, E. Demiralp, H. Zaidan, and D. Gedik, \"Stance detection in social media,\" ACM Transactions on Internet Technology (ToIT) 14 n. 4 (2014), 17:1\u201318:1 BIBREF0.\n\n[2] K. Gimpel, H. Zaidan, and D. Gedik, \"How to use Twitter posts in stance detection experiments: an analysis,\" Information Fusion 49(2014) 41\u201350 BIBREF2.\n\n[3] B. A. Hasan and Z. Ng, \"Toward a comprehensive stance classification and detection system for on-line political debates,\" International Journal of Human Language Technology 12 n. 2 (2015), 621\u2013643 BIBREF3.\n\n[4] D. Gimpel and A. C. Bruce, \"Stance classification: the case of sports debate,\" in Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics (2013).\n\n[5] M. Hasan, H. Zaidan, and D. Gedik, \"An empirical study on stance detection,\" ECTA Workshop on Computational Models of Argumentation, Pisa (June 2014), 3:1\u201314 BIBREF4.\n\n[6] S. Fadhil and S. Yildirim, \"Stance identification in social media: an application of machine learning techniques,\"",
    "ff6c9af28f0e2bb4fb6a69f124665f8ceb966fbc": " In our future work, we propose to investigate the use of unigram, bigram, hashtagbased, and ngram features for stance detection using neural network approach. The same for language models for detection of stance targets and their related features are also worth to explore.\n\nAcknowledgment\nThe current study is supported by the Turkish Scientific and Technological Research Council (T\u00dcB\u00dcAT).\nA. Cengiz, A. G\u00fcr, and D. B\u00fclb\u00fclmezer, \"A Study of Web-Based Texts about Public Health-Related Topics: A Turkish-Based Approach\", Data Mining and Knowledge Discovery, Springer Berlin Heidelberg, Berlin, 2013, pp. 1\u201318.   \nM. B\u00f6l\u00fcktepe and V. I. Haroutunian, \"Automated Extraction of Health-Related Text Documents via Semantic Stance Analysis: A Review\", Expert Systems with Applications, Vol. 39, No. 3, 2013, pp. 805\u2013828.   \nS. Hasan and K.C. Ng, \"Stance Detection with Conditional Encodings and Dialogue Structure: A Study of a Large Corpus of SemEval 2014 On-Line Debates\", Journal of Machine Learning Research, Vol. 15, 2014, no. 64, 2014, pp. 1\u201323.   \nJ. Hasan, K.C. Ng, and M. Hotho, \"Stance-Aware Stance Extraction in On-Line Political Discussions\", Proceedings of the 2014 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Montreal, Canada, 2014, pp. 1155\u20131168.   \nS. Hasan, G. Ganesh, M. Hotho, E. Choi, F. S. Chae, and S. Chang, \"Identifying Stances of Entities in On-Line Dialogues Using a Stance Dictionary and SemEval 2014 Data Sets\", In Proceedings, International Conference on Computational Linguistics (COLING'2014) Conference Tutorial on Large-Scale Stance Detection, 2014, pp. 1\u201315.   \nL. Heintz and F. F. Neno, \"Stance and Information Processing: A Study of Public Argumentative and Slandering Tweets in On-line Discussion Forums\", Natural",
    "f2155dc4aeab86bf31a838c8ff388c85440fce6e": "\n\n## Acknowledgments\n\nWe would like to thank our colleagues in the SQUAD BART group (see BART.AI/ and Figshare.CC/s/36.39.764/files/b8c38af6e5deaec32de4a0fa8/), and the BERT team. The work of this project was funded by an NSF Expeditions award and a Defense Advanced Research Projects Agency (DARPA) contract. Work on preposition supersenses was funded by a DARPA ABRACS contract. The authors were supported in part by the Office of Naval Research (ONR) and ONR Multidomain University Research Initiative for Science and Engineering (MURI) program. The U.S. government is authorized to reproduce and distribute reprints for governmental purposes. The viewpoints and conclusions in this paper are those of the authors and do not necessarily reflect the official policy or position of the United States government, on DARPA, ONR, NSF, or the United States Navy.\n## Author Information\n\n## Author Contributions\n\nThis section describes our individual contribution to the work, not including the roles each of us had on the broader project.\n## References\n\n\n_Dreamer's Fall_ is a work of fiction. Names, characters, places, and incidents are the products of the author's imagination or are used fictitiously. Any resemblance to actual events, locales, or persons, living or dead, is entirely coincidental.\n\nA Ballantine Books eBook Edition\n\nCopyright (C) 2018 by Kristen Painter\n\nExcerpt from _Ruler of the Night_ \u00a9 2019 K. Painter\n\nExcerpt from _Scouring_ copyright \u00a9 2019 K. Painter\n\nAll rights reserved.\n\nPublished in the United States by Ballantine Books, an imprint of Random House, a division of Penguin Random House LLC, New York.\n\nBALLANTINE and the HOUSE colophon are registered trademarks of Penguin Random House LLC.\n\nOriginally Published in 2014 by Ace, an imprint of Penguin Random House LLC.\n\neBook ISBN 9781984877510\n\nBallantine Books and the colophon are registered trademarks of Penguin Random House LLC.\n\nwww.ballantinebooks.com\n\nCover design: Scott Biel\n\nCover art: Stephen Youll\n",
    "ed6a15f0f7fa4594e51d5bde21cc0c6c1bedbfdc": "\nModel\n\nELMo-transformer is an LSTM-transformer architecture. During inference, a sequence with the last word left out must be supplied. We use an attention model BIBREF14 to identify all possible $c_i$ and choose the best $u$, before softmax-normalizing.\n\nThe parameters of the shallow syntax encoder were initialized from pretrained ELMo BIBREF0. $e_\\gamma$ was reinitialized every 10 epochs by taking the mean of all encoders, while $e_\\phi$ were not reinitialized.\n\nDatasets, Pretraining Hyperparameters, and Scripts\n\nDownstream tasks and learning algorithm: all tasks used a word-level RNN LSTM-CRF. ELMo-transformer was trained with a cross-entropy loss on a 1.1 billion word corpus. Training took about 30 hours (2 Tesla V100 GPUs). See \u00a7SECREF15 for the hyperparameters used for both pretrainings.\n\nPretraining tasks: all pretraining tasks consisted of pretraining cwrs on the 1.1 billion-word corpus used for downstream training. Training lasted about 30 hours (Nvidia P40 GPUs), with hyperparameters as described above.\n\nLearning algorithm hyperparameters: for RNNLMs, we use the AdamW algorithm with the same learning rate as BERT-transformer (6e-5); for LSTMs (ELMo, ELMo-transformer) we use the Adam algorithm with an initial learning rate 1e-3 (decreasing logarithmically) and a batch size of 40.\n\nPretraining corpus: for downstreams that require annotations, we use the 1.1 million word Penn Treebank. For downstream pretraining, we use the standard 1.1B-word standard English corpus. For preprocessing, we use the same word case-folding and wordpiece tokenization as the ELMo paper BIBREF0, as well as the official chunk script developed for the Conll-2000 shared task BIBREF12. Pretraining was done on 8 Nvidia P100s.\n\nScripts to create the training corpora, scripts to obtain shallow syntactic annotations, and scripts for downstream tasks are included in our code.\n\nCorpus Creation, Pretraining, Chunking, Annotating\n\nCorpus creation: we use a",
    "4d706ce5bde82caf40241f5b78338ea5ee5eb01e": "\nAcknowledgments\nThis work was supported in part by a Google Focuser Grant, and in partial by the Stanford Computational Thinking Initiative.\nBibliography Reference\n\nAharoni, E., Goldberg, Y. A., and Goldberg, Z. An efficient chunker for automatic linguistic annotation. In Proceedings of COLING 2014, pp. 1092\u201399.\n\nAharoni, E., Goldberg, Z., Goldberg, Y., and Kottur, S. Automatic phrase chunking for corpora. CoRR abs/2003.1081.\n\nAharoni, E., Goldberg, Z., and Goldberg, Y. A fast chunker for the Penn Treebank. CoRR abs/2007.0140.\n\nAnderson, D., and Zhu, Y. On the role of syntax in learning context representations. CoRR abs/2005.14489.\n\nArtzi, B., Goldberg, Y., Golub, Y., and Goldberg, Z. ELMo: Deep contextualized representations. In Proceedings of the 2017 International Semantic Computing Conference, pp. 645\u201351.\n\nArtzi, B., Ranzato, M., Soricut, G., and Zhou, K. Context-rich word representations, with applications to question answering and neural machine translation. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Short Papers, pp. 916\u201323.\n\nAugust, S., and Goldberg, Y. Modeling word-level syntax in neural networks for syntax-aware pretraining. In Proceedings of EMNLP, vol. 4, pp. 2172\u201383.\n\nGanitkevitch, A., Goldberg, Z., and Goldberg, Y. A shallow approach to learning latent phrase representations. CoRR abs/2019.03776.\n\nGanitkevitch, A., Haddad, M., Goldberg, Z., and Goldberg, Y. (2019). Towards a scalable shallow grammar induction framework. In Proceedings of the Second Workshop on Computational Grammar and Linguistic Theory: Theory in Practice, pp. 43\u20136.\n\nHall, H., Soricut, G., Goldberg, Z., Goldberg, Y., and Goldberg, Y. Bidirectional learning to predict syntactic information from neural networks representations of text. In Proceedings of ICLR, vol, 35,",
    "86bf75245358f17e35fc133e46a92439ac86d472": "\nAcknowledgments\nWe thank the anonymous reviewers and the editor for their helpful suggestions on earlier drafts.\n\nReferences\n\nBengio, S. and D. Courville. 2015. \"Representation learning: A review and future directions.\" International Journal of Machine Learning, volume 100, pages 1279\u20131298, 2015.\n\nBerk, A., M. Bansal, Z. Houlsby and P. Manning. 2015. \"Matching, mapping, and mining: Learning to represent.\" International Journal of Machine Learning, volume 100, pages 1699\u20131727, 2015.\n\nHu, G., P. Jansson, and F. G. Rosenfeld. 2019. \"Large scale pretraining using contextual word representations and cross-sentence consistency.\" Transactions of the Association for Computational Linguistics, volume 8, number 1, 2019.\n\nJayaraman, R., A. Gupta and O. Vossen, 2019. \"Capsule-and-fuse: Parallel transformer networks for dependency parsing.\" International Joint Conference on Machine Learning, 2019.\n\nKann, Y.-H. and G. Sankaranarayanan. 2018. \"Deep learning in natural language processing: Challenges and insights.\" International Journal of Machine Learning, volume 100, pages 1525\u20131549, 2018.\n\nLee, C., S. Wang, A. Gupta, O. Vossen and D. Jurafsky. 2019. \"Synthesized language: Automatic generation of short natural language templates.\" Transactions of the Association for Computational Linguistics, volume 8, number 1, 2019.\n\nMarcelle, S. and Z. Houlsby. 2015. \"Constituency-based modeling of natural language syntax with pointer-networks.\" International Journal of Machine Learning, volume 100, pages 1771\u20131803, 2015.\n\nPang, B., R. Manning and H. Schulter. 2008. \"Learning deep structures for statistical machine translation.\" Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics.\n\nRaffel, C., K. Shazeer, A. Kudugunuri, W. Xu, A. Lee, J. Wiedemann, K. Lee, S. Kim, C.-Y. Lee, S. Lou, L. Pang",
    "9132d56e26844dc13b3355448d0f14b95bd2178a": " To avoid confounding effects, different hyperparameters were used, and are summarized in \u00a7 SECREF34.\nFurther reading\nAlvarez and Dyer (2013) presented a different sequence-learning architecture, using BERT's sentence-token representations with an additional layer per chunk boundary. They found that word-history encodings help, with no clear preference for one method over the other.\nBeltagy et al. (2018) present similar findings, comparing two alternative language models based on ELMo and GPT.\n\nBengio et al. (2013) show that pretraining on synthetic data for language modeling results in a large improvement in language modeling tasks.\n\nBIBREF0. Elmo: Deep unsupervised Word Representations\nBIBREF1. Does ELMo Model Syntactic Structure?\nBIBREF2. Shallow Syntax\nBIBREF3. Representing Context for NLP with Word Embeddings\nBIBREF4. A Simple Method for Contextualized Word Representation\nBIBREF5. The BERT Model and the Transformer Architecture\nBIBREF6. Improving the Semantic Representation of NLP Models with Cwrs\n\nBIBREF7. Using Syntactic Phrase Context Induction for Neural Networks on NLP Tasks\nBIBREF8. Shallow Coreference Resolution for Coreference Resolution\n\nBIBREF9. Chunk Parse, Chunk Summarize\n\nBIBREF10. Deep Learning of Abstract Syntax\n\nBIBREF11. ELMo Embeddings Capture Syntax for Cross-Lingual Neural Machine Translation\n\nBIBREF12. Shallow Phrase Chunk Cues for Phrase-Structure Parsing\n\nBIBREF13. The Penn Treebank: The Penn Language Technology Group's New Treebank\n\nBIBREF14. Combining BiL STMs with CRFs\n\nBIBREF15. Recurrent Neural Networks for Sequence Labelling\n\nBIBREF16. Transformers: Architectures, Optimization and Experimentation\n\nBIBREF17. Character-based Language Models\n\nBIBREF18. Stochastic Softmax\n\nBIBREF19. The One Billion Word Benchmark\n\nBIBREF20. Conll 03: Coarse-Grained NER\n\nBIBREF21. Annotated Corpus of",
    "f3c204723da53c7c8ef4dc1018ffbee545e81056": "\n\nReferences\n\n[!1] D. Baldi, P. Petrova, and S. Mimno. \"A simple model for open-domain event extraction.\" In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (ACL), pages 1669\u2013 1677, 2014.\n\n[!2] D. Baldi, S. Mimno, and M. Zadeh. \"Open-domain event detection for social media: a probabilistic generative model.\" In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL), pages 1780\u20131786, 2015.\n\n[!3] H. Zhang, S. Mimno, and S. Fomina. \"Event extraction through imitation learning.\" In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL), pages 1172\u20131180, 2017.\n\n[!4] D. E. Smith, D. Mishra, V. Chechik, and M. E. M. Zadeh. \"Learning a word-level representation of online articles.\" In Proceedings of EMNLP, 2017.\n\n[!5] R. Kurach. \"Adversarial training for generative neural network modeling.\" arXiv:1809.04781 ([last accessed: 2020-11-10]).\n\n[!6] M. Salimans, A. Radford, S. Chintalla, M. N. Yang, I. Szegedy, V. Vanhoucke, A. Ilyas, and T. Szegedy. \"Improved techniques for training gans.\" In International Conference on Machine Learning (ICML), pages 1\u201312, 2018.\n\n[!7] X. Zheng, P. Yu, and P. D. Manning. \"Latent event model for tweet extraction.\" In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (ACL), pages 1132\u20131140, 2018.\n\n[!8] H. W. Zhou, K. B. Chiu, and P. S. Yu. \"Simple dirichlet process event mixture model for tweet extraction.\" In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL), pages 1380\u20131390,",
    "0602a974a879e6eae223cdf048410b5a0111665e": " We would also like to thank Prof. David Hsu and Prof. Daniel Bray for their precious guidance and helpful comments.\nFigure 1: Overview of Adversarial-neural Event Model.\nFigure 2: The training procedure of the Innef0.\nFigure 3: Visualization of Tweet data (first row) and Web news data (second row).\nFigure 4: Structure and loss function for discriminator in AEM.\n\nFigure 5: Visualization of Entity distribution for generated documents using AEM.\nFigure 6: Training procedure for AEM.\nFigure 7: Visualization of Location distribution for generated documents using AEM.\nFigure 8: Visualization of Keyword distribution for generated documents using AEM.\n\nFigure 9: Visualization of Date distribution for generated documents using AEM.\n\nFigure 10: Visualization of Generator network for generating events.\n\nFigure 11: Training procedure for Generator network in AEM.\n\nFigure 12: Structure for Generator network in AEM.\n\nREFERENCES\nBIBREF0 Yu Zhou, Jianhua Sun, David Ritter, Zhibin Liu, and Zhiheng Huang. 2014. Simple but effective text clustering approach for open domain event extraction. Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics.\n\nBIBREF1 F. Abdelhaq, S. Abbeel, and S. Deng. 2009. Real-time unsupervised extraction of topics, entities, and locations from tweets. Proceedings of the 16th ACM Conference on Information and Knowledge Management.\n\nBIBREF2 Zhou Zhou, Zhibin Liu, David Ritter, Jianhua Sun, and Zhiheng Huang. 2017. DPEMM: a Dirichlet process model for multi-level event extraction. Computational Linguistics 40:1\u201321.\n\nBIBREF3 Dong Zhang, Gao Yang, Feiyun Liu, Yong Zhao, and Jianhua Sun (2018). Generative adversarial nets for open domain text generation. CoRR abs/1802.08993.\n\nBIBREF4 Xuan Wang, Ao Liu, and Yinlin Zhang (2018). Seqgan: seqgan: Sequence Generative Adversarial Networks. http://arxiv.org/abs/1802.08994.\n\nBIBREF5",
    "56b034c303983b2e276ed6518d6b080f7b8abe6a": "\n\nCompeting Interests Statement\n\nThe authors declare that they have no competing interests.\n\nA Brief Review of Deep Learning and Generative Adversarial Nets\nTraditional algorithms for extracting information from unstructured text use knowledge-driven or predefined-template approaches such as keyword-value extraction Ding, Zhang, and Guo, 2012;Zhang et al., 2012;Hu et al., 2015;Fan et al., 2019) or topic modeling (e.g. latent semantic analysis Deerwester, Soffer, and Stemmens, 1990), for extracting information. Recently with the increasing popularity and availability of social media as a channel for public conversations, a novel class of open domain event extraction approach based on deep learning BIBREF1, BIBREF8 has become a popular research topic. In this paper, we develop an open-domain event extraction approach based on a generative adversarial network BIBREF3 which is constituted by three elements: Generator, Discriminator and Learned INLINEFORM0 Network. The details are provided in subsequent sections.\n\nDiscriminator Network\nThe objective of our work is to generate fake documents to confuse the discriminator network INLINEFORM4 which would be employed to distinguish the fake documents from the inputs. In general, given an input in the form of a document INLINEFORM1, the discriminator network aims to distinguish INLINEFORM1 from its reconstruction INLINEFORM5 generated by a generator network. In our AEM, we first encode the documents into a INLINEFORM1 -dimensional document representation such as vector INLINEFORM0 which captures the key event-related elements from the given input. We then design the generator INLINEFORM0 network INLINEFORM1, a fully connected, multilayer neural network which is used to generate a fake event related word vector INLINEFORM2 based on event representation INLINEFORM1. In general, such generative networks can be viewed as a stochastic model. The objective of discriminator network INLINEFORM4 is to learn the hidden distribution of event representation INLINEFORM1 under the document representation INLINEFORM0 (as shown at the top of Figure FIGREF4 ) using adversarial training so that INLINEFORM0 achieves low classification score according to the discriminator network INLINEFORM4. The whole network INLINEFORM0 is built from four components including event number INLINEFORM1, INLINEFORM5, INLINEFORM6, IN",
    "15e481e668114e4afe0c78eefb716ffe1646b494": "\n\nReferences\n\nH. Abdelhaq, A. Z. Karimi, Z.-H. Zhou and L. Li. EvenTweet: Discovering events using twitter data-in-motion. In K. Cho, A. Z. Karimi, C. Chen et al., 2014. Proceedings of the 41st Annual Meeting of the Association for Computational LIUETZER.\n\nH. Abdelhaq, R. Nesher, C. A. Karimi and L. Li. Open-domain event extraction. Transactions of the Association for Computational Linguistics (TACL), 2015, 2(23):243\u2013258. http://\u200bwww.\u200bacljournals.\u200borg/\u200barchive/\u200b2015.\u200bTacl-Vol.\u200b2.\u200bIssue/\u200b2015.\u200b23.\u200bpaper1115.\u200bhtml\n\nY. Chen, Y.-H. Liu, H. Abdelhaq, L. Li, X. Shen, Y.-J. Liu, R. Nesher and K. Cho. Adversarial neural language style transfer for machine translation.  Transactions of A-CoRR, 2018, 2(17).\n\nH. Chen, T. Nieh, R. Nesher and K. Cho. Automatic tweet composition with adversarial translation and event extraction. To appear in Interspeech, 2018.\n\nH. Chen, X. Shen, Y. Liu, L. Li, Y.-H. Liu and K. Cho. Event2photo: Extracting events from images. In InterSpeech 2018, pages 4716\u20134720, 2017.\n\nA. C. Clarke, R. I. Dale, R. R. K. Irwin, K. D. Dziri and C. L. Curran. A framework for natural language processing research.\n\nW. Gu, Y. Chen, C. J. Kennedy, R. Nesher and K. Cho. Text2event: Combining tweets with news articles to identify events in social media.  Transactions of A-CoRR, 2017, 2(7).\n\nJ. Gratch, D. Chawla and R. I. Dale. Text analysis: Linguistic approaches to analyzing text. AI communicator, 1987.\n\nH. Guo, C. J. Kennedy, R. Nesher, T. J. Smith",
    "3d7a982c718ea6bc7e770d8c5da564fbb9d11951": "\nReferences\n\n[1] BIBREF0.\nAlzoubi, A., Fakhri, F., Nallapati, R., and Zhang, Q. 2018. Open Event Extraction from Short Text with Clustering. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (EMNLP 2018), pp. 15\u201323.\n\n[2] BIBREF1.\nAbdelhaq, A. A. B., Shiva, A., and Zhang, Q. 2015. EvenTweet: An Open-Domain Event Model for Twitter. In Proceedings of the 54 th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 1015\u20131029.\n\n[3] BIBREF2.\nCraswell, N., Zhang, Q., Yoon, Y., Song, Y., and Dredze, D. 2007. Open domain extraction from newswire texts. Computational Linguistics (CAL), 33 (1), 31\u201361.\n\n[4] BIBREF3.\n\nGoodfellow, I., Pouget-Abado, P., Mirza, B., Ahmed, Z., Nguyen, Q., and Warde-Farley, D. 2014. Generative adversarial networks. arxiv:1406.2661v1 [cs.\n\n[5] BIBREF4.\n\nShin, Y., Yang, J., Su, D., Huang, B., and Bhattacharya, S. 2016. seqgan: sequence generative adversarial networks for training neural talker models. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 1125\u20131134.\n\n[6] BIBREF5.\n\nZhang, X., Zhang, Q., Shahrampour, N., and Lu, M. 2017. Distance learning for deep neural relation extraction using a gan adversarial approach. In Proceedings of the 33 rd Conference on Australasian Language Technology (Volume 1: Short Papers), pp. 812\u2013819.\n\n[7] BIBREF6.\n\nLiu, X., Gao, H., Xing, C., Bai, Y., and Zhang, Q. 2016. Learning from noisy crowdsourced textual entailment using adversarial learning. arxiv:17",
    "692c9c5d9ff9cd3e0ce8b5e4fa68dda9bd23dec1": "\nFrom the perspective of job-type, the following words differ in meaning:\n\n1. Cogent \u2013 related to engineering (teched)\n\n2. Influence \u2013 related to management/marketing (biz)\n\n3. Residual \u2013 related to engineering (biz)\n\nFrom the perspective of general interest, the following words differ in meaning:\n\n1. Cloud \u2013 computing or atmosphere/weather (biz/tech)\n\n2. Scam \u2013 deceptive acts or cheating (biz)\n\n3. Kettle \u2013 appliance (house-wares/kitchen)\n\nHow to cite this paper\n\nJ. Guibert. Statistical tests for assessing consistency and heterogeneity. In S. Agrawal and J. Kleinberg, editors, Proceedings of the 13th IEEE International/ACM International Conference on Distributed Systems: Applications, Systems, and Networking. Pp. 35\u201347. New York, NY: ACM Press, 2002.\nY. Li. A semi-supervised approach to identifying a person's spouse, location, and occupation from social media. In M. V. K. Chawla and J. Leskovec, editors, Proceedings of the 20th International World Wide Web Conference, Barcelona, Spain. pp. 681\u2013691. International World Wide Web Consortium, 2010.\nI. R. Preotiuc-Pietro, R. S. Sutton, and F. Raschid. Industry-discover from micro-blogging messages using social network data. In D. Tsamardinos, H. Gkoutzamanis, S. A. M. Smola, and J. Westover, editors, Proceedings of the 16th International Conference on World Wide Web. ACM Press, 2010.\nJ. Pomerantz-Weiss. Anonymity within anonymity: the hidden side of the web. In A. Y. A. K. Jain and J. B. Rosenberg, editors, Proceedings of the 20th National Conference on Artificial Intelligence, Volume 4. AAAI Press, 2003. pp. 4:982\u2013988.\nSangwon Lee, Emanuel Rosenberg. Language-based self-identification. A preliminary report. In T. P. Luebker and S. K. Feigenbaum, editors, Proceedings of the 13th Conference of the European Association for Computer",
    "935d6a6187e6a0c9c0da8e53a42697f853f5c248": " between Different\nWord Similarities between Different Industries\nWord Similarities Between Industry and Job Related Terms\n\nEmotions per Industry and Gender\nBIBREF0: . A. Di Mambro, R. Grodd, M. Zaleski, A. De Sanjose, and D. Zuccon. Inductive Mining of User Interest Profiles on Social Media. Proceedings of the 7th ACM International Conference on Web Search and Data Mining, 2013.\n\nBIBREF1: . R. Karamcheti, T. Sambasivam, S. K. Das, and R. P. Srivastava. Inductive User Profiler: A Personalized Recommendations Approach based on User Actions. Proceedings of the 9th ACM Conference on Recommender Systems, 2013.\n\nBIBREF2: . L. Natarajan, C. Dredze, and D. I. Siegel. User modeling for personalized advertisements on social networks using user's social graph information. Proceedings of the 2013 AAAI Conference on Artificial Intelligence, 2013.\n\nBIBREF3: . L. Rekawek, J. M. A. Smith, S. Mimno, and T. E. Graessler. Social media user profiling with metadata: uncovering hidden information for web mining and cross-platform social advertising. , 2008.\n\nBIBREF4: . A. Di Pietro, R. Fonseca, T. D. G. Dierickx, and J. M. A. Smith. The impact of context-based advertising on user attention and advertising memorability. Marketing Science, 2014.\n\nBIBREF5: . T. D. G. Dierickx and J. M. A. Smith. From social factors to language-use: exploring the relationship between language and social status. , 2008.\n\nBIBREF6: . R. C. G. Dierickx, T. D. G. Dierickx, and A. Di Pietro. Occupational and socioeconomic status from language and cognitive tests in social psychology: a comparative study. Journal of Personality and Social Psychology, 2009.\n\nBIBREF7: . G. Liu, V. K. Parameswaran, C. Wiebe, and",
    "3b77b4defc8a139992bd0b07b5cf718382cb1a5f": "\n\nTable TABREF23 presents some of the different fields that are considered in the Blogger profile. We include them here to understand how our chosen metadata fields correlate with each industry's domain and, particularly, how they correlate with the meaning of relevant words.\n\nFigure FIGREF5 illustrates the distribution of users by city across all Blogger users. Evidently, although not for a majority of the users, the users living in big cities (e.g. New York, Los Angeles, San Francisco, and Chicago) have a greater likelihood to be blogger in an industry. The average percentage of large city users in the industry classification was 41.49% INLINEFORM0.\n\nTable TABREF26 presents the prediction accuracy ( MICROINFORM0 ) and lower prediction bounds ( MICROINFORM1 ), when predicting the bloggers' industry using two feature selection methods: Information Gain Ratio, and Aggressive Feature Rank.\n\nTable TABREF27 presents an overview of how the performance of the different feature selection algorithms varies for the different industries:\n\nTable TABREF19 presents the features that are considered by the L0 and the L1 predictors.\nFigure FIGREF11 presents the prediction accuracy ( MICROINFORM0 ) and lower prediction bounds ( MICROINFORM1 ), of the final L1 ensemble, as measured on all the Blogger blogs.\n\nThe Confusion Matrix for the Final Ensemble\n\nThe Industry Distribution Per Blogger\n\nThe Classification Agreement for All L1 Ensembles\n\nTable TABREF30 shows the confusion matrix of all L1 ensembles (the second column is the number of test instances for which both predictions were correct).\n\nThe Accuracy of Blogger Industry Prediction\n\nTable TABREF31 presents the test set accuracy (acc) and lower error bounds ( accLB ) for the different industries. Note that, as the table suggests, the Real Estate and Religion class have similar overall accuracies.\n\nTable TABREF32 shows the confusion matrix of classifying Blogger bloggers into their respective industry based on the text in their posts.\n\nTable TABREF33 shows the test set accuracy (acc) and the lower error bounds ( accLB ) for classifying Blogger users into their respective industry based on the text in their posts, in conjunction with the metadata features.\n\nThe Performance of Ensemble Classifiers for the Different Industries\n\nTable TABREF34 presents the test set accuracy (acc)",
    "01a41c0a4a7365cd37d28690735114f2ff5229f2": " of Different Industries\n\nFigure 5. Example of word similarities of different industries. The example is drawn from our Environment and Tourism industries.  \nFigure 6. Example of word similarities of different industries. The example is drawn from our Environment and Real Estate industries.  \nFigure 7. Example of word similarities of different industries. The example is drawn from our Environment and Technology industries.\nAdditional Examples of Word Representations of Different Industries\n\nFigure 8. Example of word representations of different industries. The example is drawn from our Real Estate and Education industries.  \nFigure 9. Example of word representations of different industries. The example is drawn from our Tourism and Banking Industries\n\nAdditional Examples on How Positive and Negative Emotion Words are Used by Different Industries\n\nFigure 10. Example of positive emotional words used by different industries. The example is drawn from our Fashion and Banking industries.  \nFigure 11. Example of negative emotional words used by different industries. The example is drawn from our Fashion and Religion industries.\n\nAdditional Examples on How Industry Prediction Accuracy Changes per Different Fold\n\nFigure 12. Accuracy of the prediction task per different fold of the data.  \nFigure 13. Accuracy of the prediction task per different fold of the data.  \nFigure 14. Accuracy of the prediction task per different fold of the data.\n\nAcknowledgments\n\nThis work is based in part on research sponsored by NSF Grant #1344257.  \nA full list of people who helped in the collection or the preprocessing of the data, all the industry experts, all the volunteers, and the sponsors of the open source material is shown on our project wiki.\n\nThe project has received support from The John Templeton Foundation, a philanthropic organisation based in the U.S.A. that seeks to promote scientific research.\n\n[1] Kao, J. (2012) #occupyelections2012: The rise of social media as a force in politics. [Online] Available: https://labs.facebook.com/2012/10/08/occupyelections2012-rise-social-media-force-politics /\n\n[2] Pang, B., R. Brody, R. Agarwal, S. Das, J. DeRosa, Y. Zhou, W. Zhang, K. Liu, P. Abbeel, V. Sharma, L. Smy",
    "cd2878c5a52542ddf080b20bec005d9a74f2d916": "\nWe provide in the following table the top-three word pairs of each industry from the Technology, Tourism, and Banking industries in terms of word similarity: INLINEFORM3\n\n  | Technology:\n\n---|---|---  \nTop-ranked words\n\nCustomer | customers | customers\n\nCheap | cheap | expensive\n\n|\n\nEfficient | inefficient | inefficient\n\nDusty | dusty | clean\n\nEconomical | economical | expensive\n\nTechnology | engineering | finance\n\n|\n\n|\n\nTop-ranked words\n\nCustomer | customers | customers\n\nFood | food | food\n\n|\n\nExpensive | economical | expensive\n\nDusty | dusty | clean\n\nEconomical | economical | expensive\n\nTechnology | technology | finance\n\n|\n\n|\n\nTop-ranked words\n\nCustomer | customers | customers\n\nFood | food | food\n\nEfficient | efficient | efficient\n\nDusty | dusty | clean\n\nSystematic | scientific | scientific\n\nEnvironmental | ecological | ecological\n\nEnvironmental | ecological | ecological\n\nEnvironmental | ecological | ecological\n\nEnvironmental | ecological | ecological\n\n  | Technology:\n\n---|---|---  \nTop-ranked words\n\nCustomer | customers | customers\n\nCheap | cheap | expensive\n\nEconomical | economical | economical\n\nDusty | dusty | clean\n\nEconomical | economical | expensive\n\nTechnology | technology | technology\n\n|\n\nTop-ranked words\n\nCustomer | customers | customers\n\nDusty | dusty | clean\n\nEconomical | economical | expensive\n\nTechnology | technology | finance\n\n|\n\n|\n\nTop-ranked words\n\nCustomer | customers | customers\n\nFood | food | food\n\nEfficient | efficient | efficient\n\nDusty | dusty | clean\n\nEconomical | economical | expensive\n\nTechnology | technology | technology\n\n|\n\nTop-ranked words\n\nCustomer | customers | customers\n\nEconomical | economical | economical\n\nDusty | dusty | clean\n\nSystematic | scientific | scientific\n\nEnvironmental | ecological | ecological\n\nEnvironmental | ecological | ecological\n\nEnvironmental | ecological | ecological\n\nEnvironmental | ecological | ecological\n\nEnvironmental",
    "fd2c6c26fd0ab3c10aae4f2550c5391576a77491": "\nAcknowledgements\nThis project was supported by a grant from the U.S. Department of Education, Title III of the Higher Education Act of 1965 (Grant #S225E160001). This article reflects the views only of the authors, and the USDOE does not assume any liability for the use of any information contained in this paper.\n\nBibliography\n\n[1] E. K. Manilal, M. K. S. Murad, and M. E. Zaki. Text emotion detection using deep neural network with bidirectional recurrent neural network and context-sensitive encoding features. In 2016.\n\n[2] C. Cibani\u0107, D. G. Kar\u010dun, and V. D\u017eeroski. A comprehensive survey and taxonomy of emotion detection from text. ACM Computing Surveys (CSUR), 50(2):1135\u20131187, 2016.\n\n[3] E. P. Parrott, H. L. K. Leung, and H. L. Ro. A hierarchical taxonomy of emotion. Cognition and Emotion, 15(3):277\u2013306, 2010.\n\n[4] A. Plutchik. Emotions and human motivation: A model of human behavior. Psychology of Human Motives, 3(1):1\u201337, 1988.\n\n[5] S. D. Lewis. A taxonomy of the emotions. Emotion Review 1(1):1\u201328, 1993.\n\n[6] A. Ekman. An introduction to basic emotions. Cognition and Emotion, 2(1):9\u201331, 1989.\n\n[7] T. Plutchik. Motivated behavior: Affect, cognition, and development. Science (New York, N.Y.), 281(5381):223\u2013231, 1998.\n\n[8] T. Plutchik. What do we mean by \"emotions\"? An empirical approach. Cognition and Emotion, 19(3):329\u2013354, 2004.\n\n[9] H. L. K. Leung. Handbook of emotion. Cambridge: Cambridge University Press, 2007.\n\n[10] R. M. Gonzalez Bail\u00e3o, A. H. Obradors, O. Vilar, and C. Torrents Cordon\u00eds. Emotion expression detection: State of the art and current limitations. Comput",
    "6b6d498546f856ac20958f666fc3fd55811347e2": "\nAcknowledgements\n\nWe want to thank our colleague and advisor Mert Altu\u011f, and T.Z. Hasan who have given us a great support and motivation to finish this work.\nBibliography\n\nB. Abdel-Razek. V. Altu\u1e5bk. M. Althuwayn. \"Affect in tweets sentiment analysis: a data-driven approach.\" 2017 International Conference on Advances in Social Networks Analysis and Mining (ASONAM). 2017.\n\nJ. Agarwal. J. A. Bigham. \"Affective text classification: the role of machine learning\" In The proceedings of the th international workshop on advances in affective computing, pages 3\u20138. 2012.\n\nK. Akarajan. \"Affect-aware sentiment classification of tweets sentiment analysis.\" In Proceedings of the 2nd International Conference on Social Media and Society. 2016.\n\nT. Alkhasawna. \"Understanding sentiment analysis in twitter.\" 2012.\n\nR. Altinel. M. Bostan. L.-T. Chen. L. K. Liu. M. Klinger. X. Q. Wang. \"On the affective detection of personal tweets.\" 2014 Asia-Pacific Conference on Intellectual Computing (APCICT). 2014.\n\nT. Altinel. X. Q. Wang. L. P. Klinger. S. P. Deng. \"Emotion detection in tweets: features and techniques.\" 2016 Asia-Pacific Conference on Intellectual Computing (APCICT). 2016.\n\nP. Arora. S. J. Decker. \"Semantically unsupervised sentiment analysis of social media text data: an investigation of different classification approaches.\" Computational Linguistics 2013.\n\nJ. D. Armstrong. \"The power of the crowd in sentiment analysis.\" 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). 2013.\n\nH. A. Arzuza. M. I. Benaboud. J. Dyer. S. D. Mimno. F. R. Pfeiffer. P. R. Shah. \"Detecting and quantifying emotions in text.\" 2015 International Conference on Multimodal Communication Across the Lifespan. 2015.\n\nC. Bach. C. H\u00fctter. D. J. Lecue. A. S. P. Loper. \"T",
    "de3b1145cb4111ea2d4e113f816b537d052d9814": " Other more modern pre-trained word vector spaces like ELMo BIBREF40, DistilBERT BIBREF41, BERT+Auxiliary Losses BIBREF42, BERT-Fine-tuning for Diverse Sentence Embeddings BIBREF43 can also be tried out for the task with pre-processed tweet data provided by Wang et al.. The results of our emotional twitter classification experiments can be found at [https://github.com/armintabari/Emotion-DetectionRRNN]. The data has been processed to the best of our ability and is free for use by others.\n\nAppendix\n\n1.\n\nB.\n\n\nEmotions with Similar Texts\n\n2.\n\nB.\n\nDeep Learning Approaches for Emotion Recognition in Text\n\n3.\n\nB.\nBidirectional Recurrent Neural Networks\n\n4.\nB.\nB.\nBidirectional Gated Recurrent Unit (Bi-GRU)\n\n5.\nB.\nExperiment\n\n6.\nB.\n.\nIntroduction\n\nA lot of work has been done on detecting emotion in speech or visual data BIBREF10, BIBREF11, BIBREF12, BIBREF13. But detecting emotions in textual data is a relatively new area that demands more research. There have been many attempts to detect emotions in text using conventional machine learning techniques and handcrafted features in which given the dataset, the authors try to find the best feature set that represents the most and the best information about the text, then passing the converted text as feature vectors to the classifier for training BIBREF14, BIBREF15, BIBREF16, BIBREF17, BIBREF18, BIBREF19, BIBREF20, BIBREF21, BIBREF22, BIBREF23, BIBREF24, BIBREF25, BIBREF26. During the process of creating the feature set, in these methods, some of the most important information in the text such as the sequential nature of the data, and the context will be lost.\n\nConsidering the complexity of the task, and the fact that these models lose a lot of information by using simpler models such as the bag of words model (BOW) or lexicon features, these attempts lead to methods which are not reusable and",
    "132f752169adf6dc5ade3e4ca773c11044985da4": "\nTable TABREF5. Tweets characteristics\n\nTable TABREF10. Word Embeddings Performance\n\nTable TABREF11. Model Evaluation with Respect to Feature Set and Embeddings\n\nTable TABREF12. Model Evaluation with Respect to Different Classification Mechanisms\n\nTable TABREF13. Model Evaluation with Respect to Epoch and Batch Size\n\nTable TABREF14. Model Evaluation with Respect to Optimizer and Gradient Penalty\n\nTable TABREF15. Model Evaluation with Respect to Learning Rate\n\nTable TABREF16. Emotional Words Distribution and its Count\n\nTable TABREF17. Model Evaluation with Respect to Random State and Initialization\n\nTable TABREF18. CrowdFlower Tweet Labels Distribution\n\nTable TABREF19. Emotion Detection Accuracy on CrowdFlower Dataset\n\nTable TABREF20. Model Evaluation on Kaggle Dataset\n\nTable TABREF21. Emotional Words Distribution and its Count\n\nTable TABREF22. BERT Embeddings Performance\n\nTable TABREF23. Model Evaluation with Respect to FastText Embeddings\n\nTable TABREF24. Model Evaluation Performance with Different FastText Embeddings\n\nTable TABREF25. Model Evaluation Performance with Varying Number of Tweets in Validation Set\n\nTable TABREF26. Model Evaluation with Respect to Different Optimizers and Gradient Penalty\n\nTable TABREF27. Varying Number of Epochs and Batch Size Impact on Performance\n\nTable TABREF28. Different Optimizers and Gradient Penalty Impact on Performance\n\nTable TABREF29. Random State and Initialization Impact on Performance\n\nTable TABREF30. BERT Embeddings Performance\n\nTable TABREF31. Varying Number of Tweets in Validation Set Impact on Performance\n\nTable TABREF32. F-Measure Impact on Performance\n\nTable TABREF33. Varying Number of Epochs Impact on Performance\n\nTable TABREF34. Different Learning Rates Impact on Performance\n\nTable TABREF35. Numberbatch Embeddings Performance\n\nTable TABREF36. Embeddings Performance\n\nTable TABREF37. Attention Networks Performance\n\nTable TABREF38. BERT Performance\n\nTable TABREF39. Bert Performance\n\nTable TABREF40. Deeply Learning the Language Represent",
    "1d9aeeaa6efa1367c22be0718f5a5635a73844bd": "\nFor the future work, we plan to use more neural networks like attention-based models BIBREF37, BIBREF38 and language model based models BIBREF39 to create a refined hidden representation of the text. We also plan on training the model on a bigger dataset and also on the sentiment side of this task by introducing sentiment lexics into the embedding space.\nAcknowledgments\n\nThis work is supported by a gift from Amirali, LLC. We would like to express our gratitude to the authors of fastText, ConceptNet Numberbatch, and a lot of other tools we use for our work to succeed. The authors would like to thank Dr. N. Lazaridou and her associates for their valuable time and help.\n1 BIBREF3 Ekman, Paul, and Richard J. Davidson. Emotions and social interaction. Annual Review of Psychology, 49:175\u2013194, 1998.\n2 BIBREF4 Plutchik, Jan, et al. \"The evolution of theory of emotions: A reappraisal.\" Journal of Personality and Social Psychology, 52.4, 1992.\n3 BIBREF5 Parrott, William I, et al. \"The three-level model of emotion: An integrated scheme of human motivational states.\" Cognition and Emotion, 14.4, 1990.\n4 BIBREF6 Bharadwaj, Deepanshu, et al. \"Lexical representation of emotion.\" International Journal of Theoretical and Applied Electronic Commerce, 8.5, 2008. Viewed 10 November, 2015. BIBREF\n5 BIBREF7 Juzbas, Martin and Joakim Niegard. \"Identification of emotions in text through lexico-syntactic information.\" Data and Knowledge Engineering, 69.2, 2014. Viewed 6 June, 2016. BIBREF\n6 BIBREF8 Juzbas, Martin and Joakim Niegard. \"An efficient approach to automatic identification of emotion in text.\" Proceedings of the Sixth ACM Conference on Web Search and Data Mining, 2010. Viewed 21 December, 2015. BIBREF\n7 BIBREF9 BIBREF10 Bharadwaj, Deepanshu, et al. \"Detecting emotions in tweets from the big data repository using lexicon features.\" Information, 8.8, 2015. Viewed October 18th, 2015. BIBREF\n8 BIB",
    "012b8a89aea27485797373adbcda32f16f9d7b54": "\nAcknowledgments\n\nI would like to thank Dr. Lyle Brimble for useful feedback and comments. This research was funded by the South African National Research Foundation (Grant Number 105264).\n\nTable TABREF1. Accuracy scores and execution times (ms) reported in DSL 2015 and DSL 2017 benchmark papers. The reported times are for training a neural network on a Intel Core i5 2.1 GHz with 4GB RAM.\nTable TABREF2. First language speaker percentages for official languages of South Africa in the 2001 national Population Census\nTable TABREF3. Accuracy scores for different data sets\nTable TABREF4. Lexicon size and execution time for the naive Bayes and hierarchical lexicon classifier\nTable TABREF5. DSL 2015 data set\nTable TABREF6. DSL 2017 data set\nTable TABREF7. WiLI 2018 data set\nTable TABREF8. NCHLT 2018 text corpora\nTable TABREF9. Stacked naive Bayes and lexicon results\nTable TABREF10. Execution results comparison between different LID algorithm implementations\nTable TABREF11. NB LID n-gram language model using the DS LDS shared task 2017 training data\nTable TABREF12. Hashed feature representation character LID results for DSL 2017\nTable TABREF13. Lexicon support NB LID results for DSL 2017\nTable TABREF14. Hierarchical lexicon support NB results for DSL 2017\nTable TABREF15. Lexicon support NB results for an NCHLT 2013 training data set\nTable TABREF16. Ensemble NB results for DSL 2015\nTable TABREF17. NB support vector machines results for DSL 2015\nTable TABREF18. Language classification results for the NCHLT and WiLI data sets\nTable TABREF19. Stacked NB support vector machines result for an NCHLT 2013 training set\nTable TABREF20. Language classification results for the WiLI data set\nTable TABREF21. Data augmentation experiment for an NCHLT 2013 training set\nTable TABREF22. Adversarial training results for an NCHLT 2013 training set\nTable TABREF23. Results for using a bidirectional recurrent neural network for LID on the DSL 2015 training data set\nTable TABREF24. Average scores for different LID results using deep learning on the DSL 2017 training data set\nTable TABREF25. Shallow language model results for LID on the DSL 2017",
    "c598028815066089cc1e131b96d6966d2610467a": "\n\nAcknowledgments\n\nThe authors would like to thank the research unit at the university of the North for their support of this work. The authors would also like to thank Dr. Thomas Kocmi for his insight and guidance regarding the implementation of the deep LID method.\n\n\n\nThis is a work of fiction. Names, characters, places, and incidents either are the product of the author's imagination or are used fictitiously. Any resemblance to actual persons, living or dead, events, or locales is entirely coincidental.\n\nText copyright \u00a9 2013 by Soman Chainani  \nCover art by Aleksandar Zgog  \nFrontispiece illustration by Paul Young  \nMap art by Jason Chan  \nIllustrations by Jomme King\n\nAll rights reserved. Published in the United States by Yearling, an imprint of Random House Children's Books, a division of Random House LLC, a Penguin Random House Company, New York.\n\nYearling and the jumping horse design are registered trademarks of Random House LLC.\n\nVisit us on the Web\n\nEducators and librarians, for a variety of teaching tools, visit us at RHTeachersLibrarians.com\n\neBook ISBN 978-0-553-93899-9  \nHardcover ISBN 978-0-553-93898-2\n\nRandom House Children's Books supports the First Amendment and celebrates the right to read.\n\nv3.1_r5\n_For Samantha_\n\n# Contents\n\n_Cover_\n\n_Title Page_\n\n_Copyright_\n\n_Dedication_\n\nPrologue\n\nPart I: THE MAGIC WRECK\n\n1: STALLION  \n2: A PENNY FOR THOUGHT  \n3: RUTHEN'S SHAPE-THROWER  \n4: MYTHS AND MAYHEM  \n**5:** TROUBLE IN WONDERLAND  \n6: RUGGED  \n7: THE LUCKY SPUR  \n8: SIDEKICK  \n9: A CROWD OF MORTALS\n\n10: PAY-O-DECKS  \n**11:** RULES OF SPACE\n\n12: THE DEAD-BEEF QUESTION  \n13: THESE ARAB",
    "ca4daafdc23f4e23d933ebabe682e1fe0d4b95ed": "\n\nTABLE TABREF2.\n\nPercents of first language speakers.\nTABLE TABREF3.\n\nAccuracies for classifying the DSL 2017 BIBREF1 shared task test data with the proposed algorithm compared to other reported LID accuracies.\nTABLE TABREF4.\n\nAccuracies for classifying the DSL 2015 BIBREF19 shared task test data with the proposed algorithm compared to other reported LID accuracies.\nTABLE TABREF5.\n\nAccuracies of LID evaluations of different LID implementation methods compared to the proposed algorithm.\nTABLE TABREF6.\n\nAccuracies for the NCHLT corpora BIBREF7.\nTABLE TABREF7.\n\nExecution times of various LID implementation methods compared to the proposed algorithm with the best scores (NB+Lex stacked) highlighted.\nTABLE TABREF8.\n\nAverage accuracy reported for classification of languages from the DSL 2015 and DSL 2017 shared tasks.\nTABLE TABREF9.\n\nMean and standard deviation of different algorithms compared in the paper.\nTABLE TABREF10.\n\nExecution times (\u00b5s) of various LID implementation methods compared to the proposed algorithm with the best scores (NB+Lex stacked) highlighted.\n\nACKNOWLEDGEMENTS\n\nThe work discussed in this white paper was originally published as one of a chapter in a submitted manuscript to the 2017 Summer Research Symposium at Stellenbosch University in South Africa. The chapter has been edited down a little due to limitations of the white paper channel. Thanks to Shivaun Moodhe for reviewing and adding comments on the manuscript, as well as the rest of the SORSE research group for making the research possible. Thanks also to Prof. Mmela Ramatsi at Swinburne University of Technology and to Prof. Richard Lai at the National Taiwan University of Science and Technology, for their contributions to the research.\n\nB.B. developed the original idea for the approach and the first version. N.W. supervised the research and contributed to writing the manuscript.\n\nBIBLIOGRAPHY\n\nB. Babu, E. Pekka, D. Hajieva. 2019. South African Language Variety Identification using Ensemble N-grams. Krakow, Poland\n\nB.B. Banerjee. 2017. Language Variety Identification on Multiple Languages Benchmark Datas",
    "0ab3df10f0b7203e859e9b62ffa7d6d79ffbbe50": " Support for languages like Afrikaans is also growing. Data is still one of the biggest roadblocks, but researchers are coming up with strategies to harvest data from corpora and to identify similar languages to augment the available data.\nAcknowledgements\nThe authors would like to thank Chris Galea and Johnathan Ross for their help in preparing the first draft of this paper and would like to thank the referees for their comments and feedback.\nFunding\n\nThis publication was supported by the South African Research Chair Programme (SARRC) and the National Research Foundation (NRF) and is gratefully acknowledged.\n\nReferences\n\nBIBREF1. (DSL15) M. Otsuka, K. Doornbosch, R. Groeninkooph, N. Myllym\u00e4ki, I. R. Turchanski, Y. Kim, J. W. Zweers, A. Dey, L. van der Plas, A. Yatsenko, R. K. K. Gopal, R. S. Prasad and P. M. Resnick. DS15: Discriminative Language Identification 2015. In Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Volume 1, pages 1691-1704, Association for Computational Linguistics, 2015.\n\nBIBREF2. (JW300) J. Zhang, E. Horovitz, C. Yang, L. Xiong, T. Kueppers, B. V. C. Waddli, H. S. Chaudhuri, A. Subramanian, E.-M. Ting, S. Su, and S. Zelenko. JW300: A new benchmark for languages and language pairs. In Proceedings of the Eighth Joint Conference on Lexicon and Grammar and Joint Conference on Discourse and Sentence Structure: Volume 1, pages 211-224, American Association for Applied Linguistics, 2018.\n\nBIBREF3. J. de Beers and S. N. D. Liphoko. Nguni language resources. South African Journal of Linguistics 31-34, (2018),\n\nBIBREF4. (wikili) K. M. L. Schuster, O. Beno\u00eet-Rohlmann, M. Aoun-Sa",
    "92dfacbbfa732ecea006e251be415a6f89fb4ec6": " We expect that machine comprehension of documents written in South African and similar languages can be improved in the near future.\nAcknowledgements\n\nThe research work has been partially supported by National Research Foundation with Grant Number 76130.\nThe authors are thankful to Andriy Bogdan and M. Wouter Snoepstuivens for fruitful discussion on the topic as well as to Nkosipho Phakathi for her insights into the language resources in South Africa.\n\nThe works by BIBREF0 through to and including BIBREF5 are relevant to the area, the one from BIBREF7 onwards are about different aspects of the topic. The works from BIBREF7 through to and including BIBREF12 are about LID, BIBREF13, BIBREF14, BIBREF15, BIBREF16, BIBREF26 and BIBREF27 are about the use of machine learning in different application areas.\n\n#bib\n##  table-of-contents\n\n#bib-table-of-contents\n\n0  \n1  \n2  \n3  \n4  \n5  \n6  \n7  \n8  \n9    \nReferences\n\n#reference\n\n##  table-of-contents\n\n0  \n1  \n2  \n3  \n4  \n5  \n6  \n7  \n8  \n9  \nReferences\n\n##  table-of-contents\n\n0  \n1  \n2  \n3  \n4  \n5  \n6  \n7  \n8  \n9  \nReferences\n\n##  table-of-contents\n\n0  \n1  \n2  \n3  \n4  \n5  \n6  \n7  \n8  \n9  \nReferences\n\n##  table-of-contents\n\n0  \n1  \n2  \n3  \n4  \n5  \n6  \n7  \n8  \n9  \nReferences\n\n##  table-of-contents\n\n0  \n1  \n2  \n3  \n4  \n5  \n6  \n7  \n8  \n9  \nReferences\n\n##  table-of-contents\n\n0  \n1  \n2  \n3  \n4  \n5  \n6  \n7  \n8",
    "c8541ff10c4e0c8e9eb37d9d7ea408d1914019a9": "\nThe work on this paper was supported by funding from The National Research Foundation (Grant: 94065), the South African National Research Foundation (Grant: 82200), the University of Pretoria, the National Library of South Africa and South Africa's Department of Science and Technology.\n\n## References\n\n---\n\n[BIBREF1] Bojarski, S. (2018) DSL 2017 Shared Task: Language Detection and Classification. Proceedings of The 10th International Workshop on Discriminating between Similar Languages (DSL 2017) in conjunction with LREC 2018.\n\n[BIBREF2] Ljube\u0161i\u0107, S. (2015) JW300: 300 languages in parallel. https://www.cs.cmu.edu/jsi/jw300/\n\n[BIBREF3] Sizani, T. (2018) The University of Pretoria Xitsonga Corpus Project. https://tshivendale.org/xitsonga-corpus\n\n[BIBREF4] De Bruijn, J. and van der Kleij, H. (2018) WiLI-2018: a corpus of 235 language varieties. https://ling.auf.net/work/wlil\n\n[BIBREF5] Vlontz, R. (2018) A tutorial on native language and native variety identification. http://r0v.es/2018/03/31/a-tutorial-on-native-language-and-native-variety-identification-nlvi-lvpi-nlda\n\n[BIBREF6] http://corpus.phg.ed.ac.uk/language-identification.phg\n\n[BIBREF7] Menezes, D. (2012) Non-Content Hierarchical Language Tracing using Text Data: Exploratory and Comparative Analysis of Nchlt's South African Data. http://www.ed.ac.uk/nchlt/papers/t_menezes.pdf\n\n[BIBREF8] Trenkler, S. (2018a) Building and Using a Language Identification Pipeline (A Sklearn Case Study). https://scikit-learn.org/stable/auto_examples/language_identification.html\n\n[BIBREF9] Dahlmeir,",
    "307e8ab37b67202fe22aedd9a98d9d06aaa169c5": "\nAcknowledgement\nThis research work is supported by the National Research Foundation of South Africa through the Industrialisation Support Scheme for AI and Machine Learning. All conclusions in this paper are the authors' own and the research and methodology are discussed in this paper.\n\nReferences\n\n2.1. DSL tasks\n\n[BIBREF1]\n\nA. Bhattacharyya, et al.\n\nLanguage Discrimination using Distributed Feature Learning of Representational Units.\n\nIn: C. Eichmann, et al. (eds.).\n\nLanguage Disrimination via Representations.\n\nLREC 2017 Shared Task.\n\nKaggle Incorporated, 2017.\n\n[BIBREF2]\n\nJ. Crayton, et al.\n\nThe JW300 Language Identification Challenge.\n\nIn: C. Eichmann, et al. (eds.).\n\nBilingual lexical comparison in Indo-Aryan languages.\n\nIn: C. Eichmann, et al. (eds.).\n\nLanguage Discrimination via Representations.\n\nLREC 2017 Shared Task. Kaggle Incorporated, 2017.\n\n[BIBREF3]\n\nM. Zulu, et al.\n\nJW300: Language Identification on a large-scale.\n\nJournal of Natural Language Processing Research Journal: Explore, Create, Interact. Online Journal, vol. 6.\n\n[BIBREF4]\n\nT. Ritter, et al.\n\nA benchmark for monolingual written language identification.\n\nIn: D. De Meo, et al. (eds.).\n\nBenchmarking for Machine Comprehension. Open Data, Open Access.\n\nWorkshop Proceedings. Language and Technology Institute at Carnegie Mellon University, 2018.\n\n[BIBREF5]\n\nM. Hebden, et al.\n\nNLI vs NVIDIA: Native Language Identification.\n\n[www\n\nBIBREF6]\n\nI. Alani, et al.\n\nThe Leipzig Corpora Collection: A Resource for Corpus-Based Statistical Phrase-to-Phrase Translation.\n\nLanguage Resources and Evaluation, vol. 59. Springer International Publishing, 2018.\n\nBIBREF7]\n\nR. Sch\u00e4fer.\n\nIntroduction to the NCHLT Text",
    "6415f38a06c2f99e8627e8ba6251aa4b364ade2d": "\n\nAcknowledgements\n\nThe authors acknowledge the following: The South African Council on Higher Education (HCUP/BEDUP), Mthumazi Mabhena, Yousr Nzhanga, Leen Buitelaar, The Department of Higher Education and Training and the National Research Foundation for the support received.\nTable 1. Comparison of LID training / testing sets\n\nDSL 2015 was the first ever publicly available LID shared task. This paper discusses the results of the language identification (LID) competition for the South African languages. The paper also describes the design of the algorithm, its training set, its test set, its evaluation measures and the results which were shared for these tasks by the lead researcher for the University of Pretoria submission.\nDSL 2017 was a follow on task with similar features. This paper does not discuss the results.\nDSTI 2019 was the first ever shared task for DSTI 2019. This paper also does not discuss the results.\nNCHLT was an NLP shared task that collected corpora for DSTI 2019 but only used it for evaluation. This paper also does not discuss the results.\nAcknowledgements\nWe are grateful for the support of our funders: the Humboldt Foundation with funding from the BMBF, the DAAD, the DAAD Alumni Network, DLR, the Federal Ministry of Education and Research.\n\nReferences\n\nThis paper makes reference to the following:\n\nBautista, M. J., Wagstaff, S. (2020). Universal Declaration in 100 languages. <URL: <https://hugo.usc.edu/~mwankhede/_UDeH/UDHR.pdf>\n\nBIBREF1.\n\nDumush, J., McCallum, F., Morales-Cruz, W. (2011). South African languages and language codes. <URL: <https://www.cs.princeton.edu/~morales/papers/salgc_11.pdf>\n\nBIBREF2.\n\nHoffmann, L. J. (2019). Crosslingual transfer of learned sentence structure representations. <URL: <https://openReview.net/pdf?id=BjeUbB6u>\n\nBIBREF3.\n\nMabhena, M., Buitelaar, L. H.,",
    "e5c8e9e54e77960c8c26e8e238168a603fcdfcc6": "\nTable 1\n\nTable 2\nTable 3\n\nTable 4\n\nTable 5\nTable 6\n\nTable 7\n\nTable 8\n\nTable 9\n\nTable 10\n\nTable 11\n\nTable 12\n\nTable 13\n\nTable 14\n\nTable 15\n\nTable 16\n\nTable 17\n\nTable 18\n\nTable 19\nTable 20\n\nTable 21\n\nTable 22\n\nTable 23\nTable 24\n\nTable 25\n\nTable 26\n\nTable 27\n\nTable 28\n\nTable 29\nTable 30\n\nTable 31\n\nTable 32\n\nTable 33\n\nTable 34\n\nTable 35\n\nTable 36\n\nTable 37\n\nTable 38\n\nTable 39\n\nTable 40\n\nTable 41\n\nTable 42\nTable 43\n\nTable 44\n\nTable 45\nTable 46\n\nTable 47\n\nTable 48\nTable 49\n\nTable 50\n\nTable 51\n\nTable 52\n\nTable 53\n\nTable 54\n\nTable 55\nTable 56\n\nTable 57\n\nTable 58\nTable 59\n\nTable 60\n\nTable 61\n\nTable 62\n\nTable 63\n\nTable 64\n\nTable 65\n\nTable 66\n\nTable 67\nTable 68\nTable 69\n\nTable 70\nTable 71\nTable 72\n\nTable 73\n\nTable 74\n\nTable 75\n\nTable 76\nTable 77\nTable 78\n\nTable 79\nTable 80\n\nTable 81\n\nTable 82\nTable 83\n\nTable 84\n\nTable 85\nTable 86\n\nTable 87\nTable 88\nTable 89\nTable 90\n\nTable 91\nTable 92\nTable 93\nTable 94\nTable 95\nTable 96\nTable 97\nTable 98\nTable 99\nTable 100\n\nTable 101\n\nTable 102\n\nTable 103\n\nTable 104\nTable 105\nTable 106\nTable 107\nTable 108\n\nTable 109\n\nTable 110\nTable 111\nTable 112\nTable 113\nTable 114\n\nTable 115\n\nTable 116\nTable 117\nTable 118\nTable 119\nTable 120\n\nTable 121\n\nTable 122\n\nTable 123\nTable 124\n\nTable 125\nTable 126\nTable 127\nTable 128\nTable 129\nTable 130\n\nTable 131\nTable 132\nTable 133\n\nTable 134\nTable 135\n\nTable 136\nTable 137\n\nTable 138\nTable",
    "50be4a737dc0951b35d139f51075011095d77f2a": " For instance, when we know the probability of each class is 0.5/0.3/0.2, the true class distribution is 1:0.7/0.7 and set the reference distribution to 0:0.5/0:0.7.\nThough we use class distribution as an auxiliary variable, KL divergence focuses on feature distribution as well. For instance, in baseball-hockey classification, the features that highly indicate a class is hockey, such as word ice. Therefore, when introducing KL divergence, we should supply additional hockey features as labeled features. In our baseball-hockey dataset, feature words such as hockey, goal, coach would fit this requirement.\n\nAcknowledgments\nThe author would like to thank Prof. Huan Liu, Prof. Boqing Jiang and Prof. Guang Gong for the valuable comments. This program was supported by the National Natural Science Foundation of China (NNSFC) and the Science and Technology Project of Beijing Education Committee (11B20210002-4, 11B20102004011-5).\n\nWeisheng Wang is currently pursuing his PhD degree at Beijing Normal University under supervision of Prof. Huan Liu, and would like to thank Prof. Huan Liu and Prof. Boqing Jiang for valuable discussions. His thanks also extend to Prof. Guang Gong and Prof. Yuanzhen Zhang.\n\nReferences\n\nBIBREF0\n\nDruck, B., Gong, G., Jiang, B. \"Generalized Expectation for Text Categorization.\" In Proceedings of the Annual Conference of the North American Association for Computational Linguistics, page 98-108, 2012.\n\nBIBREF1\n\nGeman, Y., Gorman, N., Riedel, S. \"Text categorization using labeled features.\" Data Mining and Knowledge Discovery, 8(4), July 2003.\n\nBIBREF2\n\nLiu, T. D., Gong, G. \"Learning from Labeled Features in Text Categorization.\" In Proceedings of the Fourteenth International Joint Conference on Computers, Information, and Intelligence, page 23-30, 2003.\n\nBIBREF3\n\nRaghavan, S., Druck, B., McCallum, P., Zhai, Y. \"Modeling feature importance in feature space.\" Machine Learning, 41(3-5), July 2009.\n\nBIB",
    "6becff2967fe7c5256fe0b00231765be5b9db9f1": "\n\nIn Section 4, we observe the influence of \u03bb (the strength of the KL divergence term) when there exists no knowledge and when we have the knowledge of the corpus. Incorporating KL divergence boosts the model more when we have the more accurate knowledge (see Figure 4 (a), (b) ). In most cases, the choice of \u03bb is set to be proportional to the total number of labeled features with no less than a few ones.\nThe KL divergence in the framework of GE is different to the KL divergence on the input instances. In GE, $p_\\theta (y | c) = \\frac{1}{Z}Exp(1 + \\sum _i \\theta _{yi}x_i)$ by minimizing the value of the above formula (Eq. 5). Whereas when training the model using learning objective function of KL divergence, the score function is defined to be the KL divergence in this setting.\nLimitations & Future Works\nIn our experiments, we don't utilize features like document length and the number of words. Incorporating such features is future work. Further, we only consider two classes for each feature. Other features such as compound, tense, subject and object can also be leveraged. Last, we do not investigate into how to incorporate knowledge automatically. This may be a future work.\nAlthough incorporating prior knowledge boosts the learning model significantly, it may also introduce some bias into the model. Our future work includes the detection and reduction of bias.\nAcknowledgments\nThis work is supported by National Natural Science Foundation of China, Project 61471307, Joint funding from U.S. Department of Defense (Grant No.: W911NF-13-1-0333), and U.S. National Science Foundation (Grant Nos.: 1115662, 1131830).\n\n[A1] S. Gupta, A. Ghosh, and M. A. S. Daum\u00e9. \"Text Categorization with Generalization Expectation.\" Lecture Notes in Computer Science, vol. 5596, no. 7, 2007, pp. 7\u201336.\n\n[A2] S. Gupta, A. Ghosh, and M.A. S. Daum\u00e9. \"Text Classification using Constrained Prediction Models.\" Technical Report, University of Waterloo, 2008.\n\n[A3] Y. Sun and Y. Zhao. \"Text Categorization",
    "76121e359dfe3f16c2a352bd35f28005f2a40da3": "\nThere are several other effective methods that are beyond our survey scope, which can be found in BIBREF7, BIBREF10, BIBREF11.\nOur method is only limited to constraint terms expressed as functions of parameters or expectations. Some constraint terms like KL divergence are actually expressed as integrals, which cannot be employed in GE-FL. Other constraint terms can be transformed as expectations, and can be introduced into GE-FL. In BIBREF6, BIBREF13, BIBREF12, BIBREF5, they explored more sophisticated constraint representations and formalisations.\nAcknowledgments\nWe are grateful to the support of NSF of China, Grant 60873012.\nReferences\n\n1. C. Liu, Y. Wan, and S. Radev, \"Learning from data with unbalanced labeled features,\" in Proceedings of the 23rd International Joint Conference on Artificial Intelligence, 2013, 789\u2013797.\n\n2. S. Radev and S. Ribeiro, \"Eliminating features through generalization expectation criteria,\" in Proceedings of the 22nd International Joint Conference on Artificial Intelligence, 2012, 1691\u20131697.\n\n3. Y. Rui and S. Radev, \"Generalization-expectation criteria learned from labeled, unlabeled and heterogeneous data,\" in Proceedings of the AAAI/ACM Joint Conference on Artificial Intelligence, 2012, 1537\u20131542.\n\n4. M. Chen, Y. Rui, and S. Ribeiro, \"MentorNet: A new framework for leveraging knowledge in large-scale text classification,\" in Proceedings of the Conference on Empirical Methods in Natural Language Processing, 2013, 1\u20136.\n\n5. R. S. Ribeiro, C. Liu, S. Radev, Y. Wan, and C. Chen, \"Learning to leverage knowledge for more robust large-scale text classification,\" in Proceedings of the Conference on Empirical Methods in Natural Language Processing, 2013.\n\n6. C. Liu, Y. Rui, and S. Radev, \"Generalization by expectation: using labeled features to guide generalization for NLP tasks,\" in Proceedings of the Conference on Empirical Methods in Natural Language Processing, 2013.\n\n7. M. Andrzejewski, Y. Rui, and S. Ribeiro, \"Expectation criteria on",
    "02428a8fec9788f6dc3a86b5d5f3aa679935678d": "\nThere are also many ways to select neutral features, especially when we use LDA. In our experiments, we simply consider the most frequent words after removing stop words, and we do not evaluate many other possible select strategies like in BIBREF10. We also notice the KL divergence term is a kind of special case of the maximum entropy term here when the class distribution is uniform (see Section 2.3). Hence, it would be of interest to investigate if maximum entropy or KL divergence can be an efficient method in other cases.\nAcknowledgments\nWe would like to thank the anonymous reviewers for their insightful comments, and Ying Zhang and Yutao Han for helpful discussions.\n\nAppendix A\n\nProofs of Propositions\nProof of (19)\n\nWe first decompose the objective function as\n\n$$E_\\phi \\circ f_\\theta ( \\tilde{y}_t) = \\sum _{i \\in [r:1..K+1]} p(y_i) \\phi_i( \\tilde{y}_t(y_i)) = \\sum_i p(y_i) (E_\\phi( \\tilde{y}_t) + \\Delta C),$$   (Eq. 14)\n\nwhere $p(y_i) = \\sum _r \\hat{p}_r \\cdot \\frac{1/2C_r}{Z}e^{c_r \\cdot \\frac{d_r \\cdot \\rm{tr} (R^TP_\\theta ) } {1 \\over Z} e_r\\cdot \\frac{d}e_r \\cdot \\frac{d_r \\cdot \\rm{tr} \\tilde{R^TQ_\\theta } {1 \\over Z} e_r} }$, and $Z = \\sum _r \\frac{1/2C_r}{Z}e^{c_r \\cdot \\frac{d_r \\cdot \\rm{tr} (R^TP_\\theta ) } {1 \\over Z} e_r} }$.\nHere, $R = e_r \\cdot \\frac{p(y_i) \\cdot b(y_i) \\cdot \\frac{1 \\cdot \\frac{p(y_i) \\cdot \\frac{1/2C_r - \\sigma^2} {1 - b(",
    "7793805982354947ea9fc742411bec314a6998f6": "\n1.http://www.leiriah.org/repositories/3/\n\n2.http://purl.necla.pt/leiria/le_content.php?uri=l-mendes:cople2\n\n3.http://purl.necla.pt/leiria/le_content.php?uri=l-mendes:peapl2\n\n4.http://purl.necla.pt/leiria/le_content.php?uri=l-mendes:nli-pt\n\n5.http://www.leiriah.org/repositories/3/\n\n6.http://www.aclweb.org/2013/P13-08/\n\n7.http://www.aclweb.org/2017/P17-02/\n\n8.https://www.aclweb.org/2017/P18-10/\n\n9.http://www.aclweb.org/2018/P19-05/\n\n10.https://www.aclweb.org/2020/P1-03/\n\n11.http://irina-saeed.com/projects/grc.html\n\n12.https://irina-saeed.com/projects/aes.html\n\n13.http://lccn.uol.com.br/projects/awl-brazil-port\n\n14.https://lccn.uol.com.br/projects/rpl-brasil-port\n\n15.http://ilc.uul.pt/projects/brazil-port-morphology/\n\n16.http://lccn.uol.com.br/projects/rpl-brasil-le-dependency/\n\n17.http://lccn.uol.com.br/projects/brazil-port-constituency/\n\n18.http://www.kaggle.com/c/t8-challenge-brazil-english/challenge-submissions\n\n19.https://portugues-language-corpora.wordpress.com/category/language-educational-material/\n\n20.E.M. Berm\u00fadez-O",
    "007b13f05d234d37966d1aa7d85b5fd78564ff45": "\n\nThe authors sincerely thank the three reviewers as well as the organizers of the Shared Task for their reviews and suggestions that helped in the final editing of the paper.\n\nIn future work the authors plan to carry out research on the compilation of learner corpora, with a particular interest in unifying learner corpora from different sources into a large corpus of natural language corpora as well as learner corpora.\n\n*1. http://www.learner-corpus.org <http://www.learner-corpus.org/>\n\n*2. http://repositorio.up.pt <http://repositorio.up.pt/>, accessed 4 July 2017\n\n*3. http://nlcc.ic.ac.uk/learner-corpora\n\n*4. http://www.crc.ri.cuni.cz\n\n*5. http://recolha.cl.ul.pt/ <http://recolha.cl.ul.pt/>, accessed 4 July 2017\n\n*6. http://jmlr.csan.cornell.edu/papers/v27/nli/BIBREF6.pdf, accessed 5 July 2017\n\n*7. http://jmlr.csan.cornell.edu/papers/v28/nli2/BIBREF7.pdf, accessed 5 July 2017\n\n*8. http://journals.cambridge.org/article<http://journals.cambridge.org/article>\n\n*9. http://www.aclweb.org/anthology/P16-1009 <http://www.aclweb.org/anthology/P16-1009>\n\n*10. http://www.aclweb.org/anthology/P16-1010 <http://www.aclweb.org/anthology/P16-1010>\n\n*11. http://www.icorpp2017.pt/webpages/learner/submissions/papers/papers/e-10.pdf\n\n*12. http://recolha.cl.ul.pt/recolha <http://recolha.cl.ul.pt/recolha/submissions/papers/papers/a-1.pdf, accessed 4 July 2017>\n\n*13. http://",
    "2ceced87af4c8fdebf2dc959aa700a5c95bd518f": "\nReferences\n\n[Arajo et al., 2013] M. Arajo and Y. Le Fur, \"Linguistic Annotation of Text for Learner Corpus Extraction\", in: SemEval-2013 Task 2: Multilingual Text Annotation for Learner Corpus Extraction, Association for Computational Linguistics (ACL), pp. 193\u2013202, 2013.\n\n[BIBEF0] The BIBREF0 corpus and database. Retrieved from http://corpus.let.pt\n\n[BIBEF1] The BIBREF1 corpus and database. Retrieved from http://corpus.let.pt.\n\n[BIBEF2] The BIBREF2 corpus and database. Retrieved from http://corpus.let.pt.\n\n[BIBEF3] The COPLE corpus and database. Retrieved from http://bplel-corpus.cic.unl.pt\n\n[BIBEF4] D. Sousa, S.-I. Lopes, and C. Martins, \"Native language identification with unsupervised learning methods: a critical review\", Comput Linguist, 48(4), pp. 665\u2013697, 2012.\n\n[BIBEF5] M. Arajo, A. Mendes, T. J. Silva, and A. R. Silva, \"Compilation of Learner Language Corpora: Towards Unified L1-Specific Varieties\", Comput Linguist, 48(4), pp. 705\u2013722, 2012.\n\n[BIBEF6] D. Sousa, D. Vargas, and F. Ferreira, \"An evaluation and analysis of automatic native language identification of Portuguese text\", Comput Linguist, 54(2), pp. 729\u2013750, 2016.\n\n[BIBEF7] D. Sousa, J. S. Sousa, and J. D. B. Silva, \"Task 5.2: Linguistic Annotation for NLI of Learner Corpus\", Association for Computational Linguistics (ACL), pp. 1\u201310, 2017.\n\n[BIBEF8] A. Abdurrahman, O. Pujari, J. S. Sousa, R. Rammage, and F. Ferreira, \"Arab",
    "72ed5fed07ace5e3ffe9de6c313625705bc8f0c7": "\nReferences\n\n[1]\n\nAlmeida, J. B. (2019), Avalia\u00e7\u00e3o da qualidade do portugu\u00eas como segundo lingua aprendido: Um estudo dos textos de aprendizagem do portugu\u00eas l\u00edngua estrangeira. PhD dissertation, University of Coimbra.\n\nAlmeida, J. B., and Mendes, A. (2016), Automatic annotation of Portuguese language variety texts using language-independent features. In Proceedings of 5th Conference on Language Varieties, Varieties of the European Portuguese: a typological study, pp. 1 to 15. Available at https://core.ac.uk/download/pdf/89451064.pdf.\n\nAlmeida, J. B., and Mendes, A. (2015), Identifica\u00e7\u00e3o de l\u00ednguas nativas pelo seu uso de palavras e frases. In Sistemas e Pragmatics for the Spanish and Portuguese Language: Proceedings of the 8th LSPP, pp. 65-76.\n\n[2]\n\nBIBREF0\n\nInternational Corpus of Learner English (ICLE). Version 0.2. http://icle.sf.ac.uk\n\n[3]\n\nLeiria corpus, version 1.0. https://aclanthology.info/K16-0001.pdf\n\n[4]\n\nPEAPL2, version 3.0. http://www.g3-project.eu/LEAP/leap.html\n\n[5]\n\nL2 Varieties: A Language-Variety Corpus Annotation Project. https://www.languagevarieties.eu\n\n[6]\n\nNLI Shared Tasks. http://clinc.uu.se/nlisht/\n\n[7]\n\nNLI Shared Tasks 2017. https://sites.google.com/site/nlisht2017/homepage\n\n[8]\n\nZhu, D., and Wang, J. (2017), Using Deep Convolutional Neural Networks to Recognize Arabic Natural Language Inferences. In Proceedings of the Tenth International Joint Conference on Natural Language Processing, Proceedings of the Conference, pp. 2260-2265.\n\n[9]\n\nCai, Y., and Xu, Z., and Zhang, X",
    "2e37e681942e28b5b05639baaff4cd5129adb5fb": " (1) combine more textual information sources about an entity, such as its Wikipedia articles; (2) incorporate the text descriptions into pre-trained models to predict more textual facts; (3) adopt the structure-based and textual representation models with different granularities, such as word, phrase and even sentence levels, to improve the performance.\nAcknowledgments\nWe are grateful to the NSF for its support through grants CCF-1559543 and CCF-1739071.\n\nReferences\n\n[BIBREF0]\n\nS.R. Bowman, T. Ward, K. Uszkoreit.\n\nWordnet: An electronic lexical database.\nCommunications of the ACM 44 (4), 41- 47\nYear:2001.\n\n[BIBREF1]\n\nN. Covington, J. Bauer, N. Dyer, J. Fikes.\n\nFreebase: A crowd-sourced common core for the world.\nYear:2011.\n\n[BIBREF2]\n\nCheng, S., Lin, R., Du, Q., Zhe Liu, R. Xia.\n\nStructured and effective neural knowledge graph embedding in low-dimensional vector space.\n\nKDD\nYear:2017.\n\n[BIBREF3]\n\nLin, R., Wang, W., Yang, L., Zhang, Y., Yantruk, J.\n\nSVDN: A nonlinear method for knowledge graph embedding.\nYear:2016.\n\n[BIBREF4]\n\nKoopman, B., et al.\n\nOn the knowledge graph sparsity.\nYear:2018.\n\n[BIBREF5]\n\nFeng, J., et al.\n\nLearning vector representations for entities and relations using text descriptions.\nYear:2017.\n\n[BIBREF6]\n\nHu, T., et al.\n\nTweets2vec: Learning semantic vectors from short text\n\nYear:2017.\n\n[BIBREF7]\n\nCao, S., Yang, X.\n\nLearning knowledge graph representations with text.\nYear:2016.\n\n[BIBREF8]\n\nCao, S., et al.\n\nLearning knowledge representation by combining context and structured information.\nYear:2018.\n\n[BIBREF9]",
    "b49598b05358117ab1471b8ebd0b042d2f04b2a4": " (1) incorporating external knowledge such as WordNet; (2) exploring the combination of gating mechanism and other useful mechanisms, such as adaptive max pooling BIBREF32, attention in embedding.\n\nAcknowledgements\nWe are grateful to the anonymous reviewers for their helpful comments, which leads to this paper. This research is supported in part by the National Key Research and Development Program of China under Grant 2018YFB1001101 and 2016YFB1001003, and grant from the National Natural Science Foundation of China under Grants 61561135004 and 61604130, and the US National Science Foundation DBI grant IIP-1547190.\n\n1.\n\nThe abbreviation of KG is knowledge graph.\n\n2.\n\nE, r and h are used for entity, relation and head entity, respectively.\n\n3.\n\nKG refers to the set of all facts $f(h,r, t) \\leqslant 0$, which are negative examples. KB refers to the knowledge graph.\n\n4.\n\nKG1 means all facts about entities but not relations. KG2 means all relations between head entities.\n\n5.\n\nFor example, in a sentence like , e is a person. A, B and C are personal names of other people.\n\n6.\n\nThere exist other text models such as neural tensor network for KG completion BIBREF34 and neural network with auto-encoding model for BIBREF35.\n\n7.\n\nFor example, in a sentence like , e is a person. A, B and C are personal names of that person.\n\n8.\n\nFor example, in a sentence like , e is a hospital. A and B are names of other hospitals. The hospital name is represented by two other hospital names.\n\n9.\n\nFor simplicity, we use one-hot encodings for the relations.\n\n10.\n\nThe neural CBOW model adopts CNNs to encode words into vectors with position information, achieving good results BIBREF36, BIBREF37 on different NLP tasks.\n\n11.\n\nIn this work, word is used as the fine-grained unit to describe the textual representation.\n\n12.\n\nThe CNN utilizes a sequence of fully-connected layers to learn a rich high-dimensional representation from words.\n\n13.\n",
    "932b39fd6c47c6a880621a62e6a978491d881d60": " (1) exploring the effects of different combinations of text description and structured information; (2) exploring more loss functions for learning the joint representation to facilitate the usage of all information.\n\nAcknowledgments\nThis work was supported in part by the National Natural Science Foundation of China (Grant No. 61532007) and by the Natural Science Foundation of Jiangsu Province (Grant No. BK20180143).\n\n\\\n\n\\\n\n\n_The Woman Who Married a Prince_ is a work of fiction. Names, characters, places, and incidents either are the product of the author's imagination or are used fictitiously. Any resemblance to actual persons, living or dead, events, or locales is entirely coincidental.\n\nCopyright \u00a9 2017 by The Doubting Tinker\n\nExcerpt from _The Tempting of a Royal Bride_ copyright \u00a9 2015 by Roseanna M. White\n\nExcerpt from _The Seducing of a Spymaster_ copyright \u00a9 2015 by Roseanna M. White\n\nAll rights reserved.\n\nPublished in the United States by Ballantine, an imprint of Random House, a division of Penguin Random House LLC, New York.\n\nBallantine and the House colophon are registered trademarks of Penguin Random House LLC.\n\nLibrary of Congress Cataloging-in-Publication Data\n\nNames: White, Roseanna M., author.\n\nTitle: The woman who married a prince / Roseanna M. White.\n\nDescription: New York : Ballantine Books, 2017.\n\nIdentifiers: LCCN 2017012966 (print) | LCCN 2017017372 (ebook) | ISBN 9780399179518 (hardback) | ISBN 9780399179525 (audiobook downloadable) | ISBN 9780399179532 (audiobook MP3 CD) | ISBN 9780399179535 (ebook : audiobook)\n\nSubjects: | GSAFD: Paranormal romance fiction.\n\nClassification: LCC PS3607.H58 (ebook) | LCC PS3607.H58 W46 2017 (print) | DDC 813/.6\u2014dc23\n\nLC record available at https://lccn.loc.gov/\u200b2017012966\n\neBook ISBN 9780399179532\n\nRandom",
    "b36f867fcda5ad62c46d23513369337352aa01d2": "\n\n(1) More efficient learning of knowledge representation from the structured graph and textual descriptions. We will apply the attention mechanism among entities, sentences, and sub-words in an entity description.\n(2) Better text representation learning. We will develop new neural attention-based sentence representation models.\n(3) Joint representation learning for complex relationships, such as multi-hop relations and more than two entities.\n\nReferences\n\n\\bibitem{Zhang2018} Z. Zhang, Z. Chen, C. Shen, T. Huang, Y. Wu and C. Chen. Knowledge graph completion by jointly learning with structured graph and text. In Advances in Neural Information Processing Systems (NeurIPS), 2018.\n\n\\bibitem{Ruder2016} L. Ruder, J. Liang, I. V. Lal, R. S\u00f8nderhaug and M. W. Wu.\n\nSemantic word embedding without context: A low-noise baseline for fast concept drift detection. In International Conference on Recent Advances in Intelligent Systems (RAIS), 2016.\n\n\\bibitem{Bai2016} B. Bai and N. Roy Chowdhury. Learning to capture the syntax of a sentence for relation extraction. In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics, 2016., pp. 821\u2013830.\n\n\\bibitem{Shen2016} Z. Shen, Z. Zhang, T. Huang, Y. Wu and Y. Liao. Jointly modeling knowledge graph and text for relation extraction. In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics, 2016., pp. 1167\u20131175.\n\n\\bibitem{Chen2015} C. Chen, Z. Zhang, Z. Hu, T. Huang and Y. Li. Relation extraction by jointly learning with graph and text in a probabilistic way. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, 2015, pp. 1743\u20131748.\n\n\\bibitem{Shen2018a} Z. Shen, C. Shen, S. Li, M. P. Wu, T. Huang and Y. Liao. Joint embedding of knowledge graph and text for entity-oriented text understanding. In Proceedings of the 2018 Joint Workshop on Text Analysis Conference and Machine Learning Asia Pacific Symposium",
    "c6a0b9b5dabcefda0233320dd1548518a0ae758e": "\n\nAcknowledgements\nThis work was funded by Centre for Research Expertise in the Field of Computational Systems Biology (Ce-RoCOSBio-Sys), and supported by the European Space Agency, ESA, within A2-IAPP programme.\nBIBREF1.\nGloveBIBREF2, Glove 2.0.\nBIBREF3.\nAchlioptas, D. (2016). \"Modeling Context and Speaker Embeddings in Speech Recognition\", In: Proceedings of the 7th International Conference on Spoken Language Processing, SLP 2016, Madrid, Spain, 899-904.\nBIBREF4.\nBIBREF5.\nZhang, Y., J. Kott, A. Jain, W. Zhu, R. Sproat, K. Scholz, Y.-W. Ting, J. Liu & P. Abbeel. (2017). \"Learning Acoustic Embeddings with Semantic Word Information\", In: Proceedings of Interspeech, Cape Town, South Africa, 1195-1198.\nBIBREF6.\nGloVeBIBREF3, GLOVe 3.0.\nBIBREF7.\nTolman, I., R. Young, R. Waugh, E. Perrini, D. Callard, D. Marcu & M. Euston. (2003). \"Deep Learning Speech Recognition,\" In: Proceedings of INTERSPEECH 2003, Sydney, Australia, 785-788.\n\nBIBREF8.\nDeng, W., J. Xu, P. Abbeel, F. Yin, J. Liu & A. Jain. \"Learning Speaker Embeddings from Acoustic and Contextual Features Using Variational Auto-Encoders\", In: Machine Learning (ICML) Workshop, 2016.\nBIBREF9.\nBIBREF10.\nBIBREF11.\nGloVeBIBREF2, Glove\nBIBREF12.\nBIBREF13.\nBIBREF14.\nLundberg, C., R. Yoo, C. Liu & C. Gulati. \"Convolutional Neural Network Based Acoustic Embeddings for Speech Recognition\", In: Proceedings of Interspeech 2015, Nice, France, 761-765.",
    "1e185a3b8cac1da939427b55bf1ba7e768c5dae4": "\nAcknowledgments\nI'm grateful to my advisor Professor Andrew Zisserman for supporting this work with his time and his expertise. I would also like to thank Professor Michael Zadora and my colleagues Jonas Lundh for valuable feedback to this work.\nIn order to make this paper as accessible as possible the author tries to be as clear and concise as possible, and aims to highlight some of the most important works in literature relevant to the proposed approaches. As BIBREF14 refers to the same references, work presented here is accompanied by the BIBREF references to the original papers.\n[1] Hinton, G., S. Roweis and A. Ranzato. 2015. Neuralst: A neural probabilistic language model. arXiv 201514.\n\n[2] Hochreiter, S. and J. Schmidhuber. 1997. Long-Short-Term-Memory. Neural Computation 9(8):1735\u20131780.\n\n[3] Devlin, J., K. Lee and G. D. Weissman. 2019. BERT: Pre-Training of Deep BERT: Big Language Models for Fast Text Analysis. In Proceedings of the 29th International Joint Conference on Artificial Intelligence, pp. 4876\u20134874.\n\n[4] Deng, H., C. D. Ang and D. Y. Lin. 2018. VASE: Variational Auto-Encoders and Speech Separation. In International Conference on Acoustics, Speech and Language Processing (ICASSP), 2018, pp. 2933\u20132937.\n\n[5] Zadora, M., P. Lasecki and A. Zisserman. 2018. Robust Deep Features for Speaker Verification. In In Interspeech 2018: Proceedings of the 20th Annua l Conference of the International Speech Communication Association, 2018, pp. 3434\u20133440.\n\n[6] J. E. Churkintz, A. R. Wilson and P. D. L. Ellis. 2014. Speech separation and recognition training set: Revised for 1996-1998. In Proceedings of the International Conference on Speech and Language, 2014, pp. 2320\u20132324.\n\n[7] O. Lohg, J. H. Yood, J. Schuller and T. Schuller. 2017. Multi-stream convolutional",
    "26e2d4d0e482e6963a76760323b8e1c26b6eee91": "\nAcknowledgement\nThe author acknowledges support from the Finnish Research Foundation; grant no. 312405. The author further wishes to thank the anonymous reviewers of the Conference of Neural Information Processing Systems 2017 version of this paper, and in particular to acknowledge the following aspects which helped to improve the paper: the reviewer's suggestion to include the use of the RM corpus for augmentation during speaker recognition and general observations on VAE modelling.\nList of Figures\n\n Figure FIGREF1. : Two dimensional visualisation of the TIMIT data.\n\nFigure FIGREF2. : Speech waveform samples.\n\nFigure FIGREF3. : Three different tasks of TIMIT modelling.\n\nFigure FIGREF4a. : Two dimensional visualisation for TIMIT training set.\n\nFigure FIGREF4b. : Two dimensional visualisation for RM training set.\n\nFigure FIGREF4c. : Two dimensional visualisation for TIMIT test set.\n\nFigure FIGREF5. : Two dimensional visualisation for TIMIT evaluation test set.\n\nFigure FIGREF6. : Two dimensional visualisation for RM test set.\n\nFigure FIGREF7. : Two dimensional visualisation for TIMIT data with no augmentation.\n\nFigure FIGREF8. : Two dimensional visualisation for TIMIT data with addition of RM data.\n\nFigure FIGREF9. : Two dimensional visualisation for TIMIT data with augmentation from RM data and with the RM test set.\n\nTable TABREF1. : Two dimensional visualisation of the acoustic data from TIMIT.\n\nTable TABREF2. : Two dimensional visualisation of the acoustic data from RM.\n\nTable TABREF3. : Phone classification accuracy for various embedding models.\n\nTable TABREF4. : Phone classification accuracy for various embedding model configurations.\n\nTable TABREF5. : Speaker recognition task accuracy for various embedding models.\n\nTable TABREF6. : Speaker recognition task accuracy for various embedding model configurations.\n\nTable TABREF7. : Two dimensional evaluation for various audio embedding models.\n\nTable TABREF8. : Two dimensional evaluation for various audio embedding model configurations.\n\nTable TABREF9. : Relative phone classification accuracy for various audio embedding model configurations.\n\nTable TABREF10. : Relative phone classification accuracy for various audio embedding model configurations.\n\nTable TABREF11. : Relative phone classification accuracy for various audio embedding model configurations with RM test set augmentation.\n\n",
    "b80a3fbeb49a8968e149955bdcf199556478eeff": "\nAcknowledgements\nThe first author was the recipient of an ITN fellowship in 2013-2015. The author would like to thank the fellowship funding organisations, the Netherlands Organization for Scientific Research for supporting the work proposed in this paper. We would also like to thank the support from the Sino-German CRC Program for Advanced Information Systems for Speech Technologies, by which this work was carried out.\nAuthor Affiliations\nYao Hou\nThe author is a research associate at the Chair of Signal Processing, University of Sankt Augustin, Germany.\nAuthor Affiliations\nSpyros Lomaxakis\nThe author was an Erasmus Mundus Joint Master's Degree student from KU Leuven and University of Sankt Augustin, currently Research Faculty member at UCSB.\nYufeng Zeng\nThe author is a research associate at the Chair of Signal Processing, University of Sankt Augustin.\nAcknowledgments\n\nThe author would like to thank Dr Alexandra Yvonka in Sankt-Augustin for her helpful discussions.\n\nConference Papers (Papers presented at a formal conference)\nBIBREF8. K. Cho, A. Karlin, R. Vogel and T. L. Beaulieu (2016). Learning from phonetic context via convolutional neural networks. In Proceedings of Interspeech 2016.\nBIBREF9. P. Cheval, A. Karlin and T. L. Beaulieu (2016). Acoustic Word2vec for speech recognition. In Proceedings of Interspeech 2016.\nBIBREF10. L. Hinton, \u0141. Van Der Pool, R. Salakhutdin, K. Zeghlache, W. Oyallon and N. Jebara (2015). A Neural Characterization of Phonemes. In Proceeding of International Conference on Acoustics, Speech and Signal Processing (ICASSP).\nBIBREF11. D. O. Parkison, J. R. Gray and P.-Y. Chi (2015). Deep speaker recognition with contextual speaker embedding. In Proceedings of SIG-TAC Conference on Acoustics, Speech and Hearing.\nBIBREF12. D. O. Parkison, K. F. Chung, S. J. Park and L. Zadeh (2016). Speaker similarity siamese networks with contextual attentional",
    "badc9db40adbbf2ea7bac29f2e4e3b6b9175b1f9": " The views expressed herein are those of the authors and do not represent the official position of any of the sponsors.\nBIBREF\n\nBIBREF0: E. V. Klavans, \"Building more natural and effective interfaces\u2014a tutorial\", in SIGCHI 2006, Vancouver, Canada, ACM Press, 2006, pp. 43\u201346.\nBIBREF1: J. Hieber\nand A. Schlegel, \"Pun detection: a problem for machine translation? \"\nBIBREF2: G. Grefenstette and H. Lopatto,\n\n\"Detecting and localizing puns in German sentences: an approach to wordplay in text\",\n\nin Workshop on Language Resources and Technology for Translation (LREC2016), 2016.\nBIBREF3: V. Tadepalli, D. Goldfarb, S. T. Chow, and\n\nQ. V. Phan, \"Detecting homographic puns in sentences with neural models: a comparison study,\" in Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (ACL), 2016, pp. 3231\u20133240.\nBIBREF4: K. Chen and H. Zhang, \"A system for detecting puns at large scale,\" in Proceedings of the\n\n24th International Conference on Computational Linguistics (COLING), 2015, pp. 1245\u20131249.\nBIBREF5: V. Tadepalli, D. Goldfarb, and H. N. L. S. Kou, \"Detecting\n\nhomographic puns in sentences by exploiting semantic similarity of words,\" in Proceedings of the 2017 Joint Conference for the\n\n57th Annual Meeting of the Association for Computational Linguistics (ACL) and the 29th International Joint Conference on Natural Language Processing (IJCNLP).\n\nBIBREF6: K. Chen, S. Chow, and H. Zhang, \"Detecting and localizing\n\npuns in sentences with neural models: an approach to pun detection across languages,\" in Proceedings of the 2018 Conference of the Eastern Language Resource and Evaluation Conference (ELRE), 2018.\nBIBREF7: R. J. Manku and H. Yang, \"Detective: finding puns in texts. \"\n\nBIBREF8: L. Liu and",
    "67b66fe67a3cb2ce043070513664203e564bdcbd": "\n[1] A. G. Auer, J. D. Berkley, and E. W. T. Chang, \"An Introduction to the Theory of Linguistic Puns,\" Foundations of Language 6, no. 3 (2009): 281\u2013300.\n[2] A. G. Auer, J. D. Berkley, and E. W. T. Chang, \"Introduction: Puns, Play, and Word Games,\" Foundations of Language 6, no. 3 (2009): 281\u2013300.\n[3] M. Choudhary, V. Chikkaramaneni, and R. A. S. Krishnapuram, Detecting Homographic and Heterographic Puns in Hindi, Proceedings of the Thirty-Forth AAAI Conference on Artificial Intelligence, Vol. 3 (AAAI, 2014): 3447\u201352.\n[4] B. Acer, and J. D. Berkley, \"Computing with the Sounds of Language: Language-Independent Models for Word Puns,\" Proceedings of the Twelfth European Conference on Artificial Intelligence, Vol. 2 (2014): 1124\u201330.\n[5] R. C. Bowles, R. A. S. Krishnapuram, and B. Acer, Detecting Phonologically Similar Puns in English, Proceedings of Advances in Neural Information Processing Systems (2015), pp. 2732\u201339.\n[6] A. C. C. Deng, W. M. Li, J. Huang, H. Chen, R. Bowles, G. M. T. Yap, and D. Yu, Detecting Phonologically Similar Puns from an Online Dictionary: A Case Study of Mandarin Chinese Puns, Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence, Vol. 2 (AAAI, 2017): 2357\u201363.\n[7] K. D. Engel, S. J. G. Goh, D. M. Kaplan, G. M. T. Yap, W. M. Li, W. A. C. Dreyer, and D. Yu, Puns and Punishment in Mandarin Morphologically Rich Language, Proceedings of Artificial Intelligence and Natural Language Processing in Computational Linguistics, pp. 16\u201322.\n[8] D. R.",
    "f56d07f73b31a9c72ea737b40103d7004ef6a079": " We would also like to thank Professor Jiawei Han for his insights on language modeling in this work.\nREFERENCES\nBIBREF0 A. C. Berges, S. D. Hovy, M. Danilevsky, J. Hwa, B. A. Sch\u00f6lkopf.  Humour detection and generation. Comput. Linguist., 37 (3):293\u2013311, 2011.\n\nBIBREF1 M. Cakmakyuruk, L. K. K. K. Sim. A language analysis of puns and other lexical ambiguities. Trans. of the 2016 9th AAAI Spring Symposium on Human Computation for Modeling and Learning (AAAI) 2017, pp. 9\u201314, 2017.\n\nBIBREF2 T. Chopra, G. Chopra, F. P. G. Meese. Automatic translation of human-to-machine puns. Int. J. Hum.-Comput. Stud., 78 (3), pp. 709\u2013730, 2014.\n\nBIBREF3 D. C. Dredze, T. I. J., and H. T. T. Rehm. Humor in discourse: An annotated corpus and annotation guidelines. Comput. Linguist., 18 (4):477\u2013489, 2013.\n\nBIBREF4 J. A. E. Gonzalez-Beltr\u00e1n, L. Haddow, Y. R. Q. Luong, L. X. Yu, M. R. G. Wang. Machine learning for locating puns in spoken text. Comput. Linguist., 24 (2), pp. 313\u2013335, 2016.\n\nBIBREF5 W. S. Guan, M. L. J. Chao. Detecting puns utilizing word similarity and position in context. Trans. of the 2016 7th International Workshop on Language and Social Media, LSM 2016, pp. 35\u201344, 2016.\n\nBIBREF6 E. Grefenstette, R. R. K. Chung, M. Zaj\u010devi\u0107, C. Uzawa-Koji, F. F. Echizen. On human performance in pun detection. In Proc. of the 9th AAAI Workshop on Computational Puns. Association for the Advancement of Artificial Intelligence",
    "38e4aaeabf06a63a067b272f8950116733a7895c": "\nC.M. Chiu is funded by the National University of Singapore under Faculty Research Grant (FRG) MOE2020-T1-2-126. He has accepted a University Research Fellowship from NUS during the period of this work.\n\nReferences\n\n[\n\nArbib, M.B.\n\n(2002). What does it mean to be a university, and what do universities expect of us? In\n\nProceedings of the National University of Singapore Centennial Symposium 2002, pp. 43\u201351, NUS Press.\n\n]\n\nBard, M.M.\n\n(2018). Homo- and Heterographic Puns: Toward an Inclusive Theory of Puns.\n\nPaper presented at the ACL-IJCNLP Conference, Seoul.\n\nBIBREF2\n\nChen, P.,\n\nLi, M.-H.,\nJoshi, A.,\n\nSchnieders, J. A.,\nand\nHovy, E.\n\n(2018). Automated Understanding and Generation of Puns by Deep Learning.\n\nPaper presented at the NAACL Conference.\n\nBIBREF3\n\nCohen, G.\n\n(1992). Puns and metalinguistic awareness.\n\nLanguage and Communication, 13, 165\u2013186.\n\nBIBREF4\n\nDahl, P.,\n\nAharony, D.,\nYarowsky, R.\n\n(2009). A Survey of Punny Machine Translation Approaches.\n\nLanguage Resources and Evaluation, 43 (4), 631\u2013645.\n\nBIBREF5\n\nDahl, P.\n\n(2011). A survey of pun-locator systems.\n\nLanguage Resources and Evaluation, 45 (1), 129\u2013142.\n\nBIBREF6\n\nDijkstra, A.,\n\nBard, M.,\n\nPeters, N.,\nand\nFarkas, J.\n\n(2012). Generating puns from synonyms and antonyms using neural machine translation.\n\nTransactions of the Association for Computational Linguistics, 3 (3), 831\u2013846.\n\nBIBREF7\n\nDos Santos, A.M.G.,\n\nBard, M.,\n\nZubiaga, I.\n\n(2016",
    "1d197cbcac7b3f4015416f0152a6692e881ada6c": "\nReferences\n\nBIBREF1. Khashab, Mohamed H. and Schlangen, Kristin (2020). Automatic Question Answering With Explicit Answer and Input Selection.\n\nBIBREF2. Ramesh, Abhishek and Joshi, Anand (2018). Question Generation from Images: A Survey of Architectures and Benchmarks.\n\nBIBREF3. Yang, Liang, Han, Ching, Cheng, Dongsheng, Yang, Cheng, Zhou, Hong, Bansal, Dhruba, Rastogi, Rupesh and Chopra, Sumit (2018). Reading Comprehension as a Sentence Selection and Generation Task.\n\nBIBREF4. Du, Qilin, Xiao, Yi'nan and Lauscher, Kevin (2020). Learning Task-Agnostic Question Generation through Relation Extraction and Joint Reasoning.\n\nBIBREF5. Seq2Seq BIBREF5 is a sequence-to-sequence model which can be used for automatic question-generation as well.\n\nBIBREF6. Luong, Thach and Manning, Christopher D. (2015). Effective Approaches to Attention-Based Machine Translation.\n\nBIBREF7. N. Chudaparty, M. R. Penn, J.-Y. Zhu, E. Gatt, K. Cho, N. Xue, J. Xing, P. Abbeel and Z. Ghahramani (2015). OpenIE: A Flexible and Open-Source Information Extraction Platform.\n\nBIBREF8. Zhou, Sheng and Khot, Soumith (2017). Neural Question Generation with Answer-aware Context.\n\nBIBREF9. Du, Qilin, Yi'nan, Xiao, Y., Zhang, Haoyu and Lauscher, Kevin (2018). Neural Unified Sentence and Span Question Generation for Reading Comprehension.\n\nBIBREF10. BIBREF10 is the most commonly used method in question generation.\n\nBIBREF11. BIBREF11 is the first pointing method that leverages a copy network to generate questions.\n\nBIBREF12. BIBREF12 combines the copy network with pointer network to improve pointing method.\n\nBIBREF13. Hu et al. propose a sequence",
    "92294820ac0d9421f086139e816354970f066d8a": "\n\nBibliography\n\n1: Hu, Y., He, Z., Zhou, Y. and Lu, Q., 2019. Factual QG from Structured Text for Open-Domain Question Generation. In Proceedings of The 56th Annual Meeting of the Association for Computational Linguistics, pages 2164\u20132171, Brisbane, Australia.\n\n2: Zhou, H., Du, Y., Chen, S. C., Dai, W., Zheng, T., Wang, J., Lu, Q., Riezler, S., Zheng, H. and Xu, M., 2018. Neural Question Generation with Answer-Aware Context Encoders. In Proceedings of The 56th Annual Meeting of the Association for Computational Linguistics, pages 3115\u20133123, Brisbane, Australia.\n\n3: Saha, T., Taft, J., Chaganty, R., Hase, C. and Raghunathan, S., 2018. SQuAD v1.1: A New Dataset for Reading Comprehension and Factual Question Answering. In Proceedings of ICTAI 2018, Singapore.\n\n4: Goyal, S., Cho, C.-W., Singh, A. and Zweigenbaum, B., 2017. SQuAD: 100k Questions to Test the State of Question Answering over Richly Annotated Documents. In Proceedings of AI for Humans, Singapore.\n\n5: Seq2seq BIBREF19 propose a neural network sequence-to-sequence model, i.g., a generative encoder and a perceptive decoder.\n\n6: Liu, D., Zou, D., Zhang, Y., Yang, Y. and Liu, K., 2017. A Hierarchical Attention Model for Sequence-to-Sequence Learning over Long Documents. In Proceedings of International Joint Conference on Neural Networks, page 1102, Stockholm, Sweden.\n\n7: Yao, X., Zhou, Y., Wang, Z., Zhang, Z. and Lin, C., 2016. Factored Extractive Open Information Extraction For Question Answering. In Proceedings of Conference of the North American Chapter of the Association for Computational Linguistics, page 1250, Vancouver, Canada.\n\n8: Yao, X., Zhou, Y., Zhang, Z. and Lin, C., 2018. Structured Answer-Aware",
    "477d9d3376af4d938bb01280fe48d9ae7c9cf7f7": "\nReference:\n\n### Notes :::\n. http://www.aclweb.org/anthology/Q/2018/Q18-2003.pdf\n. http://www.aclweb.org/anthology/Q/2018/Q18-2004.pdf\n. http://www.aclweb.org/anthology/Q/2018/Q18-2006.pdf\n\n. http://www.aclweb.org/anthology/Q/2018/Q18-2008.pdf\n. http://www.aclweb.org/anthology/Q/2018/Q18-2010.pdf\n. http://www.aclweb.org/anthology/Q/2018/Q18-2013.pdf\n. http://www.aclweb.org/anthology/Q/2018/Q18-2015.pdf\n\"\n\n## ::: Bibliography\n\n### References :::\n\n#### Biblography\n\n: \n:\n:\n\n#### Articles on related topics:\n\n#### BIBREF0 * * * * * * * * *\n\n#### BIBREF1 * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\n\n#### * * * * * * * * *BIBREF0 * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\n:\n:\n:\n\n. http://arxiv.org/pdf/1606.03158*. :\n:\n:\n:\n\n\n. * * * * * * * * * * * * :\n\n,, * * * * * * * * * * * * * * * * * * :\n\n. * * * * * * * * *, * * * * * * * * * * * * * :\n\n.\" * * * * * * * * * * * * * * * * * * * * * * * :. ** * * * * * * * * * * * * :\n* * * * * * * :\n\n\". * * * * * * * * * * * * * * * * * * :\n\n. *",
    "f225a9f923e4cdd836dd8fe097848da06ec3e0cc": "\nReferences\n\n[1] Du2017LearningTA\n\n[2] Zhou2017NeuralQG\n\n[3] Du2017LearningTA\n\n[4] Heilman2010GoodQS\n\n[5] Chen2015MicrosoftCC\n\n[6] Luong2015EffectiveAT\n\n[7] Jiang2018FAN\n\n[8] Sun2018AnswerfocusedAP\n\n[9] Wang2018QuestionGN\n\n[10] Jia2018QueryAN\n\n[11] Sun2018AnswerfocusedAP\n\n[12] Li2017ImprovingMRN\n\n[13] Chen2017ReinstructingLF\n\n[14] Wang2018IndependentLA\n\n[15] Zhou2017NeuralQG\n\n[16] Chen2017ReinstructingLF\n\n[17] BIBREF17\n\n[18] BIBREF19\n\n[19] BIBREF18\n\n[20] Parida2017LearningLM\n\n[21] BIBREF21\n\n[22] BIBREF22\n\n[23] BIBREF24\n\n[24] Garg2016NeuralCG\n\n[25] cao2018faithful\n\n[26] Jindal2016GrammarG\n\n[27] Jiang2018FAN\n\n[28] Jin2019TowardsCL\n\n[29] Sridhara2018HierarchicallyMTQG\n\n[30] Zhou2017NeuralQG\n\n[31] Sun2018AnswerfocusedAP\n\n[32] BIBREF33\n\n[33] BIBREF34\n\n[34] BIBREF35\n\n[35] BIBREF36\n\n[36] BIBREF37\n\n[37] BIBREF38\n\n[38] BIBREF39\n\n[39] BIBREF40\n\n[4] Zhou2017NeuralQG\n\n[5] Zhou2017NeuralQG\n\n**Acclaim for the stories of _New York Times_ bestselling authors  \nToni Anderson and Elizabeth Moon**\n\n_**Mermaid_\n\n_\"Mermaids don't exist.\"_\n\n_\"They do!\"_\n\n_\"That's impossible. You know that.\"_\n\n_So say the people in the villages of La Mara on_ **_Terra Nova",
    "ff338921e34c15baf1eae0074938bf79ee65fdd2": "\nWe also see potential for incorporating domain specific inference into the task e.g. using the MedNLI dataset BIBREF14. For all types of experiments it might be worth exploring clinical BERT embeddings BIBREF15, explicitly incorporating domain knowledge (e.g. BIBREF16, BIBREF17), and possibly deeper discourse representations (e.g. BIBREF17).\nAPPENDIX ::: Assumptions\n\n1) There are different question types, and we distinguished them based on the question words: 'Which', 'What', 'When', 'How' etc.\n3) Lexical answer type ('LAT') or focus word is of type Noun and follows the question word.\n4) The LAT word is a Subject. (This clearly not always true, but we used a very simple method). Note: 'StanfordNLP' dependency parsing tag for identifying subject is 'nsubj' or 'nsubjpass'.\n\n5) When a question has multiple words that are of type Subject (and Noun), a word that is in proximity to the question word is considered as 'LAT'.\n6) For questions with question words : Which', 'What', 'When'; word immediately following the question word is a Noun and is considered as 'LAT'.\n\nAPPENDIX ::: Assumptions:\n\n1) There are different question types, and we distinguished them based on the question words: 'Which', 'What', 'When', 'How'. Note: 'StanfordNLP' dependency parsing tag for identifying subject is 'nsubj' or 'nsubjpass'.\n\nAPPENDIX ::: Rules and assumptions for the LAT Logic: Case-1 ::: How-Type question ::: How many selenoproteins are encoded in the human genome?\n\nQuestion: How many selenoproteins are encoded in the human genome?\n\nQuestion:\n\nHow many selenoproteins are encoded in the human genome?\n\nAnswer:\n\nThe LAT is either'selenoproteins', 'genome' or it might be 'encoded','encoded within' or 'encoded in'\n\nQuestion: Which enzyme is targeted by Evolocumab?\n\nFocus:\n\nWhich enzyme is targeted by Evolocumab?\n\nAnswer: It might be\n\na) 'enzyme', that is 'which enzyme is encoded",
    "e807d347742b2799bc347c0eff19b4c270449fee": "\nWe also see potential for incorporating domain specific inference into the task e.g. using the MedNLI BIBREF14 data. For all types of experiments it might be worth exploring clinical BERT embeddings BIBREF15, explicitly incorporating domain knowledge (e.g. BIBREF16) and possibly deeper discourse representations (e.g. BIBREF17).\nAPPENDIX ::: Supplementary References\nWe would like to acknowledge these papers for inspiration and other relevant work:\n\nBhojanapalli, N. K., Mancini, A. D., Schrottky, M. G., et al. (2017). \"Fully Convolutional Transformers for Language Modeling with Globally Localized Attention.\" Paper presented at: 2017 AAAI Fall Symposium: Advances in Attention Mechanisms for Modeling Language.\n\nChoromanskiyin, R., Liu, J. V., Liang, Y., Wang, Q., et. al. (2017). \"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\" Paper presented at: 2017 Conference on Empirical Methods in Natural Language Processing, EMNLP 2017: The Fourteenth Conference on Empirical Methods in Natural Language Processing, EMNLP 2017, Austin, USA, September 24, 2017 \u2013 September 28, 2017, pp. 1273-1282.\n\nDevlin, J. J., Chang, M. O., Lee, K., et. al. (2019). \"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\" Paper presented at: The 2019 Conference on Empirical Methods in Natural Language Processing, EMNLP 2019, Brussels, Belgium, October 1, 2019 \u2013 October 5, 2019.\n\nGehlenborg, K., Vuli, S. Y., Tsvetkov, H. D., et. al. (2017). \"BERTscore: A new benchmark for English Question Answering\" Paper presented at: 2017 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: NAACL-HLT 2017 - Volume 1: Short Papers, NAACL-HLT 2017, Vancouver, BC, Canada, 2017.\n\nJackson, K. M. (2019). \"Constituency Models for Sentence Processing, with Applications to Question Answering.\" Paper",
    "31b92c03d5b9be96abcc1d588d10651703aff716": "\nAPPENDIX ::: Our Results for Yes/No questions:\nFor the first 3 test batches (Batch 1: Batch 2: Batch 3: System name: QA1) we have submitted answer always 'Yes' to all the questions. In Batch 4 we used entailment. Our algorithm was very simple: Given a question we iterate through the candidate sentences and try to find any candidate sentence is contradicting the question (with confidence over 50%), if so 'No' is returned as answer, else 'Yes' is returned. In batch 4  this strategy produced better than the BioASQ baseline performance, and compared to our other systems, the use of entailment increased the performance by about 13% (macro F1 score). We used AllenNlp BIBREF13 entailment library to find entailment of the candidate sentences with question.\nbatch-4: The system returns top 20 answers predicted (with context from snippets) for each question. And top five answers for the questions present in the batch-5.\nbatch-5: The system returns top 5 answers predicted (with context from snippets) for each question. And top five answers for the questions present in the batch.\nAPPENDIX ::: Assumptions, rules and logic flow for deriving SAT Answer types from questions\nThere are question types: Which/What/When/How etc. We distinguish them based on question words: :W Which/Which/etc./W, What/which/etc. etc. etc., When/when when when/etc. when/etc. etc., Who/whose/etc. etc. etc., etc. For each question type we distinguish the following 3 cases:\n1) LAT feature added to input parameters (Question, Answer) and train the Model with SQuAD 2.0.\n2) LAT feature removed from input parameters (Question, Answer) and train the Model with SQuAD 2.0.\n3) LAT feature added to input parameters (Question, Answer) and train the model with SQuAD 2.0 data.\nAPPENDIX ::: Proposing Future Experiments( continued):\n\nIn the current model, we have a shallow neural network with a softmax layer for predicting answer span. Shallow networks however are not good at generalizations. In our future experiments we would like to create dense question answering neural network with softmax layer for predicting answer span. The",
    "9ec1f88ceec84a10dc070ba70e90a792fba8ce71": " (For training BioBERT with additional feature, we would include the words present in original word piece vocabulary, biojargon).\nWe also see potential for incorporating domain specific inference into the task e.g. using MedNLI corpus (refer: BIBREF14). For all types of experiments it might be worth exploring clinical BERT embeddings (refer: BIBREF15), explicitly incorporating domain knowledge (refer BIBREF16). Possibly, for Factoid-type tasks also embedding domain knowledge would improve the answer prediction algorithm's performance.\nAPPENDIX: Details about the code\nCode for generating the contextual word embedding and passing it to the BioBERT is available at Guthub, in the previously referred URL (end of Section 2).\n\nThe code to fine tune BioBERT with deep learning layers is available at Guthub, in the previously referred URL (end of Section 2).\n\nAPPENDIX: Code to fine tune BioBERT:\n\nAPPENDIX: Proposing Future Experiments\n\nAPPENDIX: Proposing Future Experiments ::: Additional Details About The Code\n\nCode for generating contextual word embedding and passing it to the BiBERT is available at Guthub, in the previously referenced URL (end of Section 2).\n\nThe code to fine tune the BioBERT with deep learning layers is available at Guthub, in the previously referred URL (end of Section 2).\n\nAPPENDIX: Proposing Future Experiments ::: Additional Details About The Code\n\nCode for generating contextual word embedding and passing it to the BiBERT is available at Guthub, in the previously mentioned URL (end of Section 2).\n\nThe code to fine tune the BioBERT with deep learning layers is available at Guthub, in the previously mentioned URL (end of Section 2).\n\nThe code to fine tune the BioBERT with deep learning layers is available at Guthub, in the previously mentioned URL (end of Section 2).\n\nWe used PyTorch for experimentation and we provide the models, configurations and experiments files, in the previously referred URL (end of section 2).\n\n\n\nAlso by Elizabeth Peters\n\nThe Mummy Case\n\nThe Laughing Corpse\n\nThe Tomb Thief\n\nThe Serpent's Kiss\n\nA Monkey Touched Sutra\n\nA Royal Death\n\nThe Egyptian",
    "384bf1f55c34b36cb03f916f50bbefade6c86a75": " We hope this work can provide some insights to the future NMT work especially in the reverse direction.\n\n3\n4\n5\n6\n\nFor the English-French translation, we choose the English-French WMT14 test set, whose statistics are shown in Table TABREF42. Specifically, we report the BLEU and the coverage rate on the NMT outputs, generated by the Transformer model based on the Fairseq-py framework BIBREF19, under the Mask and Grammatical Replacement perturbations.\nExperiment ::: Evaluation on Language Pairs with Different Structural Differences ::: Transformer ::: Language pairs with similar structural differences\nWe adopt the Transformer as our test bed and evaluate its translation performance on the test sets under the Mask perturbation for all three language pairs, Chinese-English, English-Japanese, and English-French. We conduct two experiments on four language pairs with different structural differences, the large distance as Chinese-English and English-Japanese, the medium distance as English-French and French-Chinese, and the small distance as Japanese-English and French-Chinese. Given the same perturbation settings, the larger the structural distance, the larger the performance decrease will be. Table TABREF45 lists the results.\nExperiment ::: Evaluation on Language Pairs with Different Structural Differences ::: Experimental Results ::: Large Structural Distance\nFor the Chinese-English translation, we conduct two experiments with different numbers of operations (5, 10) for Chinese-English and English-Japanese, and one experiment with the Transformer model on English-French translation, under the Mask perturbation. The results are illustrated in the bar chart in Figure FIGREF21. The results show that the performance decreases sharply with the increasing structural distance. For instance, the largest performance decay for Chinese-English under Mask perturbation is $56.64\\%$ with five operations while the corresponding translation quality for English-French is $38.32\\%$. Interestingly, there is no observable difference between those different structural language pairs for English-Japanese, which seems to contradict with current understanding and highlights the importance of considering the language pair characteristics in model design.\nExperiment ::: Evaluation on Language Pairs with Different Structural Differences ::: Experimental Results ::: Medium Structural Distance\nFor the English-French translation, we conduct the experiment with two perturbation operations (i.e., Masking 5 words, Masking 10 words) on English-French (BLEU 19.58) and Japanese",
    "aef607d2ac46024be17b1ddd0ed3f13378c563a6": " Besides, we find that the ratio of each POS is different on the reverse directions as depicted in Figure FIGREF32(c), which might suggest a language-specific property that essential inductive bias should be considered for different language pairs.\n\nAcknowledgements\nWe thank the anonymous reviewers for their insightful comments and suggestions.\n1\nhttps://www.natural.org/wp-content/uploads/nmt/eng2fra/Bibliographie.pdf (2020)\n\n2\nThe first BIBREF1 model is a simpler, more efficient, and faster sequence-to-sequence model that uses a feed-forward neural network to translate from English into French BIBREF2.\n3\nhttps://arxiv.org/pdf/1605.08132v1.pdf\n\n4\n\nWe use Transformer model with the same training scheme as the previous Seq2Seq model (Section SECREF12). For fair comparison, the beam search decoding is also turned off.\n5\n\nFor example, in the original work, RNN-Search use the average of attention probabilities of target words across all decodes as the final score.\n\nThe attention score in NMT is in strong contradiction to the traditional view that the words in a sentence are equally important. As shown in Figure FIGREF14, the attention score focuses heavily on the target words, leaving the input words less attended.\n\n6\n\nTransformer is a typical Transformer-based Seq2Seq model BIBREF3, which adopts an architecture in the form of a stack of self-attending transformers.\n7\n\nMore specifically, the perturbation operation includes two types of manipulations. First, the perturbation operation (also called perturbation) replaces all subwords of the selected words with zero vectors, which is called Mask operation in this study. Second, the perturbation operation erases some subwords in the selected words, which is called Deletion operation in this study. Specifically, the Deletion operation only affects the chosen target words.\n\n8\n\nWe use Fairseq-py to re-implement the Transformer and the Seq2Seq model as in the previous section. For the Seq2Seq model, the batch size is set as 64 and the maximum decoding iterations are set to 500, yielding a relatively stable BLEU score. Besides, for fairness, we employ the word-segmented beam search for all Seq2",
    "93beae291b455e5d3ecea6ac73b83632a3ae7ec7": "\n3\nAppendix - Attribution Method\nAppendix ::: Formulas and Interpretable Results\nAppendix A.1. Derivation of Attribution\nAppendix A.2. Derivation of Perturbed Feature Importance in Attribution Method\nAppendix B.1. Additional Experimental Results\nAppendix B.2. Ablations on Integrated Gradients\nAppendix C.1. Details of Datasets and Translation Modules\nAppendix C.2. Additional Details on Different Languages\nAppendix D.1. Details of Model and Training Methodology\n\nAppendix D.2. Further Details on Model Interpretability\n\nAppendix E.1. Word Importance of All Viable NMT Architectures\nAppendices\n\nAppendix E.2.1. Interpretable Results for English Language Pairs\nAppendices - Training Methods\n\nAppendix E.2.2. Ablations on Sentence Transformation and Gradient Scaling\n\nAppendix E.3. Language-Specific Behaviors of Word Importance on Various Architecture\nAppendices - Word Importance Distribution\n\nAppendix E.4.1. Additional Analysis on Syntactic Categories in Different Language Pairs\n\nAppendix E.4.2. Further Analysis on Language-pair-Related Syntactic Behaviors in Different Directions\n\nAppendices - Important Words\n\nAppendix E.4.3. Analysis on Linguistic Properties of Important Words\n\nAppendix E.4.4. Analysis on Linguistic Properties of Important Words\n\nAppendix E.4.5. Analysis on Linguistic Properties of Important Words\n\nAppendices - Syntactic Categories\n\nAppendix E.4.6. Ablations on Word Fertility\n\nAppendix E.4.7. Analysis on Linguistic Properties of Words\n\nAppendices - Word Importance Distribution\n\nAppendix E.5. Perturbation Methods\n\nAppendix E.6. Analysis on Syntactic Categories of Words\nAppendix E.7. Analysis on Linguistic Properties of Words\n\nAppendix E.8. Word Importance Distribution\n\nAppendix E.9. Ablations on Integrated Gradients\n\nAppendix E.10. Analysis on Syntactic Categories of Words\n\nAppendices - Syntactic Distribution on Various Architecture and Languages\n\nAppendix E.11.1. Perturbation Effectiveness of Deletion, Mask, Grammat",
    "6c91d44d5334a4ac80100eead4e105d34e99a284": "\nAppendix\nAppendix A ::: Additional Experimental Results\nWe provide additional experimental results for NMT model debug by comparing gradient-based method (Attribution) with several other word importance methods (i.e., Content, Frequency, and Attention). Specifically, we analyze on Chinese-French, English-French, and Japanese-French translation tasks, where the gradient-based method still has comparable or superior abilities to identify un-translated words.\nAppendix B ::: Additional Analyses on Different Perturbations and NMT Architectures\nWe provide additional analyses on Deletion, Mask, and Grammatical Replacement perturbations, as well as on two different NMT architectures Transformer and RNN-Search. In these supplementary experiments, we find that gradient-based estimation has comparable or superior effectiveness compared with previous work, confirming the effectiveness of our method. We also investigate the importance of different POS tags and word morphology, which reveal the importance of lexical and syntactic roles. Especially, the importance of word morphology is more important on Chinese-<-> English model, which indicates that the word meaning is more informative among these three language pairs.\nAcknowledgements\n\nYi Huang, Qishi Niu, and Zijie Hu served as the first three authors respectively. Without their strong support and help, this work would not be finished or published.\nReferences\n\n[1] Gennadii Alvarez, Raffaele Ciravegna, Martin Joong, and Lillian Lee. Causal explanation of trained neural networks. In Proceeding of 29th Annual Conference of the European Chapter of the Association for Computational Linguistics, pp. 752\u2013762. 2017.\n\n[2] Shilin He, Yi Huang, Zijie Hu, Qishi Niu, Shuying Liu, Feiyue Zhou, and Xudong Yan. What do models understand? Interpretability from input-output behaviors in neural machine translation. ArXiv:2001.11746 (2020).\n\n[3] Qishi Niu, Zijie Hu, Yi Huang, Xudong Yan, and Zizhao Zhang. Interpretability of machine translation models using attention: An empirical study on language pairs with structural differences. InProceeding of 2019 Conference of the Association for Computational Linguistics, pp. 4686\u20134684. 2019.\n\n[4] M. Enoz et al. BIBREF",
    "a69a59b6c0ab27bcee1a780d6867df21e30aec08": " We thank Hristo Kitanov for helping us with the data exploration. We also thank the two anonymous reviewers, as well as James Glass and Alexey Radovanovic, for their thoughtful comments and suggestions.\nWe thank the community for sharing useful and interesting information at: aclweb.org/aclhlt-3.0; aclweb.org/acl2019.html; acmart.org/AISB18; aclweb.org/ACL2018; acmart.org/HLAS2015; allennlp/nlp-progress-2018; arxiv.org/abs/1905.11764; arxiv.org/abs/2012.04143; devnds.org; hlt2020.org; paperwithwings.blogspot.co.uk; nltk.org; nlp.stanford.edu/papers.html; parl.ai; rten.nlp.sjtu.edu.cn/; sdai.stanford.edu/software/anli/anli-2.0; tqdm.stanford.edu/research/papers.html; xin/xin/XINet/XINet.html.\n\nY.-Y. Chen, L. Bansal, and D. R. Lewis. 2016. A comparison of deep-learning networks for question generation. In Proceedings of the 2016 Conference on Empirically Designed Answering Systems, pp. 1168-1179. Association for Computational Linguistics.\n\nAmini, R., H. C. R. de Oliveira, L. Zhang, and S. Kurohashi. 2018. Adversarial attacks on sentence compression for nlu evaluation: a survey. Computational Linguistics 44:217\u2013257.\n\nAnthes, J., M. Liu, P. Linzen, T. K. Liu, and E. M. Weise. 2019. Adversarial learning and language. In Proceedings of the Conference of the Association for Computational Linguistics on Human Language Technologies, pp. 3350-3361. Association for Computational Linguistics.\n\nBaroni, G., R. Bowden, and J. Gurevych. 2020.\n\nRobustness, generalization, and domain adaptation in neural language models. Arxiv preprint at",
    "b3d01ac226ee979e188a4141877a6d2a5482de98": " YN also acknowledges the support of Facebook's Social AI and NLP research groups. We thank Zack Cieslak, Kaushik Banka, and Nevenka Kusner for helpful discussions. We acknowledge the constructive feedback from Lillian Kuo, and the help of our colleagues, friends, and families in developing the baseline model and writing the paper.\n## Appendix\n\n## A. ANNOTATOR INSTRUCTIONS\n\n### Round 1\n\nHere are the full instructions given to annotators.\n\n### Round 2\n\nHere are the full instructions given to annotators.\n\n### Round 3\n\nHere are the full instructions given to annotators.\n\n## B. LABEL-CLASS BREAK-DOWN\n\nFollowing are the detailed distribution of labels for each round's training set.\n#### Round 1\n\n## C. ANNOTATOR INSPIRED EXAMPLES\n\nThese examples were suggested by annotators of each round. For each example, there is a label, which is either wrong (i.e., it does not coincide with the annotators prediction for the example), unknown (i.e., the annotators belief was not backed up by the model's predictions), or correct. The correct label is indicated by a green checkmark.\n\nRound 1\n\n##### Context and Hypothesis\n\n##### Explanation\n\n##### Annotator's Verification\n\n##### Annotator's Feedback\n\n##### Annotator's Example\n\nTable\n\n_Praise and Acclaim for_  \nMIKE PARK\n\n\"A great, rich, humane novel, a _Big Sur_ \u2013 style saga of the heart, and a love story that will leave you weeping. _The Glass Ocean_ is another masterpiece by a great American writer.\"\n\n\u2014DON LEIFER, _New York Times_ bestselling author of _Gulliver_ and _I Could Read the Sky_\n\n\"Mike Park continues his superb career in fiction: a gripping story about lost love and loss, and a book with the most powerful description of the Pacific Ocean I've encountered since Jack London's _The Sea-Wolf_.\"\n\n\u2014LARRY RABEGA, author of _The Last Town on Earth_ and _Big Engine_\n\n\" _The Glass Ocean_ is both a love story and an existential mystery that asks about the nature",
    "af5730d82535464cedfa707a03415ac2e7a21295": " We thank Sneha Sivaraman, Paul J. Sorensen, and Tom Dietterich\u2014as well as the anonymous reviewer\u2014for their comments on a recent draft of this paper.\n\nAblations/Evaluation on other models/Training curves/Training-set statistics/Number/Context-hypothesis pairs/Model errors/Context-hypothesis pairs/Number/\n\nThe total size of the ANLI dataset over the three rounds is **$20M$** tokens. Training on this new data for BERT BIBREF10 and RoBERTa BIBREF25 improves test set performance on both MNLI and SNLI, while performance on the SNLI development set (the only task on which ANLI does not generalize) does not change. Training only on ANLI does not improve performance on SNLI, but does improve performance on both MNLI and SNLI-Hard.\nWe trained several models on ANLI, and show test set performance from the new models. In addition to baselines, we also include results of XLNet BIBREF30\u2014which, unlike BERT and RoBERTa, is a more recent model architecture.\nAppendix Table TABREF\n\nBIBREF0\n\nMa, J., Chai, S., and Vedantam, S. (2010) Imagenet 1000 categories.\n\nhttps://pytorch.org/r/t/imagenet1000/\n\nBIBREF2\n\nYang, W., Sheng, C., Grefenstette, B., and Fei-Fei, F. 2009. Snli: A corpus for the study of sentence-level semantics. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL), pages 188\u2013196.\n\nBIBRF1\n\nConneau, L., Liang, P., and Dahl, G. 2017 Superglue: A Benchmark for Multitask Natural Language Understanding.\n\nhttps://s2.bilibili.com/video?vid=m4FfY-5fk9\n\nBIBREF15\n\nGeva, O., Gold-wasser, B., Littman, K., and Goldberg, D. 2018. The Annotator is your best defense: bias in NLP datasets arises not from models but from annot",
    "ee2c9bc24d70daa0c87e38e0558e09ab97feb4f2": " ML was funded by the Alphabet Antigone program.\n\nThis material is based upon work supported in part by the United States Air Force Research Laboratory (AFRL) and sponsored by the Defense Advanced Research Projects Agency (DARPA). Any opinions, findings, conclusions, or recommendations expressed are those of the authors and do not reflect the official views of the Air Force Research Laboratory, or the U.S. Government.\n\nThis work was funded by the U.S. National Science Foundation (NSF) under Grant Nos. 1820642 and 1932452, as well as ARO W911NF-19-2-0094.\n\nThis research used Google Cloud Platform for machine learning purposes.\n\nThis research was partially funded by Anzoic, Inc.\n\nThe work was done while BERT was at Uber.\n\nWe thank the University of Washington, especially the Parr Center, for Computational Science & Engineering, for their generous support of this research.\n\nThis material is based upon the work of the authors supported by DARPA under Contract No. FA-8725-14\u201310.\n\nWork was partly done while the U.S. government was providing support under Award No. N00014-18-1-2871 from the U.S. Air Force Office of Scientific Research.\n\nReferences\n\nAlon2020learningai\n\nAlonso-Ovalle2020towardsai\n\nBert2018nether\n\nBosselut2017roi\n\nCer2019making\n\nChen2016using\n\nDaum\u00e92018making\n\nFei2019beyond\n\nGeva2019taskorannotator\n\nGordon2004human-in-the-loop\n\nJozefowicz2017rethinking\n\nKaushik2018howmuch\n\nKulkarni2018data\n\nLan2017ppdb\n\nLiu2018get\n\nLiu2017textnet\n\nMarcus2018don't\n\nMoschitti2018languageunderstanding\n\n\nNie2019beyond\n\nPalmer2019parliament\n\nPalmer2019language\n\nPark2018no\n\nPapineni2016bleu\n\nPlank2017roi\n\nPoliak2018hypothesis\n\nPolyakov2019better\n\nRao2018getting\n\nSankararaman2019rethinking\n\nSap2017adversarial\n\nS",
    "b249b60a8c94d0e40d65f1ffdfcac527dab57516": " If the candidate satisfies the word shape rules of only one segment, that segment is ignored in the feature computation.\n\nSURNAME1: A segment of the form X1XY2 is a surname. A surname is defined as a string of characters that follows the following regular expression and does not change word shape when the last character is removed.\n\n\"NNNNXXX1\" OR\n\n(NNNNNNXX1 AND WORDSHAPE=\"NNNNNXXX2\" AND WORDSHAPE=\"XXX\")\n\nBANDX: A segment of the form X1XY2 where X1 is a band name, is a band with XXX being the first letter of the band name.\n\nBANDBXZ: A segment of the form X1[XY_P-_A-_P-E]X2 where X1 is a band name, X1 is followed by non-alphanumeric characters and X2 is a string with all letters as non-alphanumeric characters followed by one letter.\n\nBANDXYYYYY: A segment of the form X1[XY_P-_A-P-E]X2 where X1 is a band name, X1 is followed by non-alphanumeric character and X2 is a string with all letters as non-alphanumeric characters except for a Y in the middle.\n\nWORD: A string of characters with at least two characters.\n\nWORD_P: A word.\n\nWORD_P/N: A string of non-accented letters following WORDSHAPE1 except for digits.\n\nWORD_N: A string of non-accented letters following WORDSHAPE1 except for digits.\n\nWORDSHAPE1/1: A string of characters that does not satisfy the pattern of BAND? or BANDN? or WORD[N?]SHAPE2 except digits.\n\nWORDSHAPE2: \"XXXXYYYZZ\" OR \"XXXXYYZzz\", where XXX is a set of non-alphanumeric characters with no space between two consecutive characters, Y is a digit and zz is the last character.\n\nWORD_D/1: A string of letters with the first two characters not \"XX\" or \"XXX\".\n\nWORD_D/2: A string of letters with",
    "0f567251a6566f65170a1329eeeb5105932036b2": " Otherwise it is False. (a) It ends with a number: INLINEFORM1 #. *If the second to last and the last characters of the hashtag are digits, e.g., INLINEFORM0 #ilovey0u 4eva *It ends with a number followed by a space, e.g., INLINEFORM0 #iloveu 4 ever *It ends with a hyphen e.g., INLINEFORM0 2much: INLINEFORM1 #iloveu 4ever *If the final character of INLINEFORM0 is a number, e.g., INLINEFORM0 #ILOVEU. *The candidate INLINEFORM2 consists of only numeric characters.\n\nLanguage models\nOur language models for ranking candidate segments are trained on n-grams from Gigaword 6. The vocabulary size of the unigram word probability language model INLINEFORM6 is set to 200k. An English tweet with a hashtag is treated as one token while an all lowercase word is split into two tokens and words without spaces between them into four tokens. We set the maximum window size to 10. The bigram token probability language model INLINEFORM10 is trained on 7,056,600 pairs of tweets from 2010. We used the following features for INLINEFORM10 : (1) the frequency of each bigram; (2) the bigram frequency normalized to the tweet frequency per 100; (3) bigram-ngram-token ratio; (4) bigram-ngram-token ratio normalized to tweet-bigram probability; (5) bigram-ngram-ngram ratio for n=1,2,3 to 5-grams. We used the following features for the ngram language model on tweets from the year 2010 ( INLINEFORM11 ): (1) the bigram-word ratio normalized to the tweet probability per 100; (2) bigram-ngram ratio; (3) bigram-ngram ratio normalized to tweet probability per 10; (4) bigram-ngram-ngram ratio for n=1,2,3 to 5grams; (5) bigram-ngram-ngram ratio normalized to tweet-ngram probability. We did not train ngram probability models on the tweets from the year 2019.\n\nReference\n\nBansalBV15 Bansal, V, and Bowdle, J. (",
    "4aa9b60c0ccd379c6fb089c84a6c7b872ee9ec4f": " \nThe set of word shape rules for HashtagMaster contains the following types of hashtags:\n\n\u2022 All caps words are multi-token;\n\u2022 Camel case strings with spaces are multi-token;\n\u2022 Words with apostrophes are multi-token;\n\u2022 #Number, #Date, #Color, #Person are multi-token;\n\u2022 #Name is multi-token;\n\u2022 #Date-Word-Color is multi-token;\n\u2022 Hashtags with numbers at the end are multi-token.\n\nMulti-token:\n\nAny candidate string that contains at least two consecutive words, e.g., #FurKids are multi-token.\n\nNamed entities:\n\nWe add a set of named-entity features used in the work by Bansal et al. BIBREF12, including:\n\n> \u2022 B-Abbr, B-Acronym, B-AcronymUpper2-Upper-Case, B-AcronymUpper1-Upper-Case, B-AcronymInitial, B-Birthday, B-Company, B-CommonName, B-Concept, B-Contrib, B-Entity, B-Event, B-Geo, B-Historical, B-Idea, B-LastName, B-Location, B-Org, B-Organization, B-Person, B-PersonUpperCase, B-PersonFirstName, B-School, B-Time, B-Type of Art, B-Web, T-Name, T-Other.\n\n\u2022 B-Contrib is a named entity if it is a top 100 word in Urban Dictionary BIBREF30 and contains an upper-case last character. For example, #GIF = GIF (Entity), #LOL = lol (Entity).\n\nNamed entities with # before:\n\nWe train a binary classification model that takes hashtag and its context as input and predicts if # has been in the string. If the # is in the middle, the model predicts True, otherwise False. If the hashtag INLINEFORM0 and its corresponding hashtag INLINEFORM1 are predicted to be named entities, the corresponding INLINEFORM1 features are set to true, else false.\n\nFor English, we use a lexicon of 2,470,934 entities downloaded from Urban Dictionary B",
    "60ce4868af45753c9e124e64e518c32376f12694": "\n\n1.\n\n#[a-z][0-9][a-z], e.g. #freenetfights[a-z][a-z]\n\n2.\n\n#[a-z][0-9][a-z], e.g., #s[a-z][0-9][a-z]\n\n3.\n\n#N[a-z][a-z], e.g. #N[a-z][a-z]\n\nTable TABREF12: Word shape rules, their count and illustrative examples with human segmentation.\n\nTable TABREF13: Categorization of hashtags as single or multi-tokens with the Word Breaker system.\n\nTable TABREF14: Categorization of hashtags as single, multi-token, or other. Note: #bTV is a single-token hashtag but its candidate segmentations #bTV and #BTV are multi-token hashtags, as is #S[a-z][0-9][a-z]\n\nTable TABREF15: Categorization of hashtags as single, multi-token and other with the Word Breaker system.\n\nTable TABREF16: Categorization of hashtags according to the number of word tokens as single, multi-token or other with the Word Breaker system.\n\nTable TABREF17: Categorization of hashtags by a beam search ranking, and example hashtags.\n\nTable TABREF18: Categorization of hashtags generated by different training corpora with the Word Breaker system and their performance.\n\nTable TABREF19: Categorization of hashtags by beam search ranking and top candidates generated by Word Breaker as the base.\n\nTable TABREF20: Summary of results for various model variants.\n\nTable TABREF21: Categorization of hashtags generated by different training corpora with the Word Breaker system and their performance.\n\nTable TABREF22: Categorization of hashtags generated by different training corpora with the Word Breaker system and their performance.\n\nTable TABREF23: Categorization of hashtags generated by different training corpora with the Word Breaker system and their performance.\n\nTable TABREF24: Categorization of hashtags generated by",
    "1b1a30e9e68a9ae76af467e60cefb180d135e285": "\n\n[1]\n\nRajpurkar, Shardha, et al. \"SQuAD: 100K Intended Answer Questions in English\". In: NIPS 2016, pp. 1892\u20131910.\n\n[2]\n\nRajpurkar, Shardha, et al. \"Trivia: A Large-Scale Dataset For Reading Comprehension Over Text, Images, And Videos\". In: WWW 2016, pp. 2363\u20132372.\n\n[3]\n\nHermann, Frederick, et al. \"Distilling the Knowledge in a Million Essays\". In: EMNLP 2016, pp. 1624\u20131634.\n\n[4]\n\nLin, Yulong, et al. \"Dialogue state tracking using multi-perspective graph attention networks\". In: EACL 2016, pp. 897\u2013904.\n\n[5]\n\nRajpurkar, Shardha, et al. \"Learning to extract and generate information-seeking questions\". In: ICML 2016, pp. 1752\u20131760.\n\n[6]\n\nSchwartz, A. D., et al. \"Improving Question-answering Systems with Training Data Selection\". In: TAC 2018, pp. 19\u201326.\n\n[7]\n\nRajpurkar, Shardha, et al. \"Learning to ask: A neural network framework for answerable question generation\". In: EMNLP 2017, pp. 1474\u20131485.\n\n[8]\n\nRajpurkar, Shardha, et al. \"Deep Learning for Information Extraction: Topic, Situation, and Domain\". In: AAAI 2017, pp. 3778\u20133785.\n\n[9]\n\nNiu, Jiawei, et al. \"CoQA: A Dialogue-driven Question Answering Challenge\". In: AAAI 2018, pp. 3382\u20133387.\n\n[10]\n\nRajpurkar, Shardha, et al. \"Reading Wikipedia to Answer Open-Domain Questions\". In: AAAI 2018, pp. 3488\u20133496.\n\n[11]\n\nXu, Yongchao, et al. \"Incorporating Dialogue Sequences for Question Answering with Attention Networks\". In",
    "2c85865a65acd429508f50b5e4db9674813d67f2": "\nReferences\n\n[1] E. Aharoni, et al. Spoken language understanding in humans: A review. Behav Res Methods 42(2), 325\u2013346 (2014).\n[2] J. Riedl, et al. Neural coreference resolution using multi-gram, distributional and graph-based models. In Advances in Neural Information Processing Systems (NIPS), 2010.\n\n[3] D. Erlank, et al. Neural distributional sematics model with attention. In Proceedings of the 30th Conference on Computational Natural Language Learning (CoNLL 2016), 2016: 947\u2013956.\n\n[4] G. Peyr\u00e9, et al. Learning to reason with sentence structures via contextualized word representation. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics (NAACL-2018), 2018.\n\n[5] M. Auli, et al. The Quacl project: A corpus-oriented evaluation of question answering for reading comprehension. 2016.\n\n[6] R. Socher, et al. A framework for evaluating question answering. In Proceedings of the 30th Conference on Computational Natural Language Learning (CoNLL 2016), 2016: 7.\n\n[7] W. Xu, et al. Spoken language understanding. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), 2017: 1551\u20131560.\n\n[8] V. Ciresan, & J.R. Zitnick. The hotpotqa question answering challenge: A dataset and state-of-the-art systems. IJCNLP 6, 99\u2013105 (2016).\n\n[9] A. Cozad, et al. COQA: A crowd-sourced question answering dataset. Nlpcc 10, 3\u20135 (2015).\n\n[10] Q. Gu, et al. Quac: Question answering competition for reading comprehension over corpus and cloze. In Proceedings of the 35th Conference on Computational Natural Language Learning (CoNLL-2017), 2017: 731\u2013736.\n\n[11] J. Devlin, et al. Character-based embedding of sentences for linguistic similarity searches. 2015.\n\n[12] F. Bojanowski, et al. Character n-gram language models. In Proceedings of the",
    "73a7acf33b26f5e9475ee975ba00d14fd06f170f": "\nAppendix I\n\nCitations\n\nHovy E.\n\n. The cognitive basis of conversational discourse: the case of question formation.\n\nSlangly.com. 2019\n\nWebber B.,\n\nHovy E.\n\n. The cognitive basis of conversational discourse: the case of question formation.\n\nLanguage. 2017.\n\nHovy E.,\nWebber B.,\nGold K.,\nSato T.,\nUllman T.,\nGale C.\n\n. The cognitive basis of conversational discourse: the case of question formation.\n\nLanguage. 2017.\n\nNg Z.\n\nS.\n\n. A survey of question answering task formats.\n\nin: Proceedings of the Eighth European Conference on Information Retrieval (ECIR).\n\nTracto, The Hague: Springer, 2015: 763\u2013775.\n\nRaghavan P.,\nChen S.\n\n. On the evaluation of context-based information retrieval.\n\nJournal of Computer-Mediated Communication in Healthcare. 1998.\n\nRaghavan P.\n\n. QA-Maker: a question answer system for evaluating natural language understanding systems.\n\nProceedings of the 26th International Conference on Computational Linguistics (COLING).\n\nBerlin, Germany: Springer, 2014: 1343\u20131352.\n\nAbdul-Rahman H.,\nHovy E.\n\n. Question answering over conversations with a crowd-based web search engine.\n\nProceedings of 26th International World Wide Web Conference (WWW).\n\nHovy E.\n\n. The cognitive basis of conversational discourse.\n\nLanguage. 2020.\n\nLi N.,\nHan L.,\nQin L.,\nMa F.\n\nU.\n\n. Contextual QA systems via bidirectional language model and coreference.\n\nScientific Reports. 2017.\n\nLi N.,\nWang M.,\nGao Q.\n\n. Contextual QA systems via bidirectional language model and coreference.\n\nACM Transactions on Information Systems, 35(2):1\u201334. 2018.\n\nChowdhry N.,\nWang M.,\nMa F.,\nQin L.,\nZhao Y.\n\n. Learning to interpret questions in text and answer questions in dialogue",
    "dd53baf26dad3d74872f2d8956c9119a27269bd5": "\n\nReferences\n\n[1] D. Farkas, N. Czylwik, A. Rastegari, and L. Zettlemoyer. An unsupervised, multimodal neural model of spoken dialogue. Proceedings of The 2016 Conference on Empirical Methods in Natural Language Processing (EMNLP 2016). Association for Computational Linguistics, 2015.\n[2] N. Da Santana and B. K. Chopra. Dialogue: A case study in domain-dependent parsing for information-seeking NLP. Proceedings of The 57th Annual Meeting of the Association for Computational Linguistics, 2018.\n[3] D. Dossin and M. Burch. Dialog. Proceedings of The 57th Annual Meeting of the Association for Computational Linguistics, 2018.\n[4] C. Huang, E. Choi, D.-Y. Chung, D.-H. Lee, Y. Wang, and J.-S. Nam. Reading comprehension: An overview of current models, recent advances and challenges ahead. Cognitive Computation 2(1):1\u201322, 2018.\n[5] J. X. Chen, R. Neubig, M. Burch, T. Yallop, and W. Jiang. Query-based text summarization by convolutional neural networks with copy and attention mechanisms. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, 2016.\n[6] G. V. D. Vaswani, A. Shankar, H. Zike, K. Cho, G. Schulman, V. Vanhun, R. Salazar, G. Zweig, and G. LeCun. Attention is all you need. In Proceedings of the 34th International Conference on Machine Learning, 2017, p. 1778\u2013 1787.\n[7] H. Kuehne, E. Choi, L. Choshen, I. Titova, A. Subramanian, and R. Neubig. Deep Reinforcement Learning for Dialogue. arXiv preprint arXiv:1606.01617, 2016.\n[8] E. Choi, C. Huang, K. Chopra, H. Oh, M. Burch, T. Yallop, and N. Jairam. Machine Reading of Unannotated Text: Att",
    "218bc82796eb8d91611996979a4a42500131a936": "\n    \n[24] Le, Q., Wang, Q., Zhao, W., Niebles, J. & He, F. (2018) A Deep Convolutional Neural Network for Large Vocabulary Speech Recognition. In Proc. Automatic Speech Recognition and Understanding Workshop (ASRU), pp. 3\u20137.\n    \n[25] Kondrak, W., Pazda, L., Klimecki, M. & Gresztol, W. (2015) Learning low-dimensional representations of spectral features for multiclass and very long utterance speaker identification. In Proc. International Conference on Acoustic, Speech and Language Processing (Interspeech), pp. 3658\u20133662.\n[26] Choi, K. & Fazekas, G. (2017) Improving the generalizability of hidden recurrent representation for spoken emotion detection. In proc. 2017 World Conference on Speech and Language Processing (Interspeech).\n[27] Choi, K., Fazekas, G. & Sandler, M. (2018) The effect of attention on deep convolutional neural network in speech recognition. In Proc. Workshop of the Association for Machine Intelligence and Automation in Animation, Interactive Technologies and Applications in Entertainment (AMIAITA 2018).\n    ## \nA System for Automatic Identification of Music and Spoken Dialogue in the Wild\n\nAmin Shadnoor Nourmohammadi,1 A. D. Parada,1,3\n\nAgnieszka Chmiel,2,4\n\nAbdulrahman Alkhayer,5\n\nA. D. Parada,1,2\n\nT. N. Sainath,1\n\nThe goal of this research is to design automatic systems that are capable of identifying both spoken dialogue and music using deep neural networks that have been trained on large datasets, i.e., the German Speech Emotion Recognition Database [1]. The task is challenging because although the systems are tested in the same conditions as human listeners, they are not able to perform like humans in terms of accuracy and robustness. We propose a framework for the identification of music and spoken dialogue, which consists of two recognition modules: music detection and speech/non-speech identification.\nMusic detection (or non-speech) identification identifies which segments of the audio file are associated with the domain of music (or",
    "b21bc09193699dc9cfad523f3d5542b0b2ff1b8e": "\n\nThis document describes a proposed paper that is yet to be formally submitted for publication. The material presented here is based upon internal IBM research that is currently in progress and has not been subjected to peer review.\n\n[Table 1] indicates the mean accuracy for speech/music classification and mean accuracy for emotion classification obtained for proposed s2sL approach.\nTable TABREF14 shows the performance values for each data proportion along with mean values.\n[Table 2] indicates the size of the music and speech data sets.\n[Table 3] shows the mean accuracy for Anger/Happy classification task and mean accuracy for the Neutral/Sad classification task obtained for proposed s2sL approach.\nREFERENCES\n\n1. Hinton, G., Deng, L., Yu, D., Dahl, G. E., Mohamed, A. R., Jaitly, N., Senior, A., Vanhoucke, V., Nguyen, P., Sainath, T. N. & Kingsbury, B. (2012) Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups.\n\n2. Vinyals, O., Ravuri, S. V. & Povey, D. (2012) Revisiting recurrent neural networks for robust ASR.\n\n3. Lu, L., Zhang, X., Cho K. & Renals, S. (2015) A study of the recurrent neural network encoder-decoder for large vocabulary speech recognition.\n\n4. Zhang, Y., Pezeshki, M., Brakel, P., Zhang, S., Bengio, C. L. Y. & Courville, A. (2017) Towards end-to-end speech recognition with deep convolutional neural networks.\n\n5. Han, K., Yu, D. & Tashev, I. (2014) Speech emotion recognition using deep neural network and extreme learning machine. In Proc. Interspeech, pp. 223\u2013227.\n\n6. Trigeorgis, G., Ringeval, F., Brueckner, R., Marchi, E., Nicolaou, M. A., Schuller, B. & Zafeiriou, S. (2016) Adieu features? End-to-end speech emotion recognition using a deep convolutional recurrent network. In\n\nProc. ICASSP, pp",
    "352bc6de5c5068c6c19062bad1b8f644919b1145": "\nZ. Zhang, H. Lu, B. Schuller & S. Kopparapu (2018) A framework for simultaneous two sample learning: Audio affective content analysis. In Proceedings of ACM Multmedia Conference (MM '18), pp. 187\u2013192.\nIn this example we demonstrate the effectiveness of simultaneous two sample (s2s) format in the task of voice activity detection (sVAD) for speech/music classification.\nData preprocessing\nWe considered the audio segment from the GTZAN Music-Speech [17] (60 speech, 60 music) dataset for this task. This audio segment consists of one min (12 ssec) audio sound. Mel-frequency cepstra (MFCC) of each audio file is extracted (using frame sizes of 30 msec and 10 msec overlap) and normalized to range [0,1]. The MFCC is then augmented with the estimated noise profile and a 12-dimensional energy profile. A 40-dimensional feature vector is generated by vector concatenation of the MFCC, predicted noise profile, and energy vector. This audio is represented using an input feature vector of length INLINEFORM2, and each instance of it is generated by combining with all the samples ( INLINEFORM3's as in (4)) from the training set.\n\nData analysis and generation of test samples\nWe generate INLINEFORMB samples of training set by combining with INLINEFORMB of the training set. The generated instances of each audio sample are then categorized as either speech ( INLINEFORMB = -1) or music ( INLINEFORMB = 1 ) by a random chance. Here, INLINEFORMC = 0 denotes the sample considered is speech, and INLINEFORMC = -1 denotes the sample considered is music. This set is then used for testing the trained s2s-vadnet. We consider INLINEFORMF test samples generated by combining with INLINEFORMC reference samples belonging to the same class; for instance, for speech class, the test samples are INLINEFORMC = 0, INLINEFORMC = -1, INLINEFORMC = 1, INLINEFORMC = -1, INLINEFORMC = 1 and INLINEFORMC = 0.\nData Analysis and Testing\nFor the test instance INLINEFORMC, we consider the test instance as either active ( INLINEFORMC = INLINEFORMB)",
    "d667731ea20605580c398a1224a0094d1155ebbb": "\n\nAuthor keywords\n\ns2s, multisample learning, low-resource, Deep learning, MLP, convolutional neural network, speech recognition, low resource, deep feedforward neural network, Audio\n\nAuthor Disclosure Statement\nNo known conflicts of interest are declared.\n\nFunding\n\nThere was no funding support for this research work.\n\nAcknowledgments\n\nThis work is supported by DST SERB grant SRG/S5/2014/CIDT002 to SRH and the work is also funded by BIRAC, Govt of India.\n\nAuthor\n\nSudheer H. Dumpala\nAll rights reserved. No part of this work may be reproduced, copied, or modified in any form or by any means, without the prior written permission of the publisher, or use of the digital data storage and retrieval system, without permission in licensing from the Copyright Clearance Center.\n\nThis is an Author Accepted Manuscript of a paper accepted for publication in International Journal of Computer Vision, which has been published in this format and is not the final version of the paper. It's been typeset and formatted for publication, however, the final published version of the paper may not include this author's name/affiliation/address.\n\nISSN: 2077-0766(online version).\nThis is an electronic version of an ACCEPTED journal paper as published by Elsevier Ltd, on behalf of The Institute of Electrical and Electronics Engineers (IEEE), and has been subjected to Elsevier's Author Rights Policy. This includes: IEF rights management, IEEERE production standards, IEEE Prefacing and formatting requirements, and Elsevier's permissions requirements.\n\nThe final publication is available online on Elsevier, or can be accessed through Science Direct (Elsevier): http//journals.elsevier.com/ieeexplore\n\n#\n\nNo. 7, July 2019\n\n##\n\n##### Acknowledgements\n\nWe thank Prof. B. Sajjan for providing us with the audio clips to experiment the proposed approach, and Prof. A. L. Verdes for reviewing the draft.\n##### Citation of this Work\nNo. 7, July 2019 \u00a9 2019 The Authors. All rights reserved.\n\nThis paper presents an abstract of work published in the International Journal of Computer Vision (IJCV). For more details about the work, including access to the final paper and",
    "8bb0011ad1d63996d5650770f3be18abdd9f7fc6": "\n\nREFERENCE LIST\n\n[1] K. C. Chan, R. J. Hobbs, J. Epperson, and N. Roy Choudhury. SQuAD: A structured dialogue Dataset. In Proc. of the 2015 Conference on Empirical Methods in Natural Language Processing, ACL-2015, pp. 1430\u20131438, June 2015. \u27f9\n\n[2] J. M. Clark, C. D. L. S. Chulay, and J. L. Finkel. The MS MARCO passage ranking challenge: Patterns of difficulty in reading comprehension. In Proc. of the 2016 Conference on Empirical Methods in Natural Language Processing, ACL-2016, pp. 1734\u20131746, July 2016. \u27f9\n\n[3] P. Zhu, Z. Fang, J. Bansal, C. Yu, L. G. Kwiatkowski, B. Yang, and S. Z. Li. QANet: A hierarchical question answering model for web scale datasets. In Proc. of the 2016 Conference on Empirical Methods in Natural Language Processing, ACL-2016, pp. 1749\u20131759, July 2016. \u27f9\n\n[4] S. B. Ruder, D. Schlangen, and H. Sch\u00fctze. Reinforcement learning is all you need. In Proc. of the Conference and Colloquium on Unsupervised and Semi-supervised Learning (AISTATS) Workshop, pp. 1\u201317, 2014. \u27f9\n\n[5] S. Bansal, Q. Zheng, J. Zhu, J. Liang, and X. Ji. End to end question answering via reading, attending and reasoning. In Proc. of the 2016 Conference on Empirical Methods in Natural Language Processing, ACL-2016, pp. 2113\u20132123, July 2016. \u27f9\n\n[6] J. Bao, L. Zettlemoyer, P. Zhu, J. Zhang, H. Zhang, and N. Roy Choudhury. BIBREF: Benchmark tasks for automatic question answer testing. In Proc. of the Second Workshop on Crowdsourcing for Compositional Question Answering and Knowledge Base Search (CCA-QAKS 2016), pages 39\u201345, June 2016. \u27f9\n\n[7]",
    "b0dbe75047310fec4d4ce787be5c32935fc4e37b": "\nAll code can be found at HUIYUYUAN/k-a-r. All data can be found at HUIYUYUAN/k-a-r. As shown in Equation (15), the output of each layer is given by INLINEFORM7 * INLINEFORM5 * INLINEFORM4 * INLINEFORM1 * INLINEFORMAT7 INLINEFORMATION[ ]1 * INLINEFORMAT5 * INLINEFORMAT7 * INLINEFORMAT11 * \u2211INLINEFORMAT6 * INLINEFORMAT4 * INLINEFORMAT4 * INLINEFORMAT11 * INLINEFORMAT7 * INLINEFORMAT5 * INLINEFORMAT7 INLINEFORMATION[ ]2 * INLINEFORMAT1 * INLINEFORMAT5 * INLINEFORMAT1 * INLINEFORMAT3 * \u2211INLINEFORMAT4 * INLINEFORMAT4 * INLINEFORMAT7 INLINEFORMATION[ ]5 * \u2211INLINEFORMAT3 * INLINEFORMAT3 * INLINEFORMAT: \nIf an answer to INLINEQUERY is given by answering INLINEQUERYi j k with ANSWERi j k, where |ANSWERi j k | represents the length of INLINEANSWER, INLINEANSWER = k\u2217 INLINEANSWERi j k + (k \u2212 1)\u2217 INLINEANSWERj i j * (INLINEANSWERi j k )\u2217 INLINEANSWERj i j *, where * INLINEANSWERS ij and * INLINEANSWERSj ij represent the positions of answer spans in INLINEANSWERi j and * INLINEANSWERSj ij represents the positions of answer spans in INLINEANSWERj ij, then the loss function of INLINEANSWERi j is defined by Equation (22):\nWhere INLINEANSWERij represents the answers of different INLINEANSWERi ja to INLINEQUERYj j, * INLINEANSWERi jkj represents the positions on INLINEANSWERi j where INLINEANSWERi ja intersects with INLINEQUERYj j, and k defines the overlapping score.\nFigure 1: Knowledge Aided Reader (KAR)\n\n## Table 1\n## Table 2\n\n## Table 3\n\n## Table 4\n\n## Table 5\n\n## Table 6\n\n##",
    "d64383e39357bd4177b49c02eb48e12ba7ffd4fb": " \n##  \n## THE  \nSILVER EMPORIUM  \nBETWEEN SPACES\n\n##  \n\n## WILLIAM S. BURGOYNE  \nAND MICHAEL VAN PORTFOLIO  \n\nFOR  \n## JEM  \nAND THE\n\n## MISTLETOE BONFIRE CLUB\n\nA Del Rey eBook Original\n\n## Contents\n\nChapter One\n\nChapter Two\n\nChapter Three\n\nChapter Four\n\nChapter Five\n\nChapter Six\n\nChapter Seven\n\nChapter Eight\n\nAbout the Authors\n\nAbout the Book\n\nAbout the Author\n\nPraise for THE SILVER EMPORIUM\n\nAbout the Publisher\n\n## Chapter One\n\nFrom all the angles of the world, on all the days of its history, there has been only one real God.\n\nHe was here to start. He was here to close. He was here to judge. And He was here to make a deal.\n\nI don't know about anyone else, but my deal was with a man of God.\n\nI was here to do some last-minute thinking, though I didn't expect to get much sense from a man of God.\n\nThis man of God was a little young to be a preacher, a little old to be a priest. His nose was thin as a knife's edge, but his voice was like a great river's voice. He had a shock of sun-bleached hair that I hoped would be white as the wind and the mountains when it parted, his eyes had been burned out by the sun, but they gave the world more than they took back.\n\nSo I asked him why the whole idea of buying salvation from death in exchange for some real estate was so wrong.\n\nI couldn't have heard him right. My ears were right, though, and my eyes. I heard everything. But I didn't understand anything.\n\nSo I asked him again; I spoke with my whole brain and my whole heart, and I asked the real estate man, the devil real estate man, why this whole idea for a bargain was so wrong.\n\nAnd that made him laugh. He hadn't needed my question because I already knew the answer with all my bones. He'd known it when he had sent me down this road.\n",
    "52f9cd05d8312ae3c7a43689804bac63f7cac34b": "\n\nReferences\n\n[1] H. Daum\u00e9 III and M. M. Heilman. \"Attention Is All You Need: Hyperconnected Recurrent Networks for Reading Comprehension.\" (2018), URL: http://papers.nips.cc/paper/7641-attention-is-all-you-need.pdf.\n\n[2] M. Heilmann and H. Daum\u00e9 III. \"Towards Machine Understanding by Extracting Conversational Facts.\" In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics (Empirical Methods Papers), pp. 17\u201334. 2018. (EM): ######6 (F1: ######8 )\n\n[3] H. Daum\u00e9 III, M. M. Heilmann, and C. Clark. \"A New Benchmark Dataset for Factual Question Answering.\" In International Conference on Learning Representations, pp. 1599\u20131607. 2019. (F1: ######9 )\n\n[4] S. Cho et al. \"Towards Machine Reading, Reasoning and Composing using Conversational Fact-Based Compositional Representations.\" (ACL Anthology, 2018). URL: https://www.aclweb.org/anthology/D18-1253/.\n\n[5] H. Daum\u00e9 III et al. \"Question Answering with Concept-Fact Language Models.\" In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing and the 2018 Conference on Genre and Style, pp. 1719\u20131732. 2018. (F1: ######9 )\n\n[6] H. Daum\u00e9 III, K. Hashimoto, and M. M. Heilmann. \"A New Dataset to Evaluate Machine Linguistic Understanding of Compositionality and Multi-step Inference.\" In Advances in Neural Information Processing Systems, pp. 4829\u20134838. 2019. (F1: ######9 )\n\n[7] H. Daum\u00e9 III et al. \"Towards Machine Comprehension of Social Media with a Multi-turn Conversation Dataset.\" (EM): ######2 (F1: ######3 )\n\n[8] H. Daum\u00e9 III et al. \"DataAug: Semi-supervised Data Aug",
    "dea9e7fe8e47da5e7f31d9b1a46ebe34e731a596": "\n\nDhont, J. (2011). Code-mixing, creoles and the evolution of Indian English. American Ethnologist 38 (1), 1\u201313.\n\nFleiss, J. L., Cohen, R. J., Zijlstra, R. A. (1969). Statistical measures of agreement among multiple raters. Educational and Psychological Measurement, 11 (3), 55\u201373.\n\nGonzalez, A., Del Valle, J., Garc\u00eda-Alamancos, O. (2013). Humor in social media: A comparison on Twitter and Facebook. In Proceedings of the 19th Conference of the International Language Resources and Evaluation Conference. European Language Resources Association, 2013.\n\nHsu, K., Lin, H., Lai, B. F., Liu, J. (2014). Automatic Detection of Jokes on the Web: A New Study in Humor Classification. In Proceedings of the 2015 International Joint Conference on Knowledge Engeneering and Knowledge Management, IJCKM '15.\n\nRathi, R., Sarangi, M., Saha, A., Bandyopadhay, V., Pal, D. (2012). Hindi-English code-mixing tweets for Humor Detection: An Empirical Study. In Language Resources and Evaluation, 2014 IALRC.\n\nSchroeder, D., Stremmel, W., Maass, M. (2010). Automated classification of English-Spanish code-mixed tweets. In Social Informatics (SIGSOI 2013), 2013 32nd ACM SIG Symposium on, 2013, p. 23\u201328.\n\nThakkar, S. L. (2015). A survey on computational humor: Themes and challenges. Computers and Communications 55.\n\nVaidya, R. J., Kaur, A., Saha, A., Rathi, R. (2015). Exploring Humor in the Indian Code-mixed Social Media Texts. In Proceedings of the First International Conference on the Computational Linguistics of Indian Languages, CICLing.\n\nVaidyanathan, A., Sarkar, S., Singh, S., Singh, G. D., Yadav, R., Bandyopadhyay, V. (2015). Detecting Pun in Code-mixed Tweets. In Proceedings of the 2015 International Conference on Social Computing,",
    "955cbea7e5ead36fb89cd6229a97ccb3febcf8bc": "\n1.\n\nhttps://support.twitter.com/en/help/375527891534652757472,\n\naccessed April 7, 2017.\n\n2.\n\nD. Kao, D. Kao, and H. D. Lewis, \"Computational Computational Humor: From Theory to Practical Algorithms,\" in Proceedings of the Fifth International Conference on Computational Humor, Springer Berlin Heidelberg, 2003.\n\n3.\n\nS. Mishra and P. Hovy, \"Unsupervised Classification Of Humor in Social-Media Texts,\" in Proceedings of the International Conference on Computational Natural Language Learning, 2015, pp. 98\u2013106.\n\n4.\n\nK. N. Mishra and P. Hovy, \"DeHumor: A Tool For Deleting Humor In Text Through Humor Enhancement,\" in Proceedings of the Sixth International Conference on Computational Natural Language Learning, 2016, pp. 98\u2013111.\n\n5.\n\nhttp://www.ic.unisi.ch/ic-conference/2009/papers/07-Mishra.pdf,\n\naccessed April 7, 2017.\n\n6.\n\nAnuradha, S. C., V., B. P., P., and C. V., B. P., \"Code-switching in Mixed Language Texts: A Linguistic Study of Tweets from Twitter,\" in Proceedings of the International Conference on Computational Natural Language Learning, 2014, pp. 52\u201366.\n\n7.\n\nMishra, K., P., S. K., B., P., S. A., P., S. B., M., B., A., B., B., and J., J., \"Identifying Language Dependence in Code-mixed Tweets: A Survey on Sentiment, Humor, Code-mixing, Translation, and Spoken Forms,\" in Proceedings of the Fifth Joint International Conference on Natural Language and Knowledge Processing and Tenth Indian International Conference on Artificial Intelligence, 2014, pp. 119\u2013129.\n\n8.\n\n\"India's top 10 code-mix tweets,\" http://www.ibtimes.co.in/indias-top-10-codemix-tweets-123754,\n\naccessed April 7, 2017.\n",
    "04d1b3b41fb62a7b896afe55e0e8bc5ffb8c6e39": " For example, Twitter has been dominated by English words for long time (97% words) but recently it has been seen that people are also writing in Hindi and other Indian languages like Marathi, Konkani etc. Code-mixing of English words with Punjabi and Marathi could be an interesting experiment. The annotated corpus can also be used for improving language detection which currently relies only on character level features. Code-mixing of Hindi and other Indian languages can be further extended in this direction. Since this research field is in its nascent stage, there is lot of scope for conducting more experiments and research in this area.\n\nACKNOWLEDGEMENT\nThis research is funded by the SERB-GATE Grant under Department of Science and Technology, Government of India and IIT Bombay. Authors would like to thank Mr. Dinesh Kulkarni for the help in creating the framework for the corpus and to Dr. Shubham Rastogi for the suggestion on how to create the corpus and for his advice on early stages of the project.\n\nC. P. Kumar, C. Manjula Gopinath, R. K. Gupta and A. S. Nagpal., \"Sentiment Analysis of English and Hindi tweets using Naive and Artificial Neural Networks : An exploratory Study\", International Journal of Contemporary Hospitality Management, 19(4), 12-19, November 2015.\n\nN. Pareti and A. K. Mishra, \"On Computational Humour Detection: A Comprehensive Review\", International Journal of Language and Computing, 6(3), 3-15, 2015.\n\nJ. Gautam and R. Pendalwar, \"Humour Detection in Tweets\" 2015.\n\nA. Schroeder and N. P. Tenney, \"Half of all tweets are written in languages other than English.\" Proc. 6th International Conference on Computational Linguistics and Speech, Pages 14\u201325. Chicago, USA. October 2010.\n\nR. L. Long and D. J. Lunt, \"Detecting Humorous Intent in Spoken English and Dutch Tweets with Word-N-Grams\", 2015.\n\nA. Mishra and N. Pareti, \"A Study of Sentiment in Tweets Written in the Mixed Language of English and Hindi: An Approach Using Neural Networks\",",
    "15cdd9ea4bae8891c1652da2ed34c87bbbd0edb8": " In Hindi language tweets can also be classified as different categories like poetry, news and fiction. If those tweets can be labelled as humorous and non-humorous then, it can increase humor detection accuracy rate in a tweet.\nFurther, to understand the semantic features in our tweets we tried to include poem or stanza in the feature vector which may also help the system to identify the humorous tweets. Since the size of tweet corpus is very low, fine tuning of the model using ten-fold cross validation is also recommended. This will make the corpus more reliable and will increase generalization of the model. Finally we would like to release a bigger corpus of tweets with multiple labels to the public to work on this kind of texts.\nAcknowledgments\n\nThis work is supported by the IIT Bombay Seed Grant Program S.R.S. and by the Science, Technology and Society (STS) program at Massachusetts Institute of Technology (MIT), India.\nReferences\n\nBIBREF1 R. Schroeder, C. Fischer and W. Kroftschulte, \"Computational Humor: A Survey of System Architecture and Recent Research Progress\", Computational Linguistics, Vol. 25, Number 4, 1996\n\nBIBREF2 I. kao, D. Wang, and Z. Wu \"Comparing Pun Identifiers and Humor Detector for Chinese Texts\", International Journal of Database Theory and Application. Vol. 16, No. 2, 2016.\n\nBIBREF3 I. kao, \"Humor Detection in Social Media Text: Progress of 20 Years in Computational Linguistics with Specific Focus on Pun Detection\", Springer International Publishing, 2016.\n\nBIBREF4 M.P. Daly, V. Amati and J. Grishman, \"A Brief History of Computational Linguistics in NLP, Computational Linguistics, Vol. 19, 1992\n\nBIBREF5 C. Chiarelli, K. Dyer and Y. Li, \"Humor Classification for Language Processing: an Automated Classification of Jokes by Inference of Humorous Content\", Computational Linguistics and Chinese Language Processing, Elsevier Science Publishers, 2014.\n\nBIBREF6 D.A. Brame and R.D. Saili, \"Some Conceptualization of Code-Mixing: A View from the Language Arts\", Journal of the American Oriental",
    "ab0fd94dfc291cf3e54e9b7a7f78b852ddc1a797": "\n\nFurther, we propose a simple model architecture that obtains state-of-the-art results for machine translation and abstractive summarization using a sequence to sequence model augmented with language model representations. We show that the language model representations are complementary to our method.\n\nAcknowledgements\nWe would like to thank the anonymous reviewers for providing insightful feedback. We would also like to thank Matteo Filippi for his help with setting up and debugging our HVDC system and Simonne Devinne for her advice. Our work is supported by Amazon's AI labs and by Amazon's Machine Learning and Applied AI services groups.\n\nReferences\n\nBERT: Distill Knowledge from very large language models.\n\nBIBREF0\n\n.\n\n.\n\nBIBREF1\n\n.\n\n.\n\n.\n\n\n.\n\nRuder, S., Soares, R. & Collobert, R. A (2014).\n\nAn analysis of character n-grams in language models.\n\nBIBREF2\n\n.\n\n.\n\nN. Graves, Hinton, G., Schmidhuber, J., Weston, J., Tieleman, G. L., Baldi, M. & Li, D. (2020).\n\nTraining Generative Language Models.\n\nBIBREF3\n\n.\n\nA. Guzman, M., Bojarski, M. & Korayem, M. (Eds.). Deep Learning: The Workshop.\n\nBIBREF4\n\n.\n\n.\n\nZenMLR\n\nBIBREF5\n\n.\n\nM. Gokaslan, R. W., Choi, E.-S., Huang, J., Choi, L., Bitarov, L., Barzilay, R. & Sennrich, R. (2021).\n\nPre-training for Transfer in Low-resource Neural Machine Translation.\n\nBIBREF6\n\n.\n\n.\n\n.\n\n.\n\nG. Hsu, L.-A. Sordoni, L. & A. C. Berardelli (2017).\n\nEnhancing a Sequence-to-Sequence Model with a Language Model for Better Language Understanding.\n\nBIBREF7\n\n.\n\n.\n\n.\n\nL. Hubars",
    "6ca938324dc7e1742a840d0a54dc13cc207394a1": " We also plan to address the following questions: Is it possible to use task-specific representations instead of contextualized word representations provided by language models? Is there any potential for the joint architecture of BIBREF28? Does it help when a bi-directional model is used for training text generation tasks? Is it possible to preapre training language models on synthetic training data to make pre-training on small amounts of parallel data feasible?\n\nACKNOWLEDGMENTS\n\nWe thank our colleagues Marius Sellke and Danilo Ervin for valuable discussions on pre-training strategies. We thank the authors for WMT news and document summarization as well as Xinghui Yang for helpful discussions.\nReferences\n\n1BIBREF12\n\n2BIBREF13\n\n3BIBREF14\n\n4BIBREF15\n\n5BIBREF16\n\n6BIBREF17\n\n7BIBREF18\n\n8BIBREF19\n\n9BIBREF20\n\n10BIBREF21\n\n11BIBREF22\n\n12BIBREF23\n\n13BIBREF24\n\n14BIBREF25\n\n15BIBREF26\n\n16BIBREF27\n\n17BIBREF28\n\n18BIBREF29\n\n19BIBREF30\n\n20BIBREF32\n\n21BIBREF33\n\n22BIBREF32\n\n23BIBREF36\n\n24BIBREF36\n\n25BIBREF37\n\n26BIBREF36\n\n27BIBREF37\n\n28BIBREF32\n\n29BIBREF32\n\n30BIBREF37\n\n32BIBREF37\n\n\n**DEAD BAD GEYSER**  \n **THE BIOGRAPHIES**\n\n**MARGARET DILLOWAY**\n\n**_SCRATCH THE SURFACE_**\n\n_Dedicated to Michael Kahn,_\n\n_the most dedicated critic_\n\n_this genre can claim._\n\n# TABLE OF CONTENTS\n\nTitle Page\n\nPraise for Margaret Dilloway, _Dead Bad Geyser_\n\nChapter One\n\nChapter Two\n\nChapter Three\n\nChapter Four\n\nChapter Five\n\nChapter Six\n\nChapter Seven\n\nChapter Eight\n\nChapter Nine\n",
    "4fa6fbb9df1a4c32583d4ef70d2b29ece4b3d802": "\n\n## Acknowledgment\n\nWe thank the anonymous reviewers for their helpful comments. This work was supported by the Austrian Science Fund FWF under grant I3134-N.\n# Appendix A\n\n## ELMo\n## A.1 ELMo\n\nContextualized Word Representations from Language Models. In this section, we follow BIBREF0 which describe the construction of word representations that are applicable to arbitrary sequences by learning an embedding for each word based on a rich context. Specifically, INLINEFORM1, as part of the language model training objective, encodes the semantic and syntactic word context for each word in a sentence, and INLINEFORM2, right before the softmax function, is set to the sum over all word contexts. INLINEFORM0 is a learnable parameter.\n\n# Appendix B\n\n## Machine Translation\n\nModel. We present a set of settings that cover different model sizes and amounts of labeled training data. We experiment with (English-Turkish) translation, (English-German) translation as well as the abstractive abstractive summarization task.\n\n## B.1 Model Sizes\n\nWe consider two network sizes: the standard Big Transformer architecture with INLINEFORM0 blocks followed by self-attention BIBREF0 ; and a small (one-layer) model using the Big Transformer architecture and self-attention BIBREF0. To reduce the training run time for all the experiments we only consider 4 blocks per tower in the small model. We report results for three amounts of labeled synthetic data: 160K sentence-pairs, 5M sentence-pairs and the WMT'18 English-German (en-de) and WMT English-Turkish (en-tr) benchmarks. We apply the BPE vocabulary found in \u00a7 F.3. For all experiments we also consider a shared encoder-decoder embedding variant when INLINEFORM0 and INLINEFORM7 share the same weights BIBREF1. A list of all parameters and learning rates for each setup is in Appendix SECREF8.\n\n## B.2 Data\n\nEnglish-German. We employ the standard data split for WMT'18 news translation consisting of bitext data excluding ParaCrawl and longer than 250-token sentences as well as the WMT English-Turkish data comprising 210k sentence-pairs. We apply tokenization using the Moses tokenizer BIBREF",
    "4d47bef19afd70c10bbceafd1846516546641a2f": " We use transformer network and the fairseq toolkit, and explore pre-trained language model architectures with more parameters and bidirectional encoders. We use the sentencepiece toolkit for fast tokenization and a BPE vocabulary of 37K types.\nInformal comments\n\nThe current model is not using word-level knowledge from the LM for the prediction of new tokens; it is possible to improve the model with fine-tuning of the generated language model, however, this adds compute to language modeling and therefore is more expensive compared to training new models from small bitexts. Our current LM architecture has 353M parameters. Better architecture would improve performance; in some cases we did not even converge on pre-trained language models.\n\nCitations\n\nBruni et al. (2017) Bruni, A., Goyal, N., Lavie, T., Chen, C., Chen, C., & Duer, L. (2017). Enhancing Language with Contextualization from Multiple Texts. Trans. of the 2018 Conference on Empirical Methods in Natural Language Processing (EMNLP).\n\nJ\u00e9gou and Zissermann (2020) J\u00e9gou, M., and Zisselman, L. (2020). Instance Relational Learning. In Proceedings of the 26th Conference on Neural Information Processing Systems (NeurIPS).\n\nKim et al. (2021) Kim, S. W., Lample, W., Li, H., Lepage, G., Toshniwal, V., & Hillel, J. (2021). BART: Pre-training of Large Language Models. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL).\n\n\nLuong et al. (2015) Luong, P., Pham, T. T., Khan, G., Tieleman, G., & Hovyed, D. (2015). Effective Approaches to Adding Compositional Structure to Recurrent Neural Networks. In Conference on Empirical Methods in Natural Language Processing, pp. 1112\u20131124.\n\nNivena (2021) Niven, A. (2021). TransformerXL. In proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL).\n\n\n\n## Dedication\n\nFor Beth, my beloved wife. I love you so much.\n",
    "506d21501d54a12d0c9fd3dbbf19067802439a04": "\n\nStill, we believe our research demonstrates clear value in training both the discriminator and the generator together in parallel. By providing a framework in which to define a user-defined set of keywords, the model could easily be modified to generate different advertisement outputs. Given the variety of available peer-to-peer markets, this could ultimately result in a much greater variety of product description and listing outputs from which Airbnb consumers could choose, ultimately increasing the competitive pressure facing the peer-to-peer platform itself, and in turn leading to a better marketplace overall. \n[1] Bowman, Lila, et al. \"Generating Text With Recurrent Neural Networks.\" (https: //papers.nips.cc /paper/7363-generative-text-with-recurrent-neural-networks, last accessed, January 14, 2019).\n\n[2] Dash, Parth, et al. \"The ELU Unit Is Better for Sequence Generation Than Gated Units in Recurrent Neural Networks.\" (http: //arxiv.org /pdf/1612.08275, last accessed, January 14, 2019).\n\n[3] Radford, Alec, et al. \"Unsupervised Reparameterization for Image Generation with Sparse Priors.\" (https: //arxiv.org /pdf/1611.07006, last accessed January 14, 2019).\n\n[4] Dube, Alexey, et al. \"Introduction to Online Peer-to-Peer Markets.\" (http: //medium.com /u/alexeydube /introduction-to-online-peer-to-peer-markets, last accessed, January 14, 2019).\n\n[5] Goodfellow, Ian J., et al. \"Generative Adversarial Networks.\" (http: //arxiv.org /pdf/1412.6566, last accessed, January 14, 2019).\n\n[6] Mikolov, Tomas. \"What Are Good Word Embeddings?\" (http: //www.nips.cc /paper/5994-what-are-good-word-embeddings-why-are-they-so-difficult-to-create-and-how-cmu-lm3, last accessed, January 14, 2019).\n\n[7] Nag, Dev, et al. \"Improving Text Generation Through Attentive Reciprocal Learning",
    "701571680724c05ca70c11bc267fb1160ea1460a": "\nExperiment 1: GloVe Vectors\nExperiment 2: Word Embeddings with Part-of-Speech\nThe purpose of this experiment is to test the feasibility of learning about a listing's popularity from its description. Here, we use a recurrent neural network framework with LSTM gates in order to classify a listing as popular or not popular, as defined by its occupancy rate. We find that a GloVe vector trained on our corpus of descriptions shows promising results, though ultimately performance decreases with respect to a GloVe base vector (trained on gigaword/wiktionary)\nExperiment 1\nWe train both our model and the discriminator for a total of 10 epochs. This corresponds to the length of time that each model spends processing 1000 random inputs (for a total of 4000 sentences to classify). We measure accuracy as the percent of inputted sentences that are classified the same as the ground truth. We also measure cross-entropy loss, which measures how well the neural network is able to differentiate between real and fake generated data points. We note that both accuracies and cross-entropy loss increase towards the end of the training epoch.\nExperiment 1 (GloVe Vectors)\nExperiment 2: Word Embeddings with Part-of-Speech\n\nExperiment 3: Generative GAN w/ DMK Loss\n\nExperiment 4: GAN w/ DMK Loss & Weighted GloVe Data\n\nAcknowledgements\n\nWe would like to thank the following individuals for their invaluable input:\nLynn H. Katsumi for her insightful feedback to the project's outline.\nLorenzo Villosa for discussing our idea with us over a late night phone call.\nAlyssa D. Taranto for pointing out that the occupancy rate could be a good way to define a user's liking for a listing.\n\nAndrew Le for his extensive suggestions on the model's development.\n\nOur families for their continued support and inspiration.\nThe project was made possible through the generous support of the Department of Computer Science at Carnegie Mellon University, the Pittsburgh Technology Council, and the National Science Foundation. Special thanks are owed to our mentors Ben Orenstein, James Tarkarli, and Daniel L. Vock.\n\nAuthor Contributions\n\nThis work was performed by all three of the listed authors.\n\nReferences\n[1] Bowman, L",
    "600b097475b30480407ce1de81c28c54a0b3b2f8": "\nAnother exciting direction for future work is the integration of these generative models with other data sources, such as location and other listing features. More particularly, a number of recent studies have discussed the potential ability for deep neural networks to extract location features from text such as the presence of landmarks and specific neighborhoods. Our project, however, focused very deeply on the text-to-text generative space, and we are interested in exploring ways in which the integration of other data sources and models might enrich this domain.\nAcknowledgments\nThe team wishes to thank Dr. A. Mishra, Dr. R. Baraniukas, and J. Radford for the insightful discussion of the literature in the field of generative models. Additionally, this work was performed as part of a research assignment provided by Professor Dr. R. Esfandiari.\n\n[1] Bowman, S., Kiela, T., and C. Lample (2016). Neural Machine Translation by Jointly Learning to Align and Translate. arXiv preprint.\n\n[2] Chen, H., P. Lee, A. Riedel, and Y. Bengio (2017). A Study of Word Embedding Losses In NLP. In The 55th Conference on Association for Computational Linguistics: Short Papers.\n\n[3] Dash, A., Neelakantan, N., and S. Koyama (2018). Rethinking Neural Networks for Synthetic Data Generation. arXiv:1711.03994v1 [Cs].\n\n[4] Goodfellow, I., P. Pascanu, and C. Szegedy (2014). Generative Adversarial Networks. Advances in Neural Information Processing Systems, 29, pp. 1224\u20131232.\n\n[5] Goodfellow, I., P. Pascanu, and C. Szegedy (2014). Generative Adversarial Networks: An Overview. In: I. Goodfellow, C. Szegedy, A. Achille, S. Chintala, G. D'Souza, and F. Baldi, editors, Advances in Neural Information Processing Systems, pp. 2672\u20132678.\n\n[6] Mikolov, T., K. Tashneem, and T. Sutskever (2013). Efficient Estimation of Word Representations in Vector Space.",
    "ee7e9a948ee6888aa5830b1a3d0d148ff656d864": "\n\nAcknowledgements\nMany of the findings here were inspired by our conversation with Yifan Hu and Yoonjin Choi, which began on the way to meet with Dr. Ping Li for an exploratory meeting about the use of GANs in Airbnb listing descriptions. Our research also benefited from conversations with colleagues Ramin Yazdani and Aaron Custis, as well as from an external read over the paper by Dev Aneja. We would like to thank our collaborators and TA's, Andrew Li, Daniel Yee, and Adam Raskovich, and the teaching assistants, John Wojtowicz, Yuri Shafarman, and Meredith Oltmann, for their invaluable technical and intellectual support throughout this work. The writing of this paper benefited greatly from the advice and guidance from Dr. Ping Li.\n\nReferences\n\n[1] Bowman, S. L., et al. Variational Autoencoders for Text Generation. In Advances in Neu-ral Information Processing Systems, pages 1005\u20131015, 2017.\n\n[2] Goodfellow, I. J., Iandola, S., Szegedy, M., and Zaremba, C. Exclusive of common: a simple, robust, and effective training procedure for generative adversarial netwoks. In International Conference on Learning Representations. 2016.\n\n[3] Radford, A. J., et al. Improving Language Models with Adversarial Training. In Thirty-Third Conference on Neural Information Processing Systems (NIPS), 2017.\n\n[4] Ardila, M., et al. Online peer-to-peer marketplaces: a comparison and an empirical model. Working paper, 2017.\n\n[5] Goodfellow, I. J., et al. Generative adversarial nets. In NIPS, 2014.\n\n[6] Mikolov, T., Sutskever, I., and Chen, K. Distributed representations of sentences. In Workshop on Machine Learning for NLP, 2013.\n\n[7] Petersen, P., and Wiedeman, L. Deep learning in NLP: An overview. In Conference on Empirical Methods in Natural Language Processing (EMNLP), 2018.\n\n[8] Radford, A., et al. Language models are unsupervised multitask learners. In Thirty-Third Conference on Neural Information Processing Systems",
    "5fda8539a97828e188ba26aad5cda1b9dd642bc8": "\nWe are interested in exploring whether the self-attention is powerful enough to be the only input for CWS task. The advantage of self-attention is the fast speed it brings while the attention only takes unigram features to generate the representation of sentences which means it is possible that the representation of unigram is strong enough. With recent powerful pre-trained embedding from SIGHAN Bakeoff corpus, we further explore the ability of the self-attention and use it to get a decent result with only unigram features. With fast speed and effective representation of input, this model can be easily incorporated into other neural CWS models. The neural CWS model with self-attention mechanism has the potential ability to bring performance improvement.\n\nReferences ::: Table TABREF1\n\nTable TABREF2\n\nTable TABREF3\n\nTable TABREF4\n\nTable TABREF5\nReference ::: Table TABREF4\n\n::: Table TABREF5\n\nReference ::: Table TABREF6\n\nReference ::: Table TABREF7\n\nReference ::: Table TABREF8\n\nReference ::: Table TABREF9\n\nReference ::: Table TABREF10\n\nReference ::: Table TABREF11\n\nReference ::: Table TABREF12\n\nReference ::: Table TABREF14\n\nReference ::: Table TABREF15\n\nThe CWS task is often seen as a sequence labeling problem. The traditional sequence labeling model is always based on a scoring model that it is composed of two parts, one part is used to encode input characters, and the other part is used to perform the segmentation. The most basic form of scoring model is the Markov model BIBREF13, in which the probability of the input word sequences depend on the maximum entropy of states.\n\nThe neural scoring model is the alternative for the classic scoring model. In neural scoring model, there are two main types, one is the sequence tagging model as in BIBREF20 and the other is the sequence labeling model as in BIBREF12. The sequence tagging model is more suitable for sequence labeling tasks that take word, phrase, sentence, dependency, or chunk features as input. As the CWS task takes word feature and no other feature input as input, we focus on the sequence labeling model in this work.\n\nBIBREF14 proposes the neural graph model for neural machine translation. BIBREF15 extend the neural graph model to sequence",
    "709feae853ec0362d4e883db8af41620da0677fe": "\nAcknowledgments\nThis work is supported by National Key Research and Development Program of China (Grant 2018YFC0700600); National Natural Science Foundation of China (Grant 61772158); Fudan University Basic Research Fund (Grant 2019LJN2150)\nYi Guo, Zhilin Jiang, Yaqing Zheng received their Master's degree from Fudan University in 2017 and 2019, respectively. Sincere thanks are given to those who helped my thesis and especially the two senior researchers who reviewed the draft for many times. Special thanks are given to their teacher, Wei Li, for his encouragement.\nYi Guo\nWei Yu received his M. Phil. degree and Ph.D. degree from Fudan University in 2015 and 2021. Sincere thanks are given to those who helped my thesis and especially the two senior researchers who reviewed the draft for many times. Special thanks are given to their teacher, Lili Ma, for her encouragement.\nWei Yu\n\nWei Yue\n. Cite as follows:\n\nWei Yue, Yi Guo, Wenwei Geng, Zhilin Jiang, Yaqing Zheng.\n\n. We used the following resources to generate our report:\n\n.\n. http://www.nlg.whu.edu.cn/download-bin/nlg_papers/sigmammlr06_submission.pdf\n. http://papers.nips.cc/paper/5867-learning-a-good-sentence-embedding-representation-of-words-using-a-sentence--pair-model-on-sentences-from-an-unsupervised-linguistic-resource.pdf\n. http://proceedings.mlr.press/v97/giamprad2015.pdf\n. https://www.aclweb.org/anthology/D14-1174\n\n. G. Huang, H. Li, S. Wang, T. Zhou.\n. http://aclweb.org/anthology/D/D15/D15/papers/D15-1174/D151174.pdf\n\n. C. Liu, X. Wang, A. Li, G. Zhou, J. Cao.\n\n. H. Li, P. Li, S. Li, X. Feng, Y. Wei, M. Zhang",
    "186b7978ee33b563a37139adff1da7d51a60f581": " \nAcknowledgments\nThis research is supported by the National Science Foundation of China under Grant 81673127. \nReferences \n  1. \n  2. \n  3. \n  4. \n  5. \n  6. \n  7. \n  8. \n  9. \n  10. \n  11. \n  12. \n  13. \n  14. \n  15. \n  16. \n  17. \n  18. \n  19. \n  20. \n  21. \n  22. \n  23. \n  24. \n  25. \n  26. \n  27. \n  28. \n  29. \n  30. \n  31. \n  32. \n  33. \n  34. \n  35. \n  36. \n  37. \n  38. \n  39. \n  40. \n  41. \n  42. \n  43. \n  44. \n  45. \n  46. \n  47. \n  48. \n  49. \n  50. \n  51. \n  52. \n  53. \n  54. \n  55. \n  56. \n  57. \n  58. \n  59. \n  60. \n  61. \n  62. \n  63. \n  64. \n  65. \n  66. \n  67. \n  68. \n  69. \n  70. \n  71. \n  72. \n  73. \n  74. \n  75. \n  76. \n  77. \n  78. \n  79. \n  80. \n  81. \n  82. \n  83. \n  84. \n  85. \n  86. \n  87. \n  88. \n  89. \n  90. \n  91. \n  92. \n  93. \n  94. \n  95. \n  96. \n  97. \n  98. \n  99. \n  100. \n  101. \n  102. \n  103. \n  104. \n  105. \n  106. \n  107. \n  108. \n  109. \n  110. \n  111. \n  112. \n  113. \n  114. \n  115. \n  116. \n  117. \n  118. \n  119",
    "fabcd71644bb63559d34b38d78f6ef87c256d475": "\nData Availability\n\nCode and data are available at:\n\nhttps://osfinder.sina.com.cn/s/m/3QjGg5H.php\nAcknowledgments\n\nThis work is supported in part by National Natural Science Foundation of China (Grant No. 61573191).\n\nConflict of Interest\n\nThe author confirms that this article contains no identifiable and publicly-unavailable details or descriptions of persons or facilities.\n\nIn this paper, we use the following acronyms:\n\nAS\n\nAll-Sentences Chinese Sentences\n\nBIDR\n\nBaseline Independent Delimiter Recognition\n\nBi-affine\n\nBiaffine\n\nBIBEF\n\nBenchmarking Initiative for Language Engineering\n\nBIBREF\n\nBibliography\n\nBIBREF1\n\nHu, Z., and Su, Z.\n\n[2017]\n\nA character-based convolutional neural word segmenter. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (EMNLP 2017), pp. 1423\u20131437.\n\nBIBREF2\n\nShi, Z., and Li, N.\n\n[2017]\n\nConditional random fields for sequence labeling. In Proceedings of the 2017 ACL (Long).\n\nBIBREF3\n\nZhao, J., Chen, Z., and Xu, D.\n\n[2016]\n\nCharacter-based convolutional network for Chinese word segmentation. Journal of Artificial Intelligence Research, 42(3), 885\u2013908.\n\nBIBREF4\n\nLing, L., and Liu, S.\n\n[2016]\n\nEfficient greedy word segmentation with a maximum entropy Markov model. In Proceedings of SIGMOD (2016).\n\nBIBREF5\n\nJia, Y.\n\n[2015]\n\nChinese word segmentation with a greedy neural network. In Proceedings of EMNLP (2015), pp. 3201\u20133210.\n\nBIBREF6\n\nSong, Z., Yao, Y., Su, Z., Li, Y., and Liu, Q.\n\n[2017]\n\nWord segmentation with a cascaded graph-based CRF model. In Proceedings of the 39th SIGMOD-SIGACT-SIGAI Symposium on The Principles of Database Systems, SIGMOD 2017, San Fr",
    "da9c0637623885afaf023a319beee87898948fe9": " Also, we thank the anonymous reviewers for their careful readings and suggestions.\nReferences\nBIBREF0 Abusive Language\n\nBIBREF1 Djuric, M. A., Huang, M. S., & Kim, J. J. (2015). Understanding Human Perception in Offensive Tweets: Analysis and Extraction of Abusive Language with a Continual Deep Neural Network. In Proceedings of the 2015 International Conference on Intelligent User Interfaces, ACM, p. 3.\n\nBIBREF2 Behera, A., Bunt, A., O'Connor, J., & Wiebe, M. (2016). Investigating the Effect of Context on Classification of Online Bullying. In Proceedings of the 13th ACM International Conference on Web and Social Media, ACM, p. 136.\n\nBIBREF3 Zappavigna, L., & Liu, Z. (2015). Twitter Abuse: How to Stop Cyberbullying on Social Media Platforms. In Proceedings of the 24th ACM SIGCHI Conference on Human Factors in Computing Systems, ACM, pp. 1499\u20131508.\n\nBIBREF4 Trommer, D. E., & Zhang, K. (2016). A New View on Automated Online Abuse Detection: Automated and Linguistic Context Extensions. In Proceedings of the 30th International Joint Conference on Artificial Intelligence, IJCAI 2016, ACM, pp. 2621\u20132627.\n\nBIBREF5 Founta, M., Guittoni, L., De Pasi, L., & Grondona, F. (2018). Hate and Abusive Speech on Twitter: Building a Dataset of 100K Tweets with Cross-Validation Annotations. In Proceedings of the 2018 International Joint Conference on Computational Linguistics: Technical Papers, IJCLT:7, ACM, pp. 1793\u20131805.\n\nBIBREF6 Twitter: http://twitter.com/abuse\n\nBIBREF7 Chen, Y., Qin, S., & Jiang, L. (2016). Detecting Online Harassment and Cyberbullying Content on Twitter Using Ensemble Methods. In Proceedings of the 35th Annual ACM Conference on Information and Knowledge Management, ACM, pp. 1211\u20131213.\n\nBIBREF8 Jadab, S",
    "8a1c0ef69b6022a0642ca131a8eacb5c97016640": "\nBach, B., A. Vosselman, and D. Mc Donald. 2010. Automatically Detecting Hate Speech from Twitter: A Crowdsourced Experiment. In Proceedings of the 21th ACM Conference on Information and Knowledge Management (CIKM), 1521\u20131528. ACM.\n\nBIBREF0: \nBIBREF1: \nBIBREF2: \nBIBREF3: \nBIBREF4: \nBIBREF5: \nBIBREF6: \nBIBREF7: \nBIBREF8: \nBIBREF9: \nBIBREF10: \nBIBREF11: \nBIBREF12: \nBIBREF13: \nBIBREF14: \nBIBREF15: \nBIBREF16: \nBIBREF17: \nBIBREF18: \nBIBREF19: \nBIBREF20: \nBIBREF21: \nBIBREF22: \nBIBREF23: \nBIBREF24: \nBIBREF25: \nBIBREF26: \nBIBREF27: \nBIBREF28: \nBIBREF29: \nBIBREF30: \nBIBREF31: \nBIBREF32: \nBIBREF33: \nBIBREF34: \nBIBREF35: \nBIBREF36: \nBIBREF37: \nBIBREF38: \nBIBREF39: \nBIBREF40: \nBIBREF41: \nBIBREF42: \nBIBREF43: \nBIBREF44: \nBIBREF45: \nBIBREF46: \nBIBREF47: \nBIBREF48: \nBIBREF49: \nBIBREF50: \nBIBREF51: \nBIBREF52: \nBIBREF53: \nBIBREF54: \nBIBREF55: \nBIBREF56: \nBIBREF57: \nBIBREF58: \nBIBREF59: \nBIBREF60: \nBIBREF61: \nB",
    "48088a842f7a433d3290eb45eb0d4c6ab1d8f13c": "\nReferences\n\nBartlett, M. L., and D. E. P. Rafferty, 2014. \"On the Evaluation of Feature Selection Algorithms for Social Media Data.\" Proceedings of SIGKDD 2014, 11-17. DOI: 10.1145/2548220.2548224.\n\nBIBREF0\n\nFounta, C.; Ochoa, R.; Barros Filho, F.; Santos, C. H. D. G.; Lopes, L. D. A.; Nunes, I. C.; Silva, E. B. R. H., 2018. \"Hate and Abusive Speech on Twitter.\" In ACL-IJCNLP 2018. Amsterdam, the Netherlands, September 2018. ACL Anthology.\n\nBIBREF1\n\nBIBREF0\n\nBIBREF0\n\nChen, Y., R., J., D.; Qazi, M.; Chen, F., S. H.; Li, D. H. Z.; Zhang, H.; Li, Q., S., 2014. Abusive Tweets Detection: Feature Engineering and Analysis. Proceedings of the International Conference on Social Informatics. ACM, New York: 931-934. DOI: 10.1145/2641496.2641498.\n\nBIBREF1\n\nWarner, J., M. P., & Hirschberg, B., 2012. \"Detecting offensiveness in tweets.\" Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, New York. 1291\u20131200.\n\nBIBREF2\n\nSethi, R.; Founta, C.; Barros Filho, L. D. A., 2009. Offensive Language on Twitter. Proceedings of the 5th International AAAI Conference on Weblogs and Social Media. ACM, New York: 100-106. DOI: 10.1145/1533030.1533049.\n\nBIBREF3\n\nBIBREF0\n\nChadha, S., J.; Saha, J. K., 2012. \"Classification of Cyberbullying: A Data Mining Approach via Textual and Graph Clustering Based Filtering.\" SIGKDD 2012 Workshop. San Francisco, CA, USA.\n\nBIBREF4\n\nXia, Y., R., H",
    "4907096cf16d506937e592c50ae63b642da49052": "\nReferences\n[BIBREF1]\n\nMert R. R. Razavi and Ravi Kumar N. Srivastava.\n\nOffensive language detection on Twitter through crowdsourced classification and machine learning.\n\nIn Proceedings of the International Joint Conference on Biometrics (IJCB), 2012.\n\n[BIBREF2]\n\nJames A. Warringer, Kieran W. Clarke, and James P. W. Hargreaves.\n\nDetecting Cyberbullying on Twitter: A Machine Learning-Based Approach.\n\nCommun. ACM 59(3), pp. 14\u201322, 2014.\n\n[BIBREF3]\n\nEmilia Viviano, Stefano Tuffa, and Andrea Soroni.\n\nAddressing cyberbullying and hate speech online using automatic tweet filtering.\n\nIn Twelfth international conference on Web usage Mining (WUM), 2017.\n\n[BIBREF4]\n\nShawna Z. Davis, Matthew L. B. Founta, Michael A. Lease, and Javed Mostofi.\n\nOthering language: an open challenge for social media research.\n\nIn Proceedings of the International AAAI Conference on Web and Social Media: The International Symposium on Computational Social Science (ICWSM), 2018.\n\n[BIBREF5]\n\nShawna Z. Davis, Matthew L. B. Founta, and Javed Mostofi.\n\nA taxonomy and survey of hate speech and offensive language.\n\nComput. Sci. Soc. 80, pp. 65\u201376, BIBREFREF17 2015.\n\n[BIBREF18]\n\nAdam.\n\nAdam: an adaptive and scalable optimization system.\n\nhttp://adam.readthedocs.io/en/latest.\n\n[BIBREF19]\n\nAlex Graves and Christopher D. Manning.\n\nA tutorial on recurrent neural networks.\n\nIn Proceedings of the Thirteenth International Conference on Information-Retrieval, 2014.\n\n[BIBREF20]\n\nYonathan L. Zaslavsky, Aseem Saini, and Dario Floreano.\n\nBidirectional recurrent neural network for sequencelearning.\n\nIn Advances in Neural Information Processing Systems (NIPS) 2015 Proceedings, 2014.\n",
    "8748e8f64af57560d124c7b518b853bf2711c13e": "\nAcknowledgement\nThis work is supported by the European Regional Development Fund-Cooperation Fund, the European Union, Project Number: 2017-1-PL4-KA203-041776\n\nReference\n[1] Hovy, J., & Waseem, S. (2013). An Empirical Study of Online Hate and Offensive Language. Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, New York, NY, United States, Association for Computing Machinery.\n[2] Chen, C., & Liu, A. (2016). Detection of Offensive Language in Twitter: A Comparative Study of Different Classifiers. http://www.comp.nus.edu.sg/~yixin/papers/tw.pdf\n\n[3] Badjatiya, S., Mihaylova, A., & Matuszek, M. (2020). Detection of Online Abusive Language in Hate-Based Communities. Association for Computational Linguistics.\n\n[4] Waseem, S. (2018). The Social Media Anti-Hate Speech Dataset. International Journal of Computers and Their Representation.\n\n[5] Waseem, S., Mueenudin, A., Hovy, J., Vasishth, P., & Felfernig, B. (2014). Gender-based Annotation of Twitter. Proceedings of the 2014 ACM International Joint Conference on Pervasive and Ubiquitous Computing, Santa Clara, California, USA, Association for Computing Machinery.\n\n[6] Zhang, G., Wang, Q., Huang, Y., Wu, Y., & Qin, S. (2018). Toward Online Racism Detection Using Deep Learning Techniques. Proceedings of the 2018 17th International Conference on Autonomous Agents and Multiagent Systems, Melbourne, Australia, Association for Computing Machinery.\n\n[7] Gamb\u00e4ck, T., Ghanem, K., & Sundar, M. (2020). Towards a Comprehensive Hate Speech Detection System in Twitter. Proceedings of the 2020 International Workshop on Spoken Language Technologies, Berlin, Germany, Association for Computational Linguistics.\n\n[8] Badjatiya, S., Ghanem, K., Sundar, M., & Saurabh, H. (2018). A Multidimensional Model of Annotation for Off",
    "893ec40b678a72760b6802f6abf73b8f487ae639": "\nAcknowledgments\nThis project is the result of a fruitful cooperation where different perspectives and contributions of all authors helped to make the project completed. Special thanks to Javier Sanchez and Sung Woon Park for introducing the project idea to us and to Dr. Mustafa Anwar for discussing initial ideas for this work.\nBIBREF0. Alessio Salvo, et al. Detection of Hate and Offensive Language on Twitter through a Multimodal Approach, Proceedings of the Workshop on Harnessing Social Media for Sociological Research, pp. 1-5.\n\nBIBREF1. HateCube. 2017. https://docs.google.com/viewer?a=1&pid=chromedoc&url=http%3A%2F%2F%2Fhatecube.com%2Fabout% 2Fhatecube%2Fwpcontent%2Fuploads%2FCatalog-wp.pdf\n\nBIBREF2. Li, T. & Zhang, L., 2018. Can I trust? Comparing the Performance of Text-based Social Media Classifiers against Data-curated Labels by Human Annotators.\n\nBIBREF3. S. M. Almasi, et al., 2019. Predicting Racially/Religious/National Disapproval in Hate Speech Detection and Automatic Classification. In 2019 7th European Conference on Machine Learning and Applications. ICMLA 2019.\n\nBIBREF4. Hateful-Deter. 2018. https://docs.google.com/viewer?a=1&pid=chromedoc&url=http_2F% 2F%2Fwww%2FHateful_Deter% 2Fpaper%2FPaper% 2F9.pdf\n\nBIBREF5. B. Waseem, et al. Hate Speech Detection. 2018. https://www.aclweb.org/anthology% 2FH2017%2FHate%2F\n\nBIBREF6. J. Gamb\u00e4ck, et al. Neural Networks for Hate Speech Detection in Social Media.\n\nBIBREF7. M. V. Zhang, et al. Online Hate Speech Detection Using Multiple Types of Contextual Information. In Proceedings of the 23rd Conference on Computational Natural Language Learning. CNCLe 2018.\n\nB",
    "c81f215d457bdb913a5bade2b4283f19c4ee826c": " Based on this point, we hope to improve the hate speech detection model in the future by adapting it to new training data.\nAcknowledgements\nWe thank Prof. Thomas H.W. B\u00fcchl for his support. We also express our thanks to Ali Mujtaba for his valuable contribution in the implementation of CNN-based fine-tuning method.\n\nDatasets used in our experiments will be shared and will be made accessible to the research community by writing a paper in Kaggle and submitting it to a workshop dedicated to hate speech detection.\nReference\nBibliographic Reference\n\nBabber, S.D., Faderl, C. and Uryupina, S., 2019. Hate speech detection and mislabeled data: causes, consequences, and mitigation strategies, in Proceedings of the Workshop on End-to-End Solutions for Online Abuse, The Web Conference.\n\nBabber, S.D. and Faderl, C., 2018. A critical review of state-of-the-art methods, tools, and challenges in hate speech detection. Multimodal Computing and Interaction, 5(4), e8.\n\nBender, A., 2018. The hate-based community: a computational study of extremist online discourse. In Proceedings of the Workshop on Harms and Hate Speech in Multilingual Social Media, The Web Conference, 2.\n\nBender, A., 2014. Crowd-sourcing as a source of political and cyber-psychological abuse: understanding twitter hate speech from a psychological perspective. Journal of Language Aggression and Violence, 4(1), 26\u201335.\n\nBendtsen, R. and Hansen, G., 2016. Online hate speech. In Proceedings of the 2nd International Conference on Language Resources and Evaluation, Association for Computational Linguistics.\n\nBendtsen, R., Hansen, G. and Kromann, Y., 2015. Language in the public sphere: an analysis of hate speech on Twitter, Language and Computing, 41(1), 43\u201352.\n\nBERT: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.\n\nBerman, A., Hovy, E., and Roth, R., 2014. The Twitter hate detector: a real-time system for detecting tweets",
    "e101e38efaa4b931f7dd75757caacdc945bb32b4": " A further study can investigate the effect of fine-tuning different BERT encoders on specific hate speech tasks, such as racist and sexist content detection, etc.\n\nAcknowledgement\nThis research was supported by the Science and Technology Research Funds of IAU-TUBITAK under Grant Number 1111T0854. The authors would like to thank A. Kandemir Ibrahim and Fatma Dogan for their support.\n\nReferences:\n\n[1] Djuric, R., et al. Predicting the Type of Abusive Language on Social Media Posts Using the Latent Dynamics of the Social Media Conversation Network. ArXiv. 2019.\n\n[2] Malmasi, A., A. Vardas, and K. Auer. Automated Detection of Hate Speech in Social Media. Proceedings of the 19th International Conference on Intelligent Technologies and Informatics, 2017.\n\n[3] Waseem, A., et al. A Cross-lingual Study on Detecting Talking About Hate on Social Media. ACL. 2018.\n\n[4] Waseem, A., and L. Hovy. Automatic Classification of Tweets With Multiple Offensive Terms in the Context of Race. PLOS ONE. 2017.\n\n[5] Badjatiya, A., et al. Hate Speech Detection: A Deep Learning Perspective, 2018.\n\n[6] Gamb\u00e4ck, A., E. Vig, L. Hoyle, S. Schumacher, and G. Kebb\u00e9s. Recognizing Hate in Multilingual Social Media. ArXiV. 2018.\n\n[7] Zhang, H., et al. A Neural Semantic Hate Speech Classifier for Social Media Data. ArXiv. 2020.\n\n[8] Popescu, A., E. C. M\u00f6ller, and K. Auer. A Deep, Cross-Lingual Approach on Unsupervised Detection of Cyberbullying, 2018.\n\n[9] Davidson, S., et al. Offensive Language and the Web: What Is in the Name? Proceedings of the Web Conference, 2016.\n\n[10] K. Poggi, A. Vardi, L. Gao, T. K. Landauer, L. Sproat, S. V. N. Vijay, E. M",
    "afb77b11da41cd0edcaa496d3f634d18e48d7168": " In addition, we present an error analysis on the misclassification patterns and reveal some possible reasons that our model encountered to misclassify hateless and offensive samples as racism. To sum up, as far as we know, our transfer learning approaches are the first attempts for hate speech understanding by using new supervised fine-tuning techniques in hate speech classes with unbalanced classes' distribution by means of BERT. The results we have obtained demonstrate that it is possible to use pre-trained BERT model to fine-tune specific hate speech downstream tasks. Thus, it could be helpful to develop pre-trained hate speech detectors for different languages.\n\nACKNOWLEDGEMENTS\n\nWe are grateful to Lilit Babajanian and Gizem Ersoy for their valuable comments and suggestions.\nREFERENCES\n\n[1] Djuric, S., Babaei, S., Bansal, P., Rajpurkar, P., & Zadeh, A. (2015). A Machine learning approach for Twitter hate/offensive language detection. In NLP 2015, pages 1106\u20131112. Association for Computational Linguistics, Inc..\n\n[2] Malmasi, M., Ratti, B., Pang, H., Liu, Y., & Founta, D. (2018). Neural networks for hate speech detection in social media. Nature Machine Intelligence.\n\n[3] Malmasi, M., Ratti, B., Pang, H., Goyal, P., Y., Goyal, N., & Founta, D. (2019). Towards learning to forget: Biasing deep learning using a language model. 2019.\n\n[4] Gamb\u00e4ck, R., Zafar, M., Pang, H., & Founta, D. (2019). A framework for language modeling: Improving hate-speech detection with a convolutional neural network. 2019.\n\n[5] Waseem, A., Kargar, E., & Elhadad, A. (2016). Annotating tweets with hate speech using multiple criteria. In Proceedings of the Workshop on Online Abuse and Harassment, page. 27:6\u201327:12.\n\n[6] Djuric, S., Alnajjar, M. S., & Khattab, A. A. (2018).",
    "41b2355766a4260f41b477419d44c3fd37f3547d": "\nFuture work\nWe plan to improve the performance of the BERT-based hate speech detection model further by dealing in a better way with the existing biases in the training data and the lack of labelled hate speech examples using transfer learning approach.\n\nAcknowledgments\nWe would like to thank Mouna Abdalla and Ali Khosravi for their valuable comments on our first version of the paper.\n\nReferences\n\nBaker, M., and G. Brida. 2011. Online hate speech detection in English social media. In Proceedings of the Workshop on Machine Learning for Social Media.\n\nBarker, S., K. Iannetti, V. Koutra, E. Niv, L. Schultz, and F. Tommasi. 2015. How can machine learning facilitate human communication on social media? In Twenty-Fourth International Conference on World Wide Web, pp. 1008\u20131012.\n\nBadjatiya, E., S. Goyal, H. Khatib, and J. Wu. 2019. Predicting race from social media posts: A multi-task learning approach to hate speech detection on Twitter. Proceedings of the Conference on Empirical Methods in Natural Language Processing.\n\nBIBREF1. Anand, K., M. Founta, and J. Y. Han. 2017. Detecting hate on social media: A survey of social media detection. AAAI\n\nBIBREF2. Shami, U., B. Nusseibeh, J. P. Kamps, N. S. H. El Faisal, I. O'Brien, D. E. Cathey, U. A. Farbood, V. G. A. Bansal, and F. Qazi. 2020. The dark side of crowdsourcing: understanding racial bias in hate speech detection. In Proceedings of the Conference of the European Association for Machine Learning.\n\nBIBREF3. Agrawal, G., A. Chaudhuri, S. E. Farber, and H. Kleinberg. 2019a. Online hate speech identification using machine learning. Social Media+, 1(4).\n\nBIBREF4. Adi, H., C. Ma, K. A. Chou, P. Chiarello, and S. G. Lee. 2018. A survey on deep learning for hate speech detection. J. Super",
    "96a4091f681872e6d98d0efee777d9e820cb8dae": "\nACKNOWLEDGMENT\n\nThis work was carried out with the support of The National Programme for Artificial Intelligence and Knowledge-Based Systems, BOF2019-25, from the Scientific and Technological Research Council of Turkey (T\u00dcB\u0130TAK) and the Y\u00fcksek Karma Researcher Scholarship Program from Ko\u00e7 University. The authors express their gratitude to the Ministry of Culture and Tourism, and especially Yunus Emre University, for providing financial support, and to M. Ali Mihret and H. G\u00fclseren, who helped us to perform the experiment.\nConflict of Interest Statement\n\nThe authors declared that no potential conflict of interest exists.\n\nBIBLIOGRAPHY\n\n#1. S. Waseem, B. Badjatiya, and H. Hovy, \"Measuring Hate and Offensive Language in Twitter: A Qualitative Analysis and Baseline Model\", in Proceedings of the 17th International Conference on Weblogs and Social Media (ICWSM2016): Companion Proceedings of the 2016 International Cross-Disciplinary Conference on Web and Social Media, 2016.\n\n#2. J. D. Davidson, D. M. Lewis, J. E. Kemp, A. Paxson, W. Hovy, B. Badjatiya, and A. Bamman, \"Detecting and Categorizing Hate Speech on the Web Using Annotated Corpora\", in Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP 2015): Empirical Methods Series, 2015.\n\n##BIBREF0 Y. Liu, A. M. Tse, C. D. Fountain, J. A. Kemp, A. Bamman, B. Badjatiya, R. Rambow, and M. S. Bernstein, \"How to Detect Abuse, Harassment, and Disinformation in Social Media: A Survey\", in Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing (EMNLP 2019), 2019.\n\n#3. S. Wielebski, D. Diakopoulos, R. Rambow, H. J. M. J. M. N. De Vries, C. D. Fountain, and D. M. Kaplan, \"Automatic Hate Speech Detection with Twitter as Training",
    "81a35b9572c9d574a30cc2164f47750716157fc8": "\nFigure FIGREF8(BERT)\n\nCNN-based fine-tuning strategy: BERT based fine-tuning strategy in which, except [CLS] token of the BERT model, all transformer encoders' output vectors of length L (maximum sequence length), are given as an input to a CNN. After concatenating these values into a tensor of size L\u00d7768, a convolution operation is performed and the maximum value of each transformer encoder is generated by applying max pooling. Afterward, the softmax activation function is applied to the output.\n\nFigure FIGREF9(BERT_LSTM)\n\nInsert nonlinear layers fine-tuning strategy for BERT base model, in which a second fully connected network in size 768 is used. The first two layers use the Leaky Relu activation function with negative slope 0.01, while the final fully connected layer uses the softmax activation function.\n\nFigure FIGREF10(BERT_CNN)\n\nInsert Bi-LSTM layer fine-tuning strategy for BERT base model, in which all transformer encoders' output vectors are given as inputs to a bidirectional LSTM. After processing the input, the network passes the final hidden state to a fully connected network. Finally, the softmax activation function is applied to the input.\n\nFigure FIGREF11(BERT_CNN_GRU)\n\nInsert CNN layer fine-tuning strategy with Gated Recurrent Unit in BERT base model, in which the output of all transformer encoders is concatenated to generate a tensor and a CNN layer is applied on the tensor. After applying max-pooling on the tensor, a fully connected network is used to output a result. Softmax is applied to classify it.\n\nTable TABREF16(Class Distributions)\n\nTable TABREF17(Avaluation-Results)\n\nTable TABREF20(Misclassification-Samples by Categories)\n\nTable TABREF21(Misclassification-Samples by Categories)\n\nTable TABREF22(Misclassification-Samples by Classes)\n\nTable TABREF24(Misclassification-Samples by Categories)\n\nFigure FIGREF12(Progression-Racism)\n\nProgression of Racism tweets, where each dot represents a tweet.\n\nFigure FIGREF13(Progression-Sexism)\n\nProgression",
    "f4496316ddd35ee2f0ccc6475d73a66abf87b611": "\nOur CRC model which maps both words and concepts into the same semantic space, is the best performing model on dataless classification. The 3C model which maps words and concepts into two separate space performs competitively well when the computational cost is considered. \nIn future research, we might exploit neural modules introduced by chen2016neural in order to embed the relationships between concepts, and extend these methods to handle tasks of multi-class semantic similarity. \nAcknowledgments\n\nThis research was funded by the Academy of Finland under the Helsinki Collegium of Artificial Intelligence (HiArt) project. We would like to thank HiArt PhD students for their precious help and technical support.\nReferences\n\nAkiba, M., Lee, W. C., & Hovy, D. (2011). Text clustering using semantic contexts from a knowledge base. COLING 2011: Conference and Workshops of the Association for Computational Linguistics: Proceedings of the 47th Annual Meeting of the Association for Computational Linguistics.\n\nBaeza-Yates, R., & Ribeiro, S. (2007). Improving distributional semantics with Wikipedia relations. In Proceedings of the 22nd European Conference on Artificial Intelligence (ECAI 2007), Lecture Notes in Computer Science, volume 5128, pages 104\u2013112. Springer.\n\nBaker, M., & Surma, Y. W. (2008). Learning to annotate concepts. In Proceedings of the 24th Conference on Human Language Technology, pages 1827\u20131833. Association for Computational Linguistics.\n\nBarthet, H., Kiritchenko, B. A., Zhai, Y., Chopra, P., Derrac, J., Seneff, E., & Hauptmann, M. (2008). A distribution-based approach to entity classification. ACL 2008, Association for Computational Linguistics, 2234\u20132240.\n\nBarthet, H., Hauptmann, M., Seneff, E., & Kiritchenko, B. (2009). Wikipedia knowledge bases and semantic search in the context of large collections. In Proceedings of the 25th Conference on Association for Computational Librarianship, pages 63\u201373. Association for Computational Linguistics.\n\nBengio, S., Simonyan, K., & Weston, J. (2003). Learning word representations for",
    "e8a32460fba149003566969f92ab5dd94a8754a4": " As a result, our model provides high quality and efficient concept embeddings for low cost compared to the state-of-the-art methods.\nAnsaf Dabiri is a research scientist at the Information Sciences Institute at University of Southern California. His research interests are: machine learning, natural language processing, semantic relatedness and semantic matching. He completed his Ph.D. at Carnegie Mellon University where he worked on supervised and unsupervised learning methods for clustering, classification and topic detection.\nXin Zhang is a postdoctoral research scientist at the Information Sciences Institute at University of Southern California. His research interests include: information extraction, lexical semantics and named entity recognition. He completed his Ph.D. at University of Tennessee where he worked on improving machine translation for medical natural language processing.\n\nBIBREF0.\n\nS. Gabrilovich, L. Li, W. Giles, O. Chapelle, and L. Yates, \"Explicit Semantic Analysis: learning a structured sparse vector space from massive annotations\", Computational Linguistics, Volume 37, Issue 2, June 2015, Pages 299-322, Published by Oxford University Press on behalf of the Linguistic Society of America.\n\nS. Gabrilovich and L. Li (eds.), Semantic Web: New Developments and Possibilities, Cambridge University Press, 2014.\n\nJ. Gabrilovich, \"An evaluation of contextual models for word similarity\", Semantic Web, 2011 (1 Jan. 2012), vol. 5, no. 5, pp. 241-257.\n\nW. Gabrilovich, \"Evaluating the performance of semantic similarity measures using multiple relatedness tasks\", Proceedings of ACM on Information and Knowledge Management, vol. 8, no. 4, August 2013, pp. 736-748, ACM Press, New York, NY, USA, ISBN: 9781450313884.\n\nS. Gabrilovich, W. Giles, O. Chapelle, and L. Yates, \"Using Wikipedia to measure word meaning similarity\", Semantic Web, 2012 (1 Jan. 2013), vol. 6, no. 1, pp. 45-69.\n\nW. Giles, O. Chapelle, and L. Yates, \"Semantic clustering with Wikipedia concepts: using external knowledge to predict clusters of Wikipedia pages\", Journal of Web Semantics, vol. 6, no.",
    "2a6003a74d051d0ebbe62e8883533a5f5e55078b": " This property is especially useful with small texts such as micro blogs where concepts are under-represented and sparsity becomes a problem.\n\nAcknowledgments\n\nThe authors thank Mr. John Pang and Mr. Robert Harbridge for fruitful discussions.\n\nReferences\n\nBIBREF0\n\nBork and Kurland, S., 1997. An introduction to information retrieval, McGraw-Hill Inc.\n\nBIBREF1\n\nH. P. Lopatek, M. Lopatek, J. P. Reskaj, and K. L. J. Chodorow, 2010, \"The Probase knowledge base\u2014a large reference database for conceptual and logical tasks,\" in Proceedings of the Thirty-fifth Conference on the Application of Information and Intelligent Systems, pp. 722\u2013726. AISC, Springer.\n\nBIBREF10\n\nM. Choi, I. D. Tevethen, 2010, \"Modeling concept overlap in bag-of-words with high-dimensional vector semantic space for short text semantics,\" Computational Linguistics, vol. 29, no. 3, pp. 257\u2013286.\n\nBIBREF15\n\nP. T. Pham, J. J. Ding, and R. Harbridge, 2014, \"Query refinement by using Wikipedia entity hierarchy for named entity recognition,\" Bioinformatics, vol. 30, no. 19, pp. 2608\u20132616.\n\nBIBREF16\n\nW. Ceccarelli and T. Pilehrood, 2003, \"Learning and exploiting semantic relatedness in Wikipedia\", Text and Web Intelligence Group, Universitie de Genova and INRIA, Bordeaux, France.\n\nBIBREF17\n\nJ. T. Graesser, A. T. Collins, and K. E. L. Tan, 2003, \"The 20 newsgroups data set: Background, corpus facts, and task requirements\", Communications of the ACM, vol. 46, no. 11, pp. 107\u2013113.\n\nBIBREF18\n\nR. Harbridge, 2013, \"How to do things with words: An overview and tutorial of the word2vec model\", Proceedings of the 2012 International Conference on Information and Knowledge Management (ICIKM), Springer, pp. 943\u2013958.\n\nBIBREF19\n\nD.",
    "1b1b0c71f1a4b37c6562d444f75c92eb2c727d9b": "\nWe demonstrate the efficacy of the proposed methods over a range of real world scenarios by achieving similar or higher accuracy using only a few hundred dimensions of the dense BOC representation. Compared to BOC embedding models, in CRC model we jointly learn word-word, word-concept, and concept-concept semantic similarities. In addition, the 3C model generates continuous concept vectors which enable us to measure global concepts such as time, action, and relationship while preserving local context.\nFuture work\nUsing concepts as word representation is known to be less effective for very long texts where contextual signals can be insufficient. We plan to extend this notion in order to utilize long documents through their concepts and thus overcome the sparse BOC vector problem.\nBIBREF0   Girju, S., and K. Mochizuki, 2009. Document aggregation in the semantic web. In Journal of Data Mining, 7(2) pp. 177\u2013188.\n\nBIBREF1   Pang, B., S. Lee, S. Makhecha, and S. Pedersen. 2004. Boosting-based algorithms for short text classification. In Proc. 15th ACM international conference on Information and Knowledge Management, November 2\u20136, San Diego, California.\n\nBIBREF2   Lebanon, D., A. T. Ng, and W. F. J. Korhonen. 2003. Textual Instance Matching. Cambridge University Press.\n\nBIBREF3   Girju, S., C. Cattalini, and A. Zampolli, 2009. Explicit semantic analysis of short text using semantic vectors. In NIPS 2009 Workshop on Computation over Semantic Types.\n\nBIBREF4   Tang, F., L. C. Y. Chee, F. Xiao, and Z. Zhang. 2009. Sentiment Analysis in Tweets from Word-level to Phrase-level. In ACM SIGIR 2009 Workshops.\n\nBIBREF5   Zhang, V., D. Y. Nian, S. Qiu, and C. Cattalini, 2017. Dataless classification via semantic matching on short texts. Machine Learning, 91(1):1\u201317.\n\nBIBREF6   Zhao, T., J. Nie, H. Zhou, S. Cheng, L. Han, and F. Y",
    "9c44df7503720709eac933a15569e5761b378046": " Additionally, we expect to observe little to no difference in quality between OOV representations generated using simple n-grams and unsupervised morphemes.\nFurther investigation:\n1) Explore using OOV word representations in more downstream tasks than are currently tested. Will it help more than simple n-grams? And will the improvement be larger with unsupervised morphemes? What impact does the vocabulary size for learning have on downstream task performance? 2) Implement a weighted summation of subword vectors. Is this a better way to aggregate subword information? Does this outperform simple n-grams?\nNotes and Definitions\n\nBIBREF1 O. Erkan. Learning word representations for statistical language modeling. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, pages 1059\u20131068, 2014.  \nBIBREF2 I. Pennington, K. socialnolog, J. Dean, R. Socher. Glove: Global vectors for word representation. In Eighth International Conference on Learning Representations, 2015. In technical communications, a header element indicating that the entire preceding section is meant to be displayed as a single unit of information on a printed document.\n\nBIBREF3 Y. Yang. Predictive distributed representations and contextualized word vectors. 2016.\n\nBIBREF4 G. Le and R. Dredze. Global vectors for word representation. In Eighteenth Conference of the European Chapter of the Association for Computational Linguistics, pages 175\u2013186. Association for Computational Linguistics, July 2016.\n\nBIBREF5 L. P. Jackendoff. Lexvec: Scalable, interpretable similarity for words. Neural Information Processing Systems (NIPS): 2014 Annual Conference, 2014.\n\nBIBREF6 A. Grave Y. Radko, M. Auli, G. Farkas. Fasttext: Leveraging subword information with count-based n-grams. Transactions of the Association for Computational Linguistics, 2015.\n\nBIBREF7 J. Baroni. Lexical visualization of word vectors in the lexvec space. In Joint Conference on Lexical and Computational Semantics Companion, 2011.\n\nBIBREF8 J. Baroni. The word-context co-occurrence matrix: a new evaluation tool for skip-gram. in Joint Conference on Lexical and Computational",
    "b7381927764536bd97b099b6a172708125364954": "\nAcknowledgments\n\nThis work was performed at the Advanced Distributed Learning (ADL) research center, funded by Booz Allen. Opinions and results are not necessarily those of Booz Allen. Any mistakes or omissions are our own.\nReferences\n\n..\n\nKumar, P., Lei, H., Ng, A. & Zhai, M. (2014). fastText: Learning Subword-Level Representations for Large Vocabularies. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, pp. 1277\u20131285, 2014.\n\n..\n\nBengio, S., Steyvers, M., and Zweigenbaum, D. (2003). Distributional semantics: A tutorial. Intell Syst Res J. 11:99\u2013121.\n\n..\n\nMitchell, F. & Lapata, A. (2003). Statistical distributional semantics modeling of word meaning and word analogy tasks. Comput Linguist 2001:227\u2013267.\n\n..\n\nBogin, B., Eshima, J., J\u00e4rvinen, T. & Wille, M. (2016). The LexVec algorithm, a distributional model for context-based word representation. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pp. 866\u2013874, 2016.\n\n..\n\nBogin, B., Eshima, J., J\u00e4rvinen, T. & Wille, M. (2016). The LexVec algorithm, revised, an end-to-end trainable word embedding learning algorithm. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pp. 685\u2013695, 2016.\n\n..\n\nJ\u00e4rvinen, T., Wille, M. & Eshima, J. (2015). FastText: Learner-driven Text Classification with Distributed Representations. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pp. 133\u2013141, 2015.\n\n..\n\nJ\u00e4rvinen, T., Wille, M. & Eshima, J. (2015). LexVec Distributed Word Representations: An End-to-End Trainable Distributional Model. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pp. 2234\u20132240, 2015",
    "df95b3cb6aa0187655fd4856ae2b1f503d533583": " In addition, we will explore weighted summation of subword vectors.\n[1] T. Mikolov, K. Chen, G. Corrado, and J. Dean. Efficient estimation of word representations in vector space. The 18th International Conference on Machine Learning (ICML-2013). 2013.\n[2] O. Vylomova, T. Mihalcea, E. Kraus, L. Van Looveren, and Q. Lin. Character n-gram likelihood estimates from contextual word co-occurrence counts. In Proceedings of the 27th Conference on European Chapter of the Association for Computational Linguistics (EACL 2013). 2013.\n\n[3] D. J. Dean, R. Socher, and C. D. Manning. Word2vec, distributed memory: A tool for semantic indexing of words. The 31st International Conference on Machine Learning (ICML-2013). 2013.\n\n[4] M. Auli, M. Tiedemann, and J. Riedel. Counting the use of characters to learn word representations. In Proceedings of the 31st Conference on European Chapter of the Association for Computational Linguistics (EACL 2014) (EACL-2014)\n\n[5] A. Gupta, J. Koutnik, D. Kiela, W. Kwiatkowski, and T. F. Weimer. Implicit large vocabulary counting with skip-gram. In Proceedings of the 34th International Conference on Machine Learning (ICML 2013)\n\n[6] F. Garg, T. Huang, T. Hofmann, Y. Wu, I. Sontag, D. G. Lane, C. D. Manning, R. Socher, and W. Grefenstette. Fasttext: A probabilistic representation for fast text classification. ArXiv:1603.01121, 2016\n\n[7] F. Garg, M. Bojar, A. Gupta, and T. Huang. Subword learning in word2vec with character ngram cooccurrence. In Proceedings of the 35th International Conference on Machine Learning (ICML 2018)\n\n[8] A. Goyal, P. Liang, A. Goldfarb, R. S. K. Krishnan, C. D. Manning, S. Ritter, R. Socher",
    "f7ed3b9ed469ed34f46acde86b8a066c52ecf430": "\nFurther, future work will involve the incorporation of lexical, syntactic, and morphological features in models other than LexVec. The most clear space for improvement is the use of lexical features in place of the traditional unigram distribution, as it is well known that word context can be strongly tied to syntactic and morphological characteristics.\nWe would like to thank the sponsors of the RANLP Workshop for funding the trip to Jeju Island. We also would like to thank N. M. Alamwala, J. D. Clark, M. J. Gale, M. J. J. Kocmi, C. L. Weischedel, D. A. Wood, and D. J. Kiezun on their comments and suggestions.\nReferences\n[1] B. Sch\u00f6lkopf and T. Platt. Learning Vector Quantizations for Graph-Based Word Representations. ICML, 2009.\n  [2] E. D. Goldberg, R. E. Goodman, and D. D. Sontag. Empirical Evaluation of Subword Models for Statistical Word Representation with Skip-gram. in Proceedings of the 2013 North American Chapter of the Association for Computational Linguistics (NAACL HLT) Conference, 2013.\n  [3] N. M. de Souza and B. A. Scholle (2015). Parallel Perceptrons: Distributed Representations for Natural Language Processing. CoRR, 15-1099, 2015.\n  [4] M. J. Gale, J. D. Clark, D. D. Sontag, Z. Siddique, D. A. Wood, and A. Ng. The fastText paper and the Word2Vec Challenge. in Proceedings of the 53rd Annual Meeting of\n\nthe Association for Computational Linguistics. Association for Computational Linguistics, 2016.\n  [5] Tomas Mikolov, Kai Chapelle, Vincent Van den Broeck, Tomas Jozefowicz,  Alexey Radul, Pieter Noe,  and Aiva \u0160lajis, A. Dyer. Distributed Word Representations. In Proc. 34th Annual International ACM-SIGIR Conference on Research & Development in Information Retrieval, SIGIR, 2013, pp. 1501\u201313, 2016.\n  [6] Joost",
    "c7eb71683f53ab7acffd691a36cad6edc7f5522e": " In such situations, the external lexical resource can be obtained using thesauri of related languages. Our approach can be used to learn word vectors for any of the words in one or more languages, and can be generalized to other languages where Roget's Thesaurus BIBREF38, BIBREF39 does not exist.\n\nTable 2.\n\nTable 5.\n\nTable 12.\nTable 13.\nTable 14.\nTable 15.\nTable 16.\nTable 17.\nTable 18.\nFigure 2.\nFigure 6.\nFigure 7.\n\nFigure 9.\nFigure 10.\n\nFigure 11.\n\nFigure 13.\n\nFigure 14.\n\nFigure 15.\nTable 9.\nTable 10.\nTable 11.\nTable 14.\nTable 20.\nTable 21.\nTable 22.\n\nTable 23.\n\nTable 24.\nTable 25.\nTable 26.\nTable 27.\nFigure 3.\nTable 23.\nTable 24.\nTable 28.\nTable 29.\nTable 30.\nTable 31.\nTable 32.\nTable 33.\nTable 34.\n\nTable 35.\nTable 36.\nTable 37.\nTable 38.\nFigure 7.\n\nTable 32.\nTable 25.\nTable 37.\nTable 39.\nTable 9.\nTable 26.\nTable 30.\nTable 32.\nTable 33.\n\nTable 34.\n\nTable 35.\nTable 42.\nTable 44.\nTable 47.\nTable 48.\nS. Goyal,\n\nD. Erkan and P. Mimno (ed),\n\nProceedings of the 2015 Conference on Empirical Methods in Natural Language Processing\n\n(EMNLP 2015), 2015\n\nS. Goyal.\n\nDistributed and Queryable Subword Alignments for Paragraph-Level Sentence Alignment.\n\nEmpirical Methods in Natural Language Processing, 2016\nE. Bickel, J. Cucuringu, R. S. Bunescu, M. M. Gale and M. R. Radulescu (ed),\n\nProceedings of the 20th European Conference on Artificial Intelligence (ECAI 2016), 2016\nD. Grefenstette et al.\n\nMultilingual Word Embeddings with Cross-Lingual Transfer.\n\nProceedings of",
    "17a1eff7993c47c54eddc7344e7454fbe64191cd": " It is possible that our approach would facilitate the application of semantic resources in NLP problems such as translation and cross-lingual information retrieval by allowing to transfer word vectors that have been learned from one language to another.\nThe proposed methodology can also prove helpful in the automatic acquisition of word senses by unsupervised word embedding extraction. These word senses are closely related to the concepts we sought to encode in the dimensions, by definition, and can be easily obtained as a consequence of this process. Additionally, we can exploit our proposed approach to learn the joint associations of words with their semantic categories. For example, if we consider a category of a very complex nature such as WATER then it can be broken down to its constituent categories of WATER (e.g. drink, swim, bathe etc.) and WAVE (e.g. wave, ripples, swell etc.) which are associated with each other. Similarly, WAVE.1.1, WAVE.1.2, WAVE.1.3 etc. correspond to even smaller sub-categories for the WAVE category. Our modified algorithm can be utilized over such a lexical resource for learning a set of vectors aligned along the dimensions of WATER and WAVE.1.1.2. We can consider this as a next future work.\nLimitations. The limitation of our approach that one might observe is that although word similarity scores obtained for the proposed algorithm are often higher than the scores obtained for the original GloVe, they fail to reach the level of human similarity levels. The reason, as explained in one of the earlier subsection, appears to be that the word similarity calculation depends on the vectors of source words and the target words representing a true similarity score. Here the target word is often a word which does not appear in the given lexical resource and is consequently affected very little by the cost function. Although the additional cost term can influence the score of the target word, it is not adequate enough to significantly impact the overall word similarity scores. One possible method to improve this could be making the cost terms for the target word to be weighted based on their similarity values with the source word ( INLINEFORM0 and INLINEFORM1 in ( SECREF4 ) ). Additionally, it should be remembered that word similarity is an inherently subjective concept and it is therefore not desirable to expect that these scores should perfectly correspond to the score of human ratings. While the proposed methodology in general successfully addresses the aspect of",
    "a5e5cda1f6195ab1336855f1e39a609d61326d62": " As of yet, the methods for cross-lingual studies do not necessarily require word embedding schemes. Still, cross-lingual studies are largely based on distributional representations in a way that distributional statistics can be used as a natural measure for assessing similarity and relatedness in these languages. In the literature, distributional statistics of word vectors are used for cross-lingual studies. A promising future direction for our approach is to utilize distributional statistics of a word vector's proximity to that of a \"glue\" word to compute the influence of this word on the dimensions of other words.\nFurther, the framework of our approach can also be used to impart the concepts of sentiment and polarity in distributional word vectors. It can be shown that one of the most meaningful dimensions in the distributional semantics framework corresponds to the positivity/negativity of the sentences and paragraphs in which the given word occurs. So it will be interesting to see if the proposed cost term, instead of alignment of concepts, can be used to encode the sentiment information, and explore if this can improve the performance of word-sense related tasks such as sentiment analysis.\nIt has been known that unsupervised models such as word2vec are inherently unable to represent synonymy and semantic analogies like good-man versus man-good BIBREF45 as they assume that two words that are closer than others in vector space are semantically related to one another. So it is possible that improvements made to distributional word vectors on this front will also allow for more interpretable representations within the unsupervised word-sense disambiguation models.\nAcknowledgments\nThis work is supported by TUBITAK (The Scientific and Technological Research Council of Turkey) under contract no. 103T142.\n[1]\n\nIvory, B. and Ojalvo, C.\n\nWord Simplicity and Semantic Complexity by Word Embeddings: Insights from a Comparison of English and Dutch Words.\n\nIn:\n\nProceedings of Interspeech 2013.\n\nInternational Association for Computational Linguistics,\n\nAmsterdam, The Netherlands, October 2013.\n\n[2]\n\nZhou, Z., Cui, Q., Miao, Y. and Liu, K.\n\nLearning Sentence-level Representations\n\nof Words Using RNN, Jointly from Sentiment Analysis and Word Embeddings.\n\nIn:\n\nPro",
    "32d99dcd8d46e2cda04a9a9fa0e6693d2349a7a9": " The cross-lingual application of the proposed algorithm presents an interesting challenge for several reasons. First, even though the word2vec model is initially trained on a large corpus of English, it can be trained using other languages to allow cross-lingual word vector analysis. Second, the cross-lingual nature of cross-lingual word similarity computation presents a practical problem when utilizing semantically related concepts for the alignment. The challenge here would be to use semantically similar words to represent the same concept in different languages, and to ensure that this semantic similarity is aligned across languages. Additionally, when the target language is very different from the language for which the source word-group is intended, a very similar representation from the language-specific lexical resource may have too many outliers which can distort the learned vectors and hamper their use in some settings.\n\nIn this study, we use semantic groupings of concepts from a lexical resource in order to produce interpretable word vectors. This represents a lexical resource that implicitly provides human-written and approved descriptions of the word-groups' meanings. It may be valuable to use these word-groups, and possibly the associated concepts in them, for other purposes in NLP tasks. Such usages might follow the same lines suggested in BIBREF27, BIBREF28, but with novel applications. For example, it is possible to train an unsupervised machine translation model, based on an embedding space modified as discussed, to allow bilingual inputs to have meaningfully different outputs. An idea for future research direction arising from this is to investigate how Glove and word2vec word vectors behave when \"translated\" to a different language.\nFuture Work\nIt is an open challenge for the future work in cross-lingual settings to achieve meaningful word vector alignment across languages. When doing this, one should try to use a large common lexical resource to guide the alignment process. Although there is a growing interest in cross-lingual vector alignment approaches of different word vectors of different languages, our proposed method can be extended in the following ways to make this more feasible: \u2022 While our approach can be extended to handle a different type of lexical resources such as word frequency, co-occurrence, or collocation statistics, it is desirable for such an approach to handle a large corpus as well. \u2022 Future work might strive for better word vectors in different languages, even in cases where there is no parallel corpus available. This can be achieved",
    "eda4869c67fe8bbf83db632275f053e7e0241e8c": "\n\nAcknowledgements\n\nWe thank our Ph.D. adviser, Dr. Ashish Kapoor. We would like to thank the anonymous reviewers for their valuable feedback, the organizers of the WAT2019 workshop for their kind assistance in organizing it.\n\nReferences\n\nBERT. [http://arxiv.org/abs/1810.04805].\n\nBiduinoo. [https://www.biduinoo.com/products/text-classification/].\n\nBIBREF0\n\nHosu, S., Zhang, Y., and Liu, B. (2017). On the impact of semantics in word embedding learning. ACL.\n\nBIBREF1\n\nPang, B., Wan, H., Djuric, M. and Liu, Y. (2018). Mining sentiment from tweets without labels. WWW '18.\n\nBIBREF2\n\nPang, B., Wan, H. and Liu, Y. (2018). Paragram: Learning representations through paraphrastic sentences. WWW '18.\n\nBIBREF3\n\nRaghavan, J., Liu, Y. and Bansal-Srihari, B. (2015). What do you tweet?: A cross-domain prediction model for microblogs. NAACL '15.\n\nBIBREF4\n\nWang, O. and Tingley, D. (2018). A cross-platform, cross-modal approach to ranking tweets. WAT2019.\n\nBIBREF5\n\nPang, B., Wan, H. and Liu, Y. (2018). Semantic similarity and diversity mining on microblog texts. WWW '18.\n\nBIBREF6\n\nLi, X., Liu, Y., Pang, B. and Wan, H. (2016). Using semantic representation learning for twitter sentiment analysis. CVPR '16.\n\nBIBREF7\n\nWang, O., Tingley, D. and Liu, Y. (2018). A predictive model for twitter sentiment analysis. CVPR '16.\n\nBIBREF8\n\nRaghvan, J., Wang, O. and Tingley, D. (2018). Predicting adjacent words within tweets. SIGIR 2018.\n\nBIBREF9\n\nMikolov, T., Sharma, P. and Z",
    "2c7494d47b2a69f182e83455fe4c75ae3b2893e9": "\nAcknowledgement\nResearch for this work was supported by the Natural Sciences and Engineering Research Council of Canada. We would like to thank Dr. Yann-Ethan Ghez and Mr. Justin Chau-Chew Loh for their feedback.\n\nReferences\n\n[1]\n\nA. Abdel-Mageed and S. Zweig (2010) The Google PPDB: A semantically rich corpus for the evaluation of paraphrase and sentiment analysis tasks. In Proceedings of the 2009 Workshop on Computational and Cognitive Approaches to Psychology (CAPP).\n\n[2]\n\nS. Agarwal, N. Kumar, and P. Vishwanath (2011) An empirical study of paraphrasal data size and domain in paraphrase and sentiment analysis tasks. In\n\nProceedings of the 2011 Conference on Empirical Methods in Natural Language and Speech Processing (EMNLP), pp. 891\u2013898.\n\n[3]\n\nL. Aida, M. K. Okamura, D. K. G. Sim (2018) Exploring low-resource semantic representations of tweets for tasks. In Proceedings of the Twenty-first Conference of the European Chapter of the Association for Computational Linguistics: Special Workshop on Twitter Research (EACL Workshop on Twitter). Association for Computational Linguistics.\n\n[4]\n\nE. A. Alzahrani, S. He, M. G. Ramesh, T. Kankipati, N. Gupta, and H. G. Rabie (2019) Tweet2vec-t5: Fine-grained representations for topic-focused tweet classification and sentiment prediction. In Proceedings of the 2019 Conference on Empirical Methods. Association for Computational Linguistics.\n\n[5]\n\nH. An, V. Rajarajan, S. Subramanian, and K. Cho (2017) Constrained convolution-based convolution neural networks for paraphrase identification. In Proceedings of the Thirtieth Conference of the Association for Computational Linguistics, pp. 4103\u20134125.\n\n[6]\n\nY.-E. An (2012) Neural paraphrase extraction for tweet-based sentiment analysis. In Proceedings of the 2012 Conference on Empirical Methods in Natural Language and Speech Processing, pp. 1408\u20131413.",
    "4d7ff4e5d06902de85b0e9a364dc455196d06a7d": "\n\nAcknowledgments\nThis work was supported in part by IIT Madras and in part by Kno.e.sis Centre for Cognitive Science funded by the Ministry of Human Resources and Development, Egypt.\n\nReferences\n\n[1] Yoon, K., Belinkov, Y., & Choi, Y. K. (2017). #BOWLIE: Leveraging Twitter as a Novel Dataset for Empirical Computational Linguistics Research. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (ACL), Philadelphia, PA, USA: Association for Computational Linguistics.\n\n[2] Ermonard, O. (2015). Tweet2vec: A Unified Architecture for Unsupervised Learning of Tweet Representations. In Proceedings of the 24th European Conference on Information Retrieval, ECIR '15, Lisbon, Portugal.\n\n[3] Yoon, K., & Goh, M. (2017). FastTweet: Fast and Low-resource Learning of Temporal Representations for Microblogs. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (ACL), Philadelphia, PA, USA: Association for Computational Linguistics.\n\n[4] Belinkov, Y., & Choi, Y. K. (2019). FastTweet2Vec: Efficient and Unsupervised Word Embedding for Temporal Microblogs by Exploiting Synonymous Tweets. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics (ACL), Brisbane, Australia: Association for Computational Linguistics.\n\n[5] Rensink, A., Nee, H., & Brants, K. M. (2019). Tweet2Vec + Character-Level Embeddings: Exploring Character-Level Learning for Unsupervised Tweet Representation Learning. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics (ACL), Brisbane, Australia: Association for Computational Linguistics.\n\n[6] Madaan, A., Rambachan, A., Vijayraghavan, A., & Chugh, M. (2017). Predictive Representation Learning for Short and Irregular Tweets Using Weak Supervision. In Proceedings of the 56th Annual Meeting of the Association for Comput",
    "ecc63972b2783ee39b3e522653cfb6dc5917d522": "\nAcknowledgments\nThis research is supported by NSF Award IIA-1531040 and U.S. Department of Education, US Department of Education and Institute of Educational Sciences under the U.S. Department of Education's Institute of Education Sciences grant.\nReferences\n\n[BIBREF1] Abdel-Hamid, Y. and Schockaert, P. and Aoun, C. and Gurevych, I. (2014). Hashtags and Topical Influence: An Empirical Study. International Journal of Information Management (ijim), 42(9), pp. 1165\u20131190.\n\n[BIBREF2] Abdel-Hamid, Y., Aoun, C. and Gurevych, I. (2015). Tweets as Features: Sentiment and Topics from Microblog Data. In Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2015, pp. 589\u2013597.\n\n[BIBREF3] Abdel-Hamid, Y., Gurevych, I. and Aoun, C. (2015). Learning Word Representation in Parallel from Tweets and Documents. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, EMNLP 2015, pp. 1483\u20131493.\n\n[BIBREF4] Bravo-Hernandez, C. S. and Suwattarasai, L. and Haggard, F. and Filippov, A. and Hotho, R. and Bansal, V. N. and Chawla, G. S. (2015). Extracting Emoticons for Large-Scale Classification of Social Media Content. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, EMNLP 2015, pp. 1443\u20131455.\n\n[BIBREF5] Cucerzan, R. J., Pilehvar, R. M. and Cohn, A. and McKechnie, A. A. and Smyth, J. A. and Roth, S. B. (2015). Leveraging the Social Side of Twitter to Predict and Rank Tweets. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, EMNLP 2015, pp. 1397\u20131407.",
    "8d074aabf4f51c8455618c5bf7689d3f62c4da1d": " The final goal is building a fully linguistic processing system which considers Vietnamese and other languages of East Asia such as Chinese and Thai BIBREF4, BIBREF5. This study can be an initial survey for further following research in Vietnamese word segmentation.\nREFERENCES\n[1] BIBREF0\n[2] BIBREF1\n[3] BIBREF2\n[4] BIBREF3\n[5] BIBREF4\n[6] BIBREF5\n[7] BIBREF6\n[8] BIBREF7\n[9] BIBREF9\n[10] BIBREF10\n[11] BIBREF11\n[12] BIBREF12\n[13] BIBREF13\n[14] BIBREF14\n[15] BIBREF15\n[16] BIBREF16\n[17] BIBREF17\n[18] BIBREF18\n[19] BIBREF19\n[20] BIBREF20\n[21] BIBREF21\n[22] BIBREF22\n[23] BIBREF23\n[24] BIBREF24\n[25] BIBREF25\n[26] BIBREF26\n[27] BIBREF27\n[28] BIBREF28\n[29] BIBREF29\n[30] BIBREF30\n[31] BIBREF31\n[32] BIBREF32\n[33] BIBREF33\n[34] BIBREF34\n[35] BIBREF35\nCite as:\nNguyen, K. (2016) \"Review of Vietnamese Word Segmentation Approaches and Systems\" (Version 1), Hanoi: Digital Information Technology and Network Research Center, https://hdl.handle.net/10668/209920.\n\nLicense: Attribution-Noncommercial-ShareAlike 4.0\n\nDOI: 10.5281/zenodo.209920\n\nLast updated on January 9, 2016 by Nguyen Khanh Tien.\n \nTable of Contents\n\nTitle Page\n\nCopyright Page\n\nTHRILLERS BY JIM MYRSKI\n\nChapter 1\n\nChapter 2\n\nChapter 3\n\nChapter 4\n\nChapter 5\n\nChapter 6\n\nChapter 7\n\nChapter 8\n",
    "fe2666ace293b4bfac3182db6d0c6f03ea799277": " For example, automatic Vietnamese dictionary building, using corpora and feedback.\nAcknowledgments\nThis study is a product from many scientists. Thanks to colleagues, who gave the insights and expertise to provide this work, particularly Ngo. Nguyen, D. Tran, C. Thach, U. Tran for valuable discussion over many research works. Finally, thanks for the Vietnamese linguists, Phan Dung Thanh, Le Thi Chau, Nguyen Thi Thanh Tamy, Tran Nguyen Minh and Pham Thi Thanh.\n\nBIBREF0 Covington, B (2010) Word Segmentation, in F. P. Rabiner and M. W. Schafer (eds) Proceedings of the 2nd International Conference on Spoken Language, SL2006, pp. 696-708.\n\nBIBREF1 Le, T. T., Ngo, N. V., Nguyen, L. T., Nhu, L. H., Huu, N. H., Pham, D., Hung, V. T. (2011). A study of morphological analysis for Vietnamese language using Conditional Random Field. Paper accepted in Information Technology and Applied Computing, (ITAC).\n\nBIBREF2 Tran, V., Le, T., Huu, N., Nguyen, N., Luu, H. (2012) Towards Building an Automated Named Entity Recognition System for Vietnamese with Conditional Random Fields. In: Proceedings of ACL-11 workshop on NLP for East Asian languages and the Semantic Web, Singapore.\n\nBIBREF3 Zhao, Q., Deng, X., Liu, D. (2010) Research on Morphological Analysis of Chinese N-Gram Models Based on HMM. In: Proceedings of IWSLT-10: 2010 International Conference on Ideologies, Words, Sentences and Languages, Volume 1.\n\nBIBREF4 Ye, Y., Zhang, Q. (2012) A Survey on Chinese Word Segmentation. In: Proceedings of ECAI 2012, Proceedings of the 25th European Conference on Artificial Intelligence.\n\nBIBREF5 Ma, M. Y., Yang, Y., Xue, R. (2010) Word Segmentation on Newsprint Articles based on Maximum Entropy Approach and HMM. Paper accepted in International Conference on Knowledge and Systems (ICKS).\n\nBIBREF6 Huang",
    "70a1b0f9f26f1b82c14783f1b76dfb5400444aa4": "\nACKWARDS\nMy acknowledgements are given to the team of VLSP project which has been carried out in Vietnamese for years and helped building the necessary frameworks for Vietnamese natural language processing tasks: Nguyen and Phan: Vietnamese core word segmenter BIBREF9, and VietGiaPha project which has been collected and annotated by Nguyen and Phan BIBREF35 and BIBREF17. In the last year, Ngo and Phan developed EVBCorpus project which is already applied by many researches and NLP systems such as BIBREF16, BIBREF35, BIBREF27, BIBREF36, BIBREF37, BIBREF38 and so on. The works on word segmentation in this research are based on the projects.\n1. BIBREF0 Dinh H, Tran H. Lexical Analyses. Computer Speech & Langauge. (2002). 20 (2): 173\u2013185.\n2. BIBREF1 Tran H. Vietnamese Word Segmentation: Towards Word Sense Disclosure in Vietnamese. Proceedings of the Eighth annual International Conference on Digital Library Research and Applications 2009.\n3. BIBREF2 Tran H, Nguyen H. Vietnamese Named Entity Recognizer with Tagger-based Approach. Proceedings of the International Conference on Asian Language Processing 2007.\n4. BIBREF3 Dinh H, Tran H. Weighted Finite State Transducer for Vietnamese Word Segmentation. Proceedings of the Seventh annual Conference on Computational Linguistics 2008.\n5. BIBREF4 Liu L, Liu R. On Phonetic Features for Chinese Word Segmentation. Proceedings of the Third Annual Conference on Computational Linguistics and Intelligent Language Processing 2008.\n6. BIBREF5 Lee I. A Survey on Morphological Segmentation. Knowledge and Data Engineering. (2004). 13 (2) 877\u2013890.\n7. BIBREF6 Kwon N, Choi Y. Learning Syntactic Rules of Korean Dependency Morphology with Maximum Entropy Markov Model and Phrased-Based Dependency Contexts. Proceedings of the International Conference on Semantic Computing 2006.\n8. BIBREF7 Nguyen H, Phan B, Dinh H. Vietnamese Word Segmentation Based on Conditional Random Fields. Proceedings of the Annual International Conference on the Advancement of Artificial Intelligence 2009.\n9. B",
    "d3ca5f1814860a88ff30761fec3d860d35e39167": "\nREFERENCES\n[1] Nguyen, D., & Phan, T. (2011). JVnSegmenter: a web toolkit for Vietnamese word segmentation. Journal of the Korean Society for Information & Communication Engineering, 30(3), pp.723-729.\n\n[2] R.J. Tran, J.-C. Jiang, X. Liu, & X.-X. Huang. (2014). A study of Vietnamese word segmentation with statistical techniques: part of speech tagging, named entity recognition and text chunking. In Proceedings of the 2014 Conference of the Asian Association for Machine Intelligence Workshop on Multilingual Computing and Natural Language Processing (MCL-MCP-W), pp.37-42.\n\n[3] Dinh, G., Nguyen, D., & Phan, T. (2009). Vietnamese sentence boundary disctinction with support vector machines and maximum entropy approach. In Proceedings of the 22nd International Conference on Computational Linguistics, pp.2158-2163. Beijing. http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.243.9347&rep=rep1&type=pdf.\n\n[4], [5] H. Phe, & C.T. Vo. (1993). Building Vietnamese dictionary. In Journal of the Vietnam Academy of Sciences, 38(2), pp.81-106.\n\n[6] Dinh, G., Nguyen, D., & Phan, T. (2006). Vietnamese word segmentation using conditional random fields. Proceedings of the 33rd AAAI Conference on Artificial Intelligence, pp.1611-1616.\n\n[7] Dinh, X., Nguyen, D., & Phan, T. (2013). Vietnamese word segmentation with deep support vector machines. In Multilingua: Conference and Workshops for Multilingual Natural Language Processing, pp.103-107. Istanbul.\n\n[8] Nguyen, D., Dinh, X., & Phan, T. (2008). Vietnamese word segmentation based on Conditional Random Fields. In Proceedings of the 32nd Annual Meeting of the Association for Computational Linguistics, pp.2039-2044.\n\n[9], [10] Dinh, G., Liu, X., & Phan, T. (2008). Vietnamese word segmentation by Conditional",
    "dd20d93166c14f1e57644cd7fa7b5e5738025cd0": "\nAcknowledgements\nWe thank Prof. Giorgio Aichelburg, Prof. Daniel Dingledine, Prof. Carlo Scorzetti and Giulio Cipollone for the fruitful discussions and suggestions that led to the development of this work. We further thank the anonymous reviewers for the useful and insightful remarks. Moreover, we gratefully acknowledge support from Fondazione Cariplo during the preparation of this work.\nDeclarations of interests\nThe authors declare that they do not have competing financial interests.\n\nNotes\n\nBIBREF:\n\nBIBREF{BIBREF0}\n\nBIBREF{BIBREF1}\n\nBIBREF{BIBREF2}\n\nBIBREF{BIBREF3}\n\nBIBREF{BIBREF4}\n\nBIBREF{BIBREF5}\n\nBIBREF{BIBREF6}\n\nBIBREF{BIBREF7}\n\nBIBREF{BIBREF8}\n\nBIBREF{BIBREF9}\n\nBIBREF{BIBREF10}\n\nBIBREF{BIBREF11}\n\nBIBREF{BIBREF12}\n\nBIBREF{BIBREF13}\n\nBIBREF{BIBREF14}\n\nBIBREF{BIBREF15}\n\nBIBREF{BIBREF16}\n\nBIBREF{BIBREF15}\n\nBIBREF{BIBREF17}\n\nBIBREF{BIBREF18}\n\nBIBREF{BIBREF19}\n\nBIBREF{BIBREF20}\n\nBIBREF{BIBREF21}\n\nBIBREF{BIBREF22}\n\nBIBREF{BIBREF23}\n\nBIBREF{BIBREF24}\n\nBIBREF{BIBREF25}\n\nBIBREF{BIBREF26}\n\nBIBREF{BIBREF27}\n\nBIBREF{BIBREF28}\n\nBIBREF{BIBREF29}\n\nBIBREF{BIBREF31}\n\nBIBREF{BIBREF32}\n\nBIBREF{BIBREF33}\n\nBIBREF{BIBREF35}\n",
    "dc2a2c177cd5df6da5d03e6e74262bf424850ec9": "\n\nAcknowledgments\nThis work is supported by the National Group of Research in Computational and Data-Intensive Science and Technology.\n\nReferences\n\nBIBREF0. M. Abramo, S. Caprara, I. Marcheggiani, S. Prato, S. Verdolini. Deep neural networks for opinion leader detection on social media. In: ACM International Conference on Web Search and Data Mining. ACM, 2017.\n\nBIBREF1. N. Amstrong, K. Yogurt\u00e7u. How to identify misleading headlines online before you click on them?. In: Computational Social Choice and Markets. Omniscient, 2009.\n\nBIBREF10. C. Balzarotti, F. Rocco, G. Veronesi, F. Lopresti. Who's lying in the echo chamber? Understanding echo chamber dynamics in an age of social media. In: Nature Communications. 2018.\n\nBIBREF11. S. Caprara, A. Zanetta, M. Capozzi, F. Lopresti. Detection of fake news cascades on social media. In: Proceedings of the 11th ACM Workshop on Content and Authoritativeness. 2018.\n\nBIBREF12. E. Casadei, A. Zanetta, M. Capozzi, S. Prato, F. Lopresti. Twitter bots in Italian political campaigns: automated amplification and misinformation in the 2016 general elections. J. Comput. Media Commun.. 2017.\n\nBIBREF13. L. H. Lin, X. Wang, K. Tang. A survey of social networks and their algorithms. ACM Transactions on Internet Technology, 19(2):14:2014, 2020.\n\nBIBREF14. M. Lea, A. H. Patel, S. Y. Fadlallah. Measuring diffusion in social networks. The Annals of Statistics, 27(4):19, 1999.\n\nBIBREF15. S. Prato, M. Capozzi, S. Caprara. Echo chamber-driven misinformation: an online analysis of mainstream and disinformation online media. The American Political Science Review, 113:1093, 2020, 1\u201327.\n\nBIBREF17. S. Prato, M. Capozzi",
    "ae90c5567746fe25af2fcea0cc5f355751e05c71": "\nThe two datasets are available from the authors through email request.\n\nAcknowledgement\n\nThis project has received funding from the European Union's Horizon 2020 research and innovation program under the Marie Sk\u0142odowska-Curie grant agreement no. 771864 / K.R.\nOpen\n\nData availability: Two datasets on sharing cascades on Twitter in US and IT are available from the authors\n\nCompeting interests\n\nThe authors declare no competing interests\nReferences\n\nAbdesselam, B., & Nallapati, R. (2018). AstroTurf campaigns on Twitter: Identifying, analysing and linking social bots to political agendas. Internet Research Journal of Computers, 28(6), 33-40. doi: 10.5120/1832-3731.2018.18.\n\nBastos, I., G\u00f3mez-Bastos, C., Herrera-Viedma, B., & Herrera-Viedma, R. (2016). What causes echo chambers? Exploring the influence of network attributes on diffusion cascades on Twitter. New Media & Society, 19(6), 873-885. doi: 10.1886/NMS.1916.\n\nBauer, L., Ribeiro, S., Ribeiro, S. W., & Goldsman, A. (2016). The filtering bubble: Information cocooning in social media. Science, 353(6297), aaf7. doi: 10.1126/science.aaf7.\n\nBeetsma, R., van Elsas, J., & van Deursen, B. S. (2008). Echo chambers and misinformation online. Science, 352(6282), 1119. doi: 10.1126/science.aad5124.\n\nBenevenuto, C., Vigna, S., & Pizzolato, R. (2019). Diffusion of disinformation on Twitter: Do echo chambers and polarization matter? Science Advances, 5(4), eaaw9234. doi: 10.1126/sciadv.aaw9234.\n\nBerik, S., & Tuzel, E. (2011). Topological analysis of complex networks: An algorithmic tool to capture the shape of complex networks. Physics Reports, 505(1-2), 137-",
    "d7644c674887ca9708eb12107acd964ae53b216d": "\n\nAcknowledgments\nMany thanks to Stefano Strammiello, for the valuable suggestions, inputs and careful reading of the first draft of this work.\nReferences\n\n[1] V. P. Kogan... K. A. Haase... S. F. Mislan. On the spread of mal cious information online: Quantifying bias and echo chambers.\nCommunications ACM. 2018.\n\n[2] P. K. Vos. T. D. Robertson. R. Walker. A. Dutton. T. Gomes. M. Volk. E. Lazebnik.\nInformation wants to be free: the flow of online news, misinformation and propaganda.\nScience. 2016. 368 : a13.\n\n[3] M. A. Lewis. J. R. Cook. M. S. Wojcicki.\nPolarization in US political discourse: The role of social networks, media use, political information behavior and attitudes.\nAmerican political science review. 2015. : a36.\n\n[4] J. N. Ginsberg. J. L. Gerding. J. H. M. Wuchty. The role of confirmation bias in spreading misinformation.\nScience. 2018.\n\n[5] S. E. Gingras. G. De Souza. The filter bubble effect in social media: A systematic analysis.\nScience. 2018. 361 : 1204\u20131212.\n\n[6] F. Grosjean. A. Bamberg. H. A. Gimenez. G. Knoke. H. Liu. J. C. C. Baumdicker. C. Stehl. F. Noury. C. Vogt. S. S. Chakraborty. S. J. A. Lachowycz.\nThe role of deception agents in information spreading on social media.\nScience. 2018. 361 : 122\u2013129.\n\n[7] C. M. Bailey. Y. Wang. M. A. Niszczykl. K. McMillan. S. Chakraborty. A. Baumdicker. C. Healy. S. S. Noury.\nEcho chambers: when polarization spreads virally.\nFrontiers in psychology. 2019",
    "a3bb9a936f61bafb509fa12ac0a61f91abcc5106": " We compute P@1 in increments of 1% for question classification performance, and for QA performance we report averages over all experimental levels of QC performance, then report bootstrapped p-values for each increment using the Fisher method.\nLabel Definitions: Question terms can be mapped to categories using manual heuristics BIBREF19. To mitigate sparsity, here we generated a feature comparing the cosine similarity of composite embedding vectors BIBREF51 representing question text and category definition text, using pretrained GloVe Embeddings BIBREF52. Pilot experiments showed that performance did not significantly improve.\nQuestion Expansion with GloVe Embeddings (GloVe Version): We adapted the same question expansion model described in Section UID36, but make use of GloVe word and question pair embedding vectors BIBREF52. GloVe uses 100 dimensions, and we found performance did not significantly improve. The GloVe word and question pair vector contains one dimension for the word and another for the question, using a shared 500-dimensional word embedding.\nLabel Definitions: Question terms can be mapped to categories using manual heuristics BIBREF19. To mitigate sparsity, here we generated feature comparison scores using the similarity between the question vector and each defined category. For example, detection of the words chemical and acid would provide a count of 1 for the Chemical reaction category definition. Pilot experiments showed that we did not observe a clear benefit to this model over the baseline model.\nPreference for uncorrelated errors in multiple choice question classification: We performed a separate analysis of the experimental models' ability to predict uncorrelated noise errors in question classification. For each labeled question in the ARC development set, the answer candidates included the correct answer, and the incorrect answer candidates. For each answer set within a given question, we use a chi-squared test to analyze the correlation between predicted gold labels and wrong-answer answers. An error was defined as a question where the predicted incorrect answer was higher ranked than the correct answer. We observed strong preference for uncorrelated noise in all models with QC accuracy higher than 50%, with uncorrelated noise errors made by at least 75% of models. This is one aspect of the question classification framework for which improvements could be made in future models. Specifically, uncorrelated noise errors suggest that future question classification models should seek to make predictions that are uncorrelated to previous ones, for example, by making predictions at the closest",
    "df6d327e176740da9edcc111a06374c54c8e809c": " We determine p-values by Fisher's method for Fisher's test on the resampled mean scores. We report results using a 95% confidence interval, and mark statistical significance by P < 0.05.\nQuestion Classification with BERT\nAs summarized in Section EXP29, we train a BERT-based QA+QC model by query expansion, expanding each question using both the question text and any labels from the question classification system. This is an alternative to training a series of binary one-vs-all models, which would be a difficult task due to the cost of annotating the question classification taxonomy for supervised training.\nWe also show results on the BERT-FineTune model, which we also run using a 5-fold cross-validation over the training set to generate predicted question classification labels. This allows us to directly compare the ability of a model to predict question classification as in QA+QC model vs. the ability of the model to improve quality of questions as in BERT-FineTune model.\nTraining Data: The 7,787 training questions are all four-choice multiple choice questions from the ARC question bank, separated into 3,370 questions for training, 869 for development, and 3,548 for testing.\nHyperparameters (Probase): For the fine-tuning model, using the Probase taxonomy BIBREF53 we use the same set of hyperparameters as the BERT-QC model.\nHyperparameters (wordlist features): The wordlist features are extracted using a set of in-house wordlists mined from a corpus of 250 in-domain science textbook chapters. We use the frequency of unigram words to approximate their information value, as in Van-tu et al. BIBREF24. We follow the same hyperparameters (word list features) as BERT-FineTune model.\nStatistics: We use non-parametric bootstrap resampling to compare the baseline (L6 \u2013 L1) to all experimental model. We determine p-values by Fisher's method for Fisher's test on the resampled mean scores. We report results using a 95% confidence interval, and mark statistical significance by P < 0.05.\nPreference for uncorrelated errors in multiple choice question classification: We ran experiments to investigate whether models trained on labeled annotations and question text had a preference for uncorrelated errors, showing that uncorrelated noise is preferential when training on gold",
    "49764eee7fb523a6a28375cc699f5e0220b81766": " We then compute Fisher's method for combining bootstrap resampled statistics into a single statistic. We report the significance level p < 0.05 across questions in L7. Given that the maximum number of labels tested on a given question is 2 (at the coarsest level of fine-grained complexity), we find question classification models trained on L7 gold labels are significantly more effective than the baseline at L1.\nQuestion Classification: We make use of the LIBSvM 5.0 library BIBREF35 to train and evaluate our models (we include both results and hyperparameters in the supplementary material). We implement a linear kernel using the LIBSvmTrain function, then score predicted labels by sorting predicted label likelihoods per each label and generating a list of highest-ranked predictions. We evaluate the question classification MAP at levels of specificity from L5 to L9. Question classification results are shown in Table TABREF7 through Table TABREF9, and the question classification model hyperparameters, hyperkernsl parameters, and development set size are reported in Table TABREF35.\nModel Performance: We evaluate question classification performance first using traditional metrics. Question classification on the TREC-6 TREC-50 and the MLBioMedLAT MLBioMedLAT-BioMedLAT-BioMedLAT-GeneMedLAT-BioMedLAT-HumanMedLAT-NeuroMedLAT-NeuroMedLAT-NeuroMedLAT-BioMedLAT-Gard data are shown in Table TABREFs. 10CNN-Hierarchical shows the highest MAP on the TREC-6 TREC-50 and MLBioMedLAT at 80.7 and 78.8%, respectively, while CNN-L2-WordList performs the worst at 31.2 and 38.0%. Label Definitions: We generate class embedding vectors based on the similarity of class definitions to question terms using the GloVe class vectors. Using cosine similarity, we choose the top 10 similarity pairs for each class vector. For example, given a question term of material, we choose the top 10 pairs with similar words material, earth, minerals, sand, salt, stone, coal, metal, stone, salt, metal, gold, metal, uranium, uranium, diamond, gold, copper, gold, silver, sulfur, and gold. This results in a unique class vector for each class. We use these class vectors",
    "3321d8d0e190d25958e5bfe0f3438b5c2ba80fd1": " We combine 100 comparisons (50 baseline comparisons, 50 per model) using Fisher's method for the final statistic.\nQuestion classification paired with question answering show statistically significant gains of +3.2% MAP on predicted labels, and a ceiling gain of up to +5% MAP using gold labels. While the increase in performance when expanding a query to incorporate multiple classes of labels may be slight, our error analysis in Section SECREF7 shows that errors made by these models tend to be uncorrelated with incorrect answers and thus can significantly benefit the performance of question answering QA systems.\nDiscussion\n\nFor questions posed in context of experiments or instruction manuals, it can be difficult to extract question text or the problem domain, and as a result question classification may struggle. For example, if a question: How does a frog become a frogspawn?, is presented to a system with access only to question text, little or no semantic information would be available to classify the question. If we assume each class represents a different aspect of science content (e.g. Animals, Chemical Equations, Food Chains), question classification systems can leverage knowledge specific to those content areas. Even taking into account the challenges of label definitions (e.g. a problem domain of chemical equations might have many labels, but those labels do not define specific chemical equations, which in turn may have a number of labels such as reaction types, rate laws or equilibrium) question classification systems may do better with targeted question type queries. Additionally, as demonstrated by the baseline (TREC) questions, many factoid-style questions (including TREC) could be solved without question classification information, and instead rely strongly on simple term frequency models, so developing methods that are not overly sensitive to noise due to incorrect labels is an important area of future research.\n\nThis work makes use of several specialized resources. Because the science curriculum is designed to be covered at specified points in the curriculum, we hypothesize that targeting resources and solvers towards domains covered by standardized exams will enable higher performance on standardized tests \u2013 as such the Aristo Reasoning Challenge (ARC) is a particularly strong resource for this question classification task. However, there are still substantial challenges in annotating question classification taxonomies and datasets \u2013 for example, given the size of the GARD collection and the fact that the categories derived from it were derived from only 9 states, the annotations in BIBREF3 were collected and annotated over multiple decades, so annotators tend to",
    "bb3267c3f0a12d8014d51105de5d81686afe5f1b": "\n\nConflicts of Interest\nThe authors declare that they have no conflicts of interest.\nAuthor Contributions\nLingpeng Song and Peng Li conceived and designed the experiments, analyzed and interpreted the results, and wrote the paper.\nReferences used in this paper\n\nBIBREF0\nLeCun, Y, B. B. MacMahon, J. Durand, and M. Zimmermann. Backpropagation of error signals for unsupervised learning of hierarchical representations. Convolutional Neural Networks for Learning Filters of Images, 1993.\n\nBIBREF1\n\nBansal, A., L. Li, S. Riloff, J. Weston, and A. Caceres. Open Domain Question Answering using Knowledge Bases, 2016.\n\nBIBREF10\n\nBeltagy, A., B. B. MacMahon, and A. Caceres. Collective classification with neural contextualized word representations. In Proceedings of the 52Nd Annual Meeting of the Association for Computational Linguistics, 2016.\n\nBIBREF11\n\nPeng, D., A. Al-Moum, V. W. Cheung, and B. B. MacMahon. Collective neural semantic relevance matching for entity linking. In Proceedings of the 56Th Annual Meeting of the Association for Computational Linguistics, 2017.\n\nBIBREF12\n\nPeng, D., A. Al-Maqdesi, J. R. Tetreault, and B. B. MacMahon. Contextualized topic modeling for entity linking. In Proceedings of the 55Th Annual Meeting of the Association for Computational Linguistics, 2016.\n\nBIBREF13\n\nHotho, M., M. O. Guan, and B. B. MacMahon. Global entity coherence as an information bottleneck for disambiguating mentions. In EMNLP 2013, 2013.\n\nBIBREF14\n\nPeng, D., D. Yu, A. Al-Maqdesi, and B. B. MacMahon. Collective inference for neural entity linking. In Proceedings of COLING 2014, 2014.\n\nBIBREF15\n\nKumar, R., R. Peyton Jones, R. I. Martin, and B. B. MacMahon. Entity and event extraction",
    "114934e1a1e818630ff33ac5c4cd4be6c6f75bb2": "\n\nFunding The work was supported by National Key Research and Development Program of China (2017YFB1002101) and NSFC key project (61661146007).\nAIM\n, Department of Artificial Intelligence, Institute of Computing Technology, Chinese Academy of Sciences\n\nBIBREF_\n\n@\n\n(\n\n*\n)\nThis work was supported by a grant from the National Key Research and Development Program of China (2017YFB1002101) and the National Scientific Foundation (61661146007).\n\nBIBREF\n\n@\n\n(\n)\nThis work was partly supported by grants from the National Research Foundation, Prime Ministers Office (NSF-MOE), Ministry of Education, Singapore, under project number IZaP (MOEC/E-L0-17-13).\n\nBIBREF\n\n@\n(\n)\nThis research was supported in part by the National Research Council of Canada.\n\nBIBREF\n\n@\n(\n)\nThis work is supported by AIM, School of Informatics and Computing, University of Glasgow, and the Royal Society Wolfson Distinguished Fellowship.\n\nBIBREF\n, N.\n\n\"\n\nThis work has been supported in parts by U.S. Army Research Laboratory (ARL) grant W911NF-17-1-0285, ARL Grant Number W911NF-21-1-0327, and the Australian Research Council (ARC); by the Australian Research Council under the Industrial Transformation Research Program; by the Australian Government's support through the International Research and Development Centres program (IPD-I-2016-0071); by the Australian Research Council, through\n\nE.\n\nWe thank the anonymous reviewers for their detailed comments.\n\nBIBREF\n@\n(\n)\nThis work was supported by the Australian Research Council: Discovery program, ARC grant DP170100062, DP180100170, DECRA project DP180100076 and DECRA Project DECRA180100144.\n\n\n#   \nTable of Contents\n\nTitle Page\n\nCopyright Page\n\nDedication\n\nAcknowledgements\n\nPrologue\n\nChapter 1\n\nChapter 2\n\nChapter 3\n\nChapter 4\n\nChapter 5\n\nChapter 6\n\nChapter 7\n\nChapter 8\n\nChapter 9\n\nChapter",
    "2439b6b92d73f660fe6af8d24b7bbecf2b3a3d72": " Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of THUNUS, NExT, or National Key R&D Program of China.\nFIGURE 8: Visualization of training losses along with epochs on CoNLL-YAGO A, AQUAINT, ACE2004 and WW B. Top-left: average training loss of every epoch in training phase, TAC2010 train as development set and test on AQUAINT; top-right: AQUAINT test with early stopping as development set and test on ACE2004; bottom-left: ACE2004 test with early stopping as development set and test on CoNLL-YAGO A; bottom-right: ACE2004 test with early stopping as development set and test on WW B.\nfig-2-0\n\nfig-2-1\n\nfig-2-2\n\nfig-2-3\n\nfig-2-4\n \nTable of Contents\n\nTitle Page\n\nCopyright Page\n\nDedication\n\nCHAPTER I -\n\nCHAPTER II -\n\nCHAPTER III -\n\nCHAPTER IV -\n\nCHAPTER V -\n\nCHAPTER VI -\n\nCHAPTER VII -\n\nCHAPTER VIII -\n\nCHAPTER IX -\n\nCHAPTER X -\n\nCHAPTER XI -\n\nCHAPTER XII -\n\nCHAPTER XIII -\n\nCHAPTER XIV -\n\nCHAPTER XV -\n\nCHAPTER XVI -\n\n _To Susan_\n\n _And with love_,\n\n _Elizabeth_\n**DEATH BEFORE DISHONOR!**\n\n**A SPECTACULAR**   \n**NOVEL OF SPYCRAFT, SURRENDER, AND BATTLE  \nFROM A MASTER OF HEROISM, ADVENTURE, AND RUTHLESS POWER...**\n\nA deadly enemy of England has resurfaced... a threat that could mean war against the West.\n\nHis name is Charles Ivenson... a brilliant assassin from a merciless enemy family. He has been dispatched from Russia by his masters with one mission: to launch a surprise attack at a target to be determined in Europe.\n\nAnd who better than the British Spy Corps to find this hidden threat among us?\n\nWith his eyes fixed firmly ahead of him, Sir Roderick Alleyn",
    "b8d0e4e0e820753ffc107c1847fe1dfd48883989": "\n\nReferences\n\n[BIBREF0   ] P. C. Buneswar et al., 2013. Question answering system with entity and entity-category links. In NIPS, pages 1\u20138.\n\n[BIBREF1   ] C. Yang, H. Zhao, Wei-jing Hao, Yongxing Liu, Y. Chen, Jing Yang, and A. D. Ng, 2018. A survey on named entity recognition and related tasks. arXiv:1806.06186.\n\n[BIBREF2   ] W. Hu, Q. Wang, H.-T. Lu, Rui Xia, C.-C. Zhang, and H. Sun, 2018. Information extraction: a question of entities. In NIPS, pages 1\u201318.\n\n[BIBREF3   ] T. Zhao, J. J., Liu, G. Hsu, B. Yuan, and L. C. F. Li, 2016. The state of the art: a survey of relation extraction and entity linking. In ACL, pages 1491\u20131499.\n\n[BIBREF4   ] Y. He, H. Zhou, H. Zhao, and Z.-Y. Zhou, 2018. WordEmbedCNN: integrating n-grams and word embedding for named entity recognition on document level text. CoRR abs/1804.00121.\n\n[BIBREF5   ] S. Han, X. Wang, J. Yang, M. Jiang, and X. Cao, 2017. Collective entity linking: bridging the gap between global and local. In EACL, 3161\u20133168.\n\n[BIBREF6   ] B. Chisholm and P. Petrov, 2010. Entity linking with neural networks. In ACL-IJCNLP, pages 1815\u20131824.\n\n[BIBREF7   ] B. Chisholm and R. Socher, 2015. Distantly supervised named entity recognition using embedding spaces. In ACL, pages 1749\u20131758.\n\n[BIBREF8   ] Y. He, X. Cao, L. Cao, W. Hu, B. Zhou, R. Socher, X. Sun, and H. Zhao, 2016. Collective entity linking: linking across whole document with word context. In ACL, pages 1873\u2013",
    "5aa12b4063d6182a71870c98e4e1815ff3dc8a72": "\nReferences\nBIBREF0 Atyeo, T., Gulcehre, C., Yen, X., Karakida, T. & Toutanova, T.G. Deep contextualized word representations. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1811\u20131821, Stroudsburg, Pennsylvania, USA, September 12\u201316, 2018.\nBIBREF2 Bengio, Y. & others. Building better word vector space for word sense disambigutation. In Advances in neural information processing systems, pages 1635\u20131648, 2014.\n\nBIBREF3 Grave, S. & Mewhort, D. ELMo: Deep contextualized word representations. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 2003\u20132011, Stroudsburg, Pennsylvania, USA, September 12\u201316, 2018.\n\nBIBREF4 Dagan, D. et al. Senseval-3: Third edition of the word sense benchmark evaluation campaign. In Conference and workshops of the 51st Annual Meeting of the Association for Computational Linguistic (Volume 1: Long Papers), pages 891\u2013908. Association for Computational Linguistics, 2018.\n\nBIBREF5 Biberauer, M. B. et al. Libraries: Towards an open-source and open-access universal dependency parsebanks. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 919\u2013928, Philadelphia, Pennsylvania, USA, November 2\u20137, 2017.\n\nBIBREF6 J\u00e4rvikivi et al., 2018a. Senseval-3: English edition. URL: https://sites.google.com/site/senseval3/\n\nBIBREF7 J\u00e4rvikivi et al., 2018b. Proceedings of the RUSSE2018 shared task on word sense induction and disambiguation: System description and baseline results. URL: https://cs.helsinki.fi/srdz/docs/proceedings/russe2018/index.html\n\nBIBREF8 Bohnet, S., Schleipper, C., Mihaylov, Y., Lampinen, T., Mihaylov, S., Mihaylov, M. & Mihaylov",
    "22815878083ebd2f9e08bc33a5e733063dac7a0f": "\nAppendix\n\nThis section is a slightly expanded version of our short presentation at the IWPT 2019 NLP Hackathon.\nSome tables here may be hard to follow. For such cases we recommend to read more extensively the original text of the IWPT Hackathon, which can be found on the IWPT website at <https://hackathons.nlp.eu/iwpthmhackathon/2019/papers/>.\n1 https://en.wikipedia.org/wiki/Lemmatization, accessed October 22nd 2019.\n2 http://morgan-wood.info/publications/word2vec/, accessed October 22nd 2019.\n3 https://towardsdatascience.com/elmo-representations-for-word-sense-disambiguation-4b869b2e7a5e5c2a, accessed October 22nd 2019.\n4 https://www.cs.unc.edu/people/tawny/paper/ELMO.pdf, accessed October 22nd 2019.\n5 http://www.cis.upenn.edu/~levy/publications/papers/EMNLP-IJCNLP.pdf, accessed October 22nd 2019.\n\n6 http://wsdg.info/senseval3, accessed November 11th 2019.\n7 https://sites.google.com/site/russe18, accessed November 11th 2019.\n\nTable TABREF1\n\nWord embedding models\n\nModel\n\nCorpus\n\nArchitecture\n\nDimensions (LSTM hidden layers)\n\nDimensions (conv layers)\n\nNum of words\n\nDimensions (skipgram output)\n\nDimensions (top layer embedding)\n\nNormalization\n\nEnglish\n\nEN Wikipedia dump from Feb 2017\n\nBiLSTM over cnn on 32x32 character sequences\n\n4x4x5\n\n2048 x 4\n\n1000\n\nNo\n\nToken\n\nRussian\n\nRu Wikipedia dump from Dec 2018\n\nBiLSTM over cnn on 32x32 (rnn on rnn output)\n\n1x1x5\n\n2048 x 5\n\n1000\n\nYes\n\nToken\nTable TABREF2\n\nEvaluation setting\n\nModel\n\nArchitecture\n\nDimensions (LSTM hidden layers)\n\nDimensions (conv layers)\n\nNum",
    "220d11a03897d85af91ec88a9b502815c7d2b6f3": "\nREFERENCES\n\n## INTRODUCTION\n\nDeep contextualised word representations are a powerful tool for state-of-the-art NLP applications. The most known examples of such models are EMBERT BIBREF1 and ELMo BIBREF0.\nIn general, these models require minimal language pre-processing, just tokenization. The ELMo architecture is character-based, which makes the task of word morphosyntactic normalisation redundant.\nAlthough the field of Deep Learning can be traced at least as early as 1980s with the paper [Tishby:88], the first deep contextualised word embedding model was apparently EMBERT BIBREF1. This can be partly explained by the use of character input only. However, as shown by BIBREF0, in reality language character input is not the only reason for the success of the embedding techniques, and lemmatisation of input texts is not necessary there. Below, we show that this is not entirely true for other languages, including morphologically richer languages like Russian.\nThe problem of ambiguous words occurs in almost all languages (which also explains the high amount of data available for WSD).\nHere we focus on Russian and English only.\n\n## BACKGROUND\n\nThe word sense disambiguator task is one of the most prevalent tasks involving deep learning. The simplest way to solve this problem is to perform a search for every word in the context, and pick the meaning with the highest frequency. This algorithm is known as majority voting. The simplest way of improving it is to train logistic regression models to solve this problem better: for each word, a vector is generated based on its context occurrences (or features extracted from them), then it is fed to the logistic regression, and the model assigns the corresponding word sense. Below, there is an example of such an algorithm:\n\nAnother way of solving the problem is to train word sense disambiguators without reference to context (a so-called `supervised WSD' task). In this case, the word meaning is assigned to each word using a number of word sets (or feature sets) and then they are compared to the scores of each word set. The simplest way of training such models is to maximise a classification-specific term:\n\nHere the words are used in the sense of nouns. For example, the words `image' and `plan' are distinguished with images which in its meanings",
    "d509081673f5667060400eb325a8050fa5db7cc8": "\nAcknowledgements\nThe authors would like to thank Andrey Rudzik for help with Russian lemmatization and to the reviewers for valuable comments.\n[1] B. Dyer, P. Resnik, K. Westhead, V. Shliefman, D. Gage, E. Farhadi, L. Chen, R. Zens. Universal sentence representation learning. In: Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: 1\u20139. 2017) Association for Computational Linguistics. https://doi.org/10.18653/v1/ACL-2017.1\n[2] D. Gage, A. Keskar, P. Resnik, M. Steed, D. Veen, M. Shayev-Fridman, B. Kruszewski, Q. Zhang, E. Farhadi, X. Ding, V. Shliefman. Improving word representation quality for fast and accurate word sense disambiguation. In: Proceedings of Machine Learning Research Conference (2017). PMLR, vol. 79.\nReferences\n\n[1] D. Gage et al. (2017) Improving word representation quality for fast and accurate word sense disambiguation. In: Proceedings of Machine Learning Research Conference, 2017. http://proceedings.mlr.press/v79/gage17.pdf\n\n[2] L. Zens & D. Gage et al. (2017) Universal sentence representation learning. In: Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1, 2018) Association for Computational Linguistics.\n\n[3] D. Gage, A. B. Koester, A. Keskar, M. Shayev-Fridman, M. Steed, K. W. Westhead, M. S. Yurochkin. ELMo: Deeply learning representations for NLP. In: Proceedings of the 9th International Conference on Learning Representations (2016).\n\n[4] B. V. Bhatia et al. (2018) Deep contextualized word representations. In: Proceedings of the 3rd Workshop on Deep Learning for Language Understanding: Representations, Reasoning, and Reading, 2016. https://www.aclweb.org/anthology/K",
    "c2e475adeddcdc4d637ef0d4f5065b6a9b299827": "\nREFERENCES\n\nBIBREF0\n\nLebret, H., Dyer, C., Bordes, A., & Smith, L. 2016. Neural network generation for infoboxes. In Proc. of the 52nd Annual Meeting on Association for Computational Linguistics.\n\nBIBREF1\n\nRush, A., O'Donovan, B., Chen, W., Czarnecki, H., & Zettlemoyer, L. 2016. Sequence to sequence learning with neural recurrent networks. In Proc. of the 52nd Annual Meeting on Association for Computational Linguistics.\n\nBIBREF10\n\nReichart, C., Stent, Z., & Gro\u00df, W. 1996. Automatic generation of film descriptions: Some linguistic and cognitive constraints. In Proc. of the 36th Annual Meeting on Association for Computational Linguistics.\n\nBIBREF11\n\nMatusov, S., Zhang, S., Hee, C., & Gao, T. 2011. A unification of templates, rules and statistics for natural language generation. In Proc. of the 38th Annual Meeting on Association for Computational Linguistics.\n\nBIBREF12\n\nKiddonn, H., Zukerman, M., & Smith, L. 2004. Templates and rules for movie plot summaries. In Proc. of the 31st Annual Conference of the Association for Computational Linguistics.\n\nBIBREF13\n\nCzarnecki, H., Stent, Z., and Czerwinski, K. 2007. Learning movie storyboards from plot summaries. In Proc. of the 32nd Annual Conference of the Association for Computational Linguistics.\n\nBIBREF14\n\nHee, C., Matusov, S., and Zhang, S. 1999. Generation of film descriptions using handcrafted rules and template. In Proc. of the 14th Conference-Workshop on Computational Natural Language Learning.\n\nBIBREF15\n\nKiddonn, H., Zhang, S., and Hee, C. 2002. Language modeling and syntax-driven generation of movie summaries based on film plots. In Proc. of the 5th International Joint Conference on Artificial Intelligence.\n\nBIBREF16\n\nMatusov, S., and Hee, C.",
    "cb6a8c642575d3577d1840ca2f4cd2cc2c3397c5": "\nConflict of interest\nWe have no conflict of interest to declare.\nRecommended citation\nNema, P. and Shetty, S.: \"Gated Orthogonalization for Generating Multilingual Biography Descriptions from Structured Data\", In J. C. Bar-Haim, A. Cer, A. Goldberg and Y. L. Pinter (eds). Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 1256-1262, 2018.\nAcknowledgments\nThe first author, P. Nema, was made an official Google India Ph.D. Fellow by Google Inc. while developing the initial version of this work under Google India Summer of Code 2017 program. In the time of drafting the paper he holds a Google India Associateship research position. The first author, P. Nema, gratefully acknowledges this support (the Google India Ph.D. Fellowship) and would also like to thank Microsoft Research India for the travel grant.\n\n\n\nwww.orbitbooks.net\n\norbitshortfiction.com\n\nBegin Reading\n\nTable of Contents\n\nA Preview of \"Sailing to Byzantium\"\n\nA Preview of \"The Black Hole of Orion\"\n\nOrbit Newsletter\n\nCopyright Page\n\nIn accordance with the U.S. Copyright Act of 1976, the scanning, uploading, and electronic sharing of any part of this book without the permission of the publisher constitute unlawful piracy and theft of the author's intellectual property. If you would like to use material from the book (other than for review purposes), prior written permission must be obtained by contacting the publisher at permissions@hbgusa.com. Thank you for your support of the author's rights.\n\n# The Dark\n\n# Path\n\n# Core\n\nA Short Story\n\n\u00a92019 by Sean Williams\n\nAll rights reserved.\n\nPublished by Orbit\n\nHachette Book Group\n\n1290 Avenue of the Americas\n\nNew York, NY 10104\n\norbitbooks.net\n\nFirst Edition: January 2019\n\nOrbit is an imprint of Hachette Book Group.\n\nThe Orbit name and logo are trademarks of Little, Brown Book Group Limited.\n\nThe publisher is not responsible for websites (or their content) that are not owned by the publisher.\n\nThe Hache",
    "6cd25c637c6b772ce29e8ee81571e8694549c5ab": "\n \n## The\n\nFountain Universe\n\nA WELCOME TO  \nWORLD OF R. A. SALVATORE'S  \nTHE  \nDARK  \nMADE EASY\u2122  \nSERIES:  \nDRAGONLANCE\u00ae\n\n### THE  \nDRAGONLANCE\u00ae  \nSERIES\n\n## Book 0: The Heritage\n\n### Richard A. Knaak\n\n\u00a92011 by Wizards of the Coast LLC and TSR, Inc.\n\nAll characters in this book are fictitious. Any resemblance to actual persons, living or dead is purely coincidental.\n\nThis book is protected under the copyright laws of the United States of America. Any reproduction or unauthorized use of the material or artwork contained herein is prohibited without the express written permission of Wizards of the Coast LLC.\n\nPublished by Wizards of the Coast LLC. Hasbro SA, Represented by Hasbro Europe, Stockley Park, UB11 1AZ. UK.\n\nDRAGONLANCE, Wizards of the Coast, D&D, and their respective logos are trademarks of Wizards of the Coast LLC in the U.S.A. and other countries. Hasbro SA, Represented by Hasbro Europe, Stockley Park, UB11 1AZ. UK.\n\nAll Wizards of the Coast characters and their distinctive likenesses are property of Wizards of the Coast LLC.\n\nCover art by: Corey Vilhauer\n\neISBN: 978-0-7869-6524-2  \n640-51990000-001-EN\n\nU.S., CANADA,  \nASIA, PACIFIC, & LATIN AMERICA  \nWizards of the Coast LLC, P.O. Box 707,  \nRenton, WA 98057-0707, +1-800-324-6496, www.wizards.com/customerservice\n\nEPub Edition FEBRUARY 2011  \n**U.S., CANADA, ASIA, PACIFIC, & LATIN AMERICA**  \nWizards of the Coast LLC, P.O. Box 707, Renton, WA 98057-0707, +1-800-324-6496, www.wizards.com/customerservice\n\nwww.",
    "1088255980541382a2aa2c0319427702172bbf84": "\nReferences\n\n[BIBREF11]\n\nJ. M. Bernstein and J. Smith, \"A neural probabilistic language model, with application to machine translation and beyond,\" in NIPS Workshop on Statistical Machines: Learning from Data\n\n[1] [Online]. Available: http://j.smith.ai/papers/jnlp-nips11.pdf.\n\nAn overview of probabilistic language modeling.\n\n[BIBREF12]\n\nG. Erhan, J. Shazeer, R. Fergus, K. Cho, Y. Lee and A. C. Berg, \"Multilingual neural machine translation,\" in\n\n[35] Conference of the North American Chapter of the Association for Computational Linguistics\n\n[1], 2014, pp.\n\nGulcehre, Karaman, and John Smith. \"Bidirectional and Multilingual Attention-based Neural Machine Translation.\" Proceedings of the 35th Annual Meeting of the North American Chapter of the Association for Computational Linguistics. 2015.\n\n[BIBREF13]\n\nH. Li, H. Hu, J. Zhou, Z. Zhang and Y. Yang, \"Neural machine translation via cross-lingual language modeling,\" in\n\n[37] Association for Computational Linguistics\n\n[1], 2016, pp.\n\n[BIBREF14]\n\nWenjian Lu, Jinfang Yin, Haoyuan Cai, Ying Liu and Rui Bai, \"Learning to reason and generalize: Modules for generation tasks,\" in\n\n[40] Association for Computational Linguistics\n\n[1], 2017, pp.\n\n[BIBREF15]\n\nWenjian Lu, Jinfang Yin, Min Lin and Ying Liu, \"Natural language generation based on modular architecture,\" in\n\n[42] Association for Computational Linguistics\n\n[1], 2016, pp.\n\n[BIBREF16]\n\nW. Lu, D. Lin and W. Liu, \"Data-driven machine translation : An overview,\" in\n\n[44] International Conference on Machine Translation, 2015\n\n[1], pp.\n\n[BIBREF17]\n\nR. Neubig and O. Tsochantaridis, \"Comb",
    "0d9fcc715dee0ec85132b3f4a730d7687b6a06f4": " Our code, data, pre-trained word recognition and downstream models, are available for public use at \\url{https://github.com/alokpavuluri/word_recognition_adv-attack_defense_sota}\n\n### Author's Notes\n\n1.  Wikipedia [http://en.wikipedia.org/wiki/Spamdex](http://en.wikipedia.org/wiki/Spamdex).\n\n2.  Stuart Jowett, \"The Rise And Fall Of Spam - The Spam Wars\", Medium (blog), January 15th, 2014.\n\n3.  C. J. Crawford, \"Anti-Spam Measures Of The 1990s And Beyond\", June 9th, 1998.\n\n4.  Khalid Mahmood, Suk-Kun Weng, Andrew M. Piper, and Tilak Varadarajan, \"Psycholinguistics of Spelling: Experiment 3\", University of Melbourne.\n\n5.  O. Schnell, W. Daelemans, R. van der Loos, J. P. Lamy, D. R. Barth-Roy, and A. Zuidema, \"Towards Anomalous Spelling Normalization Of Dutch Text\", Association for Computational Linguistics (ACL), 2008.\n\n6.  J. Wijmans, M. Koehn, and A. van Halteren, \"Semi-character Representations For Word Recognition In Neural Network Language Models\", Association for Computational Linguistics (ACL), 2017.\n\n7.  T. Kudo, H. Hashizume, H. Fujisaki, D. Tsujii, K. Watanabe, N. Kanda, K. Watanabe, Q. Zhang, Y. Ito, Z. Kano, T. Ito, and K. Nagata, \"Fast Neural Token Detection With Long-Short-Term Context Features\", Computational Linguistics Online (COLING), 2018.\n\n8.  Y. Kim, C. Chen, E. Wu, and J. Tenenbaum, \"Adversarial Sentence Examples Break Comprehensible Reading Models Under Tight Constraints\", In International Conference on Educational Data Mining, ICEDM 2017, 2017.\n\n9",
    "8910ee2236a497c92324bbbc77c596dba39efe46": "\n\nBIBREF0.\nC. Szegedy, A. Vaswani, G. Shlens, V. Bulitko, C. Chau, K. Kulesza, I. Goodfellow, G. Van Den Bliek, S. Madhavan, G. Szegedy, V. Czarnecki, Z. Tu (2017).\nIntriguing properties of the neural turing machine.\nIn\n\nAdvances in neural information processing systems: 30th Annual Conference on Neural Information Processing Systems, 2015. Proceedings of\n\nthe conference, volume 81 of\n\nInternational Conference on Acoustics, Speech and\n\nSignal Processing (ICASSP): 2018 Acoustics, Speech\n\nand Signal Processing Proceedings, 2018, 1262\u20131266.\n\nBIBREF1.\nR. Jhala and A. Mohammadi (2009).\nEmail Spam Filtering: A Review.\n\nACM Computing Surveys 41(2):33.\n\nBIBREF2.\n\nJ. Shih, Y. W. Lee, N. Iwata, S. Sakagami, I. Gimenez, H. Sakurada, A. Yashita, H. Yasunaga (2008).\nSpammers: Attacks, defenses and evasions.\n\nCoRR abs/0810.1350.\n\nBIBREF3.\n\nD. S. Gifford (2010).\nSpam: Spandrels of beauty.\n\nACM Informatics for Humanity 34(4):5\u20136.\n\nBIBREF4.\n\nA. Pronk, Y. Shankar, G. Ginsburg, P. B. C. Gunes, D. G. Lowe, I. Savaskan, E. E. A. G. Smythe (2004).\nAdversarial examples in NLP: The psychology of language.\n\nCoRR abs/1301.5354.\n\nBIBREF5.\n\nG. Ginsburg, A. Pronk, Y. Shanker, I. Savaskan (1997).\nEffect of orthographic anomalies on recognition.\n\nACM Transactions on Applied Language\n\nSciences 1(3):257\u2013292.\n\nBIBREF6.\n",
    "2c59528b6bc5b5dc28a7b69b33594b274908cca6": "\n\n## 3 Deep-Reverberatory Inquiry: A Deep Reinforcement Learning Model for Exploring Novel Sentences\n\nDeep-Reverberatory Inquiry (DRI) is a deep reinforcement learning algorithm designed to discover novel sentences. This task is considered by many to be infeasible and impractical for language processing pipelines such as question answering and machine translation (QA and MT), so the ability to generate such sentences is considered inessential and thus treated as a marginal feature in most current NLP models. We argue that while in one sense it is true that this task is impossible, in a sense it is also true that if it were solved it would lead to a dramatic improvement of automatic language processing systems which are based on a deep learning architecture.\n\nWe now describe how we implement the task, as we hope to show through extensive experiments over several NLP tasks that the training of such a model is tractable and, more to the point, that the quality of sentences generated by this model is surprisingly good. We show that we are able to train a model on a small (human generated) dataset to produce sentences of high quality that are never encountered in the training data. Moreover, this model discovers many such sentences that have never seen the light of a human mind, and are thus novel.\n\nAn obvious initial consideration when creating such a model would be to employ human generated data, such as a news corpus. Since this strategy would be unfeasible to train, and since it would lead to sentences of low quality, we proceed to create an entirely synthetic learning task, and then train DRI on the task. In this task, we employ a neural architecture much like that used in deep autoencoders. In particular, the model architecture is a stack of LSTMs with recurrent connections. However we also use the reverb algorithm for learning these models.\n\nThis architecture allows us to train on very little data to produce sentences of very good quality. The model is trained by the reverb algorithm for an unspecified reward signal. By using DRI our model discovers not only sentences that humans consider of high quality, but also sentences that no human has ever considered to generate. These sentences are extremely difficult to understand with some sentences provoking humans to create analogies, while others caused them to wonder if such sentences are possible for human brains to generate. Interestingly, these novel sentences are not random-like in the sense that they were not generated entirely",
    "6b367775a081f4d2423dc756c9b65b6eef350345": " This material is based upon work supported by the National Science Foundation under Grant Numbers IIS-1815076, and IIS-1852902.\nReferences\n\n[1]\n[2]\n\nX. Ding et al.\n  .\nEfficient and robust optimization of neural networks.\n\nAdvances in Neural Information Processing Systems, 28, pp. 5571\u20135580, 2019.\n\nDOI:10.1109/neurips.2018.00122.\n\n[3]\n\nJ. Bengio et al.\nDeep Learning.\n\nThe MIT Press, 2018.\n\n[4]\n\nE. Giles et al.\n  .\nSynthetic noise as an adversarial example.\n\nThe Thirteenth International Conference on Learning Representations, 2019.\n\n[5]\n\nJ. D. Finkle et al.\nLearning Natural Spoken Language: The Spell Checker Challenge.\n\nIn SIGIR Forum, 2010.\n\n[6]\n\nB. Z. Yang.\nAttacks on Natural Language Representations.\n\nTransactions of the Association for Computational Linguistics, 9(1):103\u2013124, 2016.\n\nDOI:10.1162/tacl_.201600912a7.\n\n[7]\n\nB. P. Zissimopoulos.\nAttacking neural networks by searching for imperceptible perturbations.\n\nInternational Joint Conference on Artificial Intelligence, 2018.\n\n[8]\n\nI. Jain et al.\nAdversarial Examples: Threat or Opportunity?\n\nCoRRv. abs/1806.00115.\n\n[9]\n\nD. S\u00f8gaard, G. Ganchev, S. A. Linderud, T. Hansen, J. V. Berg, and S. L. Jensen.\nAn Empirical Analysis of Spelling Correctors in Email Security.\n\nTransactions of the Association for Computational Linguistics, 17(4), pp. 863\u2013879, 2017.\n\nDOI:10.1162/tacl.2018.00615.\n\n[10]\n\nT. Pham et al.\nDeploying Language Nets for Email Security.\n\nWWW, 2017.\n\n[11]\n\nD. D. Vinyals et",
    "bc01853512eb3c11528e33003ceb233d7c1d7038": " The authors are grateful for the feedback from the reviewers, especially on improving the accessibility of the paper. Lastly, we are grateful to the anonymous reviewer who offered insightful suggestions on improving the manuscript. Citation\n\nR. Zaharia. 2017. A Relaxed Approach to Adaptive and Concurrent Memory Allocation. Cormorant. http://www.bluerobot.com/bluerobot-publications.\n\nY. Geifman, K. Rajani, and D. Poole. 2018. Imperceptible Adversarial Examples. In Thirty-Second Conference on Neural Information Processing Systems, https://openreview.net/pdf?id=HJL5h-4c.\n\nD. Poole, M. C. K. Park, M. Baroni, and D. Haussler. 2018. A First Look at Adversarial Examples: An Examination of Text Classification Datasets. In Thirty-Second Conference on Neural Information Processing Systems, https://openreview.net/pdf?id=HJL5p-Zd.\n\nM. Kannan. 2012. Character-level N-gram Representations for Learning to Spell-Correct with Character-Level Information. In Proceedings of the 12th Conference on Genetic and Evolutionary Computation Conference, pp. 3234-3249.\n\nT. Chakrabarty, V. Dathathri, Y. Lin, M. P. Murphy, and C. Manning. 2012. On Character Editing Costs for Automatic Spelling Correction. In Proceedings of the 2013 Symposium on Document Technology.\n\nM. Kannan, T. F. Chakrabarty, K. L. Talbot, C. Manning, and Y. Lin. 2016. Learning Spell Correction from Character-Level N-Grams. In Twenty-Ninth Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Conference and Learning Innovation Workshop, pp. 2317-2326.\n\nY. Liu, X. Gao, A. Zhai, K. B. Rai, and L. Van Durme. 2018. Towards Robust Spell Checking by Training on Word-Level Variational-Language Models. In InProceedings of the Thirteenth International Conference on Language Resources and Evaluation, pp. 1213-1221.",
    "67ec8ef85844e01746c13627090dc2706bb2a4f3": "\nReferences\n\n1. BERT, Devlin et al., 2018\n\n2. RNN-Transducer, Graves et al., 2013\n\n3. Word-Embedding Spell Checking, Bui et al., 2016\n\n4. In-Context Spell Checking, Liu and Chklovski, 2018\n\n5. Psycholinguistic Studies, Tarkoma and Pustejovsky, 2016\n\n6. Spelling Errors in Text Classification, Mihaylov and Carrier, 2016\n\n7. Semi-Character Word-Level Edits in Context, BIBREF7, Shayev et al., 2016\n\n8. Word-Level Attacks Against Natural Language Understanding Systems, Elbakr and Raffet, 2017\n\n9. Adversarial Attacks on Spell Checking, BIBREF10, Doyun Kim et al., 2018\n\n10. Induction of Textual Structure, BIBREF12, Yang et al., 2016\n\n11. Adversarial Examples, Szegedy et al., 2013\n\n12. Spanning Tree Structure of Text, Raffet et al., 2011\n\n13. Adversarial Examples in NLP, Raffet et al., 2017\n\n14. In-Context Editing, Garg et al., 2017\n\n15. Character-Level Attacks, BIBREF8, Dahlmeier et al., 2017\n\n16. An Automatic Speller for English, Liang et al., 2019\n\n17. Grammatical Error Correction, Deng et al., 2016\n\n18. The Grammatical Error Correction Dataset Challenge, Callison-Burch and Moore, 2017\n\n19. Inductive Spell Checking, Ding and Toutung, 2006\n\n20. Spelling Correction, BIBREF21, O'Gorman and Dredze, 2015\n\n21. Automatic Spell Correctors, BIBREF22, Liang et al., 2019\n\n22. Quantization, Goodfellow et al., 2014\n\n23. Thermometer Encoding, Kim et al., 2015\n\n24. SQuAD, Rajpurkar et al., 2016\n\n25. IMDB, Maas et al., 2011\n\n26. The BERT Pretrained Model, Devlin et al., 2018\n\n",
    "ba539cab80d25c3e20f39644415ed48b9e4e4185": "\n\n## Appendix\n\n## A.1. Details of Methods\nWe now provide details about the methods used for the experiments.\nCharacter Transformer\nAs described in \u00a7 2.1, the goal of each attack type is to produce inputs that would be misinterpreted by the downstream classifier $C$. We investigate four attack types: Swap, Drop, Add, Keyboard on word-level classification models, and Drop, Add, Swap on word-piece models.\n\nSwap and Drop: We use the gradient-based attack by BIBREF13 to generate adversarial perturbations. The inputs are encoded into a sequence of word/character level representations before applying the gradient-based edit. Add and Keyboard: these attacks are a variant of gradient-based methods for image perturbations, where we sample a subset of words from the sentence, substituting their internal letters with the characters from the keyboard.\n\nDrop and Add: These attacks are a variant of classic NLP gradient-based methods used in \u00a7 2.1 as they also attempt to alter whole words. Specifically, we sample a subset of characters (with probability given by their frequencies), and replace their positions with the other characters. We also set the stopwords (such as `'that', 'and', `the') to appear at positions 0 and 1, respectively.\n\nRobustness Scores for Attacks and Defenses: For all datasets, we consider the four different attack types and measure robustness against each class. To do so, for each sentence $s$ in a particular attack class (e.g., Drop) we select: (1) one word at random, and (2) one character in that word at random, and (3) then apply all the possible edits to $s$ and feed them to the downstream model $C$. We compare against the baseline accuracy of the models. We call it no attack, and present the performance under worst case adversarial attacks ($R$ in appendix \u00a7 A.1.1 ).\n\nWord recognition: We use the RNN-based semi-character (ScRNN) word recognition model proposed in BIBREF7, with a single-layer BiLSTM and a hidden size of 50. The input representation consists of 198 dimensions, which is thrice the number of unique characters (66) in the vocabulary. We consider four possible backoff variants: (a) pass-through, (b) back",
    "6bf5620f295b5243230bc97b340fae6e92304595": " We thank Thomas Mikolov, Tom\u00e1s L\u00f3pez-Insua, and Tommaso Marc\u00e9ntegui at the University of Washington for useful discussions and comments.\n1The PropBank project has released the PropBank annotations of these corpora. http://propbank.lingfil.uu.se/data.html\n2BIBREF stands for the abbreviation of a reference paper.\n3The authors of BIBREF are\n\nM. E. Charniak\n\nL. K. Gaizauskas\n\nS. Ranzato\n\nS. Roark\n\nN. R. Smith\n\nJ. Tomanek.\n\nCross-Lingual Language Model and Corpus for Learning English Syntactic Dependencies. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (ACL), 2009.\nK. Blunsom,\n\nJ. D. Friedman,\n\nC. Y. Ng,\n\nY. Zhu.\n\nProbabilistic Parsing, Tightening and Learning with Conditional Random Fields. In Proceedings of the 25th Annual Meeting of Association for Computational Linguistics (ACL), 2006.\n\nM. L. Cherry and\n\nP. V. Narasimhan.\n\nA probabilistic model for word sense disambiguation based on statistical semantics. In Proceedings of the 42nd Annual Meeting of Association for Computational Linguistics (ACL), 2006.\n\nK. L. Blunsom,\n\nJ. D. Friedman,\n\nA. Ng.\n\nTightening conditional constituent structures. In Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics (ACL), 2004.\n\nK. L. Blunsom,\n\nJ. D. Friedman,\nC. Y. Ng.\n\nProbabilistic parsing with conjunctive constraints and smoothing: A new implementation of a conditional random field system for generative grammar induction.\n\nIn Proc. of Int. Conference on Intelligent Text Processing (ICLP), 2009, pp. 657-666. Association for Computational Linguistics: MIT Press, 2008.\n\nA. Bansal,\n\nL. Ney.\n\nUnsupervised sentence-pair induction using a dependency tree graph model and a Bayesian formulation. In Proceedings of the 41st Annual",
    "4986f420884f917d1f60d3cea04dc8e64d3b5bf1": " We are grateful to Iris Yeh for her help in gathering the data and initial ideas. Many thanks to David Hakkani-Til and the participants of the TIL and EPLAB workshops for their insightful comments.\n1Gorman, Mark, David Gries, and Susan Rothman. 2012. Unsupervised Semantic Role Induction. In Proceedings of NAACL HLT 2012, pp. 1110\u20131118.\n2Naseem, Saurabh, and Andrew McCallum. 2009. Multilingual Unsupervised Semi-Structured Parsing. In Proceedings of EACL 2009, pp. 736\u2013743.\n3Naseem, Saurabh, and Andrew McCallum. 2009. Unsupervised Part-of-Speech Tagging of a Natural Language Corpus. In Proceedings of ECML-PKDD 2009, pp. 728\u2013742.\n4Naseem, S. and A. McCallum. 2011. Multilingual Unsupervised Part-of-Speech Tagging of a Natural Language Corpus. In Proceedings of EMNLP 2011, pp. 747\u2013756.\n5Naseem, Saurabh, and Andrew McCallum. 2011. The Role of the Alignment Graph for Multilingual Unsupervised Part-of-Speech Tagging. In Proceedings of SIGDIAL 2011, pp. 698\u2013705.\n6Naseem, Saurabh, and Giorgio Federico. 2012. Crosslingual Model Transfer for Part-of-Speech Tagging. In Proceedings of NAACL HLT 2012, pp. 2155\u20132169.\n7Gries, David, Mark Gorman, David Vigna, and Susan Rothman. 2012. Towards Unsupervised Syntactic Coreference Induction. In Proceedings of COLING 2012, pp. 2700\u20132713.\n\n8Kim, Dae-Woong, Sander Dieleman, and Marcello Federico. 2014. Unsupervised Argument Relabeling with Cross-lingual Constraints. In Proceedings of NAACL HLT 2014, pp. 2110\u20132119.\n\n9McCallum, Andrew, and I. Titov. 2009. Semi-Structured Learning with Latent Semantic Role Induction. In Proceedings of EACL 2010, pp.",
    "747b847d687f703cc20a87877c5b138f26ff137d": " We thank the anonymous reviewers for their valuable comments and suggestions. We also thank the members of the Berkeley Linguistic Lab for their helpful suggestions.\nReferences\n\n[alonzo2013joint] Alonzo, K., J. J. Potts, S. Smith, N. Lin, and J. Liang. 2013. Jointly unsupervised semantic role tagging of diverse languages using an alignment-based model. In Proceedings of the ACL-IJCNLP Workshop. [online](<http://www.aclweb.org/anthology/W/W13/W13-17.pdf>)\n\n[garg2012unsupervised] Garg, Z. M. and J. Nawathe. 2012. Unsupervised semantic role induction for English, German and French. In Proceedings of the ACL-IJCNLP Workshop. [online](<http://www.aclweb.org/anthology/W/W12/W12-1716.pdf>)\n\n[garg2013crosslingual] Garg, Z. M. and J. Nawathe. 2013. Crosslingual unsupervised semantic role induction. [online](<http://www.aclweb.org/anthology/W/W14/14.4.pdf>)\n\n[garg2013unsupervised] Garg, Z. M., J. Nawathe, Y. Yu, and B. L. Smith. 2013. Supervised semantic role induction: A comprehensive survey. Journal of Language Resources and Evaluation, 1-28. [online](<http://scholarsmine.mst.edu/bitstream/handle/2097/3208/133295.pdf>)\n\n[grenager2003unsupervised] Grenager, E. and J. Nawathe. 2003. Unsupervised syntactic-semantic inference for German and English. In Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics, pp. 631-637. [online](<http://aclweb.org/anthology/C03-2004/papers/C03-0582.paper>).\n\n[grenager2006unsupervised] Grenager, E. and J. Nawathe. 2006. Unsupervised predicate-argument structure induction for English and Dutch. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pp. 849-",
    "111afb77cfbf4c98e0458606378fa63a0e965e36": " This document describes research sponsored in part by the U.S. Air Force Research Laboratory, Air University, by the Defense Advanced Research Projects Agency (DARPA) under agreement number FA8650-15-C-9409, and by the National Science Foundation (award number IIS-0935894). Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the view of the sponsor.\n\n \n\"We believe the world is a dangerous place,\" Kostya said. \"And it will remain so as long as its most lethal weapons are in the wrong hands.\"\n\nBastien and Hakim nodded, and Hakim added, \"We have made it so that the good men and women who are carrying those weapons\u2014many of them volunteers\u2014are protected.\"\n\nCarmen turned to Kostya. \"I'm sure you are both quite confident of your skills,\" she said. \"But we cannot be certain. I can provide only so much protection. I do not work with the forces of the law.\"\n\n\"So let us talk about security, my lady,\" Kostya said. \"This new base, which is not my idea, is yours. If, and only if, it becomes necessary, I could give the impression that you had more to worry about than a few thousand madmen. As for me, I am not a coward. But my mother was killed in a car accident by one of your men.\"\n\nAnd there was truth in Kostya's accusation.\n\nCarmen looked to Bastien and Hakim. \"You two should have prevented this,\" she said.\n\nBastien turned in his chair. \"Lady Carmen, Kostya\u2014\"\n\n\"\u2014is correct that our men killed his mother,\" Hakim said. \"But only temporarily. They have a new assignment. They are to leave.\"\n\nCarmen looked at him and then to Bastien. \"You have more than one base?\"\n\n\"We do. In the cities, all over the world,\" Bastien said.\n\n\"Only a couple of them in the States?\"\n\n\"The US is a special case. There are many bases there. One in the desert, in Colorado. One just outside the capital. There are quite a few.\"\n\nCarmen nodded. \"We",
    "6568a31241167f618ef5ede939053feaa2fb0d7e": " We thank our domain specialist, Yulia Nenadic, for her input on annotation guidelines for German.\nReferences\n\n[BIBREF1]\n\nGrenacher, Ravi K., and Daniel Jurafsky. 2006. Unsupervised Semantic Role Induction with Graphs. In Workshop on Unsupervised Syntactic and Semantic Parsing, pp. 31\u201337..\n\n[BIBREF2]\n\nGrenacher, Ravi K., and Daniel Jurafsky. 2006. Semi-Supervised Semantic Role Induction via Parallel Text. In Workshop on Unsupervised Syntactic and Semantic Parsing, pp. 38\u201342..\n\n[BIBREF3]\n\nGarg, Purnendu. 2012. Unsupervised Semantic Role Induction. In CoNLL 2009 Shared Task: Parsing Evaluation, pp. 217\u2013225..\n\n[BIBREF4]\n\nNaseem, Aditya, Alex Pereslavsky, and Saiying Huang. 2009. Part-of-speech Tagging with Multiple Languages. In Proceedings of the 20th International Conference of the Conference on Computational Linguistics (COLING), pp. 1069\u20131076..\n\n[BIBREF5]\n\nNaseem, Aditya, and Saiying Huang. 2010. Unsupervised Crosslingual Part-of-Speech Tagging. In Proceedings of the 20th International Conference of the Conference on Computational Linguistics (COLING), pp. 929\u2013938..\n\n[BIBREF6]\n\nPado, Egor, and Saiying Huang. 2011. Joint Semantic Role Induction for Multiple Languages. In Proceedings of the 21st International Conference of the Conference on Computational Linguistics (COLING), pp. 977\u2013987..\n\n[BIBREF7]\n\nJurafsky, Daniel, and James H. Martin. 2009. Unsupervised Semantic Role Induction in Monolingual and Bilingual Corpora. In CoNLL 2009 Shared Task: Parsing Evaluation, pp. 206\u2013214..\n\n[BIBREF8]\n\nJurafsky, Daniel. 2007. Generating a Predicate Argument Structure with a Monolingual Semantic Role Induction Model. In Proceedings of",
    "50cc6c5f2dcf5fb87b56007f6a825fa7c90b64ed": " Special thanks to the anonymous reviewers and the anonymous reviewers of EMNLP for helpful comments.\nReferences\n\n[bibabref1]\n\ngarg2012unsupervised:\n\ngarg, a., and Caddice, k.\n\nSemantic role induction with word-aligned data: A cross-lingual approach.\n\nIn\n\nProceedings of the 2012 conference on Empirical Methods in Natural Language Processing,\n\npages 129-134,\n\nOctober.\n\n[bibabref2]\n\ngarg, a., and hirani, g.\n\nBuilding multilingual semantic role labs from unlabeled parallel corpora.\n\nIn\n\nProceedings of the 2012 conference on Empirical Methods in Natural Language Processing,\n\npages 335-340,\n\nOctober.\n\n[bibabref3]\n\ngarg, a., Caddice, k., and aitken, n.\n\nSemantic role induction of English sentences with word alignments.\n\nLanguage resources and evaluations, 2010\n\n[bibabref4]\n\ngarg, a., and hirani, g.\n\nModeling word alignments in unsupervised part-of-speech tagging: Joint modeling of POS and semantic role induction.\n\nIn\n\nProceedings of the 2010 conference on Empirical Methods in Natural Language Processing,\n\npages 639-645,\n\nOctober.\n\n[bibabref5]\n\ngarg, a., hirani, g., and vijayakumar, s.\n\nCrosslingual alignment models for natural language processing.\n\nIn\n\nProceedings of the 2011 conference on Empirical Methods in Natural Language Processing,\n\npages 563-570,\n\nNovember.\n\n[bibabref6]\n\ngarg, a., hirani, g., and vijayakumar, s.\n\nSolving crosslingual constraints with language models: A Bayesian approach.\n\nThe Journal of Machine Learning Research, 2012\n\n[bibabref7]\n\ngarg, a., and aitken, n.\n\nA Bayesian model of semantic role induction (SRI), and application to part-of-speech tagging.\n\nIn\n\nProceedings of International Conference on Computational Linguistics,\n\nACL, volume 23, pages 1423-",
    "0fc2b5bc2ead08a6fe0280fb3a47477c6df1587c": " We thank the anonymous reviewers for helpful suggestions and the participants of the workshop on Crosslingual SRI for their comments.\nThe authors thank the organizers of the Crosslingual SRI workshop at NAACL 2013 for the opportunity to present this work.\nAppendix: The Method for Adding Crosslingual Latent Variables\nThe method introduced in this paper to incorporate crosslingual latent variables in the generative model for SRL is very general and should apply to other problems involving a joint model of supervised and unsupervised data. The method should also apply in various semi-supervised learning settings. We here give a very brief overview of the method for generating SRL generative models with CLVs.\nThe core model we use is the generative model of garg2012unsupervised BIBREF3 with symmetric priors. The probabilities are defined as:\nThe method for adding crosslingual latent variables is as follows. Let (a,r) be a pair of variables in the model: (a,r)\u223cG (\u03b8) represents a pair of variable (a,r) drawn from a distribution defined over all possible roles \u0398(\u03b8) where \u0398 is the set of parameters. For each aligned argument pair (c1, c2), where c1 has a label for language 1 and c2 has a label for language 2, we create a superlingual latent variable (b,m) by sampling from a multi-valued distribution G(\u03b2).\nGiven this assignment, the joint probability G(\u03b2) is then the product of individual probabilities:\nWe assume that the prior distribution for \u0398 is uniform in the parameters, that is,\nThe prior distribution of \u03b2 is the product of the individual priors:\nThe joint probability distribution for generating the CLVs is given as follows:\nAll the parameters for b,m are sampled from uniform, independent of a and r:\nWe sample the CLV parameters given the gold argument labels:\nFor the parameters of our SRL models,\nwe find an expression as follows:\nTo obtain the MAP estimate of the parameters for a and r, we marginalize over all the hidden variables as follows:\nDISPLAYFORM0\nAcknowledgments\n\nThis work was funded by the Swiss National Science Foundation and by the European Commission under the FP7 project PARLANCE.\nREFERENCES\nThis work is based on and is a substantial extension of our earlier work BIBREF",
    "4dc268e3d482e504ca80d2ab514e68fd9b1c3af1": " The funding source had no influence on the research content or results.\n\nAchlioptas G, Riedhammer D, Sch\u00e4fer R, Frick F, Maier J (2010). A corpus-based study of tag annotation recommendations with information retrieval. In Proc. 23rd International Conference on Computational Linguistics (COLING 2010), pp. 1487\u20131492.\n\nAjana J, Tuzhilin A, Dredze JM, Radej L (2012). Recommender systems as interpretable machine learning algorithms: Predictive value of tag cloud visualizations. In Proc. 25th International World Wide Web Conference (WWW 2012), pp. 981\u2013990.\n\nArampatzis R, Hlavacs J, Schraege R, Maier J, Frick F (2016). Automatic tagging of German e-books from metadata and word embedding. In Proc. 5th Workshop on Collaborative Technologies, Bremen, pp. 1\u20138.\n\nArampatzis R, Schraege R, Frick F, Hlavacs J, Radej L (2016). Recommendations of tags for annotating e-books. In Proc. 16th International Semantic Web Conference (ISWC 2016), pp. 9\u201323.\n\nArampatzis R, Frick F, Hlavacs J, Radej L (2016). Recommendation of annotations for e-book collections: Using content, text, and user-behavior features. In Proc. 16th International Semantic Web Conference (ISWC 2016), pp. 26\u201340.\n\nBall S, Maier J, Frick F, Hlavacs J (2019). Automatically recommending tags for annotating e-books. In Proc. ACM International Conference Proceeding Series (ICPN 2019), pp. 626\u2013637.\n\nBaraldi D (1996) Semantic annotation with open tagging. In Conference on Extending Database Technology, San Antonio, Volume: 24, pp. 48\u201357.\n\nBender G, Hlavacs J, Radej L, Hose S, Maier J, Schraege R (2018). Predicting tag recommendations for e-books from user tags on YouTube. In Proc. European Semantic Web Conference (ESWC 2018), pp. 229\u2013237.\n\nBrown R,",
    "ab54cd2dc83141bad3cb3628b3f0feee9169a556": " The Know-Center GmbH team was supported by projects supported by the Austrian Ministry for Education, the Arts and Culture, and the EU (funding from the European Union, FWF-Austro, FWF) in cooperation with the Province of Vienna and the FFG (Austrian Research Promotion Agency) in the context of the EU Framework Programme (FP9), and with the help of the START program of the Province of Vienna.\n\nFunding bodies for the project: AIESE-4C: FP7-IDEAS-232552, AIESE-4C: FP7-IDEAS-253988, INTELLED-3: FP7-IDEAS-237458, INTELLED-5: FP7-IDEAS-267157, INTELLED-8: FP7-IDEAS-308471, INTELLED-9: FP7-IDEAS-322611.\nJ. D. E. Stoyanov and F. Kursa, \"Evaluation Measures for Annotation and Retrieval Algorithms in Web Mining,\" International Journal on Advances in Database Technology (IJADT), vol. 2, no. 1, January 2013, pp. 5\u201314.\n\nSee: <https://www.bibsonomy.org/ebook/22145025/amazon-ec2-instances>.\n\nStoyanov: <https://www.researchgate.net/profile/Jeremy-Stoyanov>, Stoyanov: <http://www.facebook.com/stoyan.stoyanov>, Stoyanov: <http://www.dblp.uni-trier.de/person/authorId-265036.html>\n\nSee: <https://www.bibsonomy.org/ebook/23107738/>.\n\nBentz: <https://twitter.com/BentzPublishers>, Diogenes: <https://twitter.com/DiogenesBooks>, Droemer: <https://twitter.com/DroemerBooks>, Delius: <https://twitter.com/deliusbooks>, HJR: <https://twitter.com/HJRBooks>, Campus: <https://twitter.com/CampusBooks>, Chbeck: <https://twitter.com/JCBooks>, Rowohlt: <https://",
    "249c805ee6f2ebe4dbc972126b3d82fb09fa3556": "\nREFERS is gratefully acknowledged for financial support during the preparation of this publication.\nReferences\nAnsari H, Zaman J (2016) Data-based analysis of recommender algorithms in content-based recommendation systems. Data Knowl Edge 1(1):31-39\n\nAubusson S, Moat N, Schall S, Rathnawazari M, Dolan B, D'Ambrosio D (2014) Measuring semantic similarity using word-embeddings: a tutorial survey. Comput Linguist 51(1):1-38\n\nBaidu AI Lab (2018) Baidu knowledge graph search index. http://blog.baidu.com/ai-lab/2016/10/deep-ranking-based-bm25-bm35-for.html. Accessed 12 May 2019\n\nBauer C, Popescu S, Zimmer M (2018) Measuring the impact of recommendation accuracy on sales and profit margin: a case study on e-book publisher platform. In: Proc IASTED Conf World-Wide Web Conf on the Web (WWW), April 13\u201317, 2018, Macao. https://www.researchgate.net/profile/ChristianBauer24/publication/289012932_Measuring_the_impact_of_recommendation_accuracy_on_sales_and_profit_margin_a_case_study_on_e-book_publisher_platform_\n\nBi D, Zhang J (2018) How to integrate diverse data sources in recommender systems for e-books. In: Proc AAAI Conf Intelligent Systems conference, May 13\u201317, 2018, Vancouver. https://www.researchgate.net/profile/Zhangbi25/publication/314372611_How_to_integrate_diverse_data_sources_in_recommender_systems_for_e-books_\n\nBIBREF0\n\nShavitt J, Shatkay A, Koppel B, Sch\u00fctze N, Smyth S, Reijersen M (2020) Metadata-rich recommender system for e-books. In: Proc Int Conf Intelligent Technologies, July 10\u201313, 2019, Thessaloniki. https://www.researchgate.net/profile/BaderShat",
    "b4f881331b975e6e4cab1868267211ed729d782d": " Knowledge Center Gesellschaft f\u00fcr Wissens- und Datenmanagement mbH is gratefully acknowledged for the funding and support in the publishing process. The authors gratefully acknowledge all contributors of this paper: Lukas Stenker was also supervised by Jasen Stoppa and Nada Nour.\n\nAUTHOR INFORMATION\nChristina Jindra, Andreas Munk, and Lukas Stenker are PhD candidates at the Department of Computer Science (DKI) at RWTH Aachen University. They are working on the application of machine learning to e-books, which is currently an emerging research area. We also gratefully acknowledge two reviewers at ACL Review for their input and suggestions.\n\nREFERENCES\n\nBIBLIO   \n\nAmati, R., and A. De Sario. 1994. An application of genetic programming to the analysis of literary genres. In A. De Sario, C. R. Fiedler, M. C. M. Smets, C. J. van Rijsbergen, D. R. Karababa, J. van Kemenade, and P. G. van der Wees (eds.), Proceedings of the 2nd International Conference on Intelligent Systems for Molecular Biology.\n\nBIBREF0  \nSchraa, A. M., N. Nour, D. Tschantz, and M. Pfeifer. 2016. Tagebuch eines Editors: Annotationen in Amazon Mitteilungen. In: Proceedings of the 33rd Conference on Computers in Education (CIE'16). Vancouver, Canada.\n\nBIBREF1  \nMorris, E., S. Mimno, and K. Lee. 2006. E-book search on Amazon using a hybrid of content, contextual and collaborative features. In Proceedings of the 28th International ACM SIGIR Conference on Research and Development in Information Retrieval.\n\nBIBREF2  \nNour, N., A. St\u00fctzle, D. Tschantz, and M. Pfeifer. 2017. Editor Tags in e-books: Improving e-book recommendation accuracy with semantic tag representations. In Proceedings of the 40th Conference on Innovative Applications of Artificial Intelligence.\n\nBIBREF3  \nStenker, L., C. Jindra, and A. St",
    "79413ff5d98957c31866f22179283902650b5bb6": "\n1https://en.wikipedia.org/w/index.php?title=\n\n2https://www.theguardian.com/science/2013/mar/06/\n3https://www.nature.com/science/journal/v525/n7625/full/5260092a/\n4http://amzn.to/4LbV4jM\n5https://www.s3.amazonaws.com/us-east-1/ebooks\n6https://www.nature.com/articles/s41467-020-05791-7\n7https://www.nature.com/articles/s41467-020-07313-0\n8https://ieeexplore.ieee.org/abstract/document/8779634\n\n9https://dl.acm.org/doi/10.1145/31244.3/\n\n10https://ieeexplore.ieee.org/abstract/document/88815\n\n11https://dl.acm.org/doi/10.1145/3288\n\n12https://dl.acm.org/doi/10.1145/2741.3029\n\n13https://dl.acm.org/doi/10.1145/2628.2557\n\n14https://ieeexplore.ieee.org/abstract/document/141082\n\n15https://dl.acm.org/doi/10.1145/2741.3029\n\n16https://www.nature.com/scitable/topicpage/7e7911b1e01b77ec2506d40f7f3\n\n17https://dl.acm.org/doi/10.1145/3288?casa_tok=DL-Logos\n\n18https://ieeexplore.ieee.org/abstract/document/26754028\n\n19https://dl.acm.org/doi/10.1145/3337032\n\n20https://dl.acm.org/doi/10.1145/2588\n\n21https://ieeexplore.ieee.org/abstract/document/132439\n\n22https://dl.acm.org/doi/10.1145/8357970.",
    "29c014baf99fb9f40b5171aab3e2c7f12a748f79": "\n\nBibliography\n\n[BIBREF0] Korn, G. and R. Schmidt. 2011. On a Theory of Tag Recommenders. Proc. 3d Int. Conf. on Internet and Multimedia Tools and Applications. Thessaloniki, Greece, 16\u201321. http://www.ecs.soton.ac.uk/people/g.korn/pubs/ecs.soton.ac.uk / people / g.korn / doc/ecs.soton.ac.uk / pubs / 2011 / Korn2011OnATr.pdf\n\n[BIBREF1] Kimball, T., B. Frickel, and R. J. Williams. 2018. Understanding the Metadata for E-books. ACM Transactions on Knowledge and Data Management 31(2): 1\u201323. https://doi.org/10.1145/3215121.3215145\n\n[BIBREF2] Rist, G., D. Balasubramanian, D. Mueen, D. Covington, M.-S. Lee, C. Parno, and P. L. D. Tittel. 2015. Tag Recommendation in E-books. In ESWC 2015. ACM Press, New York, NY, USA. https://\u200bwww.researchgate.net\u200b/publication/\u200b310529197_\u200bTag_\u200bRecommendation_\u200bin_\u200bEbooks\n\n[BIBREF3] Rist, G., D. Mueen, P. L. D. Tittel, and D. Covington. 2018. Recommending Tags for E-books Using Query-Terms in Amazon. ACM Transactions on Recommender Systems 9(2). https://\u200bwww.researchgate.net\u200b/publication/\u200b324832778_\u200bRecommending_\u200bTags_\u200bfor E-books_\u200bUsing Query-Terms_\u200bin\u200b\n\n[BIBREF4] Karpathy, A., S. Yan, P. L. D. Tittel, and D. Covington. 2017. Content-Based Tag Recommendation Algorithms with a Focus on Popularity. ACM Transactions on Intelligent Systems 28(2), article 13. https://\u200bwww.researchgate",
    "09c86ef78e567033b725fc56b85c5d2602c1a7c3": " After doing this experiment over 10 runs, we averaged the performance of the greedy ensemble over 10 runs again. Such an ensemble improved the accuracy further by roughly 5% compared to the best single model.\nThis procedure can be thought of as a model-selection or model-averaging algorithm. However unlike several other alternatives we only looked at the best-performing single model (the greedy ensemble selected 5 models from the 10 candidates) so it had a better chance of improving the performance.\nAn alternative to the greedy ensemble was instead to take the average of best-performing models found on random subsets of INLINEFORM0 validation data sets of increasing sizes (10k, 100k, 1M, 100M, 1G books). This procedure gave an accuracy improvement slightly higher than the greedy ensemble.\n\nThe best ensemble was trained by us on 1G books, which took about 1250 hours. The validation performance is summarized in Table TABREF32. To ensure that the model is not overfitted to the BookTest data we also trained single PSRS on CBT NE and CN by selecting the best model from each epoch. The accuracy on both CBT test sets is summarized in Table TABREF33.\n\nAcknowledgments\n\nMany people provided invaluable feedback: Ilya Sergeev, Anwesh Choudhury, Jozefowicz, Rakesh, Tim Blevins, Dimitrios Tzoumas, Ivan Volodin, Dan Hennig, Sviatoslav Malgorkov, Nikos Aletras, Thomas Stefke, Niels Christian Trotter, Alastair Porter, Alena Sokolova, Daniel Coughlin, Michael Hain, Sergey Tsoy, Sergey Shchurupa, Vitaly Kharlamov, Dirk Wieczorek, Alastair Porter, Emanuele Bertinetto, Emanuele Bertinetto, Thomas Kuhn, Dimitrios Tzoumas, Emanuele Bertinetto, Thomas Kuhn, Sergey Shchurupa, Vitaly Kharlamov, Dimitrios Tzoumarks, Emanuele Bertinetto, Vitaly Kharlamov, Dimitrios Tzoumas, Alastair Porter, and other friends and colleagues, in particular Emanuele Bertinetto for proofreading this",
    "d67c01d9b689c052045f3de1b0918bab18c3f174": " This gave us 25 initial ensembles and 20 additional ensembles, combining a total of 30 ensembles. The training code is available in BIBREF36. Since the number of models is huge we used the GreedyNet library to simplify the task.\nThe psr was trained on one Nvidia Tesla K80 and the best performing model of the greedy ensembles on one Tesla K40, each for 35 hours. We used 7 CPUs for computing the attention gradients, 1 for pre-fetching batches of examples and 2 for shuffling batches into batches of different length.\nWe used a beam search of depth 20 and 5 candidates per beam, this was done using the CbtQuestion class which contains useful utility functions that we found useful to run our model.\nWe tested our network against the following list of commonly used baselines.\nHermann et al. BIBREF1 and Memory Networks BIBREF2 are state-of-the-art non-neural NLP models for cloze-style questions BIBREF1, BIBREF12, BIBREF38 to which we also compare our model (BIBREF4, BIBREF5, BIBREF10, BIBREF24 ). This includes the ASReader model introduced in BIBREF4 which uses the simplest architecture to date and we have used to compare against.\nThe attention reader BIBREF3 can be understood as a neural analogue of memory networks BIBREF33 and hence serves as another comparison point BIBREF3, BIBREF5, BIBREF10, BIBREF11, BIBREF24.\nThe Deep Q-learning BIBREF4, the LSTM with memory module BIBREF4, BIBREF5, BIBREF22, the copy-rnn BIBREF4, BIBREF5 and the RNN language model BIBREF9 are related algorithms often used in deep-learning and a set of recent proposals we considered evaluating BIBREF4, BIBREF9, BIBREF12.\nRecent approaches BIBREF3, BIBREF5, BIBREF10, BIBREF13, BIBREF38, BIBREF41, BIBREF42, BIBREF44, BIBREF45, BIBREF46 by some of the same Google researchers seem to perform similarly to our trained model, the differences being of the order of INLINEFORM0. To make our results",
    "e5bc73974c79d96eee2b688e578a9de1d0eb38fd": " If it could not add any new model to the ensemble we selected the entire ensemble.\n\nThe results were slightly worse over the BookTest validation set than over the BookTest test set. This may indicate that more training on the BookTest data may be required to achieve final accuracy.\nUsing the model with the best validation accuracy and the original CBT training data we evaluated the performance on test set for the various metrics. The results are summarized in Table TABREF30 and in Table TABREF31 for NE and CN questions respectively.\n\nIn the following paragraph we will introduce the best performing model.\nThe best performing model is the psr ensemble consisting of the following models. We also present the full ensemble and the model trained on original CBT data.\nFurther Model Details\nWe use all of our previous model details to describe the individual models, however here we will include some extras as well.\nIncorporating attention over the document for the AS Reader model introduced in BIBREF4 we trained an AS Reader with a two-way attention mechanism. This model BIBREF36 is exactly the same as the original AS Reader model but each unique word in the question and the context document is paired with both the last context word and the last question word. All combinations of these vectors are concatenated and used for the attention calculation. The following plot shows the attention distribution over 100 question \u2013 context document pairs where context words are highlighted in green and question words in red.\nTraining on our BookTest data has improved INLINEFORM0 over the BookTest validation set and training on the original CBT validation set has improved INLINEFORM2 over the CBT validation set. These results are summarized in table TABREF32.\nWe also trained an LSTM language model. This model was trained in a single step on a randomly chosen portion of the BookTest (10,000,000 words) and trained for 300 epochs. As a result, in total it had seen 120,000,000 words. We also trained an LSTM language model on the original Children's Book Test data (10,000,000 words) and trained for 300 epochs. Although with 120,000,000 words of coverage this language model is comparable with the BookTest trained language model in terms of total words seen, we observe that it fails to outperform the BookTest language model. We believe that this may be due to using the CBT validation and test sets for training rather than the original",
    "2cd37743bcc7ea3bd405ce6d91e79e5339d7642e": " Based on the empirical results of our experiments (section SECREF108 ), we recommend a feature set consisting of lexical features, sentence structure features, topic features, token-level features (with word embedding features for every token), as well as the contextualized word embedding features for all tokens. To the best of our knowledge, this feature set represents novel combination of features and has not been used before for modeling argumentation.\nAcknowledgements\nThanks to the following people who helped to improve and improve the results of the present paper:\nB\u00e4rbel Almeida for helping with getting a domain expert for the prayer in schools annotation, Jens Bock for critical comments on various aspects, and most of all for the invaluable suggestions how to model argument features within HMMs.\nChristopher Daehler and Tim Sporcl contributed valuable suggestions with respect to argumentation schemes and computational linguistics, respectively.\n\nDominique Almeida who corrected my poor German grammar (and syntax) multiple times, and also wrote a whole paper for me about argumentation that allowed me to understand and correct some mistakes.\n\nSebastian Grahn gave valuable information on the data availability of the domains under consideration and helped to filter and re-annotate the data.\n\nMarco Krontir\u00e4ski who gave many useful suggestions on argumentation theories and related literature, and also created the prayer in schools annotation in collaboration with me.\n\nMyriam Monfils who proofread several drafts of this paper and helped to find grammatical and typographical errors.\n\nHannes Nawrocki gave me a lot of useful insights on argumentation theory and the current state of the field.\n\nMyriam Niehaus who pointed out my mistakes and gave good and constructive advice on the annotations, models, experiments, and the paper.\n\nSven Ruetten for proofreading some sections of this paper and providing useful comments on several aspects.\n\nSabine Schiller made the German Wikipedia annotation. Her German was also very helpful for the whole paper.\n\nDavid Thorne shared an early draft of the article.\n\nThomas van Ineichen for proofed the article and providing good comments on a lot of the content.\n\nNathaniel Wadman's help on several aspects and also for proofreading the article at the last day.\n\nI would also like to thank the following people for helping with the",
    "eac9dae3492e17bc49c842fb566f464ff18c049b": " These domains are generally less challenging for argument analysis than longer articles or blog posts, so we assume that an argumentation model with expressiveness limitations might yield more reliable results in general in argumentation mining. Our preliminary results show that the identification of argument components does have an impact on argumentation analysis and might yield additional insights from the NLP perspective. We are going to refine our approaches by exploring more linguistic features. As part of our future research, we would like to extend our method to longer articles and blog posts. However, this seems to require a different approach to argument component identification and we want to investigate also argumentation in longer documents. We would like to point out that we are not aware of any existing approach that can achieve reliable argument component annotation for long documents (in terms of INLINEFORM1 ). At the same time, the use of embedding features from word embeddings is promising and we consider this as an important research direction for the future.\nRegarding the machine learning methods applied in our experiments, several open questions remain. First, we see the potential for generalization of embedding-based features across domains, yet the system exhibits domain dependence (especially for different registers of user-generated content). Second, one of the biggest challenges of argument component classification is the difficulty in finding boundaries of argument components by distinguishing argument components from surrounding text (see discussion above in section UID86 ). To overcome this problem we plan to use both HMMs for classification and ab-straction for boundary localization, as discussed in section UID110. Third, training times were very long; however, these times are not as long as in other areas of NLP. In computer-supported argumentation, we observe a low inter-annotator agreement and some disagreement between annotators, despite a rather large gold data set. One possible reason is that dialogical aspect of argumentation is not fully taken into account. This is in part caused by a lack of large labeled corpora, discussed in section SECREF51. Given this shortcoming, we propose to use a much larger annotated corpus if more annotated argumentation data is available.\nIn this article we presented a study on argumentation mining, where we investigated the annotation of argumentation in user-generated content. By choosing several controversies from an educational perspective, we focused on detecting argumentation in different registers and different domains (e.g., newswire articles, blogs or comments). To overcome existing research gaps in argumentation mining, we concentrated",
    "7697baf8d8d582c1f664a614f6332121061f87db": " When longer documents or a different register is used for analysis, it is advisable to adapt the argumentation model and selection of the annotation type to the particular corpus. As a summary, we present a table depicting the different options; see Table TABREF159.\nWe presented various uses of computational models in argumentation mining research, such as stance detection, persuasion, or modeling dialogical arguments in NLP. Future explorations of argumentation mining should focus on:\nThe first and most important issue that should be discussed is the gap between computational linguistics and argumentation studies. There are two major questions: How far should computational linguistics and argumentation research be integrated? How might the interdisciplinary gaps addressed? We will present some proposals in the forthcoming section.\nSecond, the reliability of annotated corpora must be validated. The need for establishing a strong link between computational linguistics and argumentation studies will be important in both empirical work and creating annotated corpora. We presented in detail the approach we used for analyzing inter-annotator agreement in this article and we suggest similar measures for reliability analysis of the annotated corpora.\nThird, the creation of such an annotated corpus is itself a substantial effort. We provided step-by-step descriptions of the data acquisition, annotation, and curation in a practical environment. Furthermore, we proposed a quantitative evaluation that is applicable to different annotations and their reliability, which is very helpful when one has to define annotation tasks and their reliability.\n\nFourth, since it is an open question how actual data on the Web can be utilized in this domain, we present some research agendas in computational linguistics and related areas of NLP (Section SECREF44 ). The article should encourage researchers in argumentation and NLP to follow these research directions to foster future advances in the field.\nFinally, we present a number of practical limitations of argumentation mining. Based on the results of the state of the art overview in section SECREF31 we provide potential areas of research.\nDiscussion and future work\nIn the introduction to this article, we emphasized the need for bridging computational linguistics with the domain of argumentation mine. According to [p. 5]Benzm\u00fcller.2010 we could only find seven articles within the past three years that focused on argumentation mining, although related work has been done for a long time in different domains and languages. Such gap can be closed by establishing clear requirements for a machine learning task in the",
    "1cb100182508cf55b3509283c0e2bbcd527d625e": " Another scenario is to select the Walton's dialogue-type schemes for argumentation in user-generated newswire articles or blogs. Longer documents, such as articles or articles with a non-persuasive standpoint, call for different argumentation models or no model. We also propose an abstraction-layer argumentation model for dealing with argumentation in all its different forms and structures in addition to the Toulmin's model and Walton's models.\n\nIn addition, argumentation research should be done in a variety of registers and languages, while the current work is limited to English. The annotation study provides a solid base to construct new corpora for argumentation mining in Web discourse. It is worth noting that the gold data set is larger than any existing resources for argumentation mining (Table TABREF32 in section UID30, Table TABREF33 in section UID73 ).\nFinally, we would like to stress that it is necessary to identify the most promising features as well as the best approaches for training computational models in argumentation mining. We encourage readers to critically examine our results and to apply various improvements on the approaches and features. In order to make argumentation mining research reproducible and easy to conduct, we open source all the annotation tools and data.\n\nAroniszewski.L.P.2009. Introduction to Computational Argumentation. Springer, Berlin.\nBernard, A., V. Eglite.2014. In the classroom: A corpus study on second-year students' reasoning in argumentative discourses. Studies in Language 30:1-32.\nBoland, F., P.C. Conlon.2006. Affecting argument processing. Language Discourse 22:211-239.\nBoltuzic, B., S. Snajder.2014. Mining Argument in Tweets from the Perspective of Computational Argumentation. Lecture Notes in Computer Science 8176, 1-13.\n\nBou-Coudreau, A.E., C.H. Roberts, B.J. Franklin, D.R. Hirst, L.N. Hahn, K.N. Demszky, M. Lester, B.T. Yeggesen, K.A. DeRoure, and C.A. Mutch, M. Eds.2014. Argumentation Mining. Berlin: Springer.\n\nBurfoot, S.",
    "206739417251064b910ae9e5ff096e867ee10fb8": " Longer and more complex documents should be analyzed on clause levels and be possibly analyzed in multiple domains, for they generally contain (1) multiple arguments for both sides, or (2) multiple authors contributing to the same discussion, each of them using their own arguments BIBREF33, BIBREF126, BIBREF129, BIBREF127, BIBREF130. For long documents, we suggest using at least one of the feature sets (1-4) in addition to the word embedding features.\nThe results of this paper can be summarized in the following conclusions. First, the performance of the developed system is not yet sufficient to make further practical uses of the annotated corpora easy. However, we suggest that argumentation mining on the argument component level is possible and the results can serve as a reliable starting point for future research on the topic. Second, the use-case examples covered in the introduction section show that argumentation mining can be practically useful when it is coupled with techniques for finding supporting evidence for a standpoint. Third, the developed system has a wide range of applicability if it is coupled with suitable features. The word embedding features seem to be general and suitable for any domain, although this has not yet been systematically examined.\nOne of the main limitations of our current work is its lack of reliability analysis. This is a critical point in the research of argumentation mining and should be tackled in future work. We suggest two approaches. First, the inter-annotator agreement study can be extended with a statistical testing if the annotators are (1) randomly assigned to annotate one particular document or (2) assigned to annotate all documents simultaneously with different methods (anonymously) to ensure the independence. Second, it is advisable to test the systems with a large number of documents, such as the ones from the original Toulmin corpus. More systematic annotation studies can be easily performed using existing corpora, such as PonderBlogs BIBREF62 or the original Toulmin corpus, which contain long documents, e.g., journalistic articles (see [p. 1090]Boltuzic.Snajder.2014 ).\nThis article is based on joint research funded by the Humboldt Association (UdK, Universit\u00e4t D\u00fcsseldorf), the German Federal Ministry of Defense, European Union's H2020 research program (FP7-AGROWS-249818), and a project within the",
    "d6401cece55a14d2a35ba797a0878dfe2deabedc": " To the best of our knowledge, it is the first argumentation model that was designed to be directly adapted and applied to user-generated Web discourse in natural language.\nIn this article we investigated argumentation mining (AMI) on the Web. We annotated 340 documents from across six controversial educational topics with respect to a modified Toulmin's model. Moreover, we annotated 990 documents in four different registers using different argumentation models (Toulmin and Waltonian models). The results of annotations were used as a basis to devise several computational prediction models for AM. We showed how argumentation in user generated Web text can be modeled to identify various argument components. In addition, we released the annotated corpora in the scope of argumentation mining research under free license (CC-BY-SA 4.0), as we strongly believe that it will foster a broader research within this field based on realistic datasets.\nAcknowledgements\nThis work is partially funded by the following grants: Austrian Fonds f\u00fcr wissenschaftliche Forschfdrift (FWF): (1) New Generation in Language Technology (NGI-LT) project (P23453/W1211). Project coordinator: Peter Steuer, co-financed by the Austrian Science Fund (FWF); (2) M2-Learning: Machine learning in Multimodality (P29143/J1300). Project coordinators: Peter Steuer, Christian R\u00f6nnberg; (3) M2-SocialMediaData: Social Media Big Data Mining (P30385/C1300). Project coordinator: Peter Steuer; (4) e-learning@work: Computational Modeling and Visualization of e-learning at Workplaces (P34402/K1602). Project coordinator: Peter Steuer; (5) ARGOS: Advancing Research in Machine learning for Argumentation on Social Media (P34897). Project coordinator: Peter Steuer.\n\nWe would like to thank the anonymous reviewers for their helpful suggestions, especially with respect to the argumentation modeling, for their comments on preliminary versions of the article and for pointing important related works. Finally, we also wish to thank the Toulmin International Model Commission for their comments and the constructive criticism. All these improvements allowed us to prepare even a better and more complete version of this article for the publication.\n\nFunding\nThis work is partially funded by the following grants: Austrian Fonds f\u00fcr wissens",
    "ee2ad0ab64579cffb60853db6a8c0f971d7cf0ff": "\n\nConflict of Interest\nThe authors declare that the research presented in this paper is conducted without any conflict of interest with the sponsors.\nReference\n[1] E. Kosti, H. Kim, S. Sharma, and P. E. Bourne. Speaker recognition using automatic feature extraction and i-vector. In INTERSPEECH, September 13-18, 2001, Vienna, Austria.\n\n[2] S. Sodani, A. H. D. Dittmann, D. Stolcke, N. Loizou, K. S. Sridhar, D. O. D. Lange, S. S. Palethora, N. J. M. Dunbar, and J. Kleinberger. Speech Recognition Challenge (SR2015) at Interspeech 2015.\n\n[3] J. V. Eerola, D. O. D. Lange, D. S. S. Sridhar, S. S. Palethora, A. S. E. Stolcke, S. S. Dharne. RedDots: A Benchmark Corpus of Spontaneous Speech for Speech Analysis.\n\n[4] V. B. Gotsis, T. Zueffler, D. Gledhill, A. Chorowski and J. E. Kleinberger. Automatic Speaker Recognition (ASR) System Benchmark: RSR2015 Results, Interspeech 2015, Prague, Czech Repubic, 2015.\n\n[5] S. Sankar Subramanian, K. M. S. S. Ravi Prakash, S. V. Sivanesan. Speaker Independent Speaker Verification (SISV) Using the RSR2015 Test Suite.\n\n[6] T. Zueffler, P. Materzynska, D. Gledhill and J. E. Kleinberger. Automatic Speech Recognition (ASR) System Benchmark: Results, Interspeech 2015, Prague, Czech Repubic, 2015.\n\n[7] H. Zadak, J. P. A. R. Mooij, S. S. Palethora, G. K. R. Rao, M. S. Khan, J. V. Eerola, P. Materzynska. An Automatic Speech Recognition",
    "fde700d5134a9ae8f7579bea1f1b75f34d7c1c4c": " For designing the database and deep learning method analysis, we thank our sponsor IT4Innovations. For the speech recognition experiments, we thank our colleague Mehdi Sadaghi in his Persian speech recognition project.\nAcknowledgements are also due to the project authors' home institutes for the time and facilities.\n\nReferences:\n..,. (2017). \"DeepMine Database ::: Project Description.\" Arxiv Pre-print arXiv:1710.07103v1.\n[1]: https://www.nist.gov/\n\n[2]: http://www.nps.ac.ir/\n\n[3]: reddots.csl.cam.ac.uk\n\n[4]: http://www.speechrec.nl\n\n[5]: http://www.csl.cam.ac.uk/reddots/part2\n\n[6]: https://www.cse.iit.ntu.edu.tw/\u223cjhuang/papers/paper-interspeech2016.pdf\n\n[7]: https://www.cmu.edu/\u223cshervin/Papers/nld/papers/interspeech17_reddots.pdf\n\n[8]: https://www.nist.gov/\n\n[9]: akgunay.com/\n\n[10]: http://www.csl.cam.ac.uk\n\n[11]: http://www.csl.cam.ac.uk/reddots/part3\n\n[12]: http://www.a.ijs.si/\n\n[13]: http://www.csl.cam.ac.uk/reddots/part1\n\n[14]: http://www.csl.cam.ac.uk/reddots/part2/index.html#part2\n\n[15]: ece.msu.edu\n\n[16]: http://www.cs.cmu.edu/\u223cshervin/papers/interspeech17_reddots.pdf\n\n[17]: https://archive.ics.uci.edu/courses/ECE476-F16/homework/hw10_speechID.pdf\n\n[18]: https://a.ijs.si/\n\n[19]: https://www.nist.gov/\n\n[20]: a",
    "b1a068c1050e2bed12d5c9550c73e59cd5b1f78d": " We are grateful to all colleagues who participated in the project.\n\n1.\n\nC. Alvarado. et al. S. Dufour, J. de la Osa, L. Marti, A. B. Rosales-Aguilar, K. Svensson, C. Alvarado, O. Bravo, D. D. Estrada, J. A. C. Gonzalez-Abajo, E. J. Mart\u00ednez-Fern\u00e1ndez: \"The NIST speaker recognition evaluation 2015\".\n\nNIST Report, NISTIR 7616, 2018.\nFor a detailed description, see\n\n2.\n\nA. P. Reddy, E. M. M. Tan, K. L. Ramaswamy. RedDots: A Large Dataset for Evaluating Speaker Recognition Systems.\n\nInternational Conference on Recent Advances in Speech Technologies, 2015.\nFor further information, see\n3.\n\nA. P. Reddy. RSR: A Very Large Dataset for Speaker Verification and Recognition. NIST Special Publication (SP-1692). 2012.\n4.\n\nA. K. Keshvari. A Comprehensive Overview of Persian and English Text-dependent Speaker Recognition.\n\nSemantic Computing: Advances in Knowledge Retrieval and Analytics (Selected Papers of SCP), Springer International Publishing, 2015.\n5.\n\nS. R. Almasi, F. Sajadipour, S. Hasanzadeh, M. Ahmadi Kermanshahi, E. Farahmand, H. Y. Tavakkoli: \"The Persian speaker recognition evaluation 2018\".\n\nNIST Special Publication (SP-2000), 2018.\n6.\n\nY. Wang, Z. Shen, H. Wang, Z. Guirguis, H. Wang: \"The NIST speaker recognition evaluation 2011\".\n\nNIST Special Publication (SP-1379), 2011.\n7.\n\nJ. Farkas, P. G. Plomp. Evaluation of Text-Independent Speaker Recognition Methods at the NIST 2016 Workshop on Speaker Recognition.\n\nNISTIR 7633, 2016.\nFor further information, see\n\n8.\n\nS. Cheplygina, E. M. M. Tan, S.",
    "f9edd8f9c13b54d8b1253ed30e7decc1999602da": " We would like to thank Vilem Grimm for help with editing the paper.\n.\nThis work was partially supported by The European Regional Development Fund through the European Regional Development Fund and the Czech National Program of Sustainability (NPU II) project MOBILESQUAR-1.5.01. The research leading to these results has received funding from the European Union's Horizon 2020 research and innovation programme under the Marie Sk\u0142odowska-Curie grant agreement No. 761499, and in the context of the PRINOTON programme.\n\n.\n.\n.\n.\nThis work was partially supported by The Ministry of Industry and Trade of Iran; The National Research, Development and Innovation Organization of Iran (NRDO); Islamic Azad University of Qom and Islamic Azad University of Qom Research Branch (IAUQRB), and National Centre for Excellence in Big Data Analysis and Optimization (NC-EBDO).\nThe research leading to these results has received funding from the European Union's Horizon 2020 research and innovation programme under the Marie Sk\u0142odowska-Curie grant agreement No. 101021. It is a part of the National Programme of Sustainability (NPU II) project \"Excellence in Computer Sciences and Artificial Intelligence\" in the framework of IT4Innovations.\n\nDeepMine.ai (2019)\n\nDeepMine Corp. (2018) DeepMine. Retrieved from http://deepmine.ai/\n.\n\n.\n.\n\nGarcia, P., et al. (2018) RSR2015 Challenge Results. Available from http://www.voxceleb.org/rSRec.htm\n\nViergever, T.A., et al. (2015) VoxCeleb Challenge 2019. Available from:\n\n.\n\n.\n\n.\n\n.\n.\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n\n.\n\n.\n.\n\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n\n.\n.",
    "d93c0e78a3fe890cd534a11276e934be68583f4b": " We would like to thank all participants for their collaboration.\nThis work is licenced under the MIT license. \nAll content in this open access repository has been provided by the respective publishers and authors. You can help advance research and knowledge by joining one of our support plans.\n\nOpen Access Library\n\nUniversity Library TU/e\nwww.openaccess.library.tue.nl\n\nAll rights reserved.\n\n\n## Praise for the Works of Susan Mallery\n\n##\n\n## SUSAN MALLERY\n\n##\n\n## THE WINTER SPIRIT DUET\n\nBook 1\n\n##  \nSnowed In\n\nBook 2\n\n##  \nMistletoe Magic\n\nA Berkley Sensation Novella\n\n## Susan Mallery\n\n## SNOWED IN\n\nBERKLEY SENSATION, NEW YORK\n\n## Contents\n\nPrologue\n\nChapter 1\n\nChapter 2\n\nChapter 3\n\nChapter 4\n\nChapter 5\n\nChapter 6\n\nChapter 7\n\nChapter 8\n\nChapter 9\n\nChapter 10\n\nInterlude\n\nChapter 11\n\nChapter 12\n\nChapter 13\n\nChapter 14\n\nChapter 15\n\nChapter 16\n\nInterlude\n\nChapter 17\n\nChapter 18\n\nChapter 19\n\nChapter 20\n\nChapter 21\n\nChapter 22\n\nChapter 23\n\nChapter 24\n\nInterlude\n\nChapter 25\n\nChapter 26\n\nChapter 27\n\nChapter 28\n\nChapter 29\n\nChapter 30\n\nInterlude\n\nChapter 31\n\nChapter 32\n\nChapter 33\n\nChapter 34\n\nChapter 35\n\nChapter 36\n\nChapter 37\n\nChapter 38\n\nInterlude\n\nEpilogue\n\n## PROLOGUE\n\nWhen your friends put their heads together to come up with creative ways you, their bestie, can be made fun of online, they do not think that far-reaching to cover all possibilities.\n\nJocelyn's best friend was not only very smart but, in the past, had come up with several unique ways to humiliate her. So when the two approached her and said they had devised a way they thought her life could be made miserable, she was wary.\n\nOne way to do that would not have been terribly difficult and would have done nothing to",
    "30af1926559079f59b0df055da76a3a34df8336f": "\nBIBREF0. R. T. Kuribohm, H. Nabeshima, E. G. Pauwels, H. W. Chang, M. Pang, S. J. Schultz, J. I. Gao, E. W. Weninger, T. A. Berger, C. A. Papadopulos, J. P. Baudouin, J. Ye, R. E. Nussbaum, D. E. Cox, M. A. Tremayne, W. T. Young, K. T. J. Lee, J. D. G. Meyer, F. T. F. Tung, S. A. Leong, Y. L. Cui, T. E. De Vos, Y. R. S. Sun, A. C. Rae, T. S. N. Woo, A. Mouammer, J. S. B. Vogelstein, W. B. Loh, R. N. D. T. Bekkers, A. Y. C. Li, T. S. H. W\u00f6lmke, R. C. P. Boutella, G. Chen, J. L. C. Wong, and Z. P. Sun, \"NIST speaker recognition evaluation, RedDots benchmark test set,\" in Proc. Proc. Interspeech, 2015.\n\nBIBREF1. T. J. Kekatos, J. W. Mitchell, Y. H. Chiu, B. L. K. Ng, T. J. Smith, V. A. Krylov, T. W. A. Povey, P. L. Martin, H. Nabeshima, A. Riedel, M. Papadopoulos, R. E. Nussbaum, J. Y. Cui, B. W. Moore, E. W. Weninger, R. N. D. T. Bekkers, F. T. F. Tung, M. Tremayne, and W. T. Young, \"End-to-End text-independent speaker recognition based on deep networks in the Wild,\" in Proc. Proc. of ICASSP, 2018, NewYork, USA.\n\nBIBREF2. R. T. Kuriboh",
    "ceb767e33fde4b927e730f893db5ece947ffb0d8": " The code for this work is available at https://osf.io/jy3e7/, and the trained model can be downloaded from https://osf.io/p7f8d/. We would like to thank the MSHS lab at the University of Pittsburgh for hosting us on Saturdays for our annotation sessions.\n\nReferences\n[BIBREF01]. Meng Chen. 2009. \"Structural Regularization for Improving Text Summarization.\" arXiv preprint arXiv:0805.0614. \n[BIBREF02]. Meng Chen, Danqi Chen, and Yuan Zhao. 2017. \"Improving Patient Handoff Summarization in Distributed Healthcare.\" Proceedings of the 18th International Conference on Computational Linguistics: 1-8. \n[BIBREF03]. Meng Chen, Jian Zhou, and Yuan Zhao. 2019. \"Evaluating Clinical Summarization for Patient Handoff\".  \n[BIBREF04]. Meng Chen, Jian Zhou, and Yuan Zhao. 2020. \"The Missing History of Present Illness: Toward Automatic Summarization\". Sensors 19, 6: 1-19. \n[BIBREF05]. Liza R. Kripalani, Andrew J. Tan, William J. Perrone, William M. Sasson, Aaron I. Wagner, and Alan Javanbazar. 2019. \"Improving Discharge Summaries for Readmission Care: Results of a National Retrospective Study of Non-compliance with Hospital-community Communications.\" Journal of HICCP 35(2): 159-183. \n[BIBREF06]. Edward E. Bergey, James P. McCrea, Alan W. McIntosh, Lisa D. Rosenthal, Michael M. Snyder, and C. Kent Kriska. 2000. \"A Summarization Model, System, and Report.\" Proc. of the 17th Annual Meeting of the Association for Computational Linguistics:  \n[BIBREF07]. Andrew Miller, Peter Briscoe, and Chris D. Manning. 2010. \"Automatic Summarization with Latent Topics for Texts in Clinical Settings.\" Language Resources and Evaluation 44(2): 149-162. \n[BIBREF08]. Michael S. Bernstein, Nadeem S. Mohammed, Suresh C. Krishnapuram,",
    "c2cb6c4500d9e02fc9a1bdffd22c3df69655189f": " This work is supported by the National Institutes of Health and the NIH Big Data to Knowledge (BD2K) program under Grant U54 HG006397.\n\n[BIBREF1]   T. Jain, S. Singh , B. Dua, N. Arora, B. Joshi  , B. Cui et al. : \"Informal, unstructured discharge summary notes: a common cause of readmission.\" J Am Med Inform Assoc. 14, 1287\u20131303 (2017).\n\n[BIBREF2]   R. Dhaliwal et al. : \"A simple and scalable approach to summarizing clinical encounters using natural language processing.\" J Biomed Inform 43 : 827\u2013846 (2014).\n\n[BIBREF3]   D. Kripalani, R. Dhaliwal, J. Yang, J. R. Riche. : \"Discharge summary note readability: insights into how to improve communication with patients.\" Stud Health Technol Inform. 204 : 989\u2013997 (2017).\n\n[BIBREF4]   K. E. St. Thomas Hospital : \"What you need to know: when notes must be written within 48 hours of discharge.\"  : 3\u201320 (2017).\n\n[BIBREF5]   M. Dernoncourt et al. : \"Towards automated summary of medical narratives: a deep neural network approach.\" In Advances in Neural Information Processing Systems - 31st Annual Conference of the , pages 598\u2013610 (2015).\n\n[BIBREF6]   S. S. Liu and S. Weng. : \"Automatic extraction of meaningful sentences for abstractive text summarization.\"  (2013).\n\n[BIBREF7]   X. Pan, I. Goldwater, R. S. Goodman, G. R. Rosenberg, S. Yu, B. D. Joshi et al. : \"A word grammar approach to sentence-based text summarization using latent Dirichlet allocation.\"  (2014).\n\n[BIBREF8]   S. R. Goodman, C. Szyperski, R. S. Rosensweet, D. G. Feinglass et al. : \"An approach to automatic narrative generation based on word co-occurrence analysis.\"  (2012).\n\n[BIB",
    "c571deefe93f0a41b60f9886db119947648e967c": "\n\nReferences\n\nBIBREF0\n\nRaghu, O., Rasmussen, P., Apte, Z., et al. (2010). A study of structured discharge summaries as a clinical communication tool, Ann Fam Med, 2008:1045\u201354.\n\nBIBREF1\n\nBaker, T., Sekhar, N., Kripalani, S. S., et al. (2012). Electronic health record use and summaries: clinical practice implications. J Am Board Fam Pract 23, 677\u201383.\n\nBIBREF2\n\nMozaffari, F., McIntyre, L. (2011). A Systematic Review of Text Summarization Techniques in Clinical Information Systems. AMIA Annu Proc. 21, 239\u2013249.\n\nBIBREF3\n\nKripalani, S. S., Baker, T., Mariani, M. C., et al. (2016). Efficiently summarizing EHRs using word information retrieval and visualization. J Am Med Inform Assoc J Am Med Inform Assoc 23: 1032\u201343.\n\nBIBREF4\n\nSt. Thomas Hospital. (n.d.). All discharges must have complete and accurate discharge summaries in accordance with the Joint Commission requirements. http://www.sttn.org/wp-content/uploads/2014/02/DNR-Discharge-Summary-Manual.pdf\n\nBIBREF5\n\nKripalani, S. S., Baker, T., Kripalani, K. et al. (2015). Clinical communication breakdowns due to incomplete discharge summary notes. J Am Board Fam Pract. 30, 259\u2013265.\n\nBIBREF6\n\nRaghu, O., Rasmussen, P., Apte, Z., et al. (2011). Identifying salient sentences in clinical notes with automatic sentence extraction heuristics. AMIA Annu Proc. 20, 1261\u20131266.\n\nBIBREF7\n\nMitchell, T. D., Rasmussen, P., Peyrucoeur, F., et al. (2009). Automated extraction of topics from short narratives in electronic health records. J Am Med Inform Assoc Vol 16, 8.\n\nBIBREF8\n\nMozaffari, F",
    "06eb9f2320451df83e27362c22eb02f4a426a018": "\nWhile these preprocessing procedures may seem rather harsh, we believe that our results may provide useful insights for improving keyphrase generation approaches and their ranking of keyphrase candidates.\nAcknowledgements\nThis work is funded by Horizon 2020 research and innovation project \"EUDIST: Enhancing User-Driven Intertextuality in Multilingual Scholarly Databases.\" We also thank Niklas N\u00e4ssel for helpful discussions on keyphrase extraction models.\nBIBREF0\n\n<https://www.semeval.org/projects/2010/bibref>\nBIBREF1\n\nN. N\u00e4ssel and R. Sch\u00fctze, \"Keyphrase extraction from semistructured scientific articles using heuris -tical document format analysis,\" in Proceedings of the Second Workshop on Automation of NLP in Legal and Semiotic Documents with Multi- and Mass-Media Processing (ACL) 2012, Association for Computational Linguistics, 2012.\n\nBIBREF2\n\nK. C. Chang, N. N\u00e4ssel, and R. Sch\u00fctze, \"Keyphrase extraction from PDF files and structured data using heuris -tical document format analysis,\" in Proceedings of the 16th ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR) 2010, Association for Computational Linguistics, 2010.\n\nBIBREF3\n\nK. C. Chang, N. N\u00e4ssel, F. Boes and R. Sch\u00fctze, \"Keyphrase extraction from PDF files using syntax-based feature selection,\" in Proceedings of the 11th ACM International Joint Conference on Digital Libraries (ICDl) 2013, Association for Computational Linguistics, 2013.\n\nBIBREF4\n\nK. C. Chang, N. N\u00e4ssel and R. Sch\u00fctze, \"Keyphrase extraction from semistructured documents, by exploiting document logical structure and core NLP tools,\" in Proceedings of the Fourth Conference for Evaluation of Systems in Natural Language Processing (SemEval) 2010, Association for Computational Linguistics, 2010.\n\nBIBREF5\n\nK. C. Chang and N. N\u00e4ssel, \"Semi-supervised keyphrase extraction using a topic-focused approach,\" in Proceedings of the First Workshop on Advances in Keyphrase Extraction (KAKE) 2013, Association for Computational L",
    "e54257585cc75564341eb02bdc63ff8111992f82": " Furthermore, we consider that future work in keyphrase extraction should put more effort on modeling noisy text and improving preprocessing techniques rather than trying to overcome that effect with more fine-grained approaches. In this study, we also provide an evaluation platform that can be used to re-assess any number of approaches for various preprocessing levels.\nAcknowledgments\nThis work is a part of the L3S Research Centre for Knowledge Systems funded by the European Research Council (www.l3s.de) and in part funded by the German Research Foundation (www.dfg.de). We appreciate the contributions of all authors participating in the SemEval-2010 keyphrase extraction task. We are grateful to the anonymous reviewers for their valuable and constructive critics that helped us to improve.\nReferences\n\n[BIBREF0]\nJ. Dagan Guedes, F. Kiritzmann, C. Likhachev, Y. A. Mikhailov, M. Diachun, I. Dancs, S. Kulkarni, K. Jain, R. Hajic, D. A. Clarke, A. van Genabith, D. Foulds, J. Wang, G. Tenney, and I. Titovas. 2012. The evaluation of extractive keyphrase identification measures. In Proceedings of the 7th Workshop on Semantic Evaluation, pages 34\u201341, New York, USA.\n\n[BIBREF10]\nK. Dagan and Y. A. Mikhailov. 2011. Efficient and scalable text preprocessing for information retrieval in scientific articles. In Proceedings of the 22nd Conference on Computational Natural Language Learning (CoNLL 2011), pages 101\u2013111. Association for Computational Linguistics. http://www.aclweb.org/anthology/J67.pdf.\n\n[BIBREF11]\nK. Dagan, E. Eder, D. Foulds, and Y. A. Mikhailov. 2009. An unsupervised resource-efficient text preprocessing method for keyphrase extraction. In Proceedings of the 2009 Workshop on Document Information Extraction, page 14. Association for Computational Linguistics. http://www.aclweb.org/anthology/J08.pdf.\n\n[BIBREF12]\nJ. Dagan and Y. A. Mikhailov.",
    "2a3e36c220e7b47c1b652511a4fdd7238a74a68f": " Our hope is that the community will adopt them as a common standard for evaluating keyphrase extraction experiments. The code accompanying this study can be found here. We also made available level 4 preprocessed versions of the BIBREF0 dataset along with the extracted keyphrases and an easy-to-use wrapper script to reproduce the results of Table.\n\nThis work focuses on evaluating the importance of document preprocessing for keyphrase extraction performance. From a practical perspective, this is a first exploration into the effect of document preprocessing, as it has been a blind spot in the past. In forthcoming work, we aim to use our findings to inform a better hyperparameter choice for different systems. We also aim to understand why some approaches perform better than others. A preliminary conclusion is that the use of hyperredundant features to rank candidates tends toward robustness to noisy textual content. We also found that the supervision signal helps overcome the noise and make systems less sensitive to it.\nAcknowledgements\nThanks to the BIBREF task organizers, and especially to Marco L\u00fcdecke for sharing his unpublished work that provided a strong benchmark system to measure against. We thank him for his help during this work and for sharing code and results. We would also like to thanks two anonymous reviewers, our fellow student colleagues from Politecnico di Milano and the first anonymous reviewer for their valuable and constructive feedback.\n\nReferences\n\nBIBREFBahar I. et al. BIBREF0 : Semeval 2010. Proceedings of the Workshop on Language Resources and Evaluation. Association for Computational Linguistics, Inc. 2009, pages 17\u201320, http://www.aclweb.org/anthology/W10-1113.pdf.\n\nBIBREFBoas, C., Hitzler, P., and Vuli\u010d, D. 2009. Detecting document structure using logical form. In Proceedings of the Twelfth International Joint Conference on Natural Language Processing, pages 1163\u20131171, Seoul, South Korea: Association for Computational Linguistics.\n\nBIBREFOkawa, M. and Gamon, C. 2014. Improving document preprocessing for keyphrase extraction via author-assigned reference keyphrases. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1447\u20131455.\n\nBIBREFNakov, E., Tov,",
    "9658b5ffb5c56e5a48a3fea0342ad8fc99741908": " We thank all MIMIC annotators for their contributions to their annotations during this project.\nReferences\n[1] T. Baker, T. Vishnuvardhan, and A. Cramer. A survey of recurrent-event prediction methods for medical applications. Stud Health Technol Inform, 134 (2018), e101981.\n[2] M. Kaufman, F. M. Sutarto, A. B. H. P. Tanudjaja, J. C. H. Tanudjaja, D. M. Kaushal, G. Li, B. M. D. S. Ng, K. P. Ramalingam, and J. L. Bai. Unreliable, Underused, and Ubiquitous: Improving Precision Medicine Using Unstructured Patient Text Mining. J Chem Inf Comput Sci. 2018;3(1), 8.\n[3] Zheng Ning Hu, Wenbin Zheng, and Dai Zhang. The MIMIC database: a resource for intensive care and critical care research. Intensive Care Med 2015; :.\n[4] Y. Chou, J. L. Bai, F. M. Sutarto, A. B. H. P. Tanudjaja, and J. C. H. Tanudjaja. Predicting hospital readmissions using big data-driven approaches. Biomed Inform Intellect Syst 2018;17:21.\n[5] B. Zheng, J. L. Bai, F. M. Sutarto, and J. C. H. Tanudjaja. Predicting hospital readmissions using machine learning and big data approaches. In: International Conference of Computational Science and Engineering. 2018, pp. 751\u2013758.\n[6] M. Han, K.-S. Chung, J. L. Bai, Q. Chen, F. S. M. Sutarto, A. B. H. P Tanudjaja, Y. H.-Y. Li, D. Kaushal, and J. C. H Tanudjaja. Clinical Patient Phenotypes Extraction from Nursing Progress Notes: Identification and Categorization. In Advances in Methods and Applications of Artificial Intelligence, volume 2. pp. 635\u2013643.\n[7] G. T. W",
    "46c9e5f335b2927db995a55a18b7c7621fd3d051": "\nAcknowledgements :::\n\nWe would like to acknowledge Philips Healthcare for financial support for this work, The Laboratory of Computational Physiology at The Massachusetts Institute of Technology for access to computational resources for this work, and the Beth Israel Deaconess Medical Center for providing the platform for clinical research and clinical practice in health care, and for providing a rich environment for work with these annotated texts.\n1: https://projects.iq.harvard.edu/hicpp/home/2/\n\n2: https://www.healthdata.gov/data.html#ehr-downloadable\n\n3: http://www.usnews.com/us-news/health-care-ease-in-2017\n\n4: http://www.annualreport.ihs.gov/sites/default/files/ARs/2020/html/contents-AR/contents-ar.html\n\n5: http://www.futurity.org/us-hospitals-inpatient-stays-surpass-80/\n\n6: http://medcitynews.com/2018/06/the-real-cost-of-icu-mattresses/\n\n7: https://www.beckershospitalreview.com/hospital-operations/the-costs-of-hospital-staffing-and-workforce-growth-how-much-do-nurses-make.html\n\n8: https://physionet.org/content/medical-intelligence-mining-mimic-iii-iii\n\n9: https://medcitynews.com/2018/06/the-real-cost-of-icu-mattresses/\n\n10: http://journals.sagepub.com/doi/10.1093/jpb/pbz044.001\n\n11: http://medcitynews.com/2018/06/the-real-cost-of-icu-mattresses/\n\n12: http://medcitynews.com/2018/06/the-real-cost-of-icu-mattresses/\n\n13: Clinical researchers: ETM & JW, Residents: JF & JTW\n\n14: https://cran.r-project.org/bin/WindowsBin/RcmdIDDownload; https://c",
    "ce0e2a8675055a5468c4c54dbb099cfd743df8a7": "\n\n1) E. J. Ding and S. N. Shadick, \"Automatically Extracting Clinical Phenotypes from Unstructured Clinical Text,\" Physiol. Rev., Vol. 89, No. 3: 1733\u20131774 (Mar 5, 2009).\n\n2) L. Osterhaus, D. A. Ginsburg, N. Krasan-Sivulsky, I. A. Berman, C. L. Chen, I. R. Bajewicz, C. E. Martin, J. T. McNamee, G. T. Yancey, A. M. Lepore, Z. A. Fung, and W. L. Fackler, \"Nursing progress notes and other types of clinical text in electronic health records: What is present and what is missing.\" Medinfo 2015.\n\n3) W. J. Labadie-Moseley, JTW, JF, JW, ETM, and A. M. Lepore, \"Quantifying and annotating clinical text for multi-label, multi-class classification,\" in Proceedings of the 2019 Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL 2019).\n\n4) Osterhaus, Labadie, Lepore, Martin, Bajewicz, Ginsburg, Chen, Yancey: Acknowledgement that the nursing notes (progress notes) and discharge summary annotations include PHI as per HIPAA.\n\n5) L. Osterhaus, I. A. Berman, C. L. Chen, C. E. Martin, J. T. McNamee, G. T. Yancey, A. M. Lepore, and W. L. Fackler, \"A benchmark corpus of English-language medical documents for the evaluation and comparison of data-dependent approaches to clinical text understanding.\" Data 2018.\n\n6) T. B. Yeh and R. J. Peters, \"Multimodal machine learning for clinical phenotype identification using natural language processing techniques.\" Machine Learning for Clinical Phenotyping. Vol. 3003. Springer, Dordrecht. 2011.\n\n7) L. Hjalmarsson, S. Lee-Thorp, and W. A. G. P. M. van",
    "3a6e843c6c81244c14730295cfb8b865cd7ede46": "\nAcknowledgments\nWe would like to acknowledge support in many ways including useful discussions, helpful feedbacks and suggestions, code reviews, etc., from Professor Sijie Zhang and Professor Peter Brusilovsky. We would also like to thank all the organizers of the Sarcasm Detection Shared Task BIBREF4 for providing the datasets used in this work.\nReferences\n\n[BIBREF0]\n\nE. Alsaker, B. Van Elsas, R. Buntain, Y. Choukroun, S. Wachsmann, K. Palpanas, P. M. Bakker, A. Malykhina, \"Affective Computing and Sentiment Analysis\", BIBREF0.\n\n[BIBREF1]\n\nL. Brugman, F. Cattuto, C. Heeke, A. C. M. de Vos, C. B. van Nutter, M. van Erp, \"From emoticons to sentiment: A survey of irony recognition research\", BIBREF1.\n\n[BIBREF2]\n\nM. M. Moghaddam, B. Zhang, G. Zadie, and J. Riezler, \"Sarcastic sentiment analysis through emoting tweets and non-emoting tweets: An unsupervised framework\", BIBREF2.\n\n[BIBREF3]\n\nS. Dziri, I. Kuznetsova, and A. W. Tucker, \"Sentiment Analysis of Movie Reviews: A Survey of Algorithms and Metrics\", BIBREF3.\n\n[BIBREF4]\n\nJ. I. Prabhu, A. B. Iyyer, and G. Zadie, \"Unsupervised pattern mining for automatic sarcastic text detection using tweets\", BIBREF4.\n\n[BIBREF5]\n\nM. M. Moghaddam, S. Dziri, B. Zeng, and G. Zadie, \"Classifying Dutch tweets as sarcastic or non-sarcastic\", BIBREF5.\n\n[BIBREF6]\n\nS. Dziri, M. M. Moghaddam, A. B. Iyyer, and G. Zadie, \"Sarcastic detection: A brief literature review\", BIB",
    "fabf6fdcfb4c4c7affaa1e4336658c1e6635b1bf": "\nAcknowledgments\nWe would like to acknowledge the support of the Aga Khan Foundation for research and innovation and the support of the EU Commission H2020.\nThis work has received funding from European Union's H2020 research and innovation program under a Joint Research and Innovation Action Grant.\nThis paper benefited from a generous contribution from Aga Khan Foundation for Social Impact to support AI4Good and, in particular, the project SarcasmDet.\n\nReferences\n\n[1] Mohamed, Anwar, and Michael S. Young (2004)\n\n. \"Detecting sarcasm in text\". Journal of Natural Language Engineering, 24 (1\u20132): 1\u201423.\n\n[2] Ribeiro, Tiago, and Sameer Singh (2014)\n\n. \"Toward automated detection of irony using unsupervised techniques\". In EMNLP, 19\u201324.\n\n[3] Singh, Sameer, and Ritu Bhatia (2016)\n\n. \"Combining sentiment lexicon and logical reasoning cues for sarcasm detection\". In Proceedings of the 2nd Workshop on Sentiment Analysis and Computational Social Science, COLING 2016, Amsterdam, the Netherlands, 8\u201312 October 2016, pages 63\u201373.\n\n[4] Jha, Neelam (2018)\n\n. Sarcasm detection with convolutional neural networks and multilayer feature vectors for sentiment and emotion predictions. In International Conference on Computational Linguistics, Proceedings of the 2016 Conference on International Conference on Computational Linguistics, pages 2699\u20132709.\n\n[10] Bravo, Javier, and Miguel A. R. Marquez (2012)\n\n. \"Comparing patterns, features and character n-grams on sarcastic tweet classification\". Workshop on Intelligent and Interactive Text Processing, TREC XIV, Doha, Qatar.\n\n[11] Le, Quoc, Zhi-Hao Zhou, and Xing X. Xue (2013)\n\n. \"Deep convolutional networks for sentiment analysis: a review\". International Journal of Computational Linguistics, 33: 1599\u20131625.\n\n[12] Jha, Neelam, and Sameer Singh (2017)\n\n. \"A review of recurrent belief networks for social media analysis\". Neural Networks, 84: 24\u201437.\n\n[15] Liang, Peisheng,",
    "1beb4a590fa6127a138f4ed1dd13d5d51cc96809": " Moreover, we also plan to investigate the relation between the features generated by CNN and the features extracted by the pre-trained models after training on the corpora. For example, in our approach, the global features are extracted at each higher-layer of the model, which make it possible to extract features from sentence level, paragraph level, etc. using the same model. As a part of this effort, we plan to extract such meaningful features through supervised learning, while still employing CNN as the base for feature extraction.\nThis work was supported by the EU Horizon 2020 project SarcAn (AALTA-2016-69) funded by the European Union's Aspect-Based Learning through Artificial Intelligence project.\n\n# references\n# Acknowledgments\n\nThis work is the result of collaborative efforts of many researchers. In this article, we have also presented the work of many researchers who played a crucial role in defining our research direction. Firstly, we wish to thank the University of Bielefeld for funding (European Centre for Borderline Technologies, HUMANESAS EU project) that facilitated our research in this field. Second, we thank the reviewers for their comments that helped to enhance the quality of this paper. Special thanks to Mr. Andrew Smith for his feedback and suggestions. We also wish to thank Dr. John Wilbanks and our friends at The Sarcasm Detector for advice and advice. We also thank Prof. Jian-Feng Gao for introducing us to this field.\n\n# appendix\n# Reference\n\nAndrew, M. M. (2018). Affective Computing: Concepts, Tools, and Applications, 2nd Edition. Morgan Kaufmann Publishers, Inc.\n\n# reference\n\nBIBACHIA, K., Buzek, V., Gogolla, C., and Zubran, M. (2014). Analyzing sarcasm using machine learning. In: Proceedings of the International Joint Conference on Neural Networks (IJCNN), 2014\n\nBIBACHIA, K., and Zubran, M. (2013). SentiNet: Automatic extraction of sentiment and polar values. Machine Learning, 94 (3), pp. 475\u2013487.\n\n# reference\n\nBIBACHIA, K., Zubran, M., Gogolla, C., and Zubran, H. (2013). Sentiment analysis of social media content. Multilinguo, 20 (",
    "5c5aeee83ea3b34f5936404f5855ccb9869356c1": "\n\n@!!START@!END@-A:@!END@- References.\nReferences (BIBREF0) Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, S., Jones, L., Gomez, A., Jones, R., Liu, Z. Transformer: Attention Is All You Need. In: B. Chen, S. Das, I. Savary (eds.), Advances in Neural Information Processing Systems 31 (Nips 2017), pp. 5991\u20136010, 2017.\n\nReferences (BIBREF24) Tsallis, C. H., Flacco, M., Almeida, C., and E. D. P\u00e9rez-S\u00e1nchez, \"Tsallis non-linearities with applications to information theory, thermodynamics and non-equilibrium thermodynamics\", Information and Control, pp. 45-53, 2013.\n\nReferences (BIBREF27) Blunschi, G., T. Frommer, M. G., C. Eichmann, and R. H. Buntain, \"A neural machine translation engine with pointer-generator network for machine comprehension and question answering\", CoRR abs/1710.04075, 2017.\n\nReferences (BIBREF35) Lin, Q., G. Zhen, K. Y. Ng, A. Jouppi, S. Vaswani, B. Bickel, J. Schulman, A. Y. A. Berg, Y. Bengio, Y. Cohen, D. Fox, K. I. Kay, et. al. BERT: Pretraining of deep bidirectional transformers for language understanding. CoRR abs/1810.04805, 2018.\n\nReferences (BIBREF32) Chen, W., V. Koltun, X. Sun, M. Zhang, F. Li, J. S. R. Cai, N. Zhang, and D. D. D. Li, \"Improving nmt using attention with adaptive span and sparse softmax\". In: Jia Li, N. Rambow, D. Cohen, N. Das, D. Schuster, N. Goyal, L. Henaff, S. F. J. Rosinski, G. E. Dialyna, A. Korin, M. Ranzato,",
    "f8c1b17d265a61502347c9a937269b38fc3fcab1": "\nBackground ::: Adaptively sparse Transformers\nIn this section, we describe the details to train the proposed adaptively sparse Transformers, and give quantitative evidence showing their superiority on NMT tasks. We begin by describing the standard Transformer module on which they are built. The model can be applied at the level of the encoder, the decoder, or both:\nand\nThese modules are defined over token sequences of length $t+1$ in $n$ sentences, so the input to the self-attention layer is given by:\nwhere $e_0 \\in \\mathbb {R}^{n\\times m} $ represents the encoding of the $k$th sentence in the first sentence in the sequence. Similarly, the output may be written as\n\nwhere $e_0 \\in \\mathbb {R}^{n\\times (3H+1)$} corresponds to the attention weights, $e_1 \\in \\mathbb {R}^{3H+1} $ the output of the self-attention layers, $h_l \\in \\mathbb {R} $ the output of the Lagrange layer, and $h_\\ell \\in \\mathbb {R} $ the output of the context attention layer. These are all sequences of size $n$ in $t$ tokens, so the total input size is $n \\times t \\times 3H + 1$ token pairs, while the total output size is $3H+1 \\times n \\times (t+1) + n \\cdot t \\cdot 2$ token pairs.\nThe core of the Transformer (Fig.2a) is the multi-headed self-attention (Fig.2b), which is a weighted average over the tokens in both sequential contexts. Concretely, given the $i_t$th query in the input (the current context sequence $c_t$ ), the queries in the input of the self-attention (the previous context sequence $x_t{ \\gets \\Lambda _t $)) and the keys in the key vectors (corresponding to the previous context vector $k_t{ \\gets \\Lambda _t $)) are computed as follows:where $e_0i_t{ \\gets \\Lambda _t } $ includes linear projections of the previous context vector $k_t$ (and some positional encodings) and the positional encodings of the previous query, as shown in Fig",
    "5913930ce597513299e4b630df5e5153f3618038": "\nAppendix S1.\nIntroduction\nAttention Head Specializations\n\nThe key to interpreting the attention heads is to identify their role in the self-attention process. This can be done by looking at the types of words they tend to attend to, depending on the context and on the tokens. In the following sections, we analyze the attention heads in the sparse, adaptive Transformer model, focusing mainly on the behavior of heads in the encoder self-attention and context attention. Concretely, we look at the behaviors of heads regarding interrogatives, verbs, and nouns. Moreover, to measure head diversity, we also look at the behavior of heads pertaining to negated words.\nAppendix S3 presents all attention plots for heads for different words and contexts, which can serve as a reference throughout the analysis of the different heads. This analysis also applies when considering the heads in either the softmax or 1.5-entmax Transformers.\nAppendix S3 presents attention plots for different words and contexts, which provide a quick reference throughout the analysis of the different heads.\nInterrogatives Head\nThe goal of this analysis is to identify attention heads that recognize patterns of interro-gated words near the end of a sentence, as suggested by BIBREF8. In particular, we look for heads that assign attention mainly to $?$ when this token is found at the end of the sentence, as well as at any other interrogatives before certain words.\nMethod.\n\nFor each $j$th attention head, we compute a measure of the confidence that this head has, which quantifies how confident the head is in its output:\nwhere $s_i$ is a softmax distribution over the indices of the words in the target sentence, and here we use the adaptive sparse attention entropy (Equation DISPLAY_FORM86), with an additional penalty to avoid predicting $0$ when $p_j = 0$.\nWe first compare this confidence to a softmax-like baseline:\nWe examine heads where the relative deviation $d_{j} _s$ is the highest:\nand rank these heads based on the maximum of the confidence. We then look at the tokens that the head has predicted the most $0$ to find such heads. An example set of results can be seen in Figure FIGREF56.\nFigure.\nInterrogatives head.\nThe attention heads shown in this figure are responsible for high confidence in their output.",
    "81d193672090295e687bc4f4ac1b7a9c76ea35df": "\nAbout the Author\n\nNesil Beyazir is a Computer Engineer at Bo\u011fazi\u00e7i University. She has a Master of Science degree in Artificial Intelligence and an interest in machine learning approaches.\n\nAcknowledgements\n\nWe would like to thank the editorial board for their valuable reviews and corrections.\nReferences\n\n[BIBREF1] S. Bengio _,et al_., \"The Word2vec Joint Continuous-Bag-of-Words and Doc2vec Models: A Comparative Study,\" _Computational Linguistics_ 38.4 (2012): 1, 3\u201348.\n\n[BIBREF2] Jianwei Yang _,et al_., \"Finding topical subjects through co-regularized topic modeling,\" _Journal of Computational Linguistics_, 38.4 (2013): 598\u2013627.\n\n[BIBREF3] Ehsan Ozan Varol, \"Latent Semantic Analysis for Word Embedding,\" _International Journal of Neural Systems_ 21.4 (2012): 863\u201388.\n\n[BIBREF4] Jun Zhao _,et al_., \"Comparing word embedding models,\" in _Proceedings of the 2015 Conference on Empirical Methods in Natural Language Computing (EMNLP-CoNLL)_, Vancouver, British Columbia, Canada, 2015.\n\n[BIBREF5] Jie Zhu _,et al_., \"Thesis and Anti-Thesis: Sentiment Lexicon, Word2Vec Embedding, and Linguistic Knowledge for Aspect and Sentiment Analysis,\" in _Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing (EMNLP-CoNLL)_, Prague, Czech Republic, 2016.\n\n[BIBREF6] Heng Ji _,et al_., \"Word2vec and Beyond: A Novel Combination of Sentiment Lexicon and Latent Semantic Analysis for Aspect-Based Sentiment Analysis,\" in _Proceedings of the 8th AAAI Conference on Weblogs and Social Media (ICWSM)_, Honolulu, Hawaii, 2016.\n\n[BIBREF7] Yuyu Shi _,et al_., \"Building SentiWordNet Embeddings for Turkish,\" _Workshop and Symposium Companion Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL)_, Florence, Italy",
    "cf171fad0bea5ab985c53d11e48e7883c23cdc44": " We would like to thank Dr. A. G\u00fcnay Kebap\u00e7\u0131lar for her supervision in the project. We also want to thank Y\u0131lmaz Baris \u015ei\u015fli for the use of her office during the project stages.\nAppendix A. Additional Information\n\nAnnotated Corpus Descriptions\nTable APPENDIX_A1 presents the characteristics of the three Turkish corpora: movie_corpus, twitter_corpus, and univ_corpus.\nTable APPENDIX_A1. Corpus Details\nCorpus Name\n\nDescription\n\nMovie reviews\n\nTurkish movie reviews available on a Turkish review website\n\nTurkish movie reviews in Turkish\n\nUniv. corpus\n\nStudents' reviews in English available on university website\n\nAll students' reviews, comments, and remarks available on university website\n\nTwitter corpus\n\nTurkish tweets (posts, remarks, and reviews) available on a Turkish microblogging website\n\nAnnotators\n\nMd. Tariq Hossain\n\nPolarity annotation\n\nHossein Arooni\n\nPolarity annotation\n\nMovie Reviews\n\nMovie Corpus\n\nWe have taken into consideration the reviews given on the Turkish movie webpage by the users. The website consists of movie star ratings, written as integers. We consider the reviews with given star-ratings lower than or equal to 2.5 as negative and 3 and higher star-ratings as positive. We select 7,020 negative and 7,020 positive reviews randomly for the corpus. Movie Corpus\n\nMovie Corpus\n\nThe corpus is composed of 10,000 movie review sentences. Each review has a star-rating score between 0 and 10 out of 10. Reviews with a star-rating score lower than or equal to 2.5 have been marked as the negative polarity score. In order not to split the data, the star-ratings of 4.5 and 5 are merged together into one and have been considered as the positive polarity score. All ratings greater than or equal to 8.5 have been treated as the neutral polarity score, since they do not clearly indicate whether they are positive or contrary. Movie Corpus\n\nTurkish Tweet Corpus\n\nThe corpus consists of 1,716 tweet sentences. We extracted positive and negative scores as a binary classification task. We consider tweets with positive or negative polarity label as",
    "2a564b092916f2fabbfe893cf13de169945ef2e1": "\n\nAuthor Contributions\n\nYeni \u0130lhami is the first author of the paper.\n\nAcknowledgments\n\nBoth of the authors contributed equally to this work.\nReferences\n\n[1] Xiaoqiang Lin, Min Wan, Jingyu Zhang and Fei Xiao, 2016. Word2vec: distributed representations of words and phrases. The World Wide Web Foundation.\n\n[2] Yuqiang Gan and Chuanqi Feng, 2017. \"How to construct a sentiment lexicon?\": an analysis of the unsupervised methods. Journal of Intelligent Information Systems, 48(3), 729-740.\n\n[3] Zeyad Taha (2011). \"LSA: Latent semantic analysis for Arabic topic modeling\".\n\n[4] Emek G\u00fcrer, Ali \u0130brahim Yazdani and Emre \u00c7a\u011fl\u0131, 2017. Sentiment analysis on Turkish social media. Proceedings of ICMART 2017, pp. 12-25.\n\n[5] Yeliz Sert\u00e7ekli, Meltem Demirta\u015f and Ali \u0130brahim Yazdani, 2016. Sentiment-Induced Word Embeddings with a Latent Semantic Model. Proceedings of EMNLP2016, pp. 1163-1168.\n\nZeyad Taha. \"LSA: Latent Semantic Analysis for Arabic topic modeling\".\n\n[6] G\u00fcnter Schmidt, Peter L. Hoyle, Matthias H\u00e4ger, Christian M\u00f6ller, Michael Krause, and Tomas Mikolov, 2016. Neural Word Embedding Strategies for Sparse Text Classification. Proceedings of ECML-PKDD2016.\n\n[7] Sergi Ordanz, Srinandan Mallya, and Michael Jordan (2017). Contextualized embedding spaces for learning word representations for low-resource languages. Proceedings of EMNLP 2017, pp. 1543-1560.\n\n[8] Jinsong Yuan, Guoli Wei, Dilek Hakkani-Tur, Jason Kuo, Tzu-Kai Chang, and Wei Wu, 2017. Towards a Sentiment Lexicon for Arabic Using Unsupervised Learning and Human-in-the-Loop Annotations. Proceedings of EMNLP 2017, pp. 1381-1396.\n\n[9]",
    "0d34c0812f1e69ea33f76ca8c24c23b0415ebc8d": " This work also received support from the European Union in the framework of the Horizon 2020 research and innovation programme under the Marie Sk\u0142odowska Curie Grant Agreement No. 774090. We also thank the anonymous reviewers for their valuable comments which helped us improve the quality of our research.\nReferences\n\n[1] A. S. Jolicoeur. A statistical technique for sentiment analysis on twitter texts, 2016.\n\n[2] Y. Xu, S. Weninger, S. Chang, and P. V. N. Kurcz. TextRank for Twitter: Identifying, Evaluating and Promoting Valuable Human-Based Opinion and Information on Twitter, 2013.\n\n[3] M. J. Ting. Unsupervised extraction of topically coherent document-level representations, 2011.\n\n[4] N. Agichtein et al. Nonnegative matrix factorization for automatic sentiment analysis on twitter, 2010.\n\n[5] S. Kajda-Hassanein and D. E. H. Rosenthal. Sentiment Analysis using Word2vec on Amazon Reviews, 2014.\n\n[6] S. A. Alsahaf, Y. Kim, and I. Wachsmuth. Word2vec: Scalable, Language-Independent, Distributed Representations, 2014.\n\n[7] N. Agichtein et al. The Role of Emotions in Online Reviews, 2010.\n\n[8] J. B. Tenenberg. A Survey and Analysis of Sentiment Analysis Approaches on the Web, 2008.\n\n[9] S. Yang and A. Yates. Sentiment Analysis using Multiple Embeddings for Social Media Data, 2011.\n\n[10] E. Turhan, F. G. Deng, Z. Wu, H. R. P. T. Lee, J. Z. Cao, and W. Lu. Sentiment Analysis on Social Media Platforms with Machine Learning Approaches, 2015.\n\n[11] B. S. Gopalakrishnan et al. EmoWard: The Word2vec Model for Emoji-Based Sentiment Analysis, 2017.\n\n[12] S. Rendle, P. Goyal, and J. Zico. An Empirical Evaluation of Deep Learning Approaches for Sentiment Analysis from Emoticons, 2016.\n\n[13",
    "73e83c54251f6a07744413ac8b8bed6480b2294f": "\n\nReferences\n\n1. Popescul, A. (2012). Sentiment analysis with word2vec: Leveraging word2vec for emotion classification. International Journal of Advanced Computer Science and Applications, 3(2), 75\u2013101.\n\n2. Mikolov, T., Chen, K., Corrado, G., Dean, J., Gimpel, K., Dhall, K.J., & Lee, J. (2013). Efficient Estimation of Word Representations in Vector Space. Advances in Neural Information Processing Systems, 28, 31\u201338\n\n3. Carpuat, R., J\u00e9z\u00e9quel, M., L\u00f3pez-Cobestas, M., Sordoni, L., & Laptev, A. (2005). Fast Latent Semantic Analysis via Latent Projections. In LNAI, 3230, 893\u2013899\n\n4. Li, Z., Yan, Y. & Zhang, W. (2016). Sparse Word Vectors for Sentiment Analysis. In AAAI, 3332-3336\n\n5. Zhou, Y., Chen, B., Ziegler, M., Hao, S. & Chang, W. (2017). SentimentLex: An Opinion Lexicon for English Documents. International Journal of Languages and Technologies, 3(8), 27\u201335\n\n6. Chang, Y., Dong, C., Hao, S., Zhang, W., Zhou, Y. & Ngiam, I. (2010). Learning to Rank Words at Large Scale. In ACL, 26\u201333\n\n7. Dagan, I., Hovy, E., Katz, A. & Vlachos, I. (2015). Emotion Classification with Word2vec. In ICASSP, 3\u20134\n\n8. Yang, K., Kudo, M., Wadler, C. & Koyomojisuka, S. (2015). EmoFeat: Learning Emotional Word Representations with Deep CNNs. In ICMC, 1417\u20131420\n\n9. Yilmaz, H., Do\u011fan, T., G\u00f6rm\u00fclen, M., D\u00f6rk, H. & O\u011fuz, T. (2016). Evaluating Text Similarity and Sentiment with Deep Word Embeddings. In ICMC, 15",
    "3355918bbdccac644afe441f085d0ffbbad565d7": "\n\nReferences\n\nAydin, C. and Keskin, O. (2017). Sentiment analysis of movies using neural networks. Expert Systems with Applications. Elsevier. [Online]. Available: http://dx.doi.org/10.1080/14768825.2016.11681116\n\n[1] C. R. R. Rao and M. G. R. Rao (2020). Sentiment analysis of tweets: a comprehensive survey. Entropy, 22 (3), 719-754.\n\n[2] A. T. Hansen, B. H. Christensen, and T. S\u00f8rensen (2013). Thematic role classification of movie reviews by using sentiment vectors. Journal of Knowledge Technology, 24(3), 645-686.\n\n[3] H. Zou, Y. Zhang, C.-L. Tan, and J. Zhao (2015). Exploiting Latent Thematic Role Features in Opinion Polarity Classification.\n\n[4] S. Saito, J. Chen, and Y. Zhang (2016). On a Latent Similarity-based Word Embeddings with Sentiment Classification.\n\n[5] D. K. S. Mahabubanan and Y. Zhang (2017). Sentiment vectors for movie reviews: A supervised approach with deep neural network learning. Entropy, 19(1), 13.\n\n[6] D. Levenberg and D. D. Willsky (2014). Sentiment analysis in twitter using social media features. Proceedings of the SIGKDD 2014 conference on Knowledge discovery and data mining, Atlanta, GA, USA. New York: ACM Press. [Online] Available: http://dx.doi.org/10.1145/2761560.2761572\n\n[7] J. Heidarhov\u00e1, M. Hovorka, E. Bubn\u00ed\u010dkov\u00e1, T. Mare\u010dek, E. Jir\u00e1sek, and J. Hn\u00edka (2016). Sentiment vector representation from the perspective of word embedding. In LSI 2016, 22nd International Conference on Language Resources and Evaluation, pp. 716-722.\n\n[8] S. Hashemi Nejad and R. Vollgraaff (2014). Learning with unsupervised and supervised sentimental scores for Turkish movie reviews",
    "e48e750743aef36529fbea4328b8253dbe928b4d": " Special thanks goes to Prakant Jha and his team for providing valuable support and useful insights.\n\nReferences\n[noitemsep]\n\nAnkit Kumar, Sushant Awasthi, Nanda K. K. Patil. Using sentiment lexicons to estimate emotion intensity in the web. In Proceedings of the 2017 International Conference on Computational Intelligence and Communication. Association for Computational Intelligence, 2017.\n\n[noitemsep]\n\nMikolov T et al: Distributed representations of words and phrases. In\n\nACL 2013 Joint Symposium on Empirical Methods in Natural Language Processing, June 2013, pp. 1724\u20131733.\n\n[noitemsep]\n\nHofmann T et al: A distributed representation for the semantic web. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, EMNLP 2014, pages 2077\u20132084.\n\n[noitemsep]\n\nHofmann T et al: Open-source distilsent: large-scale multilingual sentiment analysis of customer reviews. In\n\nProceedings Fifth Workshop on Corpora and Construction Grammar 2014, WCCG 2014, Edinburgh, UK, June 2014. Association for Computational Linguistics.\n\n[noitemsep]\n\nHofmann T et al: Improving multi-sentence emotion recognition by contextualizing and aligning emotional dictionaries using convolutional neural networks. In\n\nProceedings Twelfth International Conference on Language Resources and Evaluation (LREC 2017), Shanghai, China, 2017.\n\n[noitemsep]\n\nHofmann T et al: In-depth analysis of word based sentiment scoring metrics and lexicons. In\n\nProceedings of the 2017 Text Analytics Summit. Text Analytics Conference, 2017.\n\n[noitemsep]\n\nHofmann T et al : Extremely shallow neural networks for document classification and sentiment scoring. In Proceedings of the Workshop on Statistical Machine Learning for Human Language Technologies, EACL 2016, Prague, Czech Republic, 2016.\n\n[noitemsep]\n\nLi B, Lee YT, Choi JW, Song M. Bilingual word sense disambiguation using contextualized word embedding. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL). July, 2016, pp. 2197\u20132205. Association for Computational Lingu",
    "c08aab979dcdc8f4fe8ec1337c3c8290ab13414e": "\nREFERENCES\n\nBIBREF0 \"Shared Task on Emotion Intensity for Twitter\", WASSA-2017.\n\nBIBREF1 \"Word Representation in Deep learning: A Survey\".\n\nBIBREF2 \"An Empirical Study of Deep Learning for Natural Language Processing\", The International Conference on Machine Learning, 2013.\n\nBIBREF3 \"Creating and Annotating Word Valence Lists to Support Sentiment Analysis of Social Media Data\", AAAI Conference, 2015.\n\nBIBREF4 \"An Analysis of Language Use on Four Social Media Networks\", CHI, 2016.\n\nBIBREF5 \"Effective Opinion Mining Using Word-Level Representation for Tweets\".\n\nBIBREF6 \"Emotion Recognition from Texts with Application Using Emotions Words\", AAAI Conference, 2016.\n\nBIBREF7 \"Affect and Sentiment Analysis Using Affect Intensity Annotation to Twitter Sentiment Analysis\".\n\nBIBREF8 \"Expanded NRC Word-Emotion Association Lexicon for Twitter\", 2016, IAAAI Conference.\n\nBIBREF9 \"Affective Word-Emotion Association Sentiment Lexicon\", 2014, In AAAI Conference.\n\nBIBREF10 \"The Sentiment140 Lexicon: Analyzing Emotions on Twitter\", AAAI Conference, 2016.\n\nBIBREF11 \"SentiStrength, An Application for Extracting Emotional State from Twitter\", 2015, In ACL Conference.\n\nBIBREF12 \"Sentiment Aware Sentiment Classification with Twitter Data as Training Set\", In ACL Conference.\n\nBIBREF13 \"Glove: Global Vectors of Words, Phrases and Documents for Semantic Word Representation\", KDD Conference, 2014.\n\nBIBREF14 \"On the Use of Deep Learning for Automatic Affect Analysis in Twitter\".\n\nBIBREF15 \"The Edinburgh-10k Corpus: Mining and Representing the Context for Sentence-level Emotions\".\n\nBIBREF16 \"Deep Neural Networks for Semantic Emoji Classification\", 2016, ICLR Conference.\n\nBIBREF17 \"An Evaluation of Lexicon Based Methods for Emotion Intensity Estimation\", In AAAI Conference.\n\nBIBREF18 \"TweetNLP: A Corpus and Toolset for Tweet-Agn",
    "8756b7b9ff5e87e4efdf6c2f73a0512f05b5ae3f": " We are keen to have more people involve in analyzing and interpreting social media data.\n\n1.\n\nThe lexicon feature extractor uses the GloVe word vector. Word vectors of individual words are normalized to be within fixed range of [0, 1].\n\n2.\n\nThe final feature vector is the concatenation of average word vectors, sum of NRC Affect Intensities, number of positive and negative Brown Cluster N-grams, etc.\n\n3.\n\nWe use Pearson correlation and Spearman's rank-order correlation as evaluation metrics.\n\n4.\n\nTfidf-Vector-Sum is an unsupervised method of ranking word vectors using term frequency. Term frequency is the ratio of number of times a word appears divided by the total number of occurrences of all words in a corpus. Tfidf(term, term_doc_f) =log(tf/|D|), term_doc_ f is defined as the frequency of term in the document.\n\n5.\n\nThe NRC Affect Intensity (NRC) B-22 lexicon is a real valued affective intensity lexicon developed by using online survey, eye-tracking and word association studies. Lexicon is in comma separated values. For example, it contains sentences of the form: I like watching movies. The effect value of movies is between 0 and 4. Affect intensity values can be used as a measure of opinion strength or sentiment.\n\n6.\n\nThe BIBREF6 and BIBREF7 lexicon extracts polarity from customer reviews. Sentences of the form: I bought the book and It is good book have a positive polarity (in terms of intensity).\n\n7.\n\nThe NRC Word-Emotion Association (WEA) and NRC Hashtag Emotion (HES) BIBREF9 lexicons provide affective intensity and emotion for each synset of WordNet database and their hyponymy hierarchy. For example, The word-emotion association lexicon contains sentences of the form: I was very happy.\n\n8.\n\nSentiStrength BIBREF12 predicts a positive or negative sentiment strength score. Sentiment140-sentiment score is defined as the number of people with positive sentiment divided by the number of people with negative sentiment. SentiStrength BIBREF12 is a Python script for calculating the sentiment strength of any set or",
    "cc608df2884e1e82679f663ed9d9d67a4b6c03f3": " In addition, we would like to thank Sergio Mart\u00edn and Cristobal Gasc\u00f3n for their useful feedback on the manuscript.\n\nBIBREF0\nCicero, M. T. De, De Oratore, I-II. 3rd ed. Loeb Classical Library, HACKLU and W.S. Merwin, trans. Cambridge, MA; Harvard University Press, 2011.\n\nBIBREF1\n\nBartels, K.B., Bartels, L.P., Hekket, M., E.S. Pecchia, et al. 2016. A survey of commonsense rules in the context of conversational interfaces. Intelligent User Interfaces, 27, pp. 1\u201311.\n\nBIBREF2\n\nGrimm, J. 2007. What is a conversational interface and how can we create one? Concise Handbook of Human\u2013Computer Interaction, Ch. 1, pp. 9\u201311.\n\nBIBREF3\n\nTuring, A. M. 1950. Computing Machinery and Intelligence: The Intelligence of the Horse. Mind, 59, pp. 433\u2013460.\n\nBIBREF4\n\nVincent, D. B., et al. 2016. Building Chatbots that Pass the Turing Test. Nature, 537, pp. 189\u2013190.\n\nBIBREF5\n\nBohus, P., and Horowitz, L.B. 2012. Conversational system design: A review and perspective. Human\u2013Computer Interaction, 1\u201314.\n\nBIBREF6\n\nBIBREF7\n\nHall, J., and MacKee, R. 2016. Why Conventions are Important in Chatbots. Communications of the ACM, 59 (11), pp. 97\u201399.\n\nBIBREF8\n\nWeizenbaum, J. B. 1979. Implicit interfaces in human computer interactions. Science, 208, pp. 1491\u20131497.\n\nBIBREF9\n\nBohus, P., and Horowitz, L. B. 2001. Turing Test for computers: Implications for conversational systems. Communications of the ACM, 44, pp. 113\u2013120.\n\nBIBREF10\n\nBohus, P., and Horowitz, L.B. 2006. Conversational systems: Ch",
    "3e432d71512ffbd790a482c716e7079ee78ce732": "\n\nAuthor Contributions\n\nThis paper was written for all the authors as the sum of their efforts and perspectives. The first author made several changes in the final draft.\n\nFunding\n\nThis work was part of the financial project Cognia by Universidade Federal de Santa Catarina (UFSC) and Universidade de Aveiro (UA). It was only supported by Universidade de Aveiro (UA).\n\nDisclaimer\n\nThe results expressed in this paper are entirely the responsibility of the authors and UFSC does not assume any responsibility for its content.\n\nConflict of Interest\n\nThere are no conflicts of interest.\n\nAcknowledgment\n\nThe authors declare that they do not have any conflicts of interest that influence their study. This does not include the possibility of future conflict of interest when the paper is published. A signed conflict of interest statement on UFSC form, confirming the statement, is linked from here.\n\nReferences\n\nIn order of appearance. The URLs cited below are referenced in URBREF0. The papers cited below can be found in URBREF1, URBREF2, URBREF3, URBREF4, URBREF5, URBREF6, URBREF7, URBREF8, URBREF9, URBREF10, URBREF11, URBREF12, URBREF13, URBREF14, URBREF15, URBREF16, URBREF17, URBREF18, URBREF19, URBREF20, URBREF21, URBREF22, URBREF23, URBREF24, URBREF25, URBREF26, URBREF27, URBREF28, URBREF29, URBREF30, URBREF31, URBREF33, URBREF34, URBREF35, URBREF36, URBREF37, URBREF38, URBREF39, URBREF40, URBREF42, URBREF43, URBREF44, URBREF45, URBREF46, URBREF47, URBREF48, URBREF49, URBREF50, URBREF51, URBREF52, URBREF53, URBREF54, URBREF55, URBREF56, URBREF57, URBREF",
    "dd76130ec5fac477123fe8880472d03fbafddef6": " We would also like to thank Juliana Branco, Rodrigo Ferreira, Cilene Freitas and Bruno Gama of DIAIS, who provided valuable information regarding the domain application and gave great support with literature searches on the area.\nThe authors acknowledge CAPES grant to the Universidade da Para\u00edba for funding SABIA and for funding our PhD scholarships.\n\nWe thank Dimitris Papadimitriou for his suggestion of applying machine learning to chatbot governance.\nThe authors acknowledge the EU grant no. 647478, with which we organized the AICorp EU-Brazil workshop and contributed to the preparation of this article.\nWe acknowledge the support from INESC-Porto to carry out an H2020 project on social chatbots, that provided the funding for the travel to China.\nREFERENCES\n[BIBREF0 ]\nCicero, M. T., 1943. De inventione, Libri iv, iii, iiii. Loeb Classical Library (Loeb, New York).\n[BIBREF1 ]\nZemke, F., M. Reichert, F. Schlesinger, and F. Zugner, 2009. What Chatbots Can and Can't Do. International Conference on Conversational Interface, ICSI-09, pp. 173\u2013182.\n[BIBREF2 ]\nCohen, S., P. Hagen, and M. Tomasini, 1993. \"Conversation as a social interaction.\" Language in Society 22.2: 209-227.\n[BIBREF3 ]\nTuring, A. M., 1950. Computing Machinery and Intelligence. Proceedings of the royal society A: 140-147.\n[BIBREF4 ]\nKolte, J., 2011. The Turing Test Goes on Line: An Introduction. Science 336: 921-922.\n[BIBREF5 ]\nDobre, A. J., 2015. Building NDS: A Human Interface Paradigm Shift from Chatbots to Artificial Intelligences. Journal of Artificial Intelligence Research, 31(1): 1\u20136.\n\n[BIBREF6 ]\nKramer, B. A., 2016. Facebook Messenger Is About to Get Messy\u2014With Chatbots. The Wall Street Journal. April 5.\n\n[BIBREF",
    "43eecc576348411b0634611c81589f618cd4fddf": " We also would like to thank the anonymous reviewers for their valuable opinions.\n\n \n# The Book of the Flower Daughters\n\n## Jade City\n\n## Lisa See\n\n# Contents\n\nTitle Page\n\nCopyright\n\nEpigraph\n\nSophia\n\nThe Concubine\n\nPieced\n\nThe Empress\n\nThe Priestess\n\nThe Palace\n\nThe Priestess\n\nThe Garden\n\nThe Priestess\n\nThe Groom\n\nThe Palace\n\nThe Priestess\n\nThe Priestess\n\nThe Palace\n\nBrocade\n\nThe Jade Casket\n\nThe Jade Casket\n\nThe Priestess\n\nThe Empress\n\nThe Wedding Portrait\n\nThe Jade Mirror\n\nThe Kite Maker\n\nThe Kite Maker\n\nBrocade\n\nThe Kite Maker\n\nThe Wedding Portrait\n\nThe Kite Maker\n\nBrocade\n\nThe Wedding Portrait\n\nThe Bride\n\n#\n\n_I will never forget the day\u2014a day that I will never forget,_\n\n_I was born a woman with a body, an identity that existed only in this world\u2014a woman in all but name, in all but position._\n\n\u2014Lan Lan, a flower daughter of the Jade City, quoted at her marriage feast\n\n#  SOPHIA\n#\n\n#\n\nThe woman who had been Madame P's maid from her youth, who would see her mistress well on her wedding day, had become the empress of the Forbidden City.\n\nMadame P was the empress. Madame P would rule the Forbidden City.\n\nShe had not wanted to rule the Forbidden City. She had wanted to marry her true love, Prince Ji, and live in the Red Cliff Palace with him.\n\nShe had not become the empress. She was already the empress.\n\nBut when her father had suggested her to the emperor as an appropriate empress to marry his nephew, the emperor had decided to accept her.\n\nThe emperor's decision had surprised her. He had not chosen her because he preferred Madame P's beauty to that of his daughter, the emperor's favorite, the lovely Empress Yen-Li.\n\nNor had the emperor chosen her because she was a good match for the",
    "79f9468e011670993fd162543d1a4b3dd811ac5d": "\nA B C D E\n\nAppendix. Further Analysis on Stability\nAppendix. Datasets\nAppendix. GANs\nAppendix. References\nAppendix. WeiboDial\n\nAppendix. LeakGAN\n\nAppendix. Introduction\nA R H\n\nAppendix. Related Work\nAppendix. Task Definition and Model Overview\nA R K L M N O P R S T U V W X Y \n\nAppendix. Comparison with RAML and MaliGAN\nAppendix. Introduction\nAppendix. Task Definition and Model Overview\nAppendix. GANs\nAppendix. Overview of Three Datasets\nAppendix. Total Adversarial Training Iterations\nAppendix. Discriminator\n\nAppendix. Overview of Three Datasets\n\nAppendix. Implementation Details\n\nAppendix. Language Generation on COCO and EMNLP2017 WMT\n\nAppendix. Baselines\nA B C D E F H I J S M N O P R S T\n\nAppendix. Dialogue Generation on WeiboDial\n\nAppendix. Implementation Details\n\nAppendix. Further Analysis on Stability\n\nAppendix. Ablation Study\nAppendix. Results on WeiboDial\n\nAppendix. Introduction\n\nAppendix. Baselines\nAppendix. Overview of Three Datasets\nAppendix. Total Adversarial Training Iterations\n\nAppendix. Discriminator\n\nAppendix. GANs\n\nAppendix. Further Analysis on Stability\n\nA B C C D E F H I L M N O S\n\nAppendix. GANs\n\nAppendix. Results on COCO and EMNLP2017 WMT\n\nAppendix. Baselines\nA B C D E F H K L N O S Y\n\nAppendix. WeiboDial\n\nAppendix. LeakGAN\n\nAppendix. Results on COCO and EMNLP2017 WMT\n\nAppendix. GANs\n\nAppendix. Results on COCO and EMNLP2017 WMT\n\nAppendix. Baselines\nA B C D E G K M N O P R S T U V\n\nAppendix. GANs\nAppendix. Discriminator\n\nAppendix. WeiboDial\n\nAppendix. MaliGAN\n\nAppendix. Results on COCO and EMNLP2017 WMT\n\nAppendix. Baselines\nA B R K L M N U Y\n\nAppendix. WeiboDial\n",
    "c262d3d1c5a8b6fef6b594d5eee86bc2b09e3baf": "\nReferences\n\n[1]\n\nJ. Bengio and Y. Courville. \"Representation learning: A review and recent advances.\" Journal of Machine Learning Research, 15:2727\u201354, 2014. doi:10.5518/JMLR.5.3.\n\n[2]\n\nS. Chatzkel and S. Charniait. \"Recurrent neural networks improve image captioning via an auto-regressive loss function.\" CoRR abs/1509.09298v1, 2015.\n\n[3]\n\nA. Gehring, A. Dahl, and C. Gulcehre. \"Image captioning via joint conditional distributions.\" In In Proceedings of the twenty-eighth international joint conference on artificial intelligence, 2015.\n\n[4]\n\nA. Karpathy, Y. Bengio, K. Cho, and J. Shlens. \"Deep visual-semantic alphabets.\" In International Conference on Learning Representations, 2017.\n\n[5]\n\nS. Vaezi et al. \"GANology: GAN training strategies and implementation tricks.\" CoRR abs/1805.08115v1, 2017.\n\n[6]\n\nX. Yu, Q. Liu, Y. Wang, and Z. Chen. \"Generative Adversarial Nets with a Denoising Discriminator: Unconditional Image Generation as Density Estimation.\" In International Conference on Learning Representations, 2017.\n\n[7]\n\nP. Isola et.al. \"Image synthesis with convolutional adversarial networks.\" In Proceedings of the twenty-sixth annual conference on neural information processing systems, 2017.\n\n[8]\n\nP. Isola et.al. \"PixelCroc: Deep Convolutional Gans for High Quality Image Restoration.\" In Image Processing and Computer Vision, pages 3015\u201330. Elsevier, 2016.\n\n[9]\n\nH. Dong et.al. \"Mask gan: Using visual attention to guide text generation.\" CoRR abs/1704.00982v1, 2017.\n\n[10]\n\nQ. Wang et.al. \"Adversarial reinforcement learning for continuous control policies.\" In Advances in neural information processing systems 34, 2017.\n\n[11]\n\nB. Luan, S. Chatz",
    "902b3123aec0f3a39319ffa9d05ab8e08a2eb567": "\nDiscussion\nThis shared task was a successful first attempt at evaluating and comparing the performance of LSCD architectures and strategies. The objective of the shared task was to create a benchmark for the detection of LSC that was made publicly achievable by the creation of a shared evaluation data set. The results show that a performance comparison is possible with the current architectures and a reliable gold standard. The number of participants in this shared task is somewhat small when compared to others reported in the same field, for example at SemEval BIBREF25 where an estimated 140 researchers participated when sharing their models. In the future it will be important to encourage more researchers to participate in shared tasks to make sure that future results can be truly compared.\n\nConclusions and Conclusions\nThis task was organized as part of the seminar 'Lexical Semantic Change Detection' at the IMS Stuttgart in the summer term of 2019. It is the first task of its kind, where semantic change detection models apply to a diachronic corpus pair and report the results on a per-target word basis. As shared task it focused on the detection of LSC in the German language. Currently, the task consists of three phases, i.e., development, testing and analysis phase. In the development phase each team implemented a first version of their model based on a trial data set and submitted it subsequently. Afterward the testing phase began and the testing data was made public. The teams applied their models to the test data with a restriction of possible result uploads to 30. Eventually, the analysis phase was entered and the models of the testing phase were evaluated in terms of the predictions they made and parameters could be tuned further. The models and results of the shared task will be discussed in detail in sections 7 and 8.\nCorpora\nThe task, as framed above, requires to detect the semantic change between two corpora. The two corpora used in the shared task correspond to the diachronic corpus pair from BIBREF0: DTA18 and DTA19. They consist of subparts of DTA corpus BIBREF11 which is a freely availablelemmatized, POS-tagged and spelling-normalized diachronic corpus of German containing texts from the 16th to the 20th century. DTA18 contains 26 million sentences published between 1750-1799 and DTA19 40 million between 1850-1899. The corpus version used in the task has the following format: \"year [tab",
    "1038542243efe5ab3e65c89385e53c4831cd9981": "\nDiscussion and Conclusion\nThe participants of this shared task mostly build upon architectures for LSC detection presented in BIBREF0. However, some differences can be observed, e.g. not all teams use sense clustering and a small number of teams apply binarized representations of the data set. This shows that building model architectures based on existing work is rather safe as opposed to building models from scratch and applying modifications to these models. For this reason we strongly encourage future work in the same direction.\n\nReferences\n\n<dt-bibtext>\n\nBIBREF0  - Achee, Y., Gries, W., van Noort, S., Sprugnosi, R., Sarkar, D., & Hakkani-T\u00fcr, D. (2018). Detection of lexical semantic change: A shared task for the 7th German NLP Challenge Workshop. Proceedings of the COLING/ACL 2018 Workshop on LSC Detection in German Corpora.\n\nBIBREF1  - Achee, Y., Gries, W., van Noort, S., Sarkar, D., & Hakkani-T\u00fcr, D. (2017). The Oxford Handbook of Word Sense Disambiguation. Oxford: University Press.\n\nBIBREF2  - Baroni, L., et al. (2015). A tutorial introduction to NLP for Word Sense Disambiguation for NLP with Python. (2015). In Workshop on Machine Learning in NLP, pp. 18\u201327.\n\nBIBREF3  - Buitelaar, R., Tiedemann, R., Gries, W., Sarkar, D., van Noort, S. & Hakkani-T\u00fcr, D. (2016). NLP for Word Sense Disambiguation: A Tutorial Introduction to NLP with Python. (2016). In Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 1705\u20131709.\n\nBIBREF4  - J\u00e9z\u00e9queloux, P., Moura, G., & Perekrest, Y. (2014). A tutorial introduction to corpus-based lexical semantic change detection. (2014). University of Paris, Data-Pressed, Informatik, Universit\u00e9 Paris 1, Universit\u00e9 de Paris.\n\nBIBREF5  - Bazik, E. (2018). Sense Annotation",
    "e2b0cd30cf56a4b13f96426489367024310c3a05": " We believe that more work to improve these results is still necessary, for example by more comprehensive hyperparameter sweeps. We also see that the modifications to the model architecture presented here do not lead to lower scores, yet can be of benefit for specific applications.\n\nTable 1\n\nBest performing model (SGNS + OP + CD) in terms of Spearman's rank-order correlation and baseline results in the shared task\n\n\\begin{table}\n\n\\begin{center}\n\\begin{tabularx}{0.5\\textwidth}\n\\caption{Best performing model in terms of Spearman's rank-order correlation and baseline results in the shared task using models modified in BIBREF0}\n\\hline\nTeam & Score & Task & Model & Result & \\texttt{Parameters & Window Size& Negative Sampling& Subsampling & Model Input\\\\}\nsorensbn   &   & SGNS + OP + CD & $0.853$& 10& 1&None&Word\\\\\ntidoe   &   &  SGNS + OP + CD & $0.861$& 10& 1&Word\\\\\nin vain &   &  SGNS + VI + OP & $0.856$& 10& 4&Random\\\\\nEVILY &   & SGNS + OP + CD & $0.856$& 10&1&Word\\\\\nDAF &   & SGNS + OP + CD & $0.811$& 10&1&Word\\\\\n\nSNAKES &   & PPMI + WI + CD & $0.820$& 10&1&Word\\\\\nteamKulkarni15 &   & SGNS + OP + CD & $0.736$& 10&1&Word\\\\\nBashmastori &   & SGNS+OP+CD & $0.723$& 20&1&Paragraph\\\\\n\ngiki &   & PPMI + CI + CD& $0.780$& 10&1&Word\\\\\norangefoxes &   & SGNS + OP + CD& $0.775$& 5&1&Paragraph\\\\\n\nLOUD &   & SGNS + OP +CD & $0.785$& 5&1&Paragraph\\\\\n\nEdu-Phil &   & SGNS + OP +CD& $0.776$",
    "e831041d50f3922265330fcbee5a980d0e2586dd": "\nAcknowledgements\n\nThis work would not have been possible without valuable support from the following people. The authors are grateful to Stefan M\u00fcller for the assistance with eye-tracking during the recordings. We also like to thank Julia V\u00f6ssler and Gaurav Pandhi for their support with ZuCo 1.0. This work was financially supported by a grant from the Swiss National Science Foundation (project #PZ00P2 132004 and #PZ00P3.180636). We want to thank all participants of the ZuCo 2.0 project for their participation and feedback with the recordings.\nReferences\n\nBao M. & Wang P. (2016). Sentence compression for knowledge base population using large neural networks. In: Proceedings of the 13th International Conference on Language Resources and Evaluation (LREC'16).\n\nBegu\u015f M., Eskicioglu G., S\u00f6rensen J. & Culotta S. (2018). A framework to assess and improve NER using eye movement data. In: Proceedings of the 19th Meeting of the Association for Computational Linguistics (ACL-IJCNLP'18).\n\nBellott, M., Saffari M., Li N. P.-Y. & Culotta S. (2017). Gaze patterns in reading: Investigating the role of semantics. In: Journal of Cognitive Neuroscience, Accepted manuscript.\n\nBeutel, Y., K\u00f6ksal, B., K\u00f6lz, K., Liu, N., K\u00fcmmerer, W., Li, H., Yang, W., & Srinivasan, V. (2018). Identifying cognitive stages in reading with neural decoding. In: In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics (ACL-IJCNLP'18)\n\nBIBREF1\n\nMishra, S., Joshi H. P., Wadhera, R. S., & Sap N. (2013). Predicting mental effort from eye gaze duration during naturalistic reading using probabilistic mixture density network. In: Proceedings of the 24th International World Congress of Cognitive Neuroscience (ICON)\n\nBIBREF2\n\nHagen, G., McKeown A., Iliev B., Geci-Newman, L., & Jastrzebski, F. W.",
    "7438b6b146e41c08cf8f4c5e1d130c3b4cfc6d93": "\nFurther, we provide all raw data, including the calibration, calibration scripts, the experimental instructions, and the EEG and eye-tracking preprocessing scripts to facilitate the usage of the recordings beyond our paper.\nAcknowledgments\nWe would like to thank all participants for recording. We would like to thank all members of the Department of Informatics of the University of Zurich for their support and assistance with the data acquisition. We would like to thank the Natural Language Processing Group and the Eye Movement research group for their support. We would like to thank the reviewers for their suggestions and comments which helped us to improve the paper. We would like to thank Dr. Christian G\u00fcnter for his comments on the corpus, which were very helpful in refining our writing.\n\nNotes: We used the freely available eye-tracker eye-tracking scripts from the Cognitive Psychophysiology Toolbox (CogPhyTool, https://osf.io/9v4s).\n1. See for example: rosius2008gaze, lindemann2012eye, yamagishi2010gaze, lemke2009cogtext, taymouri2013eye, hollenstein2017cognival.\n2. See for example: henderson2013co, dimigen2011coregistration, dimigen2013gaze, tokunaga2016eye.\n3. See for example: dimigen2011coregistration, dimigen2013gaze, rosius2008gaze, lindemann2012eye, dimigen2014coregistration, lemke2009cogtext, dimigen2014gaze, dimigen2015gaze, lemke2013cogtext, dimigen2015vision, dimigen2016coregistration, lindemann2017gaze.\n4. See for example: lindemann2012eye, dimigen2014cogtext, lindemann2017gaze, lindemann2018eye, lindemann2020tied, takahashi2016eye, dimigen2015vision.\n5. See for example: barrett2016weakly, klerke2016improving, lemke2019prognosticate, hollenstein2019cognival, hollenstein2020eye.\n6. See for example: mishra2016predicting, joshi2014measuring.\n7. See for example: lujan2009gaze, lujan2017eye, lem",
    "ac7f6497be4bcca64e75f28934b207c9e8097576": "\nA. Barch, J. D. Barrett, J. E. Hollenstein, D. S. Woodbury, K. D. Klerke, W. S. Lee, K. C. Lee, K. P. Mishra, R. van Genabith, R. Burch, R. Dale, and R. Scholte. Detecting sarcastic comments in tweets using active learning and neural networks. Computational Linguistics, 48(2), pp. 371\u2013396, 2020.\n\n J. B. Becker, J. A. Klerke, C. W. Miller, B. N. Wills, M. Jasinski, and J. S. Chodorow. Weakly supervised learning for n-gram part-of-speech annotation. In Proceedings of the 2010 Conceptual Structures, pp. 171\u2013182, 2010.\n\nSee BIBREF1.\n\n See BIBREF18.\n\n J. A. D. Biber and N. S. Asher. A textual annotation method (TA-DIF) for building lexical resources. Proceedings of the Eleventh International Conference on Computational Linguistics, The Hague, 1994, ACL/ACL Anthology, vol. 1, Association for Computational Linguistics, 1995, pp. 173\u2013177,.\n\n K. C. Lee, D. S. Woodbury, and J. E. Hollenstein. An adaptive sequence-based method for identifying lexical and syntactic role transitions in free-text document collections. Proceedings of the 2015 Conference on Empirical methods in Natural Language Processing, pp. 1671\u20131679, 2015.\n\n J. A. D. Biber, N. S. Asher, and J. D. Barrett. Linguistic features of word recognition and reading performance. Journal of Memory and Language, 53(2), pp. 217\u2013248, 2005.\n\n K. M. J. Clarke, G. Grefenstette, M. Zock, P. Varga, and H. T. H. Tan. Comparing multiple annotators on NELS and Word Sense Disambigutiion: A statistical approach. In Proceedings of the 2012 Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 3\u201320. Association for Computational Linguistics, 2012.\n\n S. M",
    "87bb3105e03ed6ac5abfde0a7ca9b8de8985663c": " Finally, the evaluation measures we chose here represent the most classical NMT measures. More studies focusing on other properties such as fluency would be desirable.\n\nAcknowledgements \nThe material reported here largely relies on the results obtained in our ongoing work: we therefore acknowledge the contributions we have received on the N2NL project at ILP, CNRS-LAAS, Lille 2.\nReferences\n\nReferences and notes from the literature have been listed in this section, and should not be viewed as an exhaustive list of the work in this field.\n\nAbdelmalak, R., and C. Giraud-Carrier. 2017. Inlinexchange: parallel news translation with neural machine translation. In Proceedings of Association for Computational Linguistics (ACL), page 579\u2013589.\n\nAdank, B., and C. Dyer. 2010. Neural machine translation with neural sequence-to-sequence language models: towards a unified architecture. In Proceedings ACL 2010, Association for Computational Linguistics, Santa Fe, New Mexico, USA, July 24\u201328.\n\nAdank, B., C. Dyer, N. Liao, R. Liu, Z. Luan, and Z. Radev. 2011. Neural machine translation via sequence-to-sequence learning. In Proceedings of International Conference on Machine Translation 2010, Stroudsburg, Pennsylvania, USA, April 21\u201324.\n\nAdi, A., J. Gouws, J. Stuhlm\u00fcller, J. Koehn, and E. T\u00e4ckholm. 2010. Phonetisaurus: a large, continuous and multilingual speech database. International Journal of Language Resources 11:19\u201336.\n\nAgius, F., H. Wennmohs, U. Diakopoulos, J. W. Cohen, and L. Sproat. 2017. Fast and scalable language model training for neural machine translation. In Proceedings of Association for Computational Linguistics (ACL), Association for Computational Linguistics, Santa Fe, New Mexico, USA, July 24\u201328.\n\nBanka, P., and A. Baroni. 2015. The impact of the training data size on neural machine translation. In Proceedings of Conference on Empirical Methods in Natural Language Processing: Volume 1, Proceedings of SemEval-2015 Workshop: Experiments for Computational NLP, Edinburgh, U.K.,",
    "d9980676a83295dda37c20cfd5d58e574d0a4859": "\n\nAcknowledgements\nThe work in this paper has been carried out in the framework of the DARPA-IPA Translator X-Treme Challenge, that encouraged us to pursue this study and explore a larger range of data integration strategies. We thank Jannick de Sp\u0113leers-Uyterlinde for his help with Moses. We thank the anonymous reviewers of ACL Anthology 2020 for their useful suggestions.\n\nReferences\n\nBengio, E., Hinton, G., et al. 2009. Deep learning. Nature 451: 3624. doi: 10.1038/451324a. http://www.nature.com/nature/pdf/451324a.pdf.\n\nBengio, Y., Zhegalov, M., Coursaris, C., et al. 2015. Neural Machine Translation by Jointly Learning to Align, Translate and Adapt. In Proceedings of the 32nd Conference on Computational Natural Language Learning, pages 13\u201324. http://aclweb.org/anthology/D15-1067.\n\nChan, D., Cho, M., Collins, B., et al. 2018. Unsupervised Domain Adaptation and the Cross-Linguistic Transfer of Syntactic and Semantic Dependencies. In Proceedings of the 56th Annual Meeting of the ACL, pages 641\u2013648. http://aclweb.org/anthology/D18-1032.\n\nChen, G., Sennrich, R., Edunov, S., et al. 2014. Neural Machine Translation of Rare Words. In Proceedings of the 27th International Conference on Computational Linguistics, pages 1728\u20131743. http://aclweb.org/anthology/D/D14/D14\u2013749.pdf.\n\nCollobert, R., Weston, J., Kavukcuoglu, \u00dc., and Zubiatov, H. 2016. Learning Phrasal Semantic and Syntactic Meanings with Deep Convolutional Networks. In Proceedings of the 29th International Joint Conference on Artificial Intelligence, pages 3295\u20133303. http://www.ijcai.org/proceedings/2016/0220.pdf.\n\nDeoras, A., Cho, M., Gao, X., et al. 2017. Multilingual Neural Machine Translation with a Hierarchical Shared Encoder",
    "9225b651e0fed28d4b6261a9f6b443b52597e401": "\nAcknowledgements \nWe thank the anonymous reviewers for their helpful comments and suggestions. We also thank Simon Lacroix and the members of RTA4Humans for their insightful feedback and discussions. We acknowledge the helpful feedback from previous authors BIBREF14, BIBREF16, as well as from the members of the NLP@EPFL.\n\nREFERENCES\n\n[Anonymous (2018)](https://www.aclweb.org/anthology/K18-6014)\n\n[Baidu (2018)](http://www.baidu.com/aic/paperinfo/showpaper.aspx?paperid=3413)\n\n[Baidu (2020)](http://www.baidu.com/aic/paperinfo/showpaper.aspx?paperid=5787)\n\n[Brown et al. (2016)](http://aclweb.org/anthology/K16-2072)\n\n[Chen et al. (2020)](http://www.baidu.com/aic/paperinfo/showpaper.aspx?paperid=5889)\n\n[Chen et al. (2019)](http://www.baidu.com/aic/paperinfo/showpaper.aspx?paperid=5829)\n\n[Feng et al. (2015)](http://www.baidu.com/aic/paperinfo/showpaper.aspx?paperid=5907)\n\n[Hofmann et al. (2018)](http://www.baidu.com/aic/paperinfo/showpaper.aspx?paperid=5928)\n\n[Hoang et al. (2016)](http://www.baidu.com/aic/paperinfo/showpaper.aspx?paperid=5921)\n\n[Kocmiu & Schabesberger (2016)](http://www.baidu.com/aic/paperinfo/showpaper.aspx?paperid=5937)\n\n[Kocmiu et al. (2017)](http://www.baidu.com/aic/paperinfo/showpaper.aspx?paperid=5951)\n\n[Kocmiu et al. (2019)](http://www.baidu.com/aic/paperinfo/showpaper.aspx?paperid=6002",
    "565189b672efee01d22f4fc6b73cd5287b2ee72c": "\nAcknowledgements \nThis research was funded under the EU H2020 GEMINID project, grant no. 645728. We gratefully acknowledge the financial support of several companies and research organizations including Amazon Web Services/AWS, the AXA Lab & X, the AXA Group Research Department and the EU Commission's H2020 RIA HARP project (grant no. 766968), the French Ministry of Higher Education, Research and Innovation (MESR, project ID: ANR-18-PIA2-0002).\n\nTable of Contents \n  *  Preface\n  *  Abstract \n  *  Introduction \n  *  SECREF\n  *  Table of Contents \n  *  Reference Style \n  *  Table of Figures \n  *  Table of Tables \n  *  SECREF1 \n  *  SECREF2 \n  *  SECREF3 \n  *  SECREF4 \n  *  SECREF5 \n  *  SECREF6 \n  *  SECREF7 \n  *  SECREF8 \n  *  SECREF9 \n  *  SECREF10 \n  *  SECREF11 \n  *  SECREF12 \n  *  SECREF13 \n  *  SECREF14 \n  *  SECREF15 \n  *  SECREF16 \n  *  SECREF17 \n  *  SECREF18 \n  *  SECREF19 \n  *  SECREF20 \n  *  SECREF21 \n  *  SECREF22 \n  *  SECREF23 \n  *  SECREF24 \n  *  SECREF25 \n  *  SECREF26 \n  *  SECREF27 \n  *  SECREF28 \n  *  SECREF29 \n  *  SECREF30 \n  *  SECREF31 \n  *  SECREF32 \n  *  SECREF33 \n  *  SECREF34 \n  *  SECREF35 \n  *  SECREF36 \n  *  SECREF37 \n  *  SECREF38 \n  *  SECREF39 \n  *  SECREF40 \n  *  SECREF41 \n  *  SECREF42 \n",
    "b6f7fadaa1bb828530c2d6780289f12740229d84": " It would also be interesting to compare the robustness of the different ways to simulate BT to variations in the target statistics, such as increasing the sentence lengths, which we observe has a significant effect on the NMTs we tested. Last, we plan to investigate the effect of these strategies on downstream tasks such as Neural Machine Translation and Neural Post-editing.\nAcknowledgement \nWe thank the people of the Nematus project BIBREF8 for running all the experiments, and the ELL team for helping us during the data collection. Acknowledgements are due as well to the various collaborators on this work: BIBREF14, BIBREF20, BIBREF23, BIBREF35, BIBREF36, BIBREF28, BIBREF29, BIBREF33, BIBREF32. Finally, this work was supported by the project ALPHA BIBREF1 and by the EU H2020 program under grant agreement no. 730874.\nReferences\n\nThis work partially results from project CHANDELIER BIBREF1 funded by the ANR within the French National Research Agency.\nThis work was also supported by the European Union's Horizon2020 research and innovation programme under grant agreement number 641847 and from the DFG/ANR project R2SAN BIBREF2 and BIBREF3.\n\n.\n\n This is a common scenario in real-world applications (see eg. Baudena, 2018, BIBREF17 ).\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n We use the official Europarl 2007 and 2008 tests for our evaluations.\n.\n\n.\n\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n\n This also allows us to compare the in-domain testset with the out-of-domain, in terms of naturalness and domain of the parallel corpora.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n/home/kmar/nematus/logs/train-all-eng/2018-11-01 21:04:41 | WARNING: Cannot run with non-existing/absent file:  /train/all-eng.log\n/home/me/nematus/logs/train-all-en/2018",
    "7b9ca0e67e394f1674f0bcf1c53dfc2d474f8613": "\nAcknowledgments\nThis work uses publicly available Europarl English-German and Europarl English-French corpora.\nWe are grateful to Florian Rousselle for providing us with his source code and to Marie-Catherine de Marneffe for helpful discussions regarding the Europarl test data.\nWe thank the participants in the WMT 2014 shared translation task for making the common crawl data available.\nWe thank the reviewers for raising several insightful questions that guided our study.\nWe thank Moustafa Bounegru, Guillaume Boulianne, Julien Lechelle, and Marc Dumas for useful discussions.\nWe thank Yue Ma for valuable comments during our oral presentation.\nMariana R. Astudillo-Carri\u00f3n - aistud@googlemail.com\nGhislain Rousselet - ghislain.rousselet@univ-lyon1.fr\n\n# CONTENTS\n\n**Introduction to the Pronunciation Workshop**\n\n**Pronunciation Workshop**\n\n**Chapter 1: Phonetics**\n\n_Voiceless Consonants_\n\n_Stops_\n\n_Fricatives_\n\n_Affricates_\n\n_Vowels_\n\n**Chapter 2: Pronunciation of the Voiced Consonant Sounds**\n\n_Vowel Sounds_\n\n_Consonants_\n\n_The Pronunciation of the Naming Vowels_\n\n_The Consonant Sounds of the Naming Vowels_\n\n**Pronunciation Workshop**\n\n****\n\n**Chapter 3: Pronunciation of Silent Letters**\n\n**Chapter 4: Consonant Sounds**\n\n_Clicks_\n\n_Diphthongs_\n\n_The Consonant Sounds of the Naming Vowels_\n\n_Miscellaneous Pronunciation Points_\n\n**Pronunciation Workshop**\n\n****\n\n**Chapter 5: Diphthongs**\n\n_The Diphthongs and Rhymes of the Naming Vowels_\n\n_Rhyme Words_\n\n**Pronunciation Workshop**\n\n****\n\n**Chapter 6: Gain**\n\n**Part II: Word Classes**\n\n**Chapter 7: The Nouns**\n\n_Nouns 1_\n\n_",
    "4e1a67f8dc68b55a5ce18e6cd385ae9ab90d891f": "\n\nTable 1 Asker's psycholinguistic profiles of open and answered types of questions\n\nType Open Questions Answered Questions\n\nEmotion -2.65 -1.21\n\nAge -2.33 0.25\n\nPerson -3.24 -0.39\n\nEmotional valence -1.46 -0.66\n\nFamily relations -2.21 -0.14\n\nWork -2.62 -0.39\n\nHealth -2.64 -1.04\n\nReligion 1.65 -2.18\n\nSexuality 1.26 -1.07\n\nSex -0.74 -2.12\n\nCulinary -0.98 -1.24\n\nFood 1.02 -2.08\n\nLinguistic -2.12 -0.64\n\nBody 2.27 1.00\n\nSexuality -1.67 -4.35\n\nPersonality 1.22 -1.17\n\nLinguistic emotion 0.18 -0.21\n\nReligion 1.03 -0.46\n\nBody 0.11 -0.22\n\nSexuality 0.29 -2.08\n\nLinguistic -1.38 -1.34\n\nReligion 0.14 -0.45\n\nPersonality -0.07 -0.23\n\nSex 1.20 -0.73\n\nHealth 0.17 -0.03\n\nIntake of water 2.24 1.08\n\nSexuality 0.23 0.22\n\nFood 0.19 -1.08\n\nSex -1.31 -1.22\n\nSexuality -0.13 1.01\n\nFood -0.18 -2.20\n\nSex -0.36\n\nLinguistic 2.04 -1.08\n\nReligion -0.02 -0.21\n\nLinguistic personhood 0.03 -0.10\n\nHealth -3.16 4.53\n\nSexuality 0.14 -1.00\n\nSexuality -0.12 0.29\n\nHealth -1.33 1.41\n\nSexuality 0.47 0.07\n\nIntake of alcohol 0.35 6.65\n\nPersonality 0.13 0.10\n\nLinguistic -1",
    "6c96e910bd98c9fd58ba2050f99b9c9bac69840a": " (i) number of words (numWords), (ii) part of speech tags (pos(w)), (iii) frequency of function words (functWords), (iv) no. of impersonal pronouns (pronImperson), (v) no. of articles (artWords), (vii) no. of personal pronouns (pronPronoun), (viii) ROUGE-LCS (rouge), (ix) number of positive emotions (posEmotion), (x) number of negative emotions (negEmotion), (xi) number of words indicating sexuality (sexualityWords), and (xii) number of words indicating health & body (bodyWords). See table 3 for the detailed description of features.\n\nPsycholinguistic analysis\n\nLinguistic and emotional aspects of an individual are highly contextualized and they differ across the population. We observe that the psycholinguistic properties of the question asker plays an important role in answerability on Quora. Here too we use LIWC classification system to model the emotion and social aspects. In table 4, we present the psycholinguistic analysis result for the above features (see table 5 for the category-wise details).\n\nSocial network\n\nThe social network of the question asker is critical to analyze the quality of the asked questions. Here we use an author's influence on Quora as the influence-based feature of the question asker. This feature is important because higher influence is observed for high answered questions. This is expected because a question having more social impact is more likely to receive more attention and thus there is a good chance that such unanswered questions get their answers. In table 6, we present the social network influence-based features for the above-mentioned features. Here we observe that the influence value follows a linear relationship with answered questions and open questions. We note that a typical community of Q&A always has a hierarchy of users where the most active and influencial users are known as influencers. Therefore, we have used three important parameters, number of questions asked, number of followers, and number of upvotes such as ask, follow and upvote to capture the social network for the question askers of Quora. See table 3 for the complete details.\n\nQuestion quality\n\nEach question is asked with a goal and it shall be answerable only if it can be easily understood and answered by experts",
    "9af3142630b350c93875441e1e1767312df76d17": "\n\nPOS tag diversity \\& Recall: We measure the tag diversity and recall values at different time scales of $q_i$'s activity log. For each question, we compute the tag diversity and recall values for a window of $W$ minutes. We denote a textual word $wn$ in the question text as $t_n,s$ which is the text's POS tag at the time $t_n$ (we choose $W$ = 2 days for every question). The tag diversity and recall values for the question can now be calculated as: $POSDiv(q_i) = \\sum_{n \\in window}t_n,s\\cdot \\log(t_n,s)$, $Recall(q_i) = \\max _{m \\in text} \\sum_{j \\in pos_{set}_m}p_j\\cdot \\log(p_j).$\nPsycholinguistic states: We measure the psycholinguistic states of the question asker based on LIWC as mentioned in Table 1.\nLinguistic activities of a question in question text: The number of content words; the number of words appearing more than $n$ times in the question text; the average length of words in the question text; character (non-alphabet) usage.\nContent words: Content words have a meaning and carry an information. We used an article that identifies word content in the dictionary11 to count the number of content words in the post. The number of appearance of a word in the question text is calculated as the number of word occurrences in the question text divided by the total number of words in the post. The length of words in the question text is directly calculated as the sum of number of characters in words in the question text divided by the length (in number of words) of the question text. Also, we consider the number of different characters in words present in the question text and count it as a number of characters of a word. This number of characters is then divided by the number of appearances of words in the question text to calculate the average length of a word in the question text.\n\nThe above features are calculated for the question at each time step $t$ using the previous activity log. If $q_i$ remains unanswered after a time period $t$ then the features associated with $q_i$ are extracted from the text at time $t",
    "e374169ee10f835f660ab8403a5701114586f167": " The insights and observations we provide are also useful for future studies and work in the area of social media.\n\nIntroduction\n\nThe present paper looks at the role of social media platforms for political discourse during election campaigns. In this work, we first describe the political discourse framework, highlighting the importance of social media. Next, we define the user's behavior at various levels in their relationship with the political discourse and characterize how political handles and follower handles displayed their political alignment and political support BIBREF1 for the 2019 Lok Sabha elections in India. Finally, we performed user-topic modeling analysis to investigate the profile attribute changes BIBREF2 in the presence of political handle and follower handles.\n\nWe found that: (i) a considerable amount of political support is shown through profile attributes by the users, (ii) change in profile attribute represents organic behavior, (iii) followers tend to adopt opinion leader's behavior and (iv) users mostly discuss politics using profile attributes. These insights help in understanding the role of social media during an election campaign.\nReferences\nBIBREF0.\n\nKumar and Bhat, 2019: Kumar, N and Bhat, R, (2019) _Mortality and Morality: A Social Media Perspective on the Lok Sabha Elections in India_. Paper presented at The 6th ASIST 2019 (Abhijit Sinha) Memorial Workshop on Social Media and Social Sciences, University of Kashmir, Jammu University, Kashmir.\n\nBIBREF1.\n\nKumar, N and Bhat, R, (2019) Political discourse from a Social Media Perspective, TAMUCDS Working Paper Series No. 2019-10.\n\nBIBREF2.\n\nJain, U, Ram, S, Singh, R and Sharma, S, (2013) _Identification of political orientation on Twitter: Using profiles of candidates and opinion leaders_. Big Data in Developing Countries Conference, Hyderabad.\n\nBIBREF3.\n\nMittal, S, and Rathore, S, (2014) _Analysis and Modelling of Social Media for Political Campaign of Political Parties in General Elections 2014, India_. International Journal of Computer Networks and Communications, Vol. 6(Issue-14), pp: 1-9.\n\nBIBREF4.\n\nKumar, N, and Bhat, R, (2016) Twitter Usage in",
    "82595ca5d11e541ed0c3353b41e8698af40a479b": "\n\nDiscussion ::: Suggestion for Future Work\nIn this section, we discuss the limitations and future work of the work. The key limitations are the following. Firstly, our analysis suffers from the time constraints due to limitations posed by Twitter. Secondly, there are multiple limitations due to profile attribute change itself. Owing to the time constraints, we don't have the ability to analyze the behavior contagion that took place amongst chowkidar users BIBREF4 in detail. Lastly, due to the profile attribute analysis, we don't capture the complete time line of the users in set $S$ and only have the snapshots of given account at a fixed interval.\nFuture Work ::: Future Work\nFuture work ::: Influence of Leader's Twitter profiles\nIn order to test the hypothesis of the leader's profile attribute change behavior, we study influential leaders in the country with large follower base BIBREF8 and analyze the same. One way to capture the influence of the leader can be using network analysis. We can look into the followers of the leader and find out how the leader's behavior is followed by his followers or the extent of influence that the leader has gained.\nFuture Work ::: Influence of followers on Leader's behavior\nFollowing the influence of leaders on followers, we also try to understand if the followers impact the leader's behavior. For instance, the followers of a certain leader can help in predicting his behavior and try to get a better estimate of leader's behavior in the future.\nFuture Work ::: Profiles beyond Twitter\nThe followers of a handle are often represented as user objects on Facebook. There is an absence of public data on follower handles on Facebook and it is difficult to obtain the followers list of a given Twitter handle on Facebook. It is however, easy to get the profile snapshot of a user on Facebook, including profile attribute changes. Further, public data on Facebook is also more reliable as compared to on Twitter. We analyze the followers of users in set $P$ on Facebook and compare the follower handles of similar nature with those followers by making use of Facebook Graph API.\nFuture Work ::: Analysis of LCS values\nIn our work, we analyze the similarity of the profile attributes of the users. We analyze the commonness of display name, username and the followers' descriptions on Facebook. We can further extend the analysis to more profile attributes.\nFuture Work ::: Similarity analysis of followers with respect to leader's profile",
    "d4db7df65aa4ece63e1de813e5ce98ce1b4dbe7f": "\nAcknowledgements\nWe would like to thank Dhrubajyoti Chanda, Utkarsh Sharma, Komal Singh Sharma, Sanil Yadav, Rajat Bhartiya, Rishi Mody for their help and feedback in several stages of our project. Also, a special thanks to Prof. Amarnath Bansal and Prof. Siddhartha Roy for their help and feedback during the project's preparation stage.\nAuthor Contributions: Shivam Patel and Pooja Sharma contributed equally to this work. All authors agreed on all the aspects covered by this work.\n\nReferences\n\n[1] H. Bassey, K. Chakulia, S. M. N. Patil, and S. Muthukrishnan, \"Political Parties in Twitter Networks: An exploratory study, \" Proceedings of the SIGCOMM Workshop on Social Media Analysis, 2018.\n\n[2] J. B. Chowdhury, \"Analysis of Twitter User Profiles during the 2019 Indian Legislative Assembly Elections\", 2019, https://pdfs.semanticscholar.org/.2.62e6.3a22d/7ac0a5d3bfb2d5abed9c5b22d5c0be2f1e5fcefcc3bb9cbbd4a734bf2b1ac09e74d4a7ba9e3b3a2a8dab15.pdf.\n\n[3] J. Dekhalevich, A. E. B. Decker, E. Garimella, and M. K. Decker, \"Rethinking Twitter Follower Analysis: A Comprehensive Study of Account Quality and Candidate Tweet Behavior, \" 2016 IEEE International Conference on Social Computing, Social Media and Society (Socialcom), 2016.\n\n[4] J. Dekhalevich and A. E. B. Decker, \"Quantifying Tweeting Behavior: a comprehensive study of Twitter users, \" 2016, https://dl.acm.org/citation.cfm?id=3038078.\n\n[5] C. Estrada, \"Twitter profile changes: analysis of individual and collective dynamics, \" 2016, https://tjnl.acm.org/cal.14/0.1.html.\n\n[",
    "53dfcd5d7d2a81855ec1728f0d8e6e24c5638f1e": "\nOn the other hand, the generative model performs quite well on single-token questions. We conjecture that the large-scale pretraining of language models on Web text can help the models better exploit semantic patterns. In future research, it will be interesting to investigate a wider range of pre-training methods that could better cover the data distribution of social media posts.\n\nDataset Analysis\nIn the end, we provide a detailed analysis of different tweet-specific linguistic features in Table TABREF48 and several case studies of real tweets. One interesting observation we made in the data analysis is that the word distribution is quite different from that of other QA datasets, particularly from SQuAD, and many social media-related tokens like usernames and hashtags show up quite frequently. The social media-related tokens can be either question tokens or answer tokens. One conclusion we draw is that we might need more specialized language models that are well-designed for dealing with more complex and distinctive word patterns.\nThe tweets in our TweetQA dataset contain many user-related tokens. For example, the most frequently used tokens are #worldcup and @donaldtrump. In real life, lots of tweets are used to share news, especially real-time news. For example, in a game against the French football team at the World Cup, US national football star Paul's goal was blocked by the French goalkeeper. The tweet below gives the user's point of view:\n\nWe observe that many question-answer pairs collected from news articles include tweets from official events or even hashtag campaigns. For example, Table TABREF3 is an example from the CNN World section, which gives more details about an event. At the time of writing, it mentions the World Cup, which is an event. The tweet above is a comment in the chat section. It contains information about who won the game (Paul) and the event (US-FR), and it also includes the hashtag campaign #cnnworldcup to promote the event.\nAnother conclusion from the analysis is that although Tweets are written in a more informal and free fashion than other kinds of documents, they can also be more reliable, and people tend to quote tweets with more useful phrases instead of informal language expressions. One example is shown in Table TABREF3, where a journalist quotes a statement about a suicide attack:\n\nThis concludes the analysis and observation from the data analysis.\n\nThe questions in",
    "869feb7f47606105005efdb6bea1c549824baea0": "\n\nDiscussion\nWe discussed several interesting findings that can be used to guide future research. First, although the underlying information content can be similar between tweets and formal text, extracting QA pairs from social media context poses many challenges compared to formal passages. For example, we find that TweetQA contains only 0.26-2.41% named entities and only 0.24-2.72% pronouns/part-of-speech tags. On the other hand, SQuAD and CNN/DailyMail, which are derived from formal texts, contain 50.5-85.2% nouns and 55% pronouns. Second, we observe that, unlike other formal datasets, tweets are highly informal and can have a lot of information embedded in hashtags and usernames, which may bring up some new challenges in QA. The authorship-related questions that are critical for social media QA have been shown to be very challenging problems in traditional QA studies and are not surprisingly hard for models that fail to handle the informal style. Finally, we also observe that most QA pairs in TweetQA are less than five words, while formal texts are usually longer. Given these facts, we believe that the social media community can contribute a lot to improve QA over informal social media texts.\n\nTweetQA Release\nWe released TweetQA to enable the public to better understand our motivation as well as to enable QA researchers to gain access to the data. All data can be downloaded from https://twitter.com/tweetqa2018. The answers were also written by Amazon Mechanical Turk workers, and the workers are located in the world's two largest English-speaking countries (the United States and Canada) thus ensuring natural English and no foreign words. Since we provide all tweets that are related to a given news article without being edited, we believe that TweetQA can also be used to explore certain tasks of social media generation, such as automatic summarization. The detailed question-answer writing instructions can be found at https://twitter.com/twettqa/wiki/index. We encourage the community to share their systems and also comment in the public issue page of this repository.\n\nAcknowledgement\nWe would like to thank the anonymous reviewers and editor for their useful comments. We also thank the three anonymous reviewers for their constructive feedback on our revision.\n\nAppendix A\n# TweetQA Dataset\nTweetQA\nThe T",
    "c497e8701060583d91bb64b9f9202d40047effc4": " Overall, the BiDAF model performs worse than other baselines. This suggests that the BiDAF's reliance on the abstractive ability of pretrained language models is not well suited in the TweetQA context. The human performance is slightly better, and the answers are slightly more varied than that of the neural models in this case as well.\nConclusion\n\nThe human performance analysis shows that humans can answer all the questions in this task, even though the tasks are quite challenging. Therefore there is potential room for improvement. The analysis of the neural models reveals both strengths and weakness: \nThe neural models can handle questions much better than humans.\nIt is not straightforward to generalize neural networks to perform well on social media data.\nAs can be observed, the performance over different types of questions is far below the upper bound, even though the baselines are trained on our TweetQA dataset. This also verifies that social media texts do not have exactly the same properties as formal domains and thus neural-based approaches could be significantly boosted by developing domain-specific knowledge and training methods.\nWe see our proposed TweetQA dataset as a crucial first step towards the long-term goal of automatically collecting and disseminating valuable knowledge from social media.\n\nWe also expect that social media is growing to be the new domain for QA research. As seen in many examples (Figure FIGREF14 ), twitter users are able to share news information with each other. TweetQA makes the first step of exploring how QA can be used to enhance interaction among social media users.\nHowever, many challenges lie in the following directions: understanding of user mentions and hashtags, understanding of hashtags and other event-related aspects via deep semantic understanding (i.e. event-semantic-related questions), and understanding of authorship. Our analysis on Table TABREF52 shows that most of the questions are difficult to answer and in many cases are hard to formulate meaningfully with just five words, suggesting TweetQA as a long-term challenging task.\nAcknowledgments\nWe thank all the Amazon Mechanical Turk workers who participated in collecting the TweetQA dataset. This work was supported by an Amazon Research Award.\n\n1: Anshuman, P., Dyer, C., Grootendorst, H., & Suresh, R. (2018). Distantly Supervised Training of Neural Question Answering Systems Using Generative Story Inference. In Proceedings of the",
    "8060a773f6a136944f7b59758d08cc6f2a59693b": "\nAPPENDIX A\n\nIntroduction\nIn this appendix, we will describe the entire LSTM RNN training framework, including layer-wise pre-training, transfer learning, and distillation.\n\na.\n\nLayer-wise pre-training\nLayer-wise pre-training is a effective approach to train very deep neural network. In the layer-wise pre-training procedure, the weights of the teacher network are transferred to the student network. The weight transfer includes both parameters and knowledge. It benefits from the teacher network trained with the large training dataset, but the student network just transfers part of learning knowledge from it. The shallower teacher network's knowledge can be further extracted from labeled speech data by soft target, and then the knowledge could be transfered to deeper student network. The knowledge from deep network is distilled by distillation with the small model.\nb.\n\nDistillation\nDistillation is to extract knowledge from the large model to the smaller one. Our purpose of distillation is to extract knowledge in shallower student network's hidden layer: hidden units of the HMM-GMM system. The distillation process is illustrated with a simple diagram shown in Figure FIGREF13. We first train 9-layers unidirectional LSTM model with CE loss function, and extract the knowledge generated by HMM-GMM system on the basis of frame-wise softmax layer output. Then, a 2-layers distilled model is trained on it, and it achieves quite good recognition accuracy. The distillation process consumes less data and less training time than full training for large amount of data.\n\nc.\n\nTransfer Learning\nAfter distillation, the model contains both parameters and knowledge from generic scenario, so that it is less applicable in specific scenario like Amap map & navigation voice search. Transfer learning with sMBR is employed, and it utilizes the distillation model as teacher network. Training with generic scenario's model and less labeled data for specific scenario is no doubt to reduce labeled data usage and time consumption. We take the distillation model as teacher network and train a 2-layers distilled model with sMBR, and the result is also convincing. Our main work for the future remains training 9-layers teacher network and distilling it to a shallower 2-layers model to avoid high RTF.\nAPPENDIX B\n\nDescription of System\nAmap is one of the most popular web mapping and navigation services in",
    "1bb7eb5c3d029d95d1abf9f2892c1ec7b6eef306": "\nAcknowledgments\n\nThis work is supported by Guangdong Provincial Key Lab for Big Data Computing and Intelligent Information Processing. The author would like to thank Tianxi Dai for advice and help in parallel training.\n\nIntroduction to Recurrent Neural Networks\n\nNeural network is a model that can implicitly approximate a wide range of functions approximating any given function. It is also widely employed to computer vision and speech recognition. Recently, deep neural networks have been deployed in various machine learning tasks, because of their good expressiveness to learn large capacity function. In most cases of speech recognition, it cannot be directly trained with very large amount of labeled data, while its performance depletes faster without adequate knowledge. Thus a kind of neural network named recurrent neural networks (RNNs) are employed.\n\nRecurrent neural networks is a class of neural networks with a special and powerful mechanism named recurrent connection. It can update its weight through back-prediction mechanism, and it can also update their previous state as previous input by a special activation function. By training a sequence of consecutive input-output tuples, a recurrent network can achieve almost the same behavior of any machine, such as to speak Mandarin Chinese, sing melody and so on.\n\nRecurrent networks are developed from connectionist temporal classification (CTC) network, initially proposed for automatic speech recognition using sequence to sequence learning BIBREF5. With CTC network, it is possible to train a model directly from large amount of unlabeled data. The loss function is conditional random field (CRF) by CTC network, which can label each word with a label sequence in machine learning.\n\nIt is shown that recurrent network also takes full advantage of unsupervised learning in natural languages processing (NLP) area. A recurrent network with a high-order language model outperforms conventional neural network on part-of-speech tagging problem BIBREF27, named recurrent neural network with conetxt and class (RNN-C2C) BIBREF28, and on named entity recognition problem BIBREF29, which can tag each sentence with a named entity sequence.\n\nBesides, the neural network with long and short memory is employed in computer vision area. A neural architecture is developed as long-short term memory (LSTM) network BIBREF21. It can capture long-range dependencies more accurately BIBREF23. Long-short term memory has shown good performance in semantic related applications BIBREF",
    "c0af8b7bf52dc15e0b33704822c4a34077e09cd1": "\n\nReferences\n\n[1] Povey, H., & F.L. Hamilton (2016). A Study of Neural Networks for Speech Recognition. Advances in Neural Information Processing Systems - 2017.\n\n[2] Zhang, H., & J. Deng (2017). CNN with Batch Normalization and Dropout for Small-Vocabulary Speech Recognition.\n\n[3] LeCun, Y., B. Fusi, S. Bengio, D. Holliday, X. Hutter, and M. J. Wattenberg (2015). Deep learning. .\n\n[4] Zhang, H., & J. Deng (2019). A Study on How to Make CNNs Learn Fast and Well on Large-Scale Speech Recognition Datasets.\n\n[5] G. E. Hinton, Geoffrey, G. Dahl, T. Sepper, & J. van der Walt (2015). Linear Classifier Probes: Diagnosing Neural Network Functionality and Learning Processes.\n\n[6] Jiajun Pan, Huiming Hu, Qing He, Yang Ma, & Ming Li (2016). Training Very Deep Neural Network: Gradient Exploration and Neural Architecture Search.\n\n[7] G. Le and M. Chen (2016). Addressing the Initialization of Very Deep Neural Network Trained with Gradient Descent Algorithms.\n\n[8] Lianqing Jin, Qiaolai He, Ting Luo, & Zeyi Zhang (2017). Layer-Wise Pretraining with the Shallow Model for Very Deep Convolutional Neural Networks\n\n[9] J. Bouga, M. Chen, & G. Le (2018). Asynchronous SGD with Exponentially Weighted Moving Average for Large Scale Distributed Parallel Speech Recognition in Large Data Center\n\n[10] S. Chen, G. Le, & Y. Shi (2016). Blockwise Model-Update Filter: A Novel Proposal for Parallel Training with Very Deep Neural Network.\n\n[11] Lianqing Jin, Q. He, & Z. Zhang (2018). Improving Accuracy and Efficiency of Neural Network Training with Asynchronous SGD with Block-wise Updates.\n\n[12] Lianqing Jin, Q. He, & Z. Zhang (2019). Learning",
    "9de2f73a3db0c695e5e0f5a3d791fdc370b1df6e": "\nIncheon E, Lee: Theories of Sociality in Affect. In The Cambridge Handbook of Sociality, edited by N. Block and M. Hewstone. New York: Cambridge University Press, 2009, pp. 31\u201354. [Google Scholar]\nJ. Kim J: Affective Dialogue and Its Affective Computing. International Journal of Affective Computing, 5 (4) 3\u201310, 2014. [Crossref]\nJ. R. Alam and C. R. H. Chiang: Tutorial: Affective Computing: Towards Conversational Responsive Personalized Intelligent Systems. In International Conference on Social Informatics. Proceedings of the 2016 International Joint Conference on Pervasive and Ubiquitous Computing. 2016.\n\nW. C. Kopp, P. L. V. Pham, and G. F. Caudill: Affective Dialogue System: A New Interface Paradigm. International Journal of Affective Computing, 6 (4) 17\u201320, 2014. [Crossref]\nW. C. Kopp and T. G. Diettrich: An Introduction to Affective Computing. New York: Springer, 2013. [Crossref]\n\nW. C. Kopp, C. R. H. Chiang, S. Y. Chung, M. P. D. Costa, and A. Kirova: Tutorial: Human Emotion Recognition and Identification. In World AI frontiers, 2017.\n\nD. P. Sillito: Affect Recognition. In Handbook of Computational Linguistics and Emotional Processing. 2nd edition. Wiley, 2012.\n\nY. Lee: Affective Human\u2013Computer Dialogue System using Emotion Information. Doctor of Philosophy, 2011.\n\nP. A. J. Williams: Affective Interfaces and User Experiences in Smart Systems. MIT Press, 2015. [Crossref]\n\nW. C. Kopp, J. R. Alam, K. Ramesh, X. Luo, and S. Y. Chung: Tutorial: Affect Recognition and Emotion: From Speech and Language to Facial and EEG. In World AI frontiers. World AI Frontiers. 2017.\n\nY. Chung, T. G. Dietrich, and G. F. Caudill",
    "e0122fc7b0143d5cbcda2120be87a012fb987627": "\nAppendix A\n\nThe datasets generated during the course of this study are available at https://eureeca.pasteur.fr/data/emocap.html.\n\nAcknowledgments\n\nC. Han, T. Heo, and H.-B. Cho are with the Department of Computer Science and Engineering, SNU Engineering Research Center for High-performance and Reliable AI Systems (SNU-ER-AI), Seoul National University, Seoul, Korea. This work was supported by the Ministry of Science and ICT (MSIT, Korea) under Digital Contents Business Incubator Program (Project No. 20198), and the Institute for Information and Communications Technology Promotion (IITP) (Project No. 2017-15).\n\nY.-G. Cho is with the Electronics and Telecommunications Research Institute (ETRI) and the School of Computing, SNU (SNU-CS), Seoul National University, Seoul, Korea. Y.-G. Cho received his Dr of Engineering degree from the Korea Advanced Institute of Science and Technology (KAIST) and his B.S. and M.S. degrees from Seoul National University. This work was supported by ETRI and the Ministry of Science, ICT, and Future Planning through the National Institute of Advanced Science and Technology (Project No. 2018-1412-003, 2016-C2-01), and the Department of Science and ICT and Future Planning at SNU (Projects No. A01-2018-KAKEN-10 and A02-2018-KAKEN-10).\n\nT.-J. Ko is with the Center for Autonomous Intelligent Robot and the Brain-inspired Cognitive Sciences, Institute of Convergent Sciences, SNU (ICS-BAS) and the Department of Electrical and Computer Engineering, ASRI, Seoul National University, Seoul, Korea. T. Ko is with the Department of Computer Science and Engineering, SNU Engineering Research Center for High-performance and Reliable AI Systems (SNU-ER-AI), Seoul National University, Seoul, Korea. The first author is financially supported by the Korean government (MOST) through the Global Ph.D. Scholarship program (No. IRT-2016-1073-8). This work was partially supported by the National Research Foundation of Korea (NRF) under the Korean Federation for Advanced Information Research (Project No. 2018-0-01101) and",
    "5da26954fbcd3cf6a7dba9f8b3c9a4b0391f67d4": " The authors are grateful to the financial supports of the Korea Ministry of Science and ICT.\n\n1. Anderson, D., Akgun, a., and Jalali, b., A review of spoken-language emotion analysis technologies, 2015.\n2. Pecchia, M., Pelli, m., and Scarantino, a., Emotion as reflected in voices, 2016.\n3. Malkov, P., et al., DEEPFEEL : A deep learning emotion recognition method using convolutional neural networks, 2016.\n4. Liu, W., et al., Speech emotion recognition with convolutional neural network (CNN) and Recurrent Neural Network (RNN) based deep features and dynamic time warping, 2017.\n5. Choi, S., Ngiam, r., and Sim, j., Conversational dialog systems with deep learning for speech emotion recognition, 2017.\n6. Dhillon, J. S., and Wang, Q. Y., Spoken emotion recognition using deep convolutional network (CNN), 2017.\n7. Akyel, R., and Rath, n., An overview of speaker-dependent and speaker-independent automatic speech recognition and speaker identification techniques and a survey of deep learning models, 2017.\n8. Chang, J. H., et al., Convolutional neural networks for speech recognition, 2015.\n9. Sasano, K., et al., Speech-recognition applications based on deep neural networks, 2017.\n10. Hwang, E., et al., Towards multimodal deep-learning-based emotional dialogue systems, 2017.\n11. Chang, J., et al., A new evaluation of speech emotion recognition based on deep convolutional neural network feature and long short-term memory (LSTM) network with deep-learning-based acoustic features for a large-scale dataset, 2017.\n12. Fumera, R., Dai, G. W., and Ngiam, r., Emotion recognition from speech data using deep convolutional neural network (CNN)/LSTM model and speaker-chase with support vector machines (SVM), 2017.\n13. Pelli, m., et al., Emotion recognition and emotion detection using deep neural networks and their extensions, 2017.\n14. Fumera, R., et al., Emotion recognition using deep learning combined speech features and deep attention",
    "37edc25e39515ffc2d92115d2fcd9e6ceb18898b": " For the preparation of this paper, we used resources of the Institute for Computing Systems (I4C) of ETH Zurich and the Center of Computer Science and Applied Cognitive Research (C-CSACR) under the project ESI-SAN of the SNSF (200021-176543).\n\nReferences\n\nAuer et al. (2004).\n\nAuer, K., Gehrke, R., Gurevych, M., Schroff, S., Tu, A., and Zweig, G.: Rada: a large-scale resource for event and actor-based semantic role labeling of newswire texts. In Proc. of ACL 2004, 2227\u20132234, 2004.\n\nBergsma et al. (2012).\n\nBergsma, E. H., Groot, L., and Kestemont, W. Semeval-2012 task 4: sentiment analysis of newswire articles. Journal of Chinese Linguistics, 40(3), 419\u2013428, 2012.\n\nBeyechet, Y., Le Cun, Y., Collobert, R., Bengio, Y., Lenci, C., Karapetyan, H. and West, M.: Distributed representation for learning sentence meanings. In Proc. of EMNLP, 44\u201351, 2003.\n\nBiber, L., Goldberg, R., and Coulter, F.: Tweet sentiment analysis: a large-scale automatic, lexicon-independent, and corpus-based evaluation. Advances in neural information processing systems, Vol. 24, 2013.\n\nBordes et al. (2013).\n\nBordes, U., Kemp, A., Tsoi, B., Weston, J., Zweignig, G., Sutskever, L. and Bengio, Y.: Enriching word representations by contextual information in neural phrase-based language models. In Proc. of International Conference of the Association for Computational Linguistics (ICDL), 775\u2013783, 2014.\n\nBorges et al. (2010).\n\nBorges, S., Chopra, C., Daume III, S., Gershman, A., and Zweigenbaum, A.: Mining from opinion leaders using statistical learning. In Proc. of ACL-2010, 2579\u20132585,",
    "e431661f17347607c3d3d9764928385a8f3d9650": "\n\n\n[1] B. Sebastiani, B. Croce, and D. Barros, \"Finetuning the Multi-Label Classification Approach: A Simple, Scalable and Reliable Model-Agnostic Method for Labeling Datasets with Order Information,\" in A. Zampieri, P. Viegas, J. Eirewagabai, M. Coppelia, and E. Carvalho (eds.), Proceedings of the 11th International Conference on World Wide Web, W3C2017. WWW'17. Association for Computing Machinery, New York, NY, USA, 2017, pp. 839\u2013850.\n[2] D. Lee and D. Klein, \"Word Vectors for Sentiment Analysis: Learning Semantic Representations of Words using Twitter Data\", in S. Chopra, C. Chen, R. Joshi, N. Karim, and M. Marcheseille, (eds.), Proceedings of the Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL 2017), 2017, pp. 1705\u20131713, vol. 1. Association for Computational Linguistics, Dallas, TX, USA.\n[3] S. S. Choi, P. Liu, and B. Zhao, \"Leveraging Distributed Representations For Fine-Grained Topic Detection,\" in S. Chopra, C. Chen, R. Joshi, N. Karim, and M. Marcheseille, (eds.), Proceedings of the Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL 2017), 2017, pp. 877\u2013885, vol. 2. Association for Computational Linguistics, Dallas, TX, USA.\n[4] C. Caruana, M. Ranzato, M. Yacqueb, A. H. Berg-Kir\u00e9s, T. Garnett, J. S. Lewis, and R. D. Lee, \"Multitask Learning Neural Networks,\" in Advances in Neural Information Processing Systems, 2013. pp. 654\u2013662. Curran Associates, Inc., Boston, MA, USA.\n[5] M. Caruana and L. Bottou, \"Multitask Learning for Text Classification,\" in Proceedings of the 32nd International ACM SIGIR Conference",
    "876700622bd6811d903e65314ac75971bbe23dcc": " The work of this paper was partially funded by an EC/FP7 grant (677041). We would like to thank the anonymous reviewers for their suggestions that improved the content of this work and the organizers of the SemEval-2016 task for providing the datasets and the SemEval sentiment toolkit for their guidance. Finally, we acknowledge the help from Nikos Bellos and Zou Zifeng. Also, we would like to thank the members of the NLP group at FBK for their helpful discussions.\nReferences\n\n[1] Sebastiani, C., V. Poria, E. Di Rosa, and L. Barone. 2016. Fine-grained sentiment analysis. In Proceedings of the First Workshop on Multitask Learning for NLP,pages 16\u201321. Association for Computational Linguistics.\n\n[2] Goyal, P., X. Lin, L. Xue, and K. Meeden. 2011. Classifying human opinions: a survey and analysis of large-scale sentiment analysis efforts. In Proceedings of NAACL-HLT 2011, pages 109\u2013116. Association for Computational Linguistics.\n\n[3] Sebastiani, C., E. Di Rosa, and V. Poria. 2014. Automatic tweet classification using sentiment lexicons. In Proceedings of the 2013 International Workshop on Fine-grained and Multitask Learning,pages 55\u201362. Association for Computational Linguistics.\n\n[4] Caruana, R., L. Radev, M. Ranzato, R. Chen, M. Caccamo, J. de Melo, and Q. V. Pham, 2012. Multitask learning. In Proceedings of the 20th International Conference on Machine Learning-Volume 70, pages 557\u2013564.\n\n[5] Yang, F., B. Van Durme, and E. Di Rosa. 2014. Multitask learning for semantic compositionality via cross-task transfer. In Proceedings of the 2014 Conference of the Association for Computational Linguistics, pages 1217\u20131224. Association for Computational Linguistics.\n\n[6] Singh, B. P., C. Riezler, D. P. Lewis, and V. Kumar. 2016. End-to-end sentiment analysis of online reviews using multi-task neural networks. In Proceedings of the 2016 Conference on Empirical Methods in",
    "312e9cc11b9036a6324bdcb64eca6814053ffa17": "\nA preliminary exploration of using the TF-IDF features and trained models for end-to-end text recognition in pathologically imaged tumor biopsies will be reported in a forthcoming publication. Additionally, we plan to extend our approach for extracting other important information like disease stage or grade, which may be useful for cancer registry reports to inform the clinician of patient cancer status or prognosis. The code and the data are freely available on https://osf.io/u5nph/.\n\n1: NCI: National Cancer Institute\n\n2: IDC: International Classification of Diseases\n\n3: WHO: World Health Organization\n\n4: BIBREF: BioCreative\n\n5: BIBREF: BMC Bioinformatics\n\n6: BIBREF: caBIG\n\n7: BIBREF: Canada Health Infoway\n\n8: BIBREF: BMC Cancer genomics\n\n9: BIBREF: GDC Data\n\n10: BIBREF: Natural Language Toolkit\n\n11: BIBREF: Topic Modeling\n\n12: BIBREF: F-Measure\n\nBIBREF: https://doi.org/10.1101/131262\n\nBIBREF: https://bmccancergenomics.biomedcentral.com/articles/10.1186/s12885-020-08787-1\n\n# Introduction\n\nThere has been a recent surge of work on deep neural network architectures for processing of clinical natural language (CNL) data. There are two principal classes of CNL data: clinical text data and imaging data, whose representations are usually obtained in the natural text and image formats, respectively. This chapter is limited to a high level overview of how CNNs are utilized for processing of natural language text. It begins with a brief description of how standard CNNs are utilized for text recognition/classification applications and then describes how CNNs can be used for the detection of tumors in a cancer biopsy. In general, such an application involves the classification of a given image into one of a finite number of tumor classes. Typically, there are thousands of these classes. We also describe how CNNs are utilized for generating summary representations of a whole slide of biopsy tissue. One additional note: in addition a CNN is used for the extraction of clinically useful information from medical images. For example, a CNN is utilized to automatically extract the location of a carcinoma.",
    "1c0ba6958da09411deded4a14dfea5be55687619": " Furthermore, this study highlighted the importance of TF-IDF features in helping to extract important keywords from pathology cancer reports. These keywords can be further utilized for information retrieval purposes by leveraging pre-processing strategies on specific keywords. This study demonstrated the potential for TF-IDF features to serve as a standardized feature extraction technique for NLP in cancer registry activities.\n\nAcknowledgement\n\nThe authors would like to thank the National Science Foundation (NSF) for providing support to conduct this research through its caBIG program. All of the authors are grateful to the NSF and the GSC grantees for sharing the pathology report datasets for the public good under the license of CC0 through Data Commons. We also thank Dr A. Kumaravel for his valuable comments on improving the quality of our report data. This work was also supported by research performed in the Department of Physiology at the University of Toronto.\n\nReferences\n\n1\n\nCancer. Statistics. Canadian Cancer Society. 2017. Web. [https://www.cancer.ca/en/cancer-information/cancer-statistics/by-subject/cancer-statistics/canadian-cancer-statistics] URL, 2017.\n\n2\n\nInternational Classification of Diseases for Oncology. WHO. 2017. Web. [http://apps.who.int/classifications/icd10/browse/2016/en] URL, 2017.\n\n3\n\nLapata, M., et al. The BioNLP Shared Tasks: A New Benchmark for Evaluating Biomedical NLP Systems. AMIA Annu. Fall Symp. Proc.. 2011;2011:836\u2013842.  \n10.5525/13/5843583\n\n4\n\nKaur, D.K., et al. Text Mining of Cancer Diagnostics Reports: An Approach Using Named Entity Recognition and LDA-based Keywords Extraction. In: Proceedings of the Sixth International Biomedical Text Mining Conference, Boston, USA, 2015.\n\n5\n\nWang, R., et al. Automatic Text Mining for Pathology Reports with a Deep Convolutional Neural Network (DeepPath). AMIA Annu. Fall Symp. Proc.. 2014;2014:1822\u20131831.  \n10.5525/13/6174936\n\n6\n\nKaur, D.K., et al. Development of a",
    "1eef2d2c296fdd10b08bf7b4ff7792cccf177d3b": " We have also developed a new dataset, consisting of 1,949 reports across 37 different primary diagnoses. We evaluated different classification models for this task and also reported the TF-IDF features to quantify the text content of reports. The extracted features also help us visualize the text information in each pathology report using different topics. The high classification accuracy and well-ordered vocabulary could be valuable for developing new applications such as automated diagnostic classification for various cancer cases.\nIn order to enable a systematic, automatic solution to the complex process of reading a pathology report, the development of cancer surveillance tools based on advanced machine learning techniques is a necessary step. The use of automated information extraction from pathology reports can also be extended to other aspects of pathology such as analyzing and summarizing the molecular markers in pathology slides. The results of our investigation show that TF-IDF features and trained machine learning models can be used for this automatic extraction and classification task. It is important to note that not all cancer cases may have a unique diagnosis code. For example, adenocarcinoma with lymph node metastasis may be mapped to multiple codes, depending on the cancer stage (1%, 3%, and 4%, as per StatCan 2017).\nAlthough the TF-IDF strategy can be very helpful in generating a diagnostic summary, it does not give a detailed clinical analysis. For instance, the same report can be interpreted using multiple diagnostic codes by domain specialists. For such complex and detailed scenarios, we believe that further development of state-of-the-art deep learning models and their application to pathology reports provides a promising approach. A critical limitation of our methodology is the lack of balanced training data. More work is needed to investigate the potential of various deep learning approaches for such a task.\nA pathology report is prepared by various doctors based on their knowledge and skillset. The report writer may use multiple synonyms in a single report. For example, they may describe a single carcinoma as lung squamous cell carcinoma with lymph node involvement where as a domain expert one will prefer to extract the term squamous cell carcinoma with metastasis. Similarly, the same carcinoma may be reported as squamous cell carcinoma with lymph node metastasis. In order to address these issues, a deeper understanding of the domain expert knowledge is needed from the perspective of a machine learning system. Another limitation we observed was the inability to identify the detailed clinical analysis by feature analysis. For example, a deep learning system would need to identify whether the microscopic features include squamous, sarcomatoid carcinoma, and spindle",
    "d915b401bb96c9f104a0353bef9254672e6f5a47": " We would also like to thank the French ANR project JUMP (ANR-17-CE40-0030-02) which partially supports our work.\nFigure FIGREF1 Data structure example\nFigure FIGREF2 Network model overview\n\nFigure FIGREF3 Architecture overview\n\nFigure FIGREF4 Scenario overview\n\nFigure FIGREF5 Hierarchical attention mechanism.\n\nFigure FIGREF6 Training process overview\n\nFigure FIGREF7 Attention score distribution\n\nFigure FIGREF8 Results by round\n\nFigure FIGREF9 Decoding module\n\nFigure FIGREF10 Training process\n\nFigure FIGREF11 Scenario ::: Hierarchical attention ::: Hierarchical Encoder Model\n\nTable TABREF26 Model comparison\n\nTable TABREF27 Results\n\nTable TABREF28 Results\n\nTable TABREF29 Results\n\nTable TABREF30 Results\n\nTable TABREF31 Results\n\nTable TABREF32 Results\n\nTable TABREF33 Results\n\nTable TABREF34 Results\n\nTable TABREF35 Results\n\nTable TABREF36 Results\n\nTable TABREF37 Results from the oracle\n\nTable TABREF38 Results from baselines\n\nTable TABREF39 Results from other papers\n\nFigure FIGREF40 Results from another paper.\n\nTable TABREF35 Results comparison\n\nTable TABREF36 Results comparison\n\nTable TABREF35 Results comparison\n\nTable TABREF37 Results comparison\n\nTable TABREF38 Results comparison\n\nTable TABREF26 Model comparison\n\nTable TABREF24 Results comparison\n\nTable TABREF26 Model comparison\n\nTable TABREF26 Model comparison\n\nTable TABREF35 Results comparison\n\nTable TABREF37 Results comparison\n\nTable TABREF38 Results comparison\n\nBibliography\n\n\nA. Agarwal, J. L. (2019), Transformer attention models, in NLP-Oral. ACL2019, 3(15):831\u2013846, 2019, arXiv:1907.03298.\n\nB. Bamman et al., (2018), Scalable sequence-to-sequence learning with copy and repeat mechanisms. NeurIPS 2018, 2018, arXiv:1806.05122v5[cs.CL], 2018, https://jmlr.org/papers/v100/bamman18a.html, 2018.\n\nB. Berard et al., (2018), BOLD:",
    "79a44a68bb57b375d8a57a0a7f522d33476d9f33": " We would also like to thank Dr. Olivier Dumas who helped a lot with the RotoWire benchmarks and to the French government for the Labex FABI (ANR-14-CE23-0010) for the funding of this research.\n\nReferences / Bibliography\n\n1. : L. Burdet, S. Kottur, R. Lample, G. Neubig, D. Sennrich, and T. Karpukhin. Machine translation as sequence-to-sequence learning. In\nProceedings of the Conference on Empirical Methods in Natural Language Processing EMNLP, pp. 2171\u20132180, 2016.\n\n2. : R. Clark, N. Dredze, S. Gupta, Y. Zhang, J. Jurafsky, and R. Larson. Neural machine translation. In\nProceedings of the 28th International Conference on Machine Learning ICML, pp. 1436\u20131444, Berlin, Germany, 2016.\n\n3. : A. Baral, G. Neubig, N. Edunov, J. Jurafsky, E. Kolczyk, and R. Lample. Neural machine translation of documents with long-range dependencies. In\nProceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 1617\u20131645, 2016.\n\n6. : A. Gupta, S. V. Narang, and M. G. Zeinali. The question answering task: what do we know? In\nProceedings of the 1st International Conference in Computational Linguistics ICCC, pp. 1\u201310, 2015.\n\n7. : D. S. Wu, H. Huang, Y.-H. Chang, X. Zhang, and B. S. Manzur. Improving text generation ability of chatbots with an automatic data retrieval system based on unsupervised semantic retrieval. In\nIn Proc. ICMT 2017, Vol. 106, pp. 10\u201314, 2017.\n\n8. : D. Sennrich, T. Karpukhin, I. Hitzerode, G. Neubig, J. Jurafsky, E. Kolczyk, M. Schuster, J. Kocmi, S. V. Dusek, R. L. L. Popovic, P",
    "664db503509b8236bc4d3dc39cebb74498365750": "\nReferences\n\n[BIBREF1]\n[BIBREF2]\n[BIBREF3]\n[BIBREF4]\n[BIBREF5]\n[BIBREF6]\n[BIBREF7]\n\n[BIBREF8]\n[BIBREF9]\n[BIBREF10]\n[BIBREF11]\n[BIBREF12]\n\n[BIBREF13]\n\n[BIBREF14]\n\n[BIBREF15]\n\n[BIBREF16]\n\n[BIBREF17]\n\n[BIBREF18]\n\n[BIBREF19]\n\n[BIBREF20]\n\n[BIBREF21]\n\n[BIBREF22]\n\n[BIBREF23]\n\n[BIBREF24]\n\n[BIBREF25]\n\n[BIBREF26]\n\n[BIBREF27]\n\n[BIBREF28]\n\n[BIBREF29]\n\n[BIBREF30]\n\n[BIBREF31]\n\n[BIBREF32]\n\n[BIBREF33]\n\n[BIBREF34]\n\n[BIBREF35]\n\n[BIBREF36]\n\n[BIBREF37]\n\n[BIBREF38]\n\n[BIBREF39]\n\n[BIBREF40]\n\n[BIBREF41]\nCopyright (CC BY 4.0)\n\nThe authors have asserted their moral right to be identified as the authors of this work.\n\nThis work is licensed under a Creative Commons Attribution 4.0 International license. To view a copy of this license, visit <https://creativecommons.org/licenses/by/4.0/> or send a letter to Creative Commons, PO Box 6685, Princeton, NJ, 08540-0873 USA.\n\nAcknowledgements\n\nThis work was supported in part by the H2020 project AI4EU (825619) and a postDoc grant (ANR-17-CE28-0007).\n\n[BIBREF]\n\nThe authors would like to thank the anonymous reviewers and Editor in chief Joana Zorzi for their valuable help.\n\n[BIBREF1] Roberti,",
    "64af7f5c109ed10eda4fb1b70ecda21e6d5b96c8": "\nReferences\n\nAllaman, A, A, Gupta D. Detection of Propaganda in Social Media Messages via Deep Learning with Pre-trained Language Model (2020). https://arxiv.org/abs/2006.01327\n\nBERT, B, Devlin, J, and Chang, S. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (2019). https://arxiv.org/abs/1910.03123\n\nBIBREF0 Devlin, J, Card, C, Kiesel, A, Yang, L, Toutanova, O, and Liang, A. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In Proceedings of the Conference on Human Language Technologies, 2019\n\nBIBREF1 Ellul, J, and Ellul J. Propaganda: The Formation of Men's Attitudes (1953). http://users.ox.ac.uk/~ellul/Books/propaganda/ellul-propaganda.html\n\nBIBREF2 Ellul, J, and Ellul, J. Propaganda Technique (1945). http://users.ox.ac.uk/~ellul/Books/propaganda/ellul-propaganda2.html\n\nBIBREF3 Ellul, J, and Ellul, J. Propaganda Technique (1947). http://users.ox.ac.uk/~ellul/Books/propaganda/ellul-propaganda3.html\n\nBIBREF4 Kalyanapuram, S, K, Stede, C, Rafferty, L, Chaudhary, S, Bansal P S, and Liu F. Shared Task: Fine-Grained Propaganda Detection for the 2nd Workshop on NLP for Internet Freedom. In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies-NLP in the Wild. Association for Computational Linguistics, 2019\n\nBIBREF5 Li, S, Dang, K, Zhai, Z, and Cao B. Automated propaganda detection in news articles by deep learning with a novel adversarial learning strategy. In Proceedings of the International Joint Conference on Natural Language Processing. Association for Computational Linguistics. 2016\n\nBIBREF6 Saeed,",
    "b0a18628289146472aa42f992d0db85c200ec64b": "\nReferences\n\nWe acknowledge the use of the following works:\n\nBIBREF1.\n: Ellul, Jacques. `The Technological Society'. In:\n: Ellul, Jacques\n: Propaganda. Translated by John C. Sheridan.\n, R. R. R.\n\n: Charles J. Loomis,\n: The Worlds of Jacques Ellul.\n\nBIBREF2.\n: Ellul, Jacques\n\n. `Propaganda and the Public'.\n: In:\n\n: From Reason to Revolution. Edited by\n: James M. Reed.\n\nBIBREF3.\n: Ellul, Jacques\n\n. `Technological Socialism'.\n: In:\n\n: The Philosophy of Technique.\n\nBIBREF4.\n: Cozza, Alessandro\n: et al.\n: Proceedings of the 5th Workshop on NLP for Internet Freedom.\n\nBIBREF5.\n: Gralla, Marco\n\n. `The Role of Propaganda Analysis in Anti-Fake News Detection: An Overview and Challenges'.\n: In:\n: Goyal, Karunesh\n: et al.\n: Proceedings of the Second Workshop on NLP for Internet Freedom.\n\nBIBREF6.\n: van der Meulen, Stefan\n\n: et al.\n\n: Proceedings of the Second Workshop on NLP for Internet Freedom.\n\nBIBREF7.\n: Zhang, Yizhou\n: et al.\n\n: Proceedings of the Second Workshop on NLP for Internet Freedom.\n\nBIBREF8.\n: Dredze, Karl-Theodor\n: Hagen, Bernhard\n\n: et al.\n: Proceedings of the Second Workshop on NLP for Internet Freedom.\n\nBIBREF9.\n: Koo\n: et al.\n\n: `Cost-Sensitive Learning'.\n: In:\n: Proceedings of the 22nd Annual Conference of\n: the Association for Computational Linguistics\n: Companion Volume\n\nBIBREF10.\n: Popescu, Maria Carmen\n: et al.\n: `Cost-Sensitive Classification with Adaptive Thresholds'.\n: In:\n: Proceedings of the 27th Conference on\n: Computational Natural Language Learning\n: Bridging Word Problems and",
    "72ce05546c81ada05885026470f4c8c218805055": " Our work on context-embeddings incorporates research from this project. Warwick CDT for Urban Science & Progress has benefited from support from the NERC and EPSRC, as well as the EU Interreg project i-City and the Royal Society International Exchanges.\nThe authors wish to thank all contributors to the NLP-for-Internet-Freedom shared task and especially the team behind the Propaganda Techniques Corpus.\n1 PTC, Propaganda Techniques Corpus\n2 Ellul, J.., 1964. Propaganda Technique and Civilization. Socratic Seminars. New Brunswick: Transaction Publishers.\n3 Ellul, J.., 1987. Propaganda. London: Sage Publications.\n4 BIBREF4 DaSanMartino. Propaganda Technique Classification Task at the 2019 Symposium on NLP for Internet Freedom. Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing.\n5 Kovach, B., and Nenonen, S., 2017. Detecting Misinformation and Propaganda in News Articles Using Sentiment Analysis. The Semantic Web Workshop 2017.\n6 BIBREF5 Hu, Y., and others. Identifying Disreputable News Organizations in Tweets. EMNLP 2018.\n7 BIBREF7 Yi, Q., and others. Addressing Class Imbalance in Neural Network Classification. EMNLP 2018.\n8 BIBREF8 Jiang, H., and others. Class-Balanced Neural Network Architectures for Sentence Classification. ACL 2018.\n9 BIBREF9 Liao, H., and others. Cost-Sensitive Learning with a Focus on Topic Words. ACL 2018.\n10 BIBREF10 Zong, Y., Zhou, Y., and others. A General Method for Balancing Class Weights in Topic Models. ACL-IJCNLP 2018.\n11 BIBREF12 Yang, J., and others. Cost-Sensitive Learning for Sentence-Level Classification. EMNLP 2017.\n12 BIBREF13 Jiang, H., and others. Translational Data Augmentation Improves Neural Machine Translation. ACL 2018.\n13 BIBREF14 Ma, C., and others. Automatic Creation of Adversarial Corpus using Synonym Transformation. ACL 2019.\n14 BIB",
    "5b551ba47d582f2e6467b1b91a8d4d6a30c343ec": "\n\nAppendix ::: Acknowledgments\n\nWe thank all reviewers for their constructive suggestions, as well as Rei, Sujoy, Alicia, Eric, Tim, Kathy, Allen, and Micah for their feedback.\n[1]\n\nHu, X., et al. (2017). `Latent-Attentive-Sequence-To-Sequence', Proceedings of the 2017 Conference of the North America Chapter of the Association for Computational Linguistics: Human Language Technologies.\n\n[2]\n\nRibeiro, S., et al. (2016). `GloVe: Global Vocabulary, Fast and Accurate Word Representation from Text via Deep Learning', NAACL 2017 Workshop and Shared Task on Improving Word Sense Disambiguation: Learning Distributed Representations from Multiple Senses, pages 48-55.\n\n[3]\n\nZhai, F., et al. (2020). `Cookpad Recipe2Text: Recipe Generation Using Deep Learning', Proceedings of the 30th Conference of the Special Interest Group on Computer-Human Interaction: Companion Proceedings 2020, 3-10.\n\n[4]\n\nKulkarni, T. G., et al. (2018). `What Can Recommender Systems Do for Data-To-Text Generation?', Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: Companion Proceedings of the 2018 Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 6-13.\n\n[5]\n\nGoyal, P., et al. (2017). `Generating Conversations That Persuade: A New Dataset and Evaluation Study', Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 2523-2531.\n\n[6]\n\nLiu, M., et al. (2018). `Latent Attentive Sequence-to-Sequence Learning of Conditional Probabilistic Narratives via Conditional Language Modeling and Generative Adversarial Adaptation', Proceedings of EMNLP2018.\n\n[7]\n\nWang, H., et al. (2018). `Hierachical Multi-Conditioned Encoder-Decoder with Cross-Attention for Sequence-to-Sequence Generation', 2018 Conference of the Association for Computational Linguistics.\n\n[",
    "3cf1edfa6d53a236cf4258afd87c87c0a477e243": "  Our survey found that our personalized models perform well on average against the baseline model on both criteria, confirming the coherence benefit provided by personalization.\n\nTable 1: : Mean evaluation ratings of different models for user coherence on samples of 5 recipes from both Food.com and FoodReviews4.\n\nTable 2: : Mean evaluation ratings of different models for user quality on samples of 5 recipes from both Food.com and FoodReviews4.\n\nTable 3: : Mean evaluation ratings of different models for user preferences on samples of 5 recipes from both Food.com and FoodReviews4.\n\nTable 4: : Mean evaluation ratings of different models for user personality on samples of 5 recipes from Food.com.\n\nTable 5: : Mean evaluation ratings of different models for recipe quality on samples of 5 recipes from Food.com.\n\nTable 6: : Mean evaluation ratings of different models for recipe preferences on samples of 5 recipes from Food.com.\n\nTable 7: : Coherence metrics (C-score) for samples of 5 recipes from FoodReviews4.\n\nTable 8: : Personalization metrics (UMA, MRR) for samples of 5 recipes from FoodReviews4.\n\nTable 9: : Human evaluation scores for personalization (recipe coherence) and preferences (ingredient coherence) on FoodReviews4.\n\nTable 10: : Sample output for a cocktail recipe.\n\nTable 11: : Sample output for sweet waffles.\n\nTable 12: : Comparison of different models for coherence on Food.com (left), FoodReviews4 (middle), and FoodReviews5 (right, showing the same recipe with different names).\n\nPersonalized recipe generation\n\n\nhttps://aclanthology.org/2020.ACL-IJCNLP-2020.1.pdf\n\nhttps://aclanthology.org/2020.ACL-IJCNLP-2020.11.pdf\n\nDedication\n\n_To all the cats who make reading impossible_\nContents\n\n  1. Dedication\n  2. Contents\n  3. Prologue\n  4. One\n  5. Two\n  6. Three\n  7. Four\n  8. Five\n  9. Six\n  10. Seven\n  11. Eight\n  12. Nine\n  13. Ten\n  14. Eleven\n  15.",
    "9bfebf8e5bc0bacf0af96a9a951eb7b96b359faa": "\n\ntab:samplechx\n\ntab:samplewaffle\n\ntab:exeval\n\ntab:exeval2\n\ntab:metricsontest Human Evaluations: All Personalized\n\ntab:samplechx\n\ntab:samplewaffle\n\ntab:exeval\n\ntab:exeval2\n\ntab:metricsob\n\ntab:coherencemetrics\n\ntab:samplechx\n\ntab:samplewaffle\n\ntab:exeval\n\ntab:exeval2\n\ntab:metricsob\n\ntab:coherencemetrics\n\ntab:samplechx\n\ntab:samplewaffle\n\ntab:exeval\n\ntab:exeval2\n\ntab:metricsob\n\ntab:coherencemetrics\n\n::: User Interface (Human Eval)\n\n::: Personalization Methods\n\nAppendix ::: Details for Coherence Metrics\n\nA recipe must be coherent across individual steps and temporally, as well as semantically (across the whole recipe). We introduce three coherence metrics to evaluate these aspects of a generated recipe. See Appendix ::: Coherence Metrics for details on the implementation of these metrics.\n\ntab:coherencemetrics: Coherence Metrics\n\n::: Coherence Evaluation Metrics\n\ntab:metricsob\n\ntab:coherencetests: Coherence Metrics Scoring\n\ntab:coherencetests\n\ntab:coherencetests\n\ntab:coherencetests\n\ntab:coherencetests\n\ntab:coherencetests\n\ntab:coherencetests\n\ntab:coherencetests\n\ntab:coherencetests\n\ntab:coherencetests: Coherence Metrics Scoring\n::: Sample Metrics (Human Eval)\n::: Coherence Metrics Score (Human Eval)\n\nfig:exeval Human Eval: Coherence Score\n\n::: Results\n\ntab:metricsob Human Eval: Coherence Comparisons by User\n\ntab:metricsob\n\ntab:metricsob\n\ntab:metricsob\n\ntab:metricsob\n\ntab:metricsob\n\ntab:metricsob\n\ntab:metricsob\n\ntab:metricsob\ntab:metricsob\n\ntab:metricsob\n::: Result Examples\n\ntab:exeval",
    "34dc0838632d643f33c8dbfe7bd4b656586582a2": "\nAppendix ::: Generating and Scoring Models\nAll our models are transformer-based, following BOB BIBREF35. Specifically, we use a 4-layer transformer model, augmented with positional attention BIBREF36. See tab:modelarch for details of our components.\nBERT (Bidirectional Encoder Representations from Transformers) BIBREF34 is used as an additional source of information: We use a BERT BIBREF34 large uncased English cased model (2 million parameters, 12 layers) on all ingredients present in the recipe steps. All other input tokens except for the last 3 ingredients are ignored. We use BERT attention on user-generated recipes and a BOW BIBREF37 vocabulary lookup for recipe-name tokens to obtain user-recipe pairings.\nAppendix ::: Coherence Measures\nWe report BLEU-1/4, ROUGE-L, Distinct-1/2 (proportion of distinct unigrams and 2-grams), and LREC Score from [LREC2018] BIBREF38, BIBREF39 as coherence measures. We also performed a separate human evaluation over 90 randomly chosen recipes, in which 60% of users found the recipes generated by personalized models to be more coherent. See supplementary materials of BIBREF36 for details of these measures. tab:coherencemetrics reports BLEU-1/4 score of BERT language modeling baselines over recipe instructions in our setting. All other scores are better than baseline.\nappendix. : : : : Recipe Dataset : : : : Data-to-Text Generator Baselines\n\nWe compare against two data-to-text model baseline baselines. The first, Encoder-Dec, is a simple encoder-decoder model with prior recipe information. The second, Nearest-Neighbor (NN), uses BERT BIBREF34 to obtain the input recipe name to search for similar recipes from Food.com; it then generates a recipe from the selected recipe's first 3-5 ingredients. This model outputs the most prevalent recipe ingredients (from BOTTOCP BIBREF37 and Tabular N-gram) with a small probability.\n\n[Tab:name] Name of the recipe in the input. [Tab:ingredients] First 3-5 input ingredients. [Tab:calorielabel] Caloric-level label of the recipe (high,",
    "c77359fb9d3ef96965a9af0396b101f82a0a9de6": "\nTable C:3. Results of Pairwise Evaluation (tab:metricsontest)\n\nTable D:4. Coherence Metrics (tab:coherencemetrics)\n\nTable E:5. Entailment Metrics (tab:coherencemetrics)\n\nTable F:6. Topics of User Reviews (tab:expert-ranking)\n\nTable G:7. Personalization Metrics: Proportion of Review Mentioning Each Ingredient (tab:exp_ingredients)\n\nTable I:8. Personalization Metrics: Percentage Correct (tab:exp_ingredients)\n\nTable J:9. Personalization Metrics: User-Ranked Probabilities (tab:exp_ingredients)\n\nTable K:10. Personalization Metrics: Personal Ranking (tab:exp_probability)\n\nTable L:11. Personalization Metrics: User-Ranked MRR (tab:exp_probability)\n\nTable M:12. Personalization Metrics: Proportion Identical to User Profile (tab:exp_probability)\n\nTable N:13. Personalization Metrics: User-Ranked UMA (tab:exp_probability)\n\n## Contents\n\nOne\n\nTwo\n\nThree\n\nFour\n\nFive\n\nSix\n\nSeven\n\nEight\n\nNine\n\nTen\n\nEleven\n\nTwelve\n\nThirteen\n\nFourteen\n\nFifteen\n\nSixteen\n\nSeventeen\n\nEighteen\n\nNineteen\n\nAbout the Author\n\n## One\n\nThey didn't always speak to each other. There were whole days in between the visits when neither of them called the other. When both of them stayed busy and out of the house and didn't have time to think, it was easy to stay out of each other's lives. Afterward, though, during those moments of quiet when the world's noise suddenly went silent, when the world just wasn't loud enough and you could really hear, it was hard to forget how much you'd needed them. To have them close again.\n\n* * *\n\nThey didn't talk about it often. If one of them asked, the other would just say one of their favorite old lines back.\n\nBut they were thinking about it. They both were.\n\nTalking",
    "1bdc990c7e948724ab04e70867675a334fdd3051": " We repeat each survey 10 times, with results shown in tab:coherencemetrics.\nAppendix ::: Generator and Scorer Details\n\n### Encoder Layer\n\nHere, we describe details of the encoder layer.\n### Ingredient Embedding Module\n\nHere, we describe details of the ingredient embedding module.\n### Decoder Layer\n\nHere, we describe details of the decoder layer.\n\n\n\n## DEDICATION\n\nFor my family: Mom, Dad, and all the brothers and sisters\n\n## EPIGRAPH\n\nThe world breaks everyone, and afterward many are strong at the broken places.\n\n\u2014Ernest Hemingway\n\n## CONTENTS\n\nDedication\n\nEpigraph\n\n1 The New Guy\n\n2 The New Guy Takes a Ransom\n\n3 Two Brothers from the Same Mother\n\n4 A Bad Break\n\n5 A Little Family History\n\n6 Fired\n\n7 The Gat, a Bullet, and a Blade\n\n8 A Very Personal Threat\n\n9 The Brothers Gather\n\n10 The Big Move\n\n11 A Little Cigar Store Indian\n\n12 Bury It\n\n13 The Bodies Get Up Again\n\n14 The Funeral\n\n15 Two Brothers Leave Home\n\n16 The Big City\n\n17 A Surprise\n\n18 Getting Around in the Big City\n\n19 The Big Move\n\nEpilog\n\nAcknowledgments\n\nP.S. Insights, Interviews & More...*\n\nAbout the author\n\nBack Ad\n\nBooks by R. J. Esquivel\n\nCredits\n\nCopyright\n\nAbout the Publisher\n\n## 1\n\n## THE NEW GUY\n\nHe stepped off the bus looking around, waiting for one of the two men who had spoken to him earlier in the day.\n\nHe figured he was in the wrong part of town. This street looked like every street he'd ever been on in this city. He just didn't feel like breaking his back searching for one or the other of the men who had pulled him off the bus, and asked him to wait.\n\nThe sidewalk was cracked and stained with a light orange, and patches of the green paint in the middle of each street sign were cracked and peeling the edges were coming free.\n\nOne old man was sitting on a wooden",
    "78536da059b884d6ad04680baeb894895458055c": " In the future, we would like to try other domain-specific pre-training tasks and compare them with current results of these methods. We believe that the state of the art results presented in this paper would be useful for future research in the field of NLP applications and will have practical uses in real-world scenarios like information extraction and summarization.\nA.1 BioScope Corpus\nThe BioScope Corpus (http://bioscope.eu/), is a collection of online papers published on biomedicine that have a biological component. BioScope Corpus consists of 3 sub corpora: BioScope Full Papers (http://bioscope/publications), BioScope Abstracts (http://bioscope/abSTRACTS?f=html&f=BIBREF1) and BioScope Reviews (http://bioscope/reviews). The sub corpora are available in the following formats:\nBioScope Full Papers are the full text of scientific papers: abstract, introduction, methods, results and discussion.\n\nBioScope Abstracts is the text of full paper's abstract only. The abstract is used as input to all subsequent processing.\nBioScope Review Corpus is a collection of reviews written on articles published in BioScope Full Papers and BioScope Abstracts.\nBioScope Corpus comprises of 1.3 Million sentences.\n\nA.2 BioScope Review Corpus\nThe BioScope Review Corpus (http://bioscope/reviews) was created within the BioScope Corpus and is a collection of approximately 100,000 review sentences. It is an open-ended corpus that is collected from the open-access full paper corpus and is curated through human evaluation. This is done such that the curation tag of the documents follows a strict consistency principle.\n\nThe BioScope Review Corpus comprises of 1,000 documents of 3.4 Million sentences.\n\nA.3 Sentence Level Features for Speculation Cue Detection\n\nSense-disambiguated word lists: The word list for a sentence is available in the following format. Each word is given as a list of senses. The sense of word \"it\" is [s = [noun, adv, noun], the sense of word \"might\" is [s = [verb], the sense of word \"rain\" is [s = [noun, adv, noun, verb].\n\nSense-disambiguated morphological features",
    "96b07373756d7854bccc3c12e8d41454ab8741f5": "\nAcknowledgements\nFirst, a very special thanks to the CoNLL Shared Task Organizers for hosting such a rich competition, with multiple variants of the subtasks. Secondly, a very special thanks to our peers (Anirudha Tandon and Sanika Sawant) for their insightful comments and their support at all times.\n\nBIBREF0 Biologically Inspired Requirements Engineering Focused on Processes (BIBREF21)\n\nBIBREF1 Biomedical Entities in Research Finding and Exploiting Ontology (BIBREF22)\n\nBIBREF3 Unsupervised Cue Based Negation Scope Resolver (BIBREF11)\n\nBIBREF4 Using Machine Learning to Learn Unsupervised Natural Language Processing Rules for Negation and Predicate Cue Detection (BIBREF3)\n\nBIBREF5 A Comparison of Natural Language Processing Models for Negation and Speculation Detection in the Biomedical Domain (BIBREF8)\n\nBIBREF7 Using Recursive Neural Networks for Negation and Predicate Annotation of Biomedical Abstracts (BIBREF6)\n\nBIBREF8 Towards Automatic Inference of Negation and Speculation Annotation Information in Abstracts (BIBREF4)\n\nBIBREF9 Detecting Negation And Speculation Labels in Biomedical Sentences (BIBREF10)\n\nBIBREF10 Unsupervised Learning of Negation And Predicate Annotation Scopes Using Convolutional Neural Networks (BIBREF9)\n\nBIBREF11 Unsupervised Learning of Negation And Predicate Annotation using Transformers for Biomedical Abstracts (BIBREF11)\n\nBIBREF12 BERT: Pre-trained Language Representations (BIBREF20)\n\nBIBREF13 A Proposed Rule Based Approach To Negation and Speculation Scope Resolution (BIBREF5)\n\nBIBREF14 Negation And Speculation Scope Resolver Using Machine Learning (BIBREF12)\n\nBIBREF15 A Generalized Architecture for Negation And Specription Scope Detection in Biomedical Abstracts (BIBREF17)\n\nBIBREF16 A Scope Based Approach For Negation Detection and Its Application (BIBREF6)\n\nBIBREF17 An Efficient Deep Learning Approach To Negation and Scope Resolution (BIBREF6)",
    "511517efc96edcd3e91e7783821c9d6d5a6562af": "\nAppendix I\nAppendix II\nIn Appendix B, we provide the implementation details for the code used in this paper.\nAppendix III\nAppendix I\nIntroduction\nAutomatically identifying and separating factual information from speculative information is a crucial task in information analysis for multiple use-cases like fact-checking and clinical decision support. This challenge is important in both the fields of natural language processing and medical informatics, as the presence of speculative information in patient reports and medical articles can lead to information overload, and is often incorrect or even fraudulent as well. A recent example is the case of the use of ivermectin to treat the novel disease Covid-19 (Krishnan et al., 2018), which led to an unnecessary death of a patient (Gottlich et al., 2020). This phenomenon is not limited to the biomedical domain and has been observed on public health reports for both Covid-19 and the Spanish flu (Kilcullen et al., 2020). Thus, detection and resolution of speculations has the potential to significantly improve the understanding of public health reports, for both healthcare and research, and could even lead to improvement of medical care. This challenge was broken down into three subtasks: the first subtask was the identification of uncertainty cues, the second subtask was the identification and resolution of the scope of any cue, while the third subtask was the identification of weasel words. In this paper, we address the issue of speculation detection and scope resolution by performing a joint training of XLNet and RoBERTa to create a more effective approach, thereby outclassing all other approaches for speculation detection and scope resolution in the biomedical domain.\nA.1 Models\n\nB.1 Training Datasets\n\nAcknowledgements\n\nOur work in this paper has been in part based on the work by (Khandelwal and Sawant, 2018), hence all the original authors are acknowledged. All results presented in this paper are an expansion of the results by Khandelwal and Sawant (BIBREF12), and all the experiments are conducted using the work described in that paper.\nThis document is licensed under the Creative Commons Attribution 4.0 International License (CC-BY 4.0). To view a copy of this license, visit\n\n<https://creativecommons.org/licenses/by/4.0/>\n\nThis license applies to any work in which a reference to this paper or in which this paper",
    "9122de265577e8f6b5160cd7d28be9e22da752b2": "\n1. https://www.cl.cam.ac. uk/teaching%28old%29/AI-HRI%20Papers/BIBOBS21-BIBREF0.pdf#slide=36\n2. The BioScope corpus: an annotated corpus of research abstracts and full-text biomedical scientific literature for clinical decision support Inference of Uncertainty: From NLP to Clinical Decision Support\n\nF. Fusco, et al. NIPS Workshop on Uncertainty Representation and Analysis Using Machine Learning (U-RAMP), 2017\n\n3. Uncertainty Detection and Interpretation in Med-Concern Knowledge Bases (UDEMY)\n\nI. Khandelwal, W.-H. Sawant, et al. ICLR Workshop on Semantics for Health and Disease (SemEvalMed), 2017\n\n4. Improving the Accuracy of an Uncertainty Detection System through Class Weighted Training in Specification Based Machine Learning\n\nI. Khandelwal, W.-H. Sawant, et al. ICLR Workshop on Empirical Methods in NLP and Human Language Understanding (EMNLP), 2017\n\n5. Uncertainty Detection with Specification Based Class-Weighted Training (UDEMYBERT)\n\nI. Khandelwal, W.-H. Sawant, et al. EMNLP 2018\n\n6. Uncertainty Detection based Learning Class Weighted Training (UDEMYBERT), Recursive Neural Networks (UDEMYRNN) and Neural Memory Networks (UDEMYNMNMN)\n\nI. Khandelwal, W.-H. Sawant, et al. COLING 2018\n\n7. Uncertainty based Negative Class Class Weighted Training for Bidirectional Encoder Representations from Transformer (UDEMYBERTBERT), Recursive Neural Networks (UDEMYRNN) and Neural Memory Networks (UDEMYNMNMN)\n\nI. Khandelwal, W.-H. Sawant, et al. CoNLL-2018\n\n8. Uncertainty Detection based Learning Class Weighted Training using Xception for Bidirectional Encoder Representations from Transformer (UDEMYBERTBERT), Recursive Neural Networks (UDEMYRNN) and Neural Memory Networks (UDEMY",
    "e86130c5b9ab28f0ec539c2bed1b1ae9efb99b7d": "\nRecommendations\nGiven the significant gain in F1 points when trained on multiple datasets, we recommend using these techniques in future work related to the tasks discussed in the paper. Additionally, we recommend working with the same hyperparameters that we use for these models to reproduce our results.\n\nFurther details on our methodology can be found here.\nBIBR\n\n1. [Bureau of Labor Statistics, 2017], Bureau of Labor Statistics. 'Work and Employment Indicators', USA: United States. Available at https://www.bls.gov/webapps/legacy/cepapi.htm.\n\n2. [BIBREF0 S, 2017] Siddhartha Sridhar, Amrutha Ramakrishnan and Sanjeev Sridhar, \"BioScope Corpus 1B: Speculation detection and scope resolution on the BioScope Corpus\". CoNLL-2010 Shared Task 1B. Available on https://www.cl.cam.ac.uk/~js14/shared_tasks/BIBREF0/papers/BIBREF0/S.pdf.\n\n3. [BIBREF0 M, 2017] Siddhartha Sridhar, Amrutha Ramakrishnan and Sanjeev Sridhar, \"BioScope Corpus 1W: Weasel identification on the BioScope Corpus\". CoNLL-2010 Shared Task 1W. Available on https://www.cl.cam.ac.uk/~js14/shared_tasks/BIBREF0/papers/BIBREF0/M.pdf.\n\n4. [BIBREF5 K, 2015] Kumar, Punit; Sridhar, Sanjeev and Sridhar, Siddhartha, \"A maximum entropy classifier for identifying negative cues in biomedical text: The BioScope Corpus\". BioNLP-2016, October 2016. Published at AAAI International Conference on Web and Social Media 2016, Sydney, Australia, 2016, 2016. Available on http://www.aclweb.org/anthology/pdf/2016.B-5606.pdf.\n\n5. [BIBREF6 L, 2017] Lenzerini, Paolo and Moffett, Richard, \"Exploiting negation cues for biomedical scope detection\". BioNLP-2017, September 2017. Published on http://www.acl",
    "45be665a4504f0c7f458cf3f75a95d5a75eefd42": " \nThe results by Khandelwal and Sawant (BIBREF12), and ours, were better for the base variant of the models, while the large variant generally outperforms the base variant on this task with more generalizability.\nAcknowledgements\nFirst author thanks the University of Southern California and the National Cancer Institute for their support and resources. This work forms a part of the authors' thesis.\nThis work is jointly supported by the Research Council of Norway, University of Southern California, and NCI. The use of the BioScope corpus is with the permission of the National Center for Biomedical Ontology.\n[1] BIBREF0 Khandelwal M, Sawant S. Speculation Detection and Resolution for Biomedical Data Analysis. In Proceedings of the 2010 CoNLL-shared Task BioScope: Shared Task Description. [Online] 2018; Available from: <https://www.aclweb.org/anthology/K10-1029.pdf> [cited 2018-03-21].\n[2] Fung C. Biostatement of a Document. Proceedings of the 22rd International Joint Conference on Artificial Intelligence, 2016. [Online] 2016; Available from: <https://ojs.aaai.org/index.php/AAAI/article/view/6049/5360> [cited 2018-03-21].\n[3] Khandelwal M, Sawant S. Negation and Speculation Detection for Biomedical Dataset Analysis. Proceedings of the CoNLL-2013 Shared Tasks. [Online] 2013; Available from: <https://www.aclweb.org/anthology/D13-1050.pdf> [cited 2018-03-21].\n[4] BIBREF5 Chen YD, Yi D, Liu R. Negation Detection and Scope Resolution with Maximum Entropy Classifiers. Proceedings of the 20th Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies 2014. [Online] 2014; Available from: <https://dl.acm.org/citation.cfm?id=2481922> [cited 2018-03-21].\n[5] BIBREF6 Tan Q, Ngiam H, Cheok C. Use of Syntactic and Semantic Features for Negation Detection and Scope Resolution. Proceedings of Workshop on",
    "22b740cc3c8598247ee102279f96575bdb10d53f": " A major challenge in future work is to provide compositional models that are applicable both with scarce hand-annotated data as well as with corpora-derived representations in noisy-data settings, and thus enabling the discovery of knowledge and the exploration of application domains.\nReferences\n\n[BIBREF0001] B. Al-Khodaei and D. L. Dagan, 2010. What the phrase tells us: compositionality, context and frequency in paraphrasing: an empirical study. Cognitive Science, 34: 1551\u20131574.\n\n[BIBREF0002] L. Allen, Y.-S. Cha, H. Li, and T. Xue, 2016. Coherent paraphrasing from word alignments: a latent variable method. In Advances in neural information processing systems, pages 985\u2013989.\n\n[BIBREF0003] M. Ang, A. Kiela, W. C. Lin, S. Ginter, C. Lazaridou, and B. Klein, 2016. Characterizing syntactic function in English with lexicalized co-occurrence models. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, 2016.\n\n[BIBREF0004] J. Baroni, 2010. Semantic factors in word meaning: evidence from experimental and lexical analysis. In Proceedings of the 40th meeting of the North American Chapter of the Association for Computational Linguistics: short papers, 2010.\n\n[BIBREF0005] A. Beam, S. Z. Chang, V. Joshi, and D. M. Klein, 2016. Contextual compositionality with word vectors and word embedding matrices. In Neural Information Processing Systems (NIPS), pages 2221\u20132234.\n\n[BIBREF0006] S. Beam and D. M. Klein, 2016. Context-dependent compositional representations with word embedding matrices: modeling compositionality from large language model data. In Proc. of ACL, pages 2173\u20132181.\n\n[BIBREF0007] D. Berman, S. Czyborra, J. L. Kirchhoff, F. Martens, and M. R. Smith, 2014. The universal compositional matrix of meaning: modeling with matrix completion. In Proc. of ICML-2014: International Conference on Machine Learning, pages 1150\u20131158.",
    "74b4779de437c697fe702e51f23e2b0538b0f631": "\nAcknowledgments\nWe are thankful for the helpful and constructive feedback of the anonymous reviewers, as well as our colleagues in the semantics and translation communities. For their insightful comments we would like to specifically thank Shyam Raman and David Marcu. This work was supported by an AFOSR grant FA9550-17-1-0910 as well as by the Semantic Technology Center and a Facebook Fellowship.\nBibliography (A\u2013Z)\n\nAlshawi, Y., & Huddleston, G. 2001. Syntactic Theory. 2nd ed. Cambridge University Press, MA.\n\nBaroni, M., Dredze, L., Huluganti, D., & Chincha, C., 2010. Lexical coherency is compositional and reflects the linguistic properties of words. Psychological Science, 21(9), 1151\u20131160.\n\nBar-Haim, A., & Krahmer, E., 2008. A compositional semantic model for idioms. Computational Linguistics, 25, 303\u2013333.\n\nBar-Haim, A., & Krahmer, E., 2010. Exploiting compositionality in semantic disassembly. In Proceeding of COLING 2010, pages 1119\u20131122.\n\nBaroni, M., & Hacker, M., 2010. Word order in phrase structure grammars: A new method for unsupervised discovery of compositional semantics. In\n\nProceeding of COLING 2010, pages 997\u20131002.\n\nBel, A., & Stern, Y., 2013. Learning compositional phrase representations with sparse annotation. EACL 2013, pages 184\u2013192.\n\nBengtson, H., & Moens, C., 2003. Learning compositional structures of linguistic phrases. In\n\nProceedings of COLING 2003, pages 631\u2013636, Vol. 1. Association for Computational Linguistics\n\nCaruana, R., De Rijke, M., & Hardmeier, S., 2012. The compositionality of English quantifier phrases in different sentence domains: A linear geometric framework.\n\nComputational Linguistics, 28(1), 19\u201335.\n\nChen, N., & Goodman, N. 2005. A fast and accurate word alignment algorithm.\n\nProceedings of ACL 2005, Vol. 2: Short Papers. Association for Computational Linguistics\n",
    "435570723b37ee1f5898c1a34ef86a0b2e8701bb": " We plan to explore the impact of semantic compositionality representations within our recently-proposed neural architecture for compositionality BIBREF35.\nAcknowledgements\nWe thank the anonymous reviewers for valuable feedback that improved the final manuscript significantly, and the members of the CSAIL and UMass Mailing List for useful discussions. We'd like to thank the reviewers of earlier versions of the manuscript for their valuable feedback and insightful suggestions.\nReferences\n\nAnderson2013\n\nA.A. Anderson,\n\nD.H. Woodley,\n\nA.R. Bhattay,\nand E.P. Rishipal\n\n\"Towards A Unified Word Vectors Approach Using Multiple Roles and a Latent-Variable Latent Semantic Analysis\"\n\nProceedings of the International Conference on Document Analysis and Recognition (ICDAR)\n\n(Toulouse: 2013)\n\nhttp://www.aclweb.org/anthology/D/D13/\n[paper](www.aclweb.org)\n\nBender2011\n\nH. Bender,\n\nT.M. Mikolov,\n\nN.P. Smolensky,\nC.R. Lawrence,\nE. Hovy,\nA. Kuraszkopf,\nand D. Reznik\n\n\"Learning Phrase Representations with the Mapping and Non-negative Matrix Factorization Model\"\n\nProceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)\n\n(Nancy, France: 2011)\n\nhttp://www.aclweb.org\nBibliographic Code: 2011\u2044emnlp\\-2011\u2044papers/\u200b43.pdf\n\nBIBREF1\n\nO. Kempka,\n\nA. Korhonen,\nand D. Jurafsky\n\n\"Vector Space Models of Meaning: An Application to Sentence Composition\"\n\nComputational Linguistics\n\n(CL)\n\nhttp://www.aclweb.org/anthology/N11/2011.kempla.pdf\n\nBIBREF2\n\nP.T. Baroni,\n\nK.K. Schnyder,\nR.R. Povey\n\n\"A Language Model for Phrasal Compositionality from Paraphrases\"\n\nProceedings of the Conference on Empirical",
    "aa2948209cc33b071dbf294822e72bb136678345": "\nAppendix\nA.1. Detailed Model and Datasets\nAutoJudge is the neural model designed to predict the result of a civil case with plea and fact description, considering the effect of law articles. This neural model can take fact description, pleas, and law articles as inputs and get results as output. This neural model is flexible for various types of cases. In this section, we will summarize our model and compare the dataset construction for evaluation.\nA.2.1.1. Module Details\nAutoJudge can be divided into the following three modules, i.e. text encoder, pair-wise attentive reader, and output layer.\nA.2.1.2. Text Encoder\nText Encoders\n\nFact Descriptions\n\nPleas\n\nLaw Articles\n\nWe employ two sets of b-GRUs DISPLAYFORM0\n\nand one GRU DISPLAYFORM0\n\nas the text encoders separately for fact descriptions DISPLAYFORM0\n\n, pleas DISPLAYFORM0\n\n, and law articles DISPLAYFORM0\n\n. More details in Text Encoders are illustrated in Text Encoder block, described in next subsection.\n\nAutoJudge can consider different types of cases, including criminal, civil and international cases. Under such different scenario, we decide to employ different encoders for fact descriptions, pleas, and law articles respectively to suit different cases.\n\nA.2.1.3. Text Encoder for Fact Descriptions\n\nBi-Directional GRU\n\nBi-Directional GRU, proposed by Luo et al. BIBREF43, can preserve the information directionally as well as in time sequence. So far most neural sequence encoding methods consider text or sequence only from the sequential temporal context. Besides, Bi-GRU has achieved success in text classification. For example, it achieves superior performance in text modeling and semantic inference comparing to CNNs, as in [3] or [4]. Therefore, we employ two GRUs, each of which has hidden size 128 DISPLAYFORM0\n\nand the number of filters is 100\n\nfor fact descriptions DISPLAYFORM0\n\n. Specifically, the bidirectional sequence encoding and the subsequent concatenation operation can well generate INLINEFORM8 and preserve the contextual information.\n\nThe original Bi-GRU may suffer from the fact that all the hidden states and cell states are static in each",
    "d9412dda3279729e95fcb35cbed09e61577a896e": " (3) The current model is trained with the pre-defined labels of cases, but it could also benefit from the guidance of labels generated in real-world applications. We can also think of a multi-task learning problem for judgment prediction, where some other types of pleas may be predicted separately.\nAcknowledgements\nWe appreciate the review from anonymous reviewer. We are grateful for the financial support of China Scholarship Council.\nReferences\n\nBIBREF0\nG. L. D., A. T. O., J. C. Y., et al. (2015a). A survey of computer-assisted analysis in civil litigation. Science and Technology of the Law, 21(1), 59\u201378.\n\nBIBREF1\n\nC. N., B. T., X. Z., et al. (2017). Question answering over laws: an empirical evaluation with the supreme court collection. Journal of Machine Learning Research, 26(88), 3967\u20133981.\n\nBIBREF2\n\nD. H. S., E. K. P., B. A., et al. (2016a). Text classification for the supreme court: the use of features based on n-grams, charge names, and judge behavior. Transactions of the Association for Computational Linguistics (TACL-16), 17\u201329.\n\nBIBREF3\n\nL. X., Y. M., H. P. (2018). Legalreading comprehension for charge prediction in criminal cases. Advances in Neural Information Processing Systems (NeurIPS), 2135\u20132144.\n\nBIBREF4\n\nH. Y., W. W.., M. K., D. G., et al. (2016). Text classification of supreme court verdicts for the united states of america. Transactions of the Association for Computational Linguistics (TACL), 5\u201317.\n\nBIBREF5\n\nC. Q., Z. S., C. G., et al. (2017). Reading comprehension and question answering: toward open-domain question answering systems. Annual Meeting of the Association for Computational Linguistics (ACL), 1530\u20131542.\n\nBIBREF6\n\nJ. C., J. O.., R. L., et al",
    "41b70699514703820435b00efbc3aac4dd67560a": " (3) Besides the factual input (e.g., fact descriptions), judicial bias and fairness evaluation should be considered when modeling judgment prediction. Such bias and fairness evaluation should consider both legal and factual content. (4) When dealing with fact descriptions, word order could be also very important, it's also reasonable to take into account additional semantic relations in civil cases.\nAcknowledgments\nX. Gao is partly supported by the National Natural Science Foundation of China (No. 61931135). We also wish to thank Yilin Zhu and Huei-Ting Yang from Peking University for their great supports in reading comprehension and reading comprehension models.\nReferences\nBai, X., Li, S., Wang, Y., Guo, H., and Luo, Z. (2019). LRC and QA as Dual Inputs in Neural Reading Comprehension. In Proceedings of Asian Conference on Machine Learning.\nBIBEF0 :\n\nChina Supreme People's Court (2018). The Civil and Criminal Codes of the People's Republic of China. Beijing: People's Press.\n\nBIBREF1 :\n\nBaidu, Inc., and Microsoft, Inc. (2015), Coco: Common objects in contexts. Journal of Machine Learning Research 17, 3: 3311\u20133335.\n\nBIBREF2 :\n\nRocchio, A., McCallum, A., and Plank, J. (2005). Predicting the Outcomes of Patent Cases by Analyzing the Opinions and Record of the United States Supreme Court. In Proceedings of the Eleventh Conference on Empirical Methods in Natural Language Processing.\n\nBIBREF3 :\n\nLuo, Z., Sun, K., Guo, H., Yu, B., and Wang, Y. (2018). Automatic Charges Prediction with Legal Knowledge from Court Cases. In Proceedings of Asian Conference on Machine Learning.\n\nBIBREF4 :\n\nMoschitti, J. and Jurgens, J. C. (1997). An Experiment to Measure the Effectiveness of Machine Judging. In Proceedings of the Twenty-seventh Annual Meeting of the ACL.\n\nBIBREF5 :\n\nMoschitti, J. and Jurgens, J. C. (1998). A Comparison of Reading Comprehension Models. In Proceedings of the Twenty-seventh Annual Meeting of the ACL.\n\nB",
    "e3c9e4bc7bb93461856e1f4354f33010bc7d28d5": " (3) The reading mechanism can be easily extended into other aspects (e.g., inference from question) BIBREF6, BIBREF7 if being applied in other fields in the legal area. Further, the introduction of law representation or structured knowledge into AutoJudge can be promisingly addressed as well.\n# REFERENCE\n \n# Copyright \u00a9 2016 by Soman Chainani\n\nAll rights reserved. You may not copy, distribute, transmit, reproduce or otherwise make available this publication (or any part of it) in any form, or by any means (including without limitation electronic, digital, optical, mechanical, photocopying, printing, recording or otherwise), without the prior written permission of the publisher. Any person who does any unauthorized act in relation to this publication may be liable to criminal prosecution and civil claims for damages. For information address Bloomsbury USA, 1375 Broadway, New York, NY 10018\n\nBloomsbury is a registered trademark of Bloomsbury Publishing Plc\n\nPublished in the United States by Bloomsbury Children's Books, New York   \nwww.bloomsbury.com\n\nBloomsbury books may be purchased for business or promotional use. For information on   \ncorporate purchases please contact Macmillan Corporate and Premium Sales  \nDepartment at specialmarkets@macmillan.com\n\nLibrary of Congress Cataloging-in-Publication Data  \nChainani, Soman.\n\nThe school for good and evil. Volume 3: last stand of the wicked / Soman Chainani.  \npages cm. \u2014 (The school for good and evil ; no. 3)  \nISBN 978-1-68119-749-6 (hardcover) \u2014 ISBN 978-1-68119-750-4 (e-book)  \n1. Fairies\u2014Fiction. 2. Magic\u2014Fiction. I. Title.  \nPZ7.C566462Sc 2016 [Fic]\u2014dc23  \n2015003096\n\nFor my parents, with love,   \nL. and M. S. C.\n\n## Contents\n\nCopyright\n\nFirst page\n\n##\n\nThere's my brother. He's just standing there, and there's a fire coming out of his mouth, and that sounds pretty much exactly like what you'd expect from a fire-breathing dragon.",
    "06cc8fcafc0880cf69a2514bb7341642b9833041": " (3) Civil law system is a hybrid system that combines common law and civil law. Some studies BIBREF1, BIBREF2 have applied deep learning models for legal reasoning under different aspects. However, it might not be enough to apply them into decision prediction since case materials have a completely different form. It's a promising avenue to further explore the connections between deep learning models and civil law system.\nIn this paper, we argue that the reading mechanism is important and necessary for law articles to be considered in judgment prediction. Moreover, law articles should be considered as a part of the case materials. With our LRC framework, it is demonstrated that deep neural networks are a promising tool to predict judgments in civil cases.\nAppendix A: Supplementary Materials\nIn this section we provide supplementary materials for Table TABREF1\u223cTable TABREF37.\n\nTable A.1. Details of Legal Preprocessing Rules\nTable A.2. Detailed Statistics of the Datasets\nTable A.3. Statistics of Plea\nTable A.4. Statistics of Judgment\n\nAppendix B: Additional Tables\n\nTable B.1. Case Documents With Legal Preprocessing\n\nTable B.2. Statistics of Names and Legal Articles\n\nTable B.3. Statistics of Legal Preprocessed Fact Descriptions and Plea\n\nTable B.4. Statistics of Case Documents After Preprocessing\n\nTable B.5. Top 50 Articles for Each Plea\n\nTable B.6. Statistics of Case Documents After Preprocessing\n\nTable B.7. Statistics of Legal Preprocessed Pleas\n\nTable B.8. Statistics of Case Documents After Preprocessing\n\nTable B.9. Statistics of Pleadings and Case Documents After Preprocessing\n\nTable B.10. Statistics of Legal Preprocessed Law Articles\n\nTable B.11. Statistics of Case Documents After Preprocessing\n\nTable B.12. Statistics of Pleadings and Case Documents After Preprocessing\n\nTable B.13. Statistics of Legal Preprocessed Fact Descriptions and Plea\n\nTable B.14. Statistics of Case Documents After Preprocessing\n\nTable B.15. Top 50 Articles for Each Plea\n\nTable B.16. Statistics of Case Documents After Preprocessing\n\nTable B.17. Statistics of Case Documents After Preprocessing\n\nTable B.18. Detailed Information of BERT Model\n\nTable B.19. BERT Model's Pre",
    "d650101712e36594bd77b45930a990402a455222": " (3) The ability to choose which aspects to focus on is also required for a more specific judgment. It makes sense in civil cases that judgments are determined both by law articles or specific facts and individual's situations. How to model the interactions between different aspects in such a manner is still interesting but not simple.\nThe Chinese Supreme People's Court provides a website for people to check on existing judgments. They also plan to publish them in a machine-readable format. It is an effective and efficient way to access them online and provide better legal services. We plan to exploit this opportunity to further explore judgment prediction in civil cases.\n\n[1] B. Xu et al., \"Learning Semantic Representation via Reading Comprehension,\" Proceedings of The Web Conference (WWW 2017), 2017.\n[2] R. Zhao et al., \"A Survey on Fact-based Judgment Prediction: Deep Learning, Text Classification and Reasoning for Judging Cases,\" ACM Computing Surveys (CSUR), 48(1)2, 9pp.\n[3] J-M. Cai et al., \"Text Mining for Case Studies: Current Practice and Challenges,\" Journal of Computer System Sciences, 76(3), 2018.\n[4] Y. Liang, \"Information Extraction of Chinese Legal Cases,\" Journal of Knowledge-Based Intelligence 571\u2013597.\n[5] J.-X. Ma et al., \"A Brief Survey of Rule-based Case-Based Reasoning Systems for Automated Judgment Prediction,\" Computational Linguistics and Intelligent Text Analysing 32(Supp. 3), 2015.\n[6] N. Lu et al., \"An Automatic Judgment Prediction System for Criminal Cases,\" Proceedings of The 25th World Conference on Artificial Intelligence, 2017.\n[7] P. Pan et al., \"Automatic Case Prediction and Its Impacts on Fairness and Efficiency of the Chinese Civil Proceedings,\" Proceedings of The 32nd AAAI Conference on Artificial Intelligence and the 10th International Conference on Innovative Use of AI, 2018.\n[8] Y. Luo et al., \"Convolutional Neural Networks for Automatic Judgments in Civil Cases,\" 2018.\n[9] Z. Li et al., \"Deep Learning Representation for Legal Judgment Prediction,\" Science Robotics, 1(1), 2017.\n[10] K. Zhou et al., \"Explorations on",
    "cb384dc5366b693f28680374d31ff45356af0461": ".\n\nAppendix ::: Association of LGBTQ Representation and Social Groups\nAlthough we focused our analysis primarily on the New York Times data for this paper, we performed several additional analyses of the data for other large-scale social groups: Democrats, Republicans, African Americans, and Muslims. These analyses supplement some of our findings from the New York Times, while simultaneously providing additional historical context for our conclusions.\nThe political literature on media bias is already substantial, and these results add to a growing body of research about political bias and polarization. These works include several computational experiments which have shown that newsrooms have significantly more positive attitudes towards Democratic politicians and their policies than Republicans, particularly on social media and in television news. The more positive representations of Democrats have been observed in articles across multiple newsrooms and outlets, including both mainstream media and blogs BIBREF50, BIBREF79, BIBREF78, BIBREF50, BIBREF50. In addition, mass media in the United States has generally supported affirmative action for minorities, such as with police force BIBREF24 and hiring BIBREF25.\n\nFurthermore, multiple computational models have shown that mass media have been significantly less negative towards Democratic politicians compared to Republicans. BIBREF40 found that mass media write much more positively about Democratic politicians than Republican politicians, often by amplifying positive information (e.g. more reports of positive economic trends instead of neg-atives such as recession) and suppressing negative information (e.g. fewer reports of conflicts). In addition to presenting greater positive valence, BIBREF50 showed that mass media discuss Republicans in such a way that Democratic politicians are perceived as worse than Republicans. Similar results were found in BIBREF79, which examined mass media discussions of economic issues such as GDP, unemployment, and inflation. BIBREF79 found that mass media articles discussing Republicans are much more negative towards Republican policies and politicians, especially in a negative and hostile tone, compared to those discussing Democratic politicians.\n\nResults from our case study showed that the New York Times showed strikingly different and evolving patterns of linguistic cues with respect to these four social groups. We found that discussions of American(s) showed decreasing negative evaluations (with higher paragraph-level valence) over time. This was consistent with prior work, which was also largely quantitative. BIBREF50 presented evidence from other newsrooms indicating that Democrats are presented as more deserving of good outcomes, as well as more morally upright",
    "d41e20ec716b5904a272938e5a8f5f3f15a7779e": " between a social group label and its nearby words. Indeed, the directly-induced dominance for all labels varies considerably over time, which highlights potential avenues for future work.\n\nAppendix ::: Disgust prediction results\nBecause Moral Foundations theory explains that there are five dimensions of moral disgust (caring, fairness, loyalty, respect, and purity BIBREF63), we directly examined the dimensions' relationship to disgust using the Moral Foundations Dictionary BIBREF64. For each of the three dimensions, we extracted sentences containing the dimension's words (including those containing prefix or suffixes) and computed how strongly these words were related to the moral foundation.\nFigure FIGREF71 shows the cosine similarities between the dimension's words and the corresponding elements from the Moral Foundations Dictionary. The five dimensions are clustered clearly in the first two dimensions, suggesting that they all share a similar relationship with disgust. However, there appear to be differences between the word sets that map to the five dimensions for different dimensions. For example, the words for caring are all related more closely with fairness (and thus disgust) than the other dimensions. Similarly, the words for fairness appear to be more closely related to loyalty and respect, while respect seems to be related less closely with fairness (and thus disgust). For completeness, we also computed cosine similarities for dimensions' individual component-words (such as beingrelated to caring with caring) and found that they all cluster even more tightly with respect and purity.\nAppendix ::: Vermin prediction results\nWe previously quantified the semantic relationships between words with different lexical properties, but vermin is an extreme case of a novel label in that it combines two lexical categories: words like rodent and rat are often used as animals, and words like cockroach and termite are used as inanimate. Our distributional semantic vector space models thus need to incorporate semantic information about words from both of these categories to capture proper representations of the relationships between vermin and its neighbor words. For the experiment examining the language's implicit relationship with dehumanization, we create a vector space that contains two vectors, one for animal-related words like rodent and rat and another for inanimate-related words like cockroach and termite. We thus train Word2Vec models trained on a filtered collection of words containing one of these two lexical categories on each vector space separately, and directly induce a vector representation for the concept of vermin from the intersection of a",
    "0682bf049f96fa603d50f0fdad0b79a5c55f6c97": ".\n\nAppendix ::: Moral disgust prediction results\nThe word2vec model does not directly capture moral disgust, so we again attempt to derive a value directly from the vector representation instead. Inspired by the regression-based sentiment prediction approach used for word embedding vectors, and the Moral Foundations dictionary used for the valence lexicon, we construct the vector representation for moral disgust by taking the average of each word's vector from the Moral Foundations dictionary BIBREF64 weighted by frequency.\n\nFigure FIGREF72 shows the average valence score for this vector representation over all LGBTQ word2vec vectors from all years. Consistent with the ridge regression model analysis of the valence lexicon, the predicted value for homosexual has the lowest score ($r = -0.35$ based on 2000 training and testing), and as with the average neighbor valence approach, American is significantly more positive than any of the group labels investigated ($p < 0.0001$). The predicted scores show similar trends to average neighbor valence, with gay having the highest predicted score, followed closely by homosexual and the aggregate, followed by American with the lowest predicted value. Gay is significantly more positive than homosexual over all years (Wilcoxon signed-rank test; $p < 0.0001$ and $p = 0.05$ for homosexual).\n\nAppendix ::: Vermin-related word2vec regression results\nWe attempt to create an analogous vector representation to moral disgust using only words that are associated with the dehumanizing vermin concept (using data from the years 1986-2018).\nFigure FIGREF73 shows the average valence score for this vector representation over all word2vec representations from all years. As with moral disgust, homosexual's nearest neighbors have the lowest average valence score, and American's nearest neighbors have the highest average score.\n\nAppendix ::: Vermin nearest neighbor regression results\nAs with directly-inducing regressions to predict moral disgust and directly-inducing regressions to predict average neighbor valence, here we attempt to directly predict our target label using its nearest neighbor in the vector space of words that are associated with the dehumanizing vermin concept.\n\nFigure FIGREF74 shows the average nearest neighbor of the vector representation representing all LGBTQ labels (and American as a comparison) for all years. The nearest neighbor for this vector representation is the vector representing the vermin concept (overall Pearson's correlation = 0.64).\n\nAppendix ::: Sentiment prediction",
    "97d1ac71eed13d4f51f29aac0e1a554007907df8": "\n\nReferences :::\n\nBosselut, V., & G. Brants. 2003. Lazy evaluation for extractive summarization. In ACL-COLING 2003, pages 1342\u20131351. Association for Computational Linguistics.\n\n\n# JANE HAMILTON STEWART\n\n# A Matter of Magic\n\nA Puffin Book\npuffin.co.uk\n\n# About the Author\n\nJANE HAMILTON STEWART's book, The Enchanted Castle, was awarded the Children's Book of the Year in 1972 by the children's branch of the Booksellers Association. In 2013, to celebrate the 70th anniversary of Penguin Books, _The Enchanted Castle_ was chosen as one of the 70 books that shaped the Penguin decade.\n\nJANE HAMILTON STEWART was born in Edinburgh in 1920. Her father was a doctor and her mother a teacher, and she moved to Glasgow as a child when her father had taken up a post there. She always lived and worked in the west of Scotland, and she was married to a Scottish medical officer. Since her marriage ended in 1964, she has lived between Scotland and Norfolk. She is the author of twenty-four books, including novels _The Enchanted Castle_, _Aunt Maria_, _Mary Macgregor_ and _The Little Princess_, picture books and adult novels.\n\nThe following titles are also available in Puffin Classics:\n\n_The Little White Donkey_\n\n_The Faraway Tree Series_\n\n_Trees\n\n_A Tree on Great Ormond Street\n\n_Willow Fay_\n\n_The Fire Engine_\n\n  PUFFIN BOOKS\n\nUk | USA | Canada | Ireland | Australia\n\nIndia | New Zealand | South Africa\n\nPuffin Books is part of the Penguin Random House group of companies whose addresses can be found at global.penguinrandomhouse.com\n\nFirst published in Great Britain in 1981\n\nThis electronic edition published in 2019 by Puffin Books\n\nan imprint of Penguin Random House Children's\n\n10 9 8 7 6 5 4 3 2 1\n\nCopyright \u00a9 Jane Hamilton Stewart, 1981\n\nThe moral right of the author has been asserted\n\neISBN 978-0-141-98362-2",
    "c17b609b0b090d7e8f99de1445be04f8f66367d4": " The authors also gratefully acknowledge the anonymous reviewers of this work and the editors of AAAI18 for their valuable comments.\nReferences ::: Pretrained Language Models\n\n[BIBREF1] D. D. Devin et al. (2016). \"ELMo: A large multilingual corpus for language understanding.\" In Proceedings of the 2016 Conference of the North-American Chapter of the Association for Computational Linguistics, Philadelphia, PA.\n\n[BIBREF2] Iyyer, M. et al. (2018). \"GPT-2: Towards understanding texts.\" arXiv:1803.00215.\n\n[BIBREF3] Iyyer; Angrave; Child; Zettlemoyer. (2019). \"Bert: Pre-training of deep bidirectional transformers for language understanding.\" In Proceedings of the 2019 Conference of the North-American Chapter of the Association for Computational Linguistics, New York, NY.\n\n[BIBREF4] Eskimez; T. (2019). \"End-to-end abstractive text summarization with Bert: What can a language generator tell a language understanding model?\" In Proceedings of the 58'th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), Madrid, Spain, Association for Computational Linguistics.\n\n[BIBREF5] G\u00f3mez; Sordoni; Caragea. (2015). \"Automatic extraction of salient sentences using max-margin ranking and dynamic programming.\" In Proceedings of the 2015 Conference of the Association for Computational Linguistics (Volume 1: Long Papers), Vancouver, Canada, Association for Computational Linguistics.\n\n[BIBREF6] Liang; Yu; Vidal-Gaxiola. (2018). \"A neural extractive summary system: A combination of pointer-generator and latent variables.\" In Proceedings of the 2018 Conference of the Association for Computational Linguistics (Volume 1: Long Papers), Seoul, Korea, Association for Computational Linguistics.\n\n[BIBREF7] Goud; Gopalan. (2016). \"Using deep learning for automatic news event summarization.\" In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, Toronto, Canada.\n\n[BIBREF8] Gheorghiu; Dolan; Barzilay. (2017",
    "53014cfb506f6fffb22577bf580ae6f4d5317ce5": "\nReferences\nAbdallah, L. A., et al., 2016. Deep convolutional neural networks with attention for image analysis. In Computer Vision and Pattern Recognition (CVPR), CVPR 2016 Conference, pages 876\u2013885.\n\nAgarwal, S. and Lavie, J. (2018). Attention over attention: Attentive summarization models for document summarization. In Proceedings of the 31st Conference on International Conference on Machine Learning, International Conference on Machine Learning.\n\nAgarwal, S., et al. (2019). Attentive models for abstractive summarization of documents. In Proceedings of the 34th Annual Conference on Computational Natural Language Learning, Association for Computational Linguistics.\n\nAndreas, L., et al. (2016). Building an indo-european language resource. Proceedings of the COLING Conference, pages 1872\u20131881, Singapore.\n\nAndrew, T. and Rosenthal, M. (2018). Language models based on bidirectional recurrent neural networks. In Proceedings of ICLR 2018, International Conference on Learning Representations.\n\nBidder, A. and Barzilay, R. (2019) The importance of language modeling for summarization. In Proceedings of ACL-IJCNLP, Conference of the Association for Computational Linguistics and the International Joint Conference on Natural Language Processing.\n\nBogdanovi\u010d, A., Bontempi, S., Barzilay, R., and Auli, M. (2018). Extractive summarization based on the attention over attention mechanism. In ACL, pages 1718\u20131728, Brussels, Belgium.\n\nBogdanovi\u010d, A., et al. (2017). Attentive recurrent neural networks for abstractive summarization: A study of recent advances. In Proceedings of ACL, Association for Computational Linguistics, pages 2976\u20132988.\n\nBosselut, S., et al. (2018). Neural abstractive story summary. In Proceedings of International Conference on Machine Learning (ICML), International Conference on Machine Learning.\n\nCer, M., et al. (2018). Multimodal summarization. In Proceedings of the 29th Conference of the Association for Computational Linguistics, Association for Computational Linguistics, pages 3002\u20133017, Melbourne.\n\nCheng,",
    "fa30a938b58fc05131c3854f12efe376cbad887f": "\n\n*\n\nThe main conclusions of this paper still holds, but we had to change the title of Section SECREF10, because the paper presented different work.\n\nBIBREF0.\n\n<http://www.forbes.com/sites/kateclancy/2016/02/15/facebook-sinks-deeper-in-the-blackhole-with-new-reactions-api/>\n\nBIBREF1.\n\n<http://blog.huffingtonpost.com/aashni-kaur/what-facebook-reactions-mean-for-human-relationships_b-77152911.html>\n\nBIBREF2.\n\nThe difficulties of emotion classification have been discussed several times: eisner2013evaluation and schuller2018social, as well as in the SemEval 2013 Shared Task paper by santos-fernandez2014evaluation, where they also show that emotions expressed through emoticons can be successfully used as weak signals.\n\nBIBREF3.\n\nAlthough most works that use this dataset focus only on fine-grained or coarse-grained evaluation, there is some other work which considers using emotion categories from emoticons in combination with emoticons as labels, exploiting the ability of emoticons to express different emotions depending on context BIBREF27.\n\nBIBREF4.\n\nThe Fairy tales dataset has been used also in the SemEval 2016 emotion detection shared task MARTINEZ2016, though there is some discussion in the readme file that the final annotation contains inconsistencies and also includes redundant annotations.\n\nBIBREF5.\n\nAlthough distant supervision has been used for the creation of emotion lexicons, it has also been used as weak supervision of emotion recognition, for example exploiting the presence of emoticons that are also found in the lexicon BIBREF28.\n\nBIBREF6.\n\nUsing emoticons and hashtags can yield very accurate emotion recognition results ZANZELLI2016, and can also be combined with other signals to create a lexicon of affective words BIBREF29.\n\nBIBREF7.\n\nTask 6 at SemEval 2007 was concerned with the classification of emotions in online microblogs (Twitter), and the Fairy Tales data set in task 7, which we do not use in",
    "f875337f2ecd686cd7789e111174d0f14972638d": "\nThis work has been partially supported by the Slovenian Research Agency under grants P2-0089 and ARRA P3-0084.\n\n1. https://www.facebook.com/help/5679174512072260.\n2. http://m.facebook.com/help/4870982433842509\n3. http://www.facebook.com/groups/reactions\n\n4. http://m.facebook.com/help/group.php?gid=2066253079682598\n\n5. http://affectivetext.wordpress.com/wp-content/uploads/AffectiveText-Manual.html\n\n6. http://m.facebook.com/help/group.php?gid=209275680841386\n\n7. http://www.semanticeval.org/2013/task14/\n\n8. http://www.semeval-2015.org/task5/instructions/\n\n9. http://affectivetext.wordpress.com/wp-content/uploads/Fairy_Tales_annotator_instructions.pdf\n\n10. http://aicataleg2014.webs.upc.es/downloads/FairytailAnnotations.zip\n\n11. http://www.isear-project.org\n\n12. http://m.facebook.com/Help/Groups/?gid=20013990932996522\n\n13. https://www.facebook.com/help/46106577873579.\n\n14. http://pompi.unimore.it/iacobacci2015sensemBED\n\n15. http://www.facebook.com/help/845366739331485\n\n16. http://arxiv.org/abs/1512.01207\n\n17. http://sentimentshares.com\n\n18. http://sentimentshares.com/\n\n19. https://www.facebook.com/help/402768271237.\n\n20. http://affectivetext.wordpress.com/wp-content/uploads/Features.html\n\n21. Table 1 here\n\n22. Table 2 here\n\n23. http://affectivetext.wordpress.com/wp-",
    "de53af4eddbc30c808d90b8a11a29217d377569e": " We would also like to thank Paolo Bello, Stefano Stramilla BIBREF35 and other members of EASI team for helpful suggestions.\nA BIB\n\nBIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB\n\nBIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB\n\nBIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB\n\nBIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB\n\nBIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB\n\nBIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB\n\nBIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB\n\nBIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB\n\nBIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB, BIB\n\nBIB, BIB, BIB, BIB, BIB, BIB",
    "dac087e1328e65ca08f66d8b5307d6624bf3943f": "\nAcknowledgments\nThis work is supported in part by the Sina Scholarship Foundation and the Startup Research Programs of Shandong University.We take this chance to thank them.\n\nReferences\n[[1].Lee, R. S., et al.\n    SocialHoneypot: A public Twitter dataset for studying social network spammers.\n    In Computer Networking and\n    Emerging Technologies Conference, 2010. p.\n    1063\u20131070.]] [[2].Wang, L., et.\n    In Proceedings of the First Workshop\n    on Social-Aided Recommender Systems and\n    Social Network Spammer Detection: SASS 2013.   p. 25\u2013\n    31.]] [[3].Park, T. C., L., & Chae, L. H.\n    Discovering Twitter spammers via network graph.\n    In Proceedings of the 3rd International\n    Conference on Recommender Systems, 2013.\n    p. 1\u20136.]] [[4].\n    Lee, R. S., A., et. al.\n    Robust Spammer Identification in Social Network Services.\n    ACL,2011.][[5].Zhao, Q., et. al.\n    Detecting Twitter bot accounts by content analysis.\n    ACL, 2013.][[6].Zhao, C., et. al.\n    Discovering Twitter spammers via topic modeling.\n    ACL, 2014.][[7].Gao, G., et. al.\n    Identification of Twitter bot accounts using topic clustering.\n    ACL, 2014.]\n\n[[8].Grabner, L., & Jelinek, R. F.\n    A practical introduction to sparse principal component analysis,\n    the topic model and its relation to\n    Dirichlet distribution. In Advances in\n    Databases, 2003. p. 137\u2013162.]] [[9].Pedregosa, F., et. al.\n    Scikit-learn: Machine learning in python. http:// scikit-\n    learn.org.] [webpage]\n\n[[10].Vincent, M., et. al.\n    Extraction of scientific knowledge from twitter. In Proceedings of the\n    Second International Conference on Weblogs and Social\n    Media, 2010. p. 63\u201370.]]\n\n\n",
    "a1645d0ba50e4c29f0feb806521093e7b1459081": "\nAcknowledgments\nThis work was supported by TianChiao Foundation, National Science Foundation of China (Grant #61521005 and #61472137). We would like to thank the reviewers for the very constructive comments. Finally, we would like to thank our advisors for their valuable suggestions during the process.\nReferences\n[1] Kikulewi, D., Pfeffer, A., and O'Hara, D. (2013) Spambots in microblogging: identifying spammer accounts by examining the follower network. In Proceedings of the ACM Symposium on Applied Computing, ACM, New York, USA, pp. 1145-1150.\n\n[2] Lee, H., Natarajan, T., and Liu, Y (2011) Seven simple spammers: an exploratory study of the humanlike behavior in social honeypots. Proceedings of the 19th International World Wide Web Conference, WWW '11, Hyderabad, INDIA, pp. 1131-1135.\n\n[3] Li, B. (2016) The most suspicious retweets and its topic feature in microblogging. Proceedings of the 18th ACM Conference on Information and Knowledge Management, CIKM '16, Phoenix, AZ, USA, pp. 645-647.\n\n[4] Lee, H., Natarajan, T., Liu, Y., and Bock, J. (2012) Smart spammers: a survey of social honeypot spammers and their detection methods. Proceedings of the 32nd International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '12, Osaka, JAPAN, pp. 663-664.\n\n[5] Li, J. and Li, Q. (2014) Mining tweets via association rules and latent topics. Proceedings of the 33rd International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '14, Hong Kong, CHINA, pp. 647-650.\n\n[6] Nguyen, T. (2016) Topic-aware social spammer detection methods. In Proceedings of the 11th ACM SIGKdd Asia-Pacific Conference on Knowledge Discovery and Data Mining, SIGKDD Asia 2016, Melbourne, AUSTRALIA, pp. 867-873.\n\n[7] Tan, P. and Liu, Y. (2014) Spammer",
    "3cd185b7adc835e1c4449eff81222f5fc15c8500": "\nAcknowledgements\n\nThis work is partially supported by MOST and Huazhong University of Science and Technology(HSUT).\n\n \n# THE  \nFATAL  \nPUNISHMENT\n\nTed Olsen\n\nwww.penguin.com.au\n\nPENGUIN BOOKS\n\nAn imprint of Penguin Random House Australia Pty Ltd\n\nLevel 13, 201 Elizabeth Street\n\nSydney, NSW 2000, Australia\n\nCopyright \u00a9 Ted Olsen, 2016\n\nThis novel is work of fiction. Names, characters, places and incidents are the product of the author's imagination. Any resemblance to actual persons, living or dead, incidents or locales is entirely coincidental.\n\nAll rights reserved. No part of this publication may be reproduced or transmitted in any form or by any means, electronic or mechanical, including photocopying, recording, or any information storage and retrieval system, without prior permission in writing from Penguin Random House Australia, Level 13, 201 Elizabeth Street, Sydney, NSW 2000, Australia.\n\nThe characters and events in this book are fictitious\u2014any resemblance to real characters or events is pure coincidence.\n\nA Luce production\n\neBook ISBN: 9780698409071\n\nCover design by Julianna Lee\n\nCover photography by Getty Images\n\n# Table of Contents\n\n1: Dead Man in the Water\n\n2: No Ties on Earth\n\n3: No Cuffs\n\n4: Not a Smile\n\n5: No Chance\n\n6: No Dice\n\n7: No Snooping\n\n8: No Way to Escape\n\n9: No Good to Anybody\n\n10: No Help at All\n\n11: No Plan to Follow\n\n12: No Hope\n\n13: No One Around\n\n14: No Time to Explain\n\n15: No Reason at All\n\n16: No Goodbye\n\n17: _If Only_\n\n# 1\n\n# Dead  \nMan  \nin the Water\n\n\"You!\" Jasmine screamed at the woman in black.\n\n\"So what?\" she answered cheerfully, not looking remotely terrified, although she was.\n\n\"How did you get here?\" Jasmine demanded. \"By a black helicopter? Did you and your friends, including our friend, kill him? Is",
    "f03112b868b658c954db62fc64430bebbaa7d9e0": "\nACKNOWLEDGMENTS\n\nWe would like to thank Sai Liu for early discussions regarding Reinforcement Learning in NLP. We also thank Sai Liu, Gennady Lavrenko, and the anonymous reviewer for insightful comments. This research was partially funded through a Google Faculty Research Award FRAZEL3. We would like to acknowledge the support by the Simons Foundation (https://simonsfoundation.com/), the National Science Foundation (AFOSR Grant No. 1655105), the NSF under a CAREER award (CNS-1751791, CCF-1739723), and an anonymous internal award from IBM Research (CR#8-1876-0-01). The views expressed in this publication are those of the authors and do not necessarily reflect the official position of IBM.\nReferences\n\n[BIBREF1]\n\nSee LiuDong:2017:DCC for examples of sequence-to-sequence approaches to text generation or read LiuDongDong:2016:P16-1 for a comprehensive overview.\n\n[BIBREF2]\n\nChen:2018:EMNLP2018 for a survey on neural models for text summarization.\n\n[BIBREF3]\n\nRabinovich:2015:ACL2015 proposed a sequence-to-sequence architecture to train a neural extractive summarization system. The authors rely on hand-crafted attention mechanisms (not attention flows) to select meaningful sentences.\n\n[BIBREF4]\n\nPecherski:2017:ACL2017, Raff:2015:ICASS2017 use convolutional LSTMs to encode the input document D into a representation that is used to produce a target summary. They employ a two-branch encoder that learns a representation of the document that is in turn fed to a softmax layer which produces a target summary.\n\n[BIBREF5]\n\nXu:2015:AAAI2015, He:2016:ICML2016 combine neural encoders with classical extractive summarization rules. They propose to first generate a set of sentence features from the document that correspond to possible extraction rules and then extract sentences using feature-based decoding.\n\n[BIBREF6]\n\nGu:2018:TACL2018, Gu:2017:EMNLP2017 employ recurrent encoders in conjunction with attention or reinforcement learning strategies to rank",
    "5152b78f5dfee26f1b13f221c1405ffa9b9ba3a4": " With respect to human evaluations, we plan to expand our study to the identification of relevant key terms to assess the informativeness of summaries.\nACKNOWLEDGMENTS\n\nWe thank the anonymous reviewers for their insightful feedback on an earlier draft of this paper. We would also like to thank the members of our lab for their support.\n\nBIBREF0\n\nBoudin, H., Nenkova:1997, A Methodology for Combining Reranking Systems with Support Vector Machines for Text Summarization. In: Proceedings of the Fifth Conference of the Association for Computational Linguistics, Vol. 1 (ACL-97), pp. 90-96.\n\nBIBREF1\n\nLi:2016, Sequence-to-sequence Learning with Attention for Abstractive Summarization. In: Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics, ACL 2016, pp. 3275-3280.\n\nBIBREF2\n\nSee e.g., Cheng:2016, An Attention-Based Encoder-Decoder with Selective Recurrent Response for Abstractive Summarization. In: Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL), pp. 3351-3365.\n\nBIBREF3\n\nSmith, D., Ritter, A.:2016, TOWREXTR: A Text-Only Wide-Coverage Extractive System. In: Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics, ACL 2016, pp. 2687-2700.\n\nBIBREF4\n\nLewis, C., Goodman, N., Mane, J.:2016, Extrinsic Text Summarization with Routing Decoder Networks. In: Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (ACL), pp. 1741-1753.\n\nBIBREF5\n\nKudo, T., Ogura, H., Okazaki, B., Tsukano, Y., Tonegawa:2016, A Neural Network Model for Text Summarization. In: Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (ACL), pp. 1659-1669.\n\nBIBREF6\n\nSee Boudin:2004, Learning Summary Rankings with",
    "a6d3e57de796172c236e33a6ceb4cca793dc2315": " We also aim to generalize our method to open-domain summarization by training the system on entire collections of documents. The problem with large-scale data has been previously tackled via collective labeling techniques BIBREF26, BIBREF27, BIBREF66, and we plan to further investigate how effective these methods are in practice for large-scale summarization.\nAcknowledgement\nThe authors would like to thank the anonymous reviewers at ACL 2018 for providing invaluable feedback and pointing out our mistakes.\nReferences\n\n[BIBREF0]\n\nS. R. Auer, S. C. Dredze, D. R. Pustejovsky, and S. C. Ng, \"Cocos: automatic summarization by extracting and reweighting sentences,\" in Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL-2012), 1:1\u201310, 2012.\n\n[BIBREF1]\n\nM. Bach, E. D. Klein, and A. L. Goldberg, \"Abstractive summarization using attention-based encoders,\" in Proceedings of the Conference of the European Chapter of the Association for Computational Linguistics (EACL-2015), Vol. 6, 1:721\u2013733, 2015.\n\n[BIBREF10]\n\nS. R. Ammor, O. Vinyals, Y. Bengio, C. Courville, and Y.-W. Zhang, \"Scaling up sequence-to-sequence learning,\" in International Conference on Learning Representations (ICLR-2016), 2\u20137, 2016.\n\n[BIBREF11]\n\nA. See, Y. Chen, A. M. R. Joshi, and S. Goldwater, \"Non-autoregressive-based language generation with copy-feedback,\" in Advances in Neural Information Processing Systems (NeurIPS-2017), Vol. 2018, 5:8135\u20138145, 2017.\n\n[BIBREF14]\n\nU. Bunt, Z. Zhou, W. Chai, H. Jiang, and D. Ang, \"QueryFocused Text Summarization: from documents to question-answer pairs,\" in Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics (ACL 2018), accepted for publication, June 2018.\n\n[B",
    "395b61d368e8766014aa960fde0192e4196bcb85": "\n\n\\end{documentbody}\n\\begin{documentbody}\n\\addtocontents{1}\n\n2 Acknowledgements\n\\addtocontents{2}\nThis work was conducted in part at the MIT-IBM Watson AI Lab and in part at the University of Queensland. It is supported by the Natural Science Foundation of China (Grant U1811202). The authors would like to thank the Amazon Alexa team for conducting experiments on Amazon Alexa.\n\\addtocontents{1}\n\\printbibliography\n\n\\addcontentsline{1}\n\\printbibliography\n\n\\addcontentsline{1}\n\\printbibliography\n\n\\addcontentsline{1}\n\\printbibliography\n\n\\addcontentsline{1}\n\\printbibliography\n\n\\addcontentsline{1}\n\\printbibliography\n\n\\addcontentsline{1}\n\\printbibliography\n\n\\addcontentsline{1}\n\\printbibliography\n\\end{document}\n\\addtocontents{1}\n\\printbibliography\n\n\\addcontentsline{1}\n\\printbibliography\n\n\\addcontentsline{2}\n\n\\printbibliography\n\\end{document}\n\n\n\\end{document}\n\\end{document}\n\\end{document}\n\n\n\\section{Acknowledgements}\nThis work was conducted in part at the MIT-IBM Watson AI Lab and in part at the University of Queensland. It is supported by the Natural Science Foundation of China (Grant U1811202). The authors would like to thank the Amazon Alexa team for conducting experiments on Amazon Alexa.\nAppendix A: Proof for Theorem 1.1}\n\nProof. To show that our model-based attacking method is optimal for minimising (1) cross entropy minus log of (3) 1-pos rate over the true labels, we introduce a modified loss $ L= F - E$. $ F$ is the cross entropy; we use the convention of subtracting the log function (i.e., we have $ L \\le 0$), and $E$ and $F$ are the loss and objective functions of (10) and (11) respectively. Then according to the definition of cross entropy defined in (5), (10) can be rewritten as:\n\n\\begin{align}\nL & = E(X, y) \\notag \\\\\n& \\color{teal",
    "92bb41cf7bd1f7886784796a8220ed5aa07bc49b": " In this sense, we see that there is a trade-off between adversarial performance and sentiment preservation; that is, the adversarial examples that have higher attacking performance may not be as realistic as desired. Therefore, we conclude that there is no one-shot and bulletproof method for creating good adversarial examples, revealing the importance of considering the target task and the criteria for quality.\nFurther work ::: Design\nAs our goal is to generate adversarial examples that change the prediction of the target classifier (i.e. criterion (a)), we find that it is important that the adversarial examples have a reasonable language (criteria (b) and (c)). While for images (and more generally for CV), there have been a number of attacking methods such as C&W BIBREF10 and ZOO BIBREF10 that focus their attention on these metrics, in NLP there are not many attacking methods that have a similar commitment. This suggests that these methods may not be as effective on NLP tasks because the perturbation cannot be as trivial (e.g. changing one word in a sentence can make it incoherent). Therefore, in the future we would like to propose more effective attacking methods that are able to generate adversarial examples that maintain (a) attacking performance, (b) textual similarity and (c) fluency.\nFurther work ::: Evaluation\nWe propose BLEU, ACPT, BERT and human evaluation to quantify the quality of adversarial examples. These methods address only the first three criteria (a, b, c), with no human annotation required. While these metrics provide a reasonable proxy for assessing the quality of the adversarial examples (especially the last two), we find (following our human annotation) that all methods do not preserve the sentiment of the original inputs (a crucial criterion when using adversarial examples as regularisation), which we regard as an artefact of these methods.\nThe idea of using adversarial examples in NLP has shown some promising results (e.g. BERT in CV BIBREF25), we think there may be advantages to focusing on generating examples that preserve the sentiment of the original inputs (criteria (c) and (d)). To explore this, we believe more human annotation such as our fluency and sentiment preservation studies could be beneficial in order to better understand why using adversarial examples for generating better models is in fact important.\nA Note on the Code\n\nIn our code, we distinguish between target model, target classifier and attacking method",
    "4ef11518b40cc55d86c485f14e24732123b0d907": "\nAcknowledgements\nWe thank the organisers of NLP Adversarial Workshop for their help in preparing this manuscript. We thank all members of the group chat (Slack) for their help and the valuable discussions, especially Darian Dibu, Wadah Almehad, Sam Hays, Timur Kocukyilmaz, Mingxuan Ma and the whole team at DeepMind. Lastly, we especially thank our editor Elie Cohen and the whole NeurIPS team for their help and support.\n1... references\n1. Adversarial Learning with Robust Optimisation (ALRO), 2018.\n\n2.. references\n1. A Neural-Symbolic Architecture for Sentiment Classification, 2012.\n\n2. Attacking Convolutional Neural Networks using Generative Adversarial Networks, 2018.\n\n3. A Survey on Adversarial Attacks, 2020.\n\n4. Auto-Encoding Adversarial Robustness, 2018.\n\n5. Adversarial Attacks on Pre-trained Language Models, 2018.\n\n6. DeepFool: A Simple and Efficient Adversarial Attack on Deep Networks, 2017.\n\n7. Adversarial Attacks on Pre-trained Machine Learning Models, 2018.\n\n8. Adversarial Attacks with Gradient Projection: An Unified Explanation, 2019.\n\n9. Untargeted black box network-based attacks, 2020.\n\n10. TextBugger: A Black-box Method to Fool Language Classifiers at the Syntax Level, 2019.\n\n11. Adversarial Text Fooling: The Missing Link in Attack Surface Analysis, 2019.\n\n12. Black-box Text Bugging: A Data-driven White box Attacking Method for Natural Language Processing, 2018.\n\n13. Adversarial Examples in Generative Models and Language Models, 2019.\n\n14. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding, 2019.\n\n15. Distilling Adversarial Examples for Image Classifiers, 2018.\n\n16. Understanding Sentiment Bias in Language Classifiers, 2020.\n\n17. A Comprehensive Sentiment Analysis of English Online Consumer Reviews, 2016.\n\n18. SentEval: An Open Benchmark for Sentiment Analysis of Consumer Reviews, 2018.\n\n19. Sentiment Analysis with B",
    "6a219d7c58451842aa5d6819a7cdf51c55e9fc0f": "\nAppendix\n\nA\n\nBenchmark Language Pairs for CoVoST\n\nTranslated Domains for CoVoST\n\nCoVoST Corpus Language Pairs\n\nBIBREF1\n\nBIBREF11\n\nBIBREF14\n\nBIBREF15\n\nBIBREF18\n\nBIBREF19\n\nBIBREF20\n\nBIBREF21\n\nBIBREF22\n\nBIBREF23\n\nC\n\nE\n\nF\n\nJ\n\nL\n\nN\n\nO\n\nV\n1\n\n2\n\n3\n\n4\n\n5\n\n6\nAcknowledgments\n\nThis material is based upon work supported by the U.S. Office of Science and Technology for the U.S. Department of Energy (contract number DE-SC0011944). This research used the Extreme Science and Engineering Discovery Environment (XSEDE), which is supported by National Science Foundation grant number ACI-1570193, and a shared resource of the University Corporation for Atmospheric Research, the Space Science and Engineering Center (SSEC), and the National Center for Atmospheric Research (NCAR). The computations are performed on the LAMMPS cluster at Lawrence Berkeley National Laboratory. This work was supported by the National Science Foundation of the U.S. under Award No. OAC-1806523. This work was supported in part by the Spanish Government under grant UID16-MIW-16-0429. We gratefully thank the reviewers and organizers of ACL 2019 for the insights and helpful feedback. We would like to thank Nagesh Sitaraman for his assistance with generating Tatoeba data. We would also like to thank the anonymous reviewers for the helpful feedback.\n\nData Availability\n\nCoVoST corpus is released under an open CC0 license, and the corresponding source files can be found at the following GIT web page: https://github.com/facebookresearch/covost\n\nTatoeba corpus is released under a friendly CC BY 2.0 FR license, and the source files can be found at the following GIT web page: https://tatoeba.org\n\nNote that Tatoeba corpus sentences aligned across multiple languages do not all have their speech components. We hence focus on Tatoeba sample triplets (speech, transcript, English translation) aligned to English. The following URLs",
    "cee8cfaf26e49d98e7d34fa1b414f8f31d6502ad": " We hope this corpus will help advance the field of multilingual speech translation and encourage the scientific community to develop more languages into CoVoST.\nAcknowledgements\nWe thank everyone involved in the development of CoVoST, especially the Common Voice team for releasing its data for public usage.\nReferences\n\nS. Adhikari, T. Acero, S. Al-Qudsi, R. Awasthi, Y. Bharadwaj, B. Bhattcharya, F. Beilic, L. B. Breuel, N. B. Brown, T. Bunek, A. Calder\u00f3n, B. Carus, F. G. Chakraborti, S. Chami, B. Chauhan, A. Churamani, M. Chwast, G. Clef-Ekke, A. De Santo, J. Di Gangi, P. Dimopoulos, M. Di Nucci, L. D. Duarte-Ferreira, M. Ducos, C. El Bim, J. Erkembise, Z. E. Fan, R. Ferl, M. Fornaciari, R. Foschini, S. A. Francis, R. Gargallo-Benz, L. Guo, G. Gupta, R. H. Guy, S. Haman, S. Hargreaves, M. H. Hasanbegloo, F. Herrero, X. Horng, S. Huang, E. Hsiao, R. I. Iranzosnchez, B. I. Jalali, H.-S. Jang, S. Jap, R. Janani, R. Janicki, S. J. Johnson, W. Jothi, J. K. Joshi, B. Julin, B. S. K. Kannan, J. Kowalski, S. Kurkcu, S. L. Kurkcu, J. Lin, Y. J. Lorentzen, I. Lechevalier, A. B. Lewington, C. Little, T. L. Lu, M. Madniran, R. Martinez, P. Mascaro, U. K\u00f6tzsch, A. Mehta, J. Menon, R. Mesa",
    "f8f4e4a50d2b3fbd193327e79ea32d8d057e1414": "\nBIBREF1\n\nZosnchen, S., Lehman, A., and Cieri, F.\n\n2018a. CoVoST: A Common Voice Speech-Translation Corpus with 11 Languages.\n\nACL 2019, pp. 2886\u20132892.\n\n@inproceedings{Zosnchen2018a,\nauthor = { Zosnchen, S., Lehman, A., and Cieri, F.},\ntitle = { CoVoST: A Common Voice Speech-Translation Corpus with 11 Languages},\nyear = {2019},\nbooktitle = {Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics (ACL 2019)},\nmonth = {September 15, 2019},\nfile = {Zosnchen2018a.pdf},\npublisher = {Association for Computational Linguistics},\n}\n\nBIBREF2\n\nCho, K., Ranziero, A., and Knight, K.\n\n2018. End-to-end Speech-to-Text Translation: A Survey.\n\nTransactions of the Association for Computational Linguistics, 10(2), 293\u2013327.\n\n@article{Cho2018,\nauthor = { Cho, K., Ranziero, A., and Knight, K.},\ntitle = {End-to-end Speech-to-Text Translation: A Survey},\njournal = {Transactions of the Association for Computational Linguistics},\nyear = {2018},\npages = {293\u2013327},\nvolume = {10},\nnumber = {2},\nmonth = {June},\n}\n\nBIBREF3\n\nShaughnessy, N., Kuhn, O., and Dredze, T.\n\n2018. The Fisher Corpus of Human Read Speech: A Resource for Automatic Speech Translation Research.\n\nEACL 2018, pp. 966\u2013772.\n\n@inproceedings{Shaughnessy2018a,\nauthor = {Shaughnessy, N.},\ntitle = {The Fisher Corpus of Human Read Speech: A Resource for Automatic Speech Translation Research},\nyear = {2018},\nbooktitle = {Proceedings of the 16th European Conference on Computational Linguistics (EACL 2018), Volume 1: Short Papers},\nmonth =",
    "bc84c5a58c57038910f7720d7a784560054d3e1a": "\n\nAcknowledgements\n\nWe thank the crowdworkers at CrowdFlower (Piotr, Alex, Jasmin and Sasha) for collecting translations and CrowdFlower support for corpus-wise annotations (thanks to Alex, Mike and David). We also thank Zhiru Chang for the early data collection, Erich Riemer for his valuable comments during the early stage of data processing.\n\n[1]\n\nBentivogli et al. (2012) Multilingual Speech Translation for Cross-language Information Retrieval and Access. Proc. NIPS\n\n[2]\n\nMacken et al. (2008) An Improved Language Model for Statistical Machine Translation. Proceedings of the ACL\n\n[3]\n\nGraves et al. (2013) Phonetis: Speech Recognition in 10 Languages. Proc. AAAI\n\n[4]\n\nDi Giangi et al. (2019) LibriVox Deen: a Large-Scale Parallel Book Corpus in Persian and English. Proceedings of the TASLP\n\n[5]\n\nBoito et al. (2019) MassST: A Dataset for Multilingual Multimodal Speech Translation. Proc. ACL Speech Understanding and Evaluation Workshop, Poster\n\n[6]\n\nZhang et al. (2017) Training Sequence-to-Sequence Decoder on Multiple Languages. Proceedings of the ACL Speech and Language Modeling Workshop\n\n[7]\n\nSacreboeuf et al. (2017) LibriVox deen: a New Large-Scale Corpus for Machine Translation of Classical Persian Text. Proceedings of the TASLP\n\n[8]\n\nKocmi\u0144ski et al. (2019) E-ParaPara: Building End-to-End Translated Speech Corpora. Proceedings of the TASLP\n\n[9]\n\nIrnanzosnchez et al. (2019) An Evaluation of End-to-End European Parliaments Translation in Many-to-One Multilingual Scenarios. Proceedings of the ACL Workshop on Multilingual Language Resources and Transfer (EACL-MULR)\n\n[10]\n\nBlevins et al. (2018) A corpus of authentic European Parliament proceedings: Evaluation, analysis and insights. Proceedings of the Workshop on Low-Resource and Difficult Domains for Speech Translation",
    "29923a824c98b3ba85ced964a0e6a2af35758abe": " Our code is available at https://github.com/facebookresearch/covost. We encourage the community to use the multilingual corpus and the baseline results to advance end-to-end ST research, including the current exploration of the next generation multilingual ST models which takes advantage of data from multiple source languages.\n\nReferences\n\nBaldwin, A, & Hockenmaier, M (2013). The CALLHOME corpus. In First Annual Language Resource and Evaluation Conference, LREC 2013; pp. 1\u20134.\n\n\u2013, Hockenmaier, M (2011). Fisher corpus. In First Annual Language Resource and Evaluation Conference, LREC 2011; pp. 39\u201344.\n\nBeilharz, S, Gimpel, Y, Storzner, W et al. (2019). LibriVox-de-e: creation of a multilingual transcription and translation corpus with Librivox audiobooks for the German-English language pair. Proceedings of Interspeech 2019; pp. 2208\u20132212.\n\nBoito, A, & Masson-Pelletier, S (2019). Mass-multilingual cross-lingual speech-translation evaluation and evaluation framework. In Third Workshop on Machine Translation for Social Good, WMT 2019; pp. 175\u2013183.\n\nBaharudinewand, T, Khashabi, A, & Moosavi, J-M (2020). End-to-end speech translation with multilingual cross-lingual pre-training. In ACL 2020; pp. 3937\u20133938.\n\nBerard, A, Houy, E, Pino, S et al. (2018). Harri-es-sage: A toolbox for harnessing end-to-end speech translation. In Fourth Conference on Machine Translation, WMT 2018; pp. 1878\u20131883.\n\nBhattacharya, A, Pang, P, Yates, J et al. (2018). En-de-caffe: exploring the limits of cross-lingual transfer on end-to-end speech translation. The TransParent-al: Child of Machine Translation Workshop, MTM 2018; pp. 13\u201329.\n\nBlei, D (2018). Language models are unsupervised multilingual compressors. Proceedings of EMNLP 2018;",
    "559c68802ee2bb8b11e2188127418ca3a6155ba7": "\nAcknowledgements\n\nThis work was supported in part by the University of Washington Computer Science and Engineering department, and by a Google PhD Fellowship. This material is based upon work supported by the National Science Foundation under Grant No. 1616746. Funding from the UW Provost's Faculty Research Fund, by the Simons Foundation, by an Amazon Engineering research award, by Amazon Web Services Credential Grant, and by the Washington Research Foundation is also acknowledged.\n\nReferences\n\nWe would like to thank Aditya Bhagwan, Dan Jurafsky, Hector E. Jimenez, Hesham Akbari, Yueqi Liu, Eun-Huei Liu, Yingjie Li and Xiaoyuan Liu for valuable comments, suggestions and feedback. We also thank the reviewers for their insightful comments.\n\nBIBREF1\n\nkanezaki2018speech, Nishino2018Deepspeech\n\nBIBREF2\n\ngu2017survey, cheng2017deep, ritter2018speech\n\nBIBREF3\n\ngu2017survey, niu2016end, sak2017neural, chu2018deep\n\nBIBREF4\n\nkanezaki2018speech, garg2017speech, kanezaki2018voice, zeyer2017text, yu2018investigation, wagner2017speech, berracchi2018conversational, bertinelli2018parallel\n\nBIBREF5\n\nkanezaki2018speech\n\nBIBREF6\n\nkanezaki2018speech, zeller2017text, garg2017speech, ritter2017text, zeyer2017speech, wagner2017speech, berracchi2018conversational, bertinelli2018parallel, pino2019harnessing\n\nBIBREF7\n\nboito2019mass, boito2020mass, boito2019mass, li2019unsupervised, woldeyohannis\n\nBIBREF8\n\nbao2019joint, zhang2018joint, mccuskey2019joint, yang2019joint, zhang2019joint, kang2019nmt, le2020multilingual\n\nBIBREF9\n\niranzosnchez2019europarlst, iranzosnchez2020europarlst\n\nBIBREF10\n\ncommonvoice, google-speech-corpus\n\n",
    "8dc707a0daf7bff61a97d9d854283e65c0c85064": " We hope this multilingual ST corpus will serve as a good bench for future study.\n\nAcknowledgements\n\nThis work is funded in part by the German-French Joint Research Fund, and by EU H2020 ERANET project. We thank all the Common Voice contributors for their quality efforts. We also thank all the collaborators in Tatoeba who have contributed to the construction of TT. The authors thank the Google Research team for generously providing the common resource licenses for the TT corpus. We thank Liang Ma for providing the access to the translation servers.\nReferences\n\n[Bender2018]\n\nT. Bender, L. Xue, S. Ganchev et al. 2019. Neural Machine Translation with OpenWebText. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, EMNLP, Stroudsburg, PA.\n\n[BIBREF1]\n\nO'Flaherty, B. P., & O'Rourke, S. 2014. Tatoeba : a collection of aligned and translated texts.\n\n[BIBREF2]\n\nGanchev, S., Bender, T. E., Xue, L., Nguyen, P. H., Chen, R., & Rieser, M. 2018. Towards End-to-End Speech Translation. In Proceedings of the Workshop on Spoken Language Translation, Interspeech, Copenhagen.\n\n[BIBREF3]\n\nIrannosnchez, I., Ganchev, S., Bender, T. E., & Xue, L. 2020. A Joint Estimator for End-to-End Speech Translation and Speech Recognition. In Proceedings of the Workshop on Speech Translation Systems (ST'20), Association for Computational Linguistics, Florence, Italy.\n\n[BIBREF4]\n\nCamburo, A., Sordoni, C. N., & Leckey, L. 2019. Combining Multiple Speech Recognition Modalities for End-To-End Neural Machine Translation. In Proceedings of the Workshop on Multilingual Machine Translation Systems (WWW-WMT19), Montreal, Canada.\n\n[BIBREF5]\n\nIannuzzi, S., Bozzo, C., Buitrago, D., & Vigario, L. 2019. A Dataset and Study of Low-Resource Text-to-",
    "ffde866b1203a01580eb33237a0bb9da71c75ecf": " We hope CoVoST can serve as a supplement (out-of-data) data for future language experiments. We release all data on https://research.fb.com/covost.\n\n\n\nFor my father\nBOOK TWO\n\n1. The Tavern of Fools\n\n2. The Road to Lormont\n\n3. The Road to Thraxhaz\n\n4. The Bitter Sea\n\n5. The Tower\n\n6. A Question of Mercy\n\n7. Treachery on the Road\n\n8. A Meeting of Kings\n\n9. The Tower Is Sealed\n\n10. The Riders of the Venn\n\n11. Dark and Deadly\n\n12. At the Tavern\n\n13. The Tavern Has Words\n\n14. The Wrath of the Riders\n\n15. The End of the Game\n\n16. The Price of Truth\n\n17. The Price of Favor\n\n18. The Fate of King Leanbeoc\n\n19. The Storm at Lormont\n\n20. The Price of Power\n\n21. The Price of Sorrows\n\n22. War on the Hill\n\n23. A King to Win or to Lose\n\n24. Bells of Lormont\n\nAuthor's Note\n\nAbout the Author\n\nAbout the Illustrator\n\nAlso by Christopher Paolini\n\nCredits\n\nCopyright\nThis is a work of fiction. Names, characters, places, and incidents are either the product of the author's imagination or are used fictitiously, and any resemblance to actual persons, living or dead, business establishments, events or locales is entirely coincidental.\n\nThe Inheritance\n\nBook Two\n\nOf Brilliant Lament\n\nby\n\nCHRISTOPHER  \nPAOLINI\n\nText copyright \u00a9 2015 by Christopher Paolini\n\nCover design by Matthew Esk\n\nCover illustration based on original illustrations by Paul Young\n\nAll rights reserved. Published in the United States by Delacorte Press, an imprint of Random House Children's Books, a division of Random House, Inc., New York.\n\nRandom House and colophon are registered trademarks  \nof Random House, Inc.\n\nVisit us on the Web\n\nEducators and librarians, for a variety of teaching tools",
    "6cd8bad8a031ce6d802ded90f9754088e0c8d653": "\nReferences\n[Bender2016] Bender, K., and Gurevych, V. (2016). Recurrent Neural Networks for Text Classification: From Sequence to Sequence. CoRR.abs/1603.03461.\n\n[BIBREF0] Collobert, M., Minc, N., Kalchbrenner, N., Kavukcuoglu, F. and West, J. (2008). Natural Language Processing: A Review. Foundations and Trends R. Neural Syst. Process. 3, 2: 115-246.\n\n[BIBREF1] Wang, M., Jia, W., Ng, H.-Y., Du, J. and Pilehvar, D. (2011). Learning to Rank with Neural Networks. In Proceedings of the 26th Annual Proceedings of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 259\u2013271.\n\n[BIBREF2] Quang, K., Nguyen, A., Nguyen, V. and Phan, Q. (2014). Relation Classification with Recurrent Neural Networks. In: Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing.\n\n[BIBREF3] Zhu, K.-S., Zhang, J., Zhang, Y. and Zhang, G. (2015). Learning Deep Relation Representations Using Convolutional Neural Networks. In: Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing.\n\n[BIBREF4] Vinyals, J., Mathur, I., Poesio, J.; Cho, K., Chopra, S., Weston, J. and Khudanpour, M. (2014). Convolutional Neural Networks for Sentence Classification. ArXiv.1408.04113.\n\n[BIBREF5] Kim, D., Sung, J., Song, G., Chen, L., Hsiao, T.E., Hanisch, E., Daley, D., and Zhai, H. (2015). Convolutional Neural Network for Predicting Sentence Relations. CoRR.abs/1510.07609.\n\n[BIBREF6] Nguyen, A., Phan, Q., Quang, K., Zhang, G. and Zhang, K.-S. (2015). Deep Neural Network for Relation Classification. In",
    "30eacb4595014c9c0e5ee9669103d003cfdfe1e5": "\nReferences\nAdel, H., Ebert, S., Hofmann, S., Thorne, N., Wiegand, S., Demberg, F. (2017). Recurrent Neural Networks for Relation Classification. The Web Conference 2017 (WWW 2017), San Francisco, CA, USA, 19th May 2017.\n\nAllen, Z., Riloff, S., Kott, L., et al. (2012). Recurrent Concurrent Neural Computation. In Proceedings of the 31st Conference on Neural Information Processing Systems (NIPS 2012), Quebec City, Canada, 7\u201312 December 2012.\n\nBIBREF0\n\nDemberg, F., Stede, Z., Steed, S., et al. (2011). Entity Disambiguation Using Support Vector Machines and Classifiers Based on Graphical Models. In Proceedings of the 8th Semantic Evaluations (SemEval), New Orleans, LA, USA, 3\u20137 August 2011.\n\nBIBREF1\n\nKim, J.Y., DeMeno, T., Chou, H., He, M.Y., Lee, J.S., Cho, E.H., and Song, H. (2014). Neural networks for Relation Extraction. In Proceedings of the 11th SemEval Workshop at EMNLP 2014, Barcelona, Spain, 2\u20137 November 2014.\n\nBIBREF2\n\nZeng, G., Zhu, H., and Wang, C. (2015). RNN for Relation Classification on Semantic Parsing Valued Entities Data. In Proceedings of the 13th SemEval Workshop at EMNLP 2015, Copenhagen, Denmark, 17\u201323 September 2015.\n\nBIBREF3\n\ndeSantos, C., Ammar, L., and Riedel, S. (2015). Neural Relation Classification. In Proceedings of the 12th SemEval Workshop at EMNLP 2015, Copenhagen, Denmark, 17\u201323 September 2015.\n\nBIBREF4\n\nKim, J.Y., Zeng, G., and Wang, C. (2016). A Convolutional Neural Recurrent Network for Relation Classification on Dependency Parsed Sentences. In Proceedings of the 14th SemEval Workshop at EMNLP 2016, Prague, Czech Republic, 13\u201317 November 2016.\n\nBIBREF5\n\nKim, J.Y.",
    "0f7867f888109b9e000ef68965df4dde2511a55f": "\nREFERENCES\n\nBIBREF0\n\nBlank, R., Radev, D. and Sch\u00fctze, H.: Relation-based classification of newswire articles for event detection. In: Proc. of the ACL Workshop on the Analysis of Concentrated Text (COT). Association for Computational Linguistics, Chicago, 2014.\n\n[Crossref]\n\nBIBREF1\n\nDredze, M., Bl\u00f6chl, C., St\u00e4dler, S. and Zesch, T.: Maxent model for relation classification on SemEval'10 data. In: SemEval Workshop on Semantic Evaluation: Tasks, Techniques, Tools, 2010.\n\n[Crossref]\n\nBIBREF2\n\nPavlic, V., Chaudhry, V., Liu, W. and Zesch, T.: Relation classification with convolutional neural networks. In: 2015ACL. Association for Computational Linguistics, Philadelphia, 2015.\n\n[Crossref]\n\nBIBREF3\n\nKim, D., Guthring, A. and Liang, Z.: Recurrent neural networks for relation classification. In: Proc. of The Conference on Empirical Methods in Natural Language Processing, 2015, pages 719\u2013728.\n\nDeSantos, R., Oyola, J. and Zesch, T.: Improving relation extraction using a ranking loss function and lexical features. In: Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computational Linguistics, 2015.\n\nMikolov, T., Chen, K., Corrado, G. and Dean, J.: Glove: Global Vectors for Word Representation. In: 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 2015, pages 3082\u20133090.\n\n[Crossref]\n\nBIBREF4\n\nCho, M., Lee, H., Chordia, S. and Gulcehre, M.: Convolutional Neural Networks for Sentence Classification. In: Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computational Linguistics, 2015.\n\n[Crossref]\n\nBIBREF5\n\nK",
    "e2e977d7222654ee8d983fd8ba63b930e9a5a691": "\nThis list of references is mainly used in the preparation and publication of this book. For a complete list of references of the book, please go to http://springer.com/acp.\n\nIn this chapter we present an overview over the most important NLP technologies, explain how they have been developed, and give recommendations regarding their usage. We also discuss the main challenges, describe their influence on the choice of the technology, and provide a brief overview of currently available tools.\nLanguage technology includes all systems, methodologies, and theoretical approaches that aim at creating artificial representations, linguistic resources, language corpora, and processing tools to support researchers and language end-users. NLP technology is broadly classified into three main classes: (1) syntactic tools and methods, (2) processing environments, and (3) language resources. These three classes are highly interrelated: As a consequence, linguistic resources are often created with syntactic tools, e.g., to create word representations, or resources such as language parsers are often used for lexical analysis, etc.\nSyntactic tools and methods as well as processing environments are not really alternatives but rather two separate views on the same issue. In NLP technology, this is, however, clearly visible in the fact that different NLP tools are often accompanied by different processing environments (Bick1996, Sch\u00e4fer1999, Langer, Kiefer, and Scholz2010).\nThis chapter focuses on the three main classes of NLP technology: (1) syntactic tools and methods, (2) processing environments, and (3) language resources.\n\n\u2022 Syntactic tools and methods are concerned with the transformation of language data from one form to another. In general, the transformation of language data concerns the automatic analysis, the automatic generation and the automatic reconstruction of language data from other forms (e.g., a syntactic analysis, such as used for dependency parsing, or a morphosyntactic analysis, such as for inflectional morphology).\n\nWe distinguish more fine-grained syntactic tools and methods from coarser-grained ones. Coarse-grained methods are general methods that work on language data as their sole input. This also concerns methods that, after transforming the input lexically, perform further analysis on the result syntactically. Fine-grained methods aim at solving a specific linguistic problem and accept the transformation lexically as input. One consequence of",
    "0cfe0e33fbb100751fc0916001a5a19498ae8cb5": "\nCited Literature\nBIBREF0\nSchmidt, H., Steyvers, M.: A maximum entropy classifier for named entity recognition. In: Proceedings of the 2009 Workshop on Interacting with the Web, pages 81\u201387 (2009).\nBIBREF1\nSteyvers, M., Ma, Q., Hollenbach, U., Blunkett, C., Klein, P., Neumann, M.: Named entity recognition based on maxent with application-specific features. In: Iwata, M., Matsumoto, M., Suzuki, Y., Matsumoto, S., Shikata, H., Tateno, C., Inui, M., Toyoda, M., Gao, X., Kanzaki, M., Sung, B., Lee, H., Larson, J.B., Liu, K.-H., Liu, S.-Y., Matsumoto, T., Matsumoto, T., Suzuki, N., Tateno, C.: Proceedings of the First Workshop on Semantic Evaluation, CLEF 2010, pp. 97\u2013103. CEUR Workshop Proceedings, CEUR-WS.org, 769.\nBIBREF2\nXu, Y., Liu, K-H.: Semantic role recognition for entity mention recognition using a deep convolutional neural network. In: The International Joint Conference on Computational Linguistics 2014 (IJCNLP), pages 1213\u20131221, 2014.\nBIBREF3\nXu, Y., Liu, K-H.: Semantic role recognition with recurrent neural network and convnet. In: The Thirty-Second Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 2015.\nBIBREF4\nLiu, K-H., Hollenbach, U., Blunkett, C., Steyvers, M., Hollenbach, U., Neumann, M., Srivastava, S.: Convnet semantic role recognition: Learning hierarchical representations for deep contextual modeling. In: The Twenty-Second International Joint Conference on Computational Linguistics (Volume 2: Short Papers), 2015. Association for Computational Linguistics.\nBIBREF5\nKim, E., Kim, E., Lee, K-A., Choi, S.-J., Jeong, S.-M.: Joint entity linking and entity mention recognition with cnn based on conditional random fields",
    "35b3ce3a7499070e9b280f52e2cb0c29b0745380": "\n\nData statement ::: Dataset characteristics\nx-stance. The dataset is composed of 3,146 questions asked during political campaigns for national or communal or cantonal elections. The questions are in four languages: Swiss Standard German, Swiss French, Swiss Italian and English. In total, we observe 716 candidates (for one out of three seats or positions) as well as 57,848 comments on a total of 135,719 questions. The questions are all open questions and ask for a yes/no/rather yes/rather no response. The comment is also free-text and can go up to 500 characters. The labels are yes/favor, no/against, rather yes/rather no. The comments were downloaded at the time of data creation from smartvote.ch.\n\nAuthors'statements\nVasile Mure\u015fan is a Ph.D. candidate in Computational Linguistics. His research interests include computer vision, natural language processing and machine learning.\nSabina Meijer is a computer scientist with a keen interest in languages and their role as a common ground for human understanding. She has worked in machine reading and the semantics of artificial language. Sabina's research interests are multimodal language processing, linguistic knowledge acquisition and representation and multimodal modeling.\nStefen U. L\u00fctkemeijer is an Associate Professor in Computational Linguistics. His research interests include lexical, textual and multimodal language acquisition and representation, and computational discourse analysis. His most recent work in computational linguistics includes argumentative argument mining, argument search and discourse analysis in social media.\nReferences\n\n[Aberer2020] Aberer, M., & Gurevych, H., 2020. x-stance. In Proceedings of the 3rd Workshop on Shared Task for Multilingual Political Argumentation Mining, Association for Computational Linguistics (ACL), Florence, Italy, pages 29\u201338.\n\n[BIBREF0] Aberer, M., Gurevych, H., Schmitt, M., et al., 2018. Multilingual stance detection for political science. Proceedings of the 14th Workshop on Semantic and Statistical Machine Translation (WSSST+), Berlin, Germany, pages 87\u201393.\n\n[BIBREF1]\n\n[BIBREF2]\n\n[BIBREF3]\n\n[BIBREF4]\n\n[BIBREF5",
    "71ba1b09bb03f5977d790d91702481cc406b3767": "\nData Statement ::: Data Annotation\nThe data do not contain any personal attributes. Instead, we provide our hashing of responder IDs to allow the users to assess whether they wish to remain anonymous.\nData Statement ::: Citation\nPlease state the DOI or any other handle/identifier for citation purposes.\n\nWe will upload the dataset soon to the data-forum BIBREF24. The most up-to-date information will be provided as soon as possible.\nM-Bert is based on the base implementation from Aliaksandr Czelusniak for Bert: BERT: pre-training of Deep Bidirectional Transformers for Language Understanding. 2019. Available: https://huggingface.co/transfers/bert-base-multilingual-cased. This work has been supported in part by National Science Foundation (NSF) Grant No. 1849958.\nThis material is based upon work supported by the National Science Foundation Graduate Research Fellowship Program (GRFP) under Grant No. 2015120532; Award No. 32486089. The views expressed herein are solely those of the authors and do not necessarily represent the official views of the National Science Foundation.\n\nWe would like to thank the organizers of the 2018 SemEval Conference on Semantic Evaluation for sharing the code.\nBIBREF01.\nKiritchenko, N. A. and Iyyer, M., 2016. Multilingual Document Classification using Multidimensional Hierarchical Agglomerative Clustering. In Proceedings of the 2016 Workshop on Multi-Lingual Multi-Document Learning, pp. 30\u201336, Ithaca, NY, USA, July.\n\nBIBREF02.\nKiritchenko, N. A. and Iyyer, M., 2017. Multi-Target Stance Detection Benchmark Data for Research. Available: http://aclweb.org/anthology/W17-5001.\n\nBIBREF03.\nWiebe, E., 2018. BIBREF2 \u2013 A Collection of Tweets annotated for Catalan Independence using Linguistically-inspired Representations. Available: http://aclweb.org/anthology/W18-5001.\n\nBIBREF04.\nKiritchenko, N. A. and Iyyer, M., 2019. Cross-target stance detection with multilingual neural network",
    "612c3675b6c55b60ae6d24265ed8e20f62cb117e": "\n\nQuestions: Between one and three sentences, depending on the length of the political issue covered.\nAnswers: Always categorical with one answer option (yes/ rather yes/rather no/no).\nComments: Always one single long paragraph.\n\nArgument: No special formatting.\n\nData Statement ::: Textual resources\nQuestions and answers in the English, German, French and Italian languages.\n\nWe did not process the text in any way to obtain a machine-readable form. The entire text corpus consists of 14,832,987 characters. A text analysis would therefore be complicated by the variety of characters and would make it difficult to quantify the number of questions and questions.\nData Statement ::: Original context\nThe context of texts on the platform smartvote.ch.\n\nQuestions correspond to topics of the Smartvote editors that have been chosen to be discussed in the media. All the topics are related to Swiss politics.\n\nData Statement ::: Curation rationale\nOnly use questions that are about political issues.\n\nOnly use answers that are about political issues.\n\nOnly use comments that are about political issues.\n\nThe voting advice platform does not restrict voters and candidates to political issues. We included all questions from the candidates who could have written general comments.\nThe questions were edited by political scientists and then shown to candidates for approval.\n\nOnly use questions that are closed.\n\nOnly use answers that are closed.\n\nOnly use comments that are closed.\n\nThe voting advice platform does not restrict answers to questions. We included all answers from the candidates who could have written general comments.\n\nData Statement ::: Stance class distribution\n\nThe questions are about political issues and so express some type of stance regarding the issue. We used as stance positive the majority class (favor) and as stance negative the minority class (against).\n\nTrain/test/evaluate: Train, test and evaluate on four sets.\n\nWe did not hold any data hidden for evaluation.\n\nData Statement ::: Number of questions and answers\n\nTrain, test and evaluate on four sets.\n\nTrain set: 5,992 questions (28.3% favor, 73.3% rather yes, 15.4% rather no).\n\nValidation set: 1,500 questions (39.02% favor, 57.02% rather yes, 3.95% rather no).\n\nTest set(s",
    "bd40f33452da7711b65faaa248aca359b27fddb6": "\n\nData Statement ::: Targets\nQuestion: A specific topic such as healthcare or taxes.\n\nAnswer: Yes / Rather yes / Rather no / No.\n\nCommentary: May be a proposition or justification. Free text of up to 500 characters.\n\nData Statement ::: Stance detection task\nXstance: The stance of a comment with respect to a specific question.\n\nStance: Yes / Rather yes / Rather no / No.\n\nData Statement ::: Task distribution\nData is held out for topics: 6.\n\nData is held out for targets: 12.\n\nData: Training set: 12532, Validation set: 966, Test set: 2750.\n\nData: Language distribution (questions) de-CH: 4.5 / fr-CH: 2.9 / it-CH: 0.5 / en-CH: 19.1;\n\nLanguage distribution (answers) de-CH: 6.6 / fr-CH: 2.6 / it-CH: 5.7 / en-CH: 77.8.\n\nData: Stance detection task. Xstance: Yes/ Rather yes/ Rather no / No/  No.\n\nStance detection task. Xstance: Yes/ Rather yes/ Rather no / No.\nTraining set 12532, Validation set 966, Test set 2750;\n\nLanguage distribution (questions) de-CH: 2.8 / fr-CH: 2.0 / it-CH: 5.9 / en-CH: 17.8;\n\nLanguage distribution (answers): de-CH: 4.7 / fr-CH: 4.9 / it-CH: 3.9 / en-CH: 57.9.\nStance detection task. Xstance: Yes/ Rather yes/ Rather no / No/  No.\nStance detection task. Xstance: Yes/ Rather yes/ Rather: No/  No.\n\nLearning rate 5e-5 (3e-5, 2e-5), epochs 3, 4,;\n\nLearning rate 5e-5 (3e-5, 2e-5), epochs 3, 4, dropout 0.1;\n\nTarget distribution: 4.8 / 12.0 / 7.4 / 8.0 / 8.5 / 8.8 / 8.2 / 5.",
    "787c4d4628eac00dbceb1c96020bff0090edca46": "\nThe questions were posed to candidates for national elections who were registered in the Swiss polling book.\nData Statement ::: Text language\nWe classify the texts into Swiss Standard German (70.9% de-CH), Swiss Standard French (25.7% fr-CH), English (3.3% en-CH) and Italian (1.2% it-CH).\nReference to language: Questions, answers, arguments and comments are text in any of the listed languages.\n\nData Statement ::: Original annotation\nThe questions and answers are in any of the listed languages. The answers are categorical (Yes / No / Rather Yes / Rather No) that take on a free-form comment to justify the answer position.\nReference to annotation: Categorical answers on three levels, where higher levels represent more positive opinions (i.e. the level Above Both indicates an absolutely positive stance, whereas the level Above Neither indicates a negative stance).\n\nData Statement ::: Automatic Annotation\nQuestion answers are automatically classified by applying the Bert model that is pretrained jointly in 104 languages. The task of stance identification is to correctly predict if answers are favorable (labeled Yes), neutral (labeled Rather Yes) or contrary (labeled Rather No) or unfavorable (labeled No) to various issues, questions, candidates or other texts. Labeling is done by choosing the class the answer is most often labeled with in relation to training examples. This can be either across all target issues, across all targets of the same type (such as candidates, types of questions, etc.), or across all questions where a target is not specified (i.e. for cross-lingual detection).\n\nReference to automatic annotation: We fine-tuned the model with a cross-entropy loss, using the AllenNLP library. The model was trained in the cross-lingual supervised setting, and evaluated independently for different languages, and also in a cross-target transfer setting.\n\nData Statement ::: Curation rationale\nThe training set consists of questions and answers from 175 communal, cantonal and national elections between 2011 and 2020. Mainly data pertaining to national-level issues were included to reduce variability.\nData Statement ::: Language variety\nThe training set consists of questions and answers in Swiss Standard German and Swiss French (61.7% de-CH; 38.3% fr-CH). The test sets also contain questions and answers in Swiss Italian (62.1",
    "3c3807f226ba72fc41f59f0338f12a49a0c35605": "\nReferences\n\n[1] R. Borklund, D. Erkin, L. G\u00f6ransson, J. O. Grimm, A. Jussila, C. Lee and G. Sundberg, \"GDPR: One Year Later - A Quantitative Evaluation of Compliance and Enforcement,\" International  \nJournal of Laws in Crisis and Disaster Management, vol. 29, no. 1, pp. 83-99, 1 June 2019.\n\n[2] J. Amsuess, J. P. Naughton, J. H. Jansen, G. M\u00e4der, J. M. J. van de Sandt, M. D. H. Knijnen and I. G. Karamanova, \"What is the Most Secure Internet of Things Security Architecture?\", Information & Security,  \npp. 1\u201320, April 2020.\n\n[3] D. Grymowski, C. Lee, V. Y. Chao, J. M. J. van de Sandt, P. Mylomov and D. C. Schuurman, \"Who is in your smart connected home? An analysis of the security of the built-in camera of connected  \nsecurity camera solutions\", in Proceedings of the 11th Annual Conference on Computer and Communications Security,  \nNew York, NY, USA, September 2016.\n\n[4] T. Zhang, L. D. O. Lei, Y. Cui and J. A. Miller, \"A Privacy Framework for Autonomous Vehicles Through Legal Data Sharing and Privacy Injunctive Remedies,\" ACM Transactions on  \nMotors and Control, vol. 22, no. 2, pp. 1-32.\n\n[5] S. S. Nath, B. T. Lim, A. Baral, V. Shankar, J. D. G. Kleinberg and D. H. Kim, \"Why Do Privacy Policies Matter: A Field Study of User Knowledge and Understanding,\" Proceedings  \nof the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, vol. 21, no. 4, pp. 24:1-24:31,  \nSeptember 2018.\n\n[6] M. Blyth and A. P. S. Greenberg, \"Privacy-Preserving Distributed Personalized",
    "c70bafc35e27be9d1efae60596bc0dd390c124c0": "\nBIBREFTan, E., et al. 2009. Polisis: Proactive disclosure for protecting individual privacy. In Proceedings of the 22nd ACM User Interface Conference (UIST'09). ACM, New York. [DOI=10.1145/1530166.1530179]\nBIBREF1BIBREF2D. Bindis, A., et al. 2007. E-privacy: Understanding the privacy and rights of online users. Institute of Electrical and Electronics Engineers.\nBIBREFTan-EtAl, J., et al. 2016. PolisisQA: Question answering over online privacy policies. In Proceedings of the 25th Annual Conference on Human Factors in Computing Systems (CHI'16). ACM, New York. [DOI=10.1145/2856773.2863929]\nBIBREF3BIBREF4S. Fischbein, M., et. al. 2012. Privacy by default: The case for public awareness and understanding. Communications of the ACM 56, no 10(10), pp. 68\u201376. [DOI=10.1145/2006961.2007069]\nBIBREF5S. Rekatsinas, K., et. al. 2014. Privacy concerns and attitudes towards data use in the eu. Journal of Marketing. 77(3), pp. 53\u201362. [DOI=10.1509/j.jma.73.53]\nBIBREF6S. Dwork, C., et. al. 2013. The case for private-better-than-secure databases. Communications of the ACM 59, no 12, pp. 86\u201393. [DOI=10.1145/2416993.2417096]\nBIBREF7S. Cappos, D., V. Stoyanovich, et. al. 2016. Privacy-enabling and privacy-protective privacy statements: An exploratory study in user decision-making. Proceedings of the 8th International Joint Conference on Privacy, Security and Trust (PST2017). [DOI=10.1109/PST.2017.7.00260]\nBIBREF8S. Hovy, E. 2015. Applying Natural Language Processing to Privacy. Communications of the ACM 58, no 2. [DOI=10.11",
    "81d607fc206198162faa54a796717c2805282d9b": "\nData Collection / Analysis\n\nThis document provides a brief statistical summary of the PrivacyQA corpus (Table TABREF17). Table TABREF18 describes the statistics of individual privacy policy documents.\n\nTable TABREF12.  \nStatistics over Top 50 Mobile Applications\nData Collection\n\nWe describe the steps used to collect a set of user-generated privacy questions that can be answered using knowledge of a privacy policy, to address the goal of reducing privacy risks without requiring the user to read entire privacy policies. First, Turkers are asked to imagine they have access to a third-party privacy assistant, to whom they can ask any privacy question about a given mobile application. We utilize the Amazon Mechanical Turk HIT service in order to recruit crowdworkers.\nQuestion Generation\n\nWe use an adversarial crowdsource method to generate the set of questions. To generate the question/answer pairs, crowdworkers are given information about a mobile application as well as screenshots of the app in action. We aim to include questions that include multiple different categories of privacy: third-party privacy, first-party privacy, data security, data retention, user choice, other, and international audiences. Table TABREF9 shows two different examples of questions asked by the crowdworkers, as well as the answers given by experts. We define the question type according to the OPP-115 categories from the privacy policy annotations.\nQuestion Generation / Answer Elicitation\n\nExperts attempt to answer questions posed by the crowdworkers using expert knowledge. Questions are organized into nine categories from the OPP-115 annotation scheme BIBREF49:\n\nFirst Party Collection/Use: What, why and how information is collected by the service provider\n\nThird Party Sharing/Collection: What, why and how information shared with or collected by third parties\n\nData Retention: How long user information will be stored\n\nUser Choice/Control: Control options available to users\n\nUser Access, Edit and Deletion: If/how users can access, edit or delete information\n\nPolicy Change: Informing users if policy information has been changed\n\nInternational and Specific Audiences: Practices pertaining to a specific group of users\n\nOther: General text, contact information or practices not covered by other categories.\n\nTable TABREF15 describes the distribution of questions over OPP-115 categories. As expected, first party and third party related questions are the largest categories. The remaining categories are quite sparse,",
    "51fe4d44887c5cc5fc98b65ca4cb5876f0a56dad": "\n\nAuthor Disclaimer\nThe authors are solely responsible for this material. It does not necessarily represent the views of the agency, DARPA, the U.S. Government or the authors' institutions.\n\nTable.TABREF1\n\nTable.TABREF15\n\nTable.TABREF16\n\nTable.TABREF17\n\nTable.TABREF18\n\nTable.TABREF19\n\nTable.TABREF21\n\nTable.TABREF20\n\nTable.TABREF22\n\nTable.TABREF23\n\nTable.TABREF30\n\nTable.TABREF31\n\nTable.TABREF32\n\nTable.TABREF33\n\nTable.TABREF36\n\nTable.TABREF37\n\nTable.TABREF38\n\nTable.TABREF41\n\nTable.TABREF42\n\nTable.TABREF43\n\nTable.TABREF44\n\nTable.TABREF45\n\nTable.TABREF46\n\nTable.TABREF47\n\nTable.TABREF48\n\nTable.TABREF49\n\nTable.TABREF50\n\nTable.TABREF51\n\nTable.TABREF53\n\nTable.TABREF55\n\nTable.TABREF56\n\nTable.TABREF57\n\nTable.TABREF58\n\nTable.TABREF59\n\nTable.TABREF60\n\nTable.TABREF62\n\nTable.TABREF63\n\nTable.TABREF64\n\nTable.TABREF65\n\nTable.TABREF66\n\nTable.TABREF67\n\nTable.TABREF68\n\nTable.8\n\nTable.TABREF69\n\nTable.TABREF70\n\nTable.7\n\nTable.TABREF71\n\nTable.TABREF72\n\nTable.TABREF73\n\nTable.TABREF74\n\nTable.TABREF75\n\nTable.FIGREF3\n\nTable.FIGREF4\n\nTable.FIGREF5\n\nTable.FIGREF6\n\nTable.TABREF76\n\nTable.FIGREF7\n\nTable.FIGREF8\n\nTable.FIGREF9\n\nTable.FIGREF10\n\nTable.TABREF77\n\nTable.TABREF78\n\nTable.TABREF79\n\nTable.TABREF80\n\nTable.FIGREF11\n\nTable.TABREF81",
    "f0848e7a339da0828278f6803ed7990366c975f0": "\nAppendix\nA list of experts who provided answers for the PrivacyQA corpus.\n\nBruno, Laura, Ph.D. Stanford Law School\nLanctot, Danielle, M.S. LLM UC Berkeley\nPirani, Chirag, Graduate Student, UCLA\nKang, Michael S. Ph.D. MIT Computer Science\nMcKiernan, John, Ph.D. Indiana University Law School\nYagielo, Ilya, Research Professor, Vanderbilt Institute for Public Policy Research\nO'Leary, Sarah, M.B.A. Northwestern University Pritzker School of Law\nBIBREF0 Practical Inference \u2013 The Art of Legal Reasoning: The State of the Art\n\nBIBREF1 The GDPR \u2013 Is It Enough?\n\nBIBREF2 The General Data Privacy and Protection Regulation\n\nBIBREF3 Can You Read and Really Understand Privacy Policies?\n\nBIBREF4 Why People Don't Read and Understand Privacy Policies.\n\nBIBREF5 How Do People Make Privacy Choices?\n\nBIBREF6 Measuring Consent in the Age of Web Trackers (and the EU General Data Protection Regulation)\n\nBIBREF7 People Don't (Really) Read Privacy Policies.\n\nBIBREF8 Understanding Privacy Policies Through Search Engine Use (and Their Fees)\n\nBIBREF9 The Difficulty of Understanding Privacy Policies in Practice\n\nBIBREF10 The Importance of Understanding a Security Policy (and its Fees)\n\nBIBREF11 Privacy Is a Social Contract.\n\nBIBREF12 Facebook to Pay \u00a319.5m After Privacy Ruling.\n\nBIBREF13 User privacy on the internet\n\nBIBREF14 The Data Transparent Handbook v1.7.\n\nBIBREF15 Neural models enable us to understand open-domain news\n\nBIBREF16 Open-domain Reading Comprehension\n\nBIBREF17 Evaluating the Open-domain Reading Comprehension Literature\n\nBIBREF18 Evaluating Open-domain Reading Comprehension Corpus Development BIBREF19\n\nBIBREF19 How To Make a Reading Comprehension Corpus\n\nBIBREF20 Reading between the Lines: Neural Models Enable Us to Find the Causal Relations in Online News",
    "b85fc420eb2f77f6f14f375cc1fcc5155eb5c0a8": " We gratefully acknowledge support from the Google Faculty Research Award and the G-Cube Lab at IIT Madras for part of this work.\nReferences\n\nBruna, H., J. Papineni, and K. Knight. Bi-directional recurrent neural networks for neural machine translation in multiple languages. Conference on Empirical Methods in Natural Language Processing, 2013.\n\nChen, W., W. Collins, E. Grave, and R. Socher. Neural semantic parsing with recursive neural network, 2014.\n\nJoulin, A., and M. Mikolov. Character-level continuous-space representations for text generation and inference. In ICTAI 2016, pages 63-74, 2016.\n\nKotzimas, C., Q. Li, S. R. Subramanian, D. Jurafsky, T. G. Kim, B. Y. Zhu, M. Zhai, S. H. Choi, A. Das, K. Liu, R. Zemel, P. K. Chung, S. M. Oh, J. A. Garcia Rodriguez, A. M. Black, G. S. Corrado, and J. R. Smith. Neural word representations learn to predict and generalize. In EMNLP, pages 1004-1012. 2014.\n\nMikolov, T., T. Y. Lee, and F. S. Yu. Distributed representations of sentences across different languages and domains. CoRR abs/1301.3781, 2013.\n\nMikolov, T., S. R. Sutskever, D. Warde-Farleys, D. Ghahramani, A. Krizhevsky, I. Sutskever, S. S. Savarese, and J. Dean. Distributed representations of words and phrases and their compositionality. In Proceedings of the 2013 Conference on Advances in Neural Information Processing Systems, pages 2510-2518. 2013.\n\nPfeffer, J., E. T. Giles, and V. S. D. Silva. Understanding a million emoji faces: Inferring human emotions from short text snippets. In Proceedings of the 2015 CHI Conference on Human Factors in Computing Systems, pages 3397-3405. 2015.\n\nReimers, N., S. Das, J. A. Garcia",
    "792f6d76d2befba2af07198584aac1b189583ae4": " This work was funded in part by NSF (NSF17-28447) and an Amazon Research award.\n\n[BIBREF1]\n\nD. S. Klein and S. M. Collins.\n\nA simple approach to learning word representations.\n\nIn Proceedings of the 2015 conference on empirical methods in natural language processing, pp. 150\u2013162, 2015.\n\n[BIBREF2]\n\nR. Gimpel, J. P. Cohen, Y. Bordes, A. Y. Ng, and P. Miura.\n\nA character-level language model for neural machine translation.\n\nIn Advances in Neural Information Processing Systems 29, pp. 3839\u20133848.\n\n[BIBREF3]\n\nH. H. Zhang and J. Tenenbaum.\n\nBidirectional gated recurrent neural networks for compositional lexical semantic models.\n\nIn Conference on Empirical Methods in Natural Language Processing (EMNLP), 2017.\n\n[BIBREF4]\n\nD. Gers and H. Sch\u00fctze.\n\nSelf-supervised learning of word representations.\n\nIn Conference on Empirical Methods in Natural Language Processing (EMNLP), 2016.\n\n[BIBREF5]\n\nB. Poczos and R. Salakhutdinov.\n\nRecurrent gated convolutions for language modeling.\n\nIn Conference on Empirical Methods in Natural Language Processing (EMNLP), 2017.\n\n[BIBREF6]\n\nO. Levy.\n\nAn embedding space for semantically labeled text.\n\nIn Proceedings of the 2015 conference on empirical methods in natural language processing, pp. 923\u2013932, 2015.\n\n[BIBREF7]\n\nJ. Toutanova, P. A. Miller, C. Guille, and Y. Ng.\n\nLearning semantic representations for text classification.\n\nCoRR abs/1503.00665, 2015.\n\n[BIBREF8]\n\nT. Sakaguchi, M. S. Dinu, and R. Salakhutdinov.\n\nLearning textual topic representations from unsupervised data.\n\nIn Proceedings of the 2016 conference on empirical methods in natural language processing, pp. 1098\u20131106, 2016.\n\n[BIBREF9]\n\n",
    "127d5ddfabec5c58832e5865cbd8ed0978c25a13": "\n\n1) In deep learning terminology, a neural network with LSTM units, or Long Short Term Memory, networks instead of GRU units are called LSTMs.\n\n## References\n\n[BIBREF0]. D. Socher. Introduction to Recurrent Neural Network Language Models. Annals of Distributed Computing, 63:73\u201393, 2014.\n\n[BIBREF1]. A. Karpathy, P. Singh, J. Long, A. Goyal. Continuous Bag-of-Words: Learning to Represent Documents with LSTMs. EECS Department of UC Berkeley, 2014.\n\n[BIBREF2]. K. S. Bhatia, B. Liu, Y. Li, E. K. Sun, B. Narasimhan, K. S. Lui, S. H. Raskara. Compact vector representation for unsupervised neural-network language models. 2017. URL: <https://arxiv.org/pdf/1703.11131>\n\n[BIBREF3]. Ameet Talwar, Michael Bittner, Shih-Fu Chang. Composing word vectors from character representations. In Neural Information Processing Systems (NeurIPS), 2017.\n\n[BIBREF4]. W. Jiang, X. Wu, D. I. Wong, B. Choudhury, S. Dasgupta. Improving word representations by reconstructing text. In International Conference on Learning Representations (ICLR), 2016.\n\n[BIBREF5]. T. R. Mi, H. Li, L. Xing, K. W. Chen. Char-RNN: Character recurrent neural networks for open-vocabulary word vectorization. In International Conference on Learning Representations (ICLR), 2016.\n\n[BIBREF6]. J. M. Bachrach, J. D. Erkens, W. J. C. Lin, D. A. Martin. Word vectors for text mining. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (ACL), 2016.\n\n[BIBREF7]. R. Y. Bhandari, Ameet Talwar, Y. Y. Zhou, M. Bittner, T. R. Mi. Document-level word vectors and their application to text classification and related",
    "b91671715ad4fad56c67c28ce6f29e180fe08595": "\n\nAppendix\nWe use a version of the official tweet1k corpora BIBREF0 as training data for word vector learning. BIBREF0 is composed of about 1.5 billion tweets for training and each tweet consists of about 100 words. We perform downsampling to reduce its memory footprint and use it only for learning the vocabulary. The corpus is pre-processed by first removing all retweets, cleaning up user names and URL links, replacing slang with their common usage equivalents, and lowercasing the text. The final data set contains 5K tweets.\nWe use the most recent version of word2vec - an enhanced version of the original corpus as pre-processing for tweets. The pre-processed corpora consist of about 10 million tweets from July 22 to July 28 of 2010 and each tweet consists of about 5 words. The corpus is pre-processed by removing all punctuation and cleaning up URLs, as well as replacing slang. We limit the vocabulary to the words that occur more than 25 times in total. This limits the vocabulary size to 1K words. We also remove all posts that appear to be related to topics like politics and finance, and the rest are fed to the Word2vec model. In all, this pre-processing leads to around 4.5 billion word vectors, of which around 93K are out-of-vocabulary words (OWOV) and the remaining 4.6 Billion Word2vec word vectors are in the vocab.\n\nTable 1: Predictions from tweet2vec and word model applied to tweets from word1k corpus (BIBREF0 ) and tweets from tweet2k corpus (BIBREF4 ).\n\nTable 2: Training and test set sizes for each model as a function of number of parameters.\n\nTable 3: Hashtag prediction performance on small, medium and large held-out tweets from tweet2k (BIBREF4) corpus for each model and for both test sets: RW containing rare words, and FW containing frequent words.\nTable 4: Hashtag prediction performance on large, medium and small held-out tweets from tweet_2k (BIBREF4) corpus as complexity of the task is changed by varying the threshold of minimum number of hashtags required per post.\n\nTable 5: Precision@1, recall@10 and mean rank (of the top predicted tag) for each test set.\n",
    "a6d37b5975050da0b1959232ae756fc09e5f87e8": "\nBIBREF0\n\nIan Goodfellow, Jean-Yves Bigand and Yoshua Bengio.\n\n\"Experience Replay: An Augmented Recurrent Reinforcement Learning Algorithm,\"\n\nICLR Workshop on Neural Computation and Recommender Systems, 2017.\n\nIan Goodfellow, Aaron C. Courville, Matthew P. Hoffman and Yoshua Bengio.\n\n\"Very Deep CNNs for Text Classification,\"\n\nICLR Workshop on Deep Learning in NLP, 2016.\n\nBIBREF2\n\nY. Zhang, M. Chen, Z. Xiang, D. Y. Lin, P. Liu, S. Li, B. Zou.\n\n\"Deep Hashtag Recommendation.\"\n\nICLR Workshop on Topic-Oriented Recommendation of Semantically Similar Tweets, 2017.\n\nBIBREF3\n\nY. Zhang, M. Chen, Z. Xiang, D. Y. Lin, P. Liu, S. Li, B. Zou.\n\n\"Deep Convolutional Hashtag Recommendation,\"\n\nNIPS Workshop on Social Media Mining for Understanding and Social Impact, 2018.\n\nBIBREF4\n\nBozena Piotrowska.\n\n\"Fast Supervised Learned Word Representations for Natural Language Processing.\"\n\nNIPS, 2017.\n\nBIBREF5\n\nGraves, Alex.\n\n\"Improving Language Models with Character-based Pre-trained CNNs.\"\n\nICLR Workshop on Neural Computation and Recommender Systems, 2017.\n\nBIBREF6\n\nY. Zhang, M. Chen, Z. Xiang, D. Y. Lin, P. Liu, S. Li, B. Zou, A. Courville, H. Liu.\n\n\"Word2vec Models of Neural Networks on Twitter.\"\n\nArXiv:1510.07132, 2015.\n\nBIBREF7\n\nH. Liu, P. Liu, S. Li, A. Chatfield, Z. Xiang.\n\n\"Learning to Embed with Character-CNNs, LSTMs and RNNs.\"\n\nNIPS Workshop on Social Media Mining for Understanding and Social Impact, 2018.\n\nBIBREF8\n\nAlejandro Lopez, Yun Feng-Chun H",
    "e82fa03f1638a8c59ceb62bb9a6b41b498950e1f": "\n\n[BIBREF3] T. Bielza, G. S. Grefenstette, A. Lascarides, N. Todorov and B. de Vogel. \"Context-Sensitive Semantic Networks Using WordNet and Lattices.\" In Proceedings of COLING 2003, 2003.\n\n[BIBREF4] R. R. Lesk. \"Computing Synonyms and Antonyms.\" In Proceedings Second Conference on Computational Linguistics, Association for Computational Linguistics (ACL-IJC-ACL), 1969.\n\n[BIBREF5] K. B. M. Lesk and D. A. Hill. \"A lexical-graph representation for semantic relations.\" In Proceedings of Computational Linguistics Conference, 1967, 5\u201312.\n\n[BIBREF6] A. G. Barone. \"Learning Semantic Relations from Wordnet Graph Representations.\" In Proceedings of ACL, 2010.\n\n[BIBREF7] Y. Xu, X. Yan, L. Zhang and T. Li. \"A supervised machine learning approach to WordNet-based word sense disambiguation.\" In Proceedings of ACL, 2017, 3\u201312.\n\n[BIBREF8] M. Joty, A. Gatt, Y. S. Ng and A. C. Goldstein. \"Word sense disambiguation using sense-aware features and decision trees.\" In Proceedings of ACL, 2010.\n\n[BIBREF9] Y. Xu, J. F. Wang and T. Li. \"The supervised machine learning approach to WordNet-based word sense disambiguation.\" In Proceedings of ACL, 2015, 7\u201311.\n\n[BIBREF10] Y. Xu, T. Li and X. Yan. \"A supervised approach to WordNet-based disambiguation using deep learning neural networks.\" In Proceedings of ACL, 2017, 10\u201316.\n\n[BIBREF11] B. Liang, B. Yu and K. Li. \"Word sense disambiguation using Bi-directional long- and short-term memory networks.\" In Proceedings of ACL, 2015, 21\u201327.\n\n[BIBREF12] S. Liu, S. Gao, Z. Dang and K. Liu. \"Augmenting Gloss Information in Supervised Embedding Models",
    "7ab9c0b4ceca1c142ff068f85015a249b14282d0": "\nReferences\n\n[BIBREF2]\n\nLesk, A. (1964). A theory of language structure. The Hague, Mouton.\n\n[BIBREF3]\n\nSurdeanu, F. I., & Radev, D. D. (2004). Glossing and sense tagging. Transactions of the AAAI conference on Artificial Intelligence, 2004, p. 676- 682.\n\n[BIBREF4]\n\nMikolov, T., Chen, K., Cohn-Ganzberg, M. C., Goldhar, D., Johnson, S., and West, J. (2013). GloVe: Global vectors of words. In Advances in Neural Inf. Proc. Systems, 25, p. 2679-2684.\n\n[BIBREF5]\n\nBj\u00f6rklund, P., Soricut, A., Cimiano, C., & H\u00f6lttinen, E. (2016). Sense-aware lexical semantic graphs. CoRR, abs/1607.04343.\n\n[BIBREF6]\n\nWang, J., Yang, X., & Zhang, Y. (2016). Word sense gloss graph for lexical semantic disambiguation. In Proceedings of the 12th International Joint Conference on Lexical and Computational Semantics, Lisbon, Portugal.\n\n[BIBREF7]\n\nRuder, D., Hansen, A., Ilyas, A., & Yang, F. (2016). Improving super- word sense disambiguation systems with semantic graph embeddings. In Proceedings of the 7th International Workshop on Learning and Reasoning over Knowledge, San Francisco, CA, USA, EACL.\n\n[BIBREF8]\n\nCohn-Ganzberg, M., Goldhar, D., & McIntyre, V. (Eds.). (2014). Word sense disambiguation and word sense induction. Lecture notes in computer science 9851, Springer, Cham.\n\n[BIBREF9]\n\nWang, J. & Yang, X. (2020). Using gloss information in supervised neural network-based Word Sense Disambiguation. In Proceedings of the 12th International Joint Conference on Lexical and Computational Semantics.\n\n[BIBREF10]\n\nLiu, B., & Xiang, D.",
    "00050f7365e317dc0487e282a4c33804b58b1fb3": "\n\nReferences\n\n[1] Yang Liu, Zhiheng Zhang, Jing Liu, Mingwei Ma, and Ping Li. \"A Neural Network-based Approach for Fine-Grained Word Sense Disambiguation.\" EACL 2016, page 905\u2013910, 2016.\n\n[2] William Klatt, Adam Laury, D. H. P. Povey, and Jason F. Bell. \"Automatic Word Sense Disambiguation: A Survey of Progress Since Senseval-3\". Computational Linguistics, 41(2), 2012.\n\n[3] Yue Zhang and Jian Yang. \"A Gloss-Context-Aware Sentence-Pair Approach to Word Sense Disambiguation,\" 2019.\n\n[4] James I. Matthews, Andrew McCallum, and Andrew Y. Ng. \"The Lesk Algorithm for Word Sense Disambiguation, an Evaluation of New Strategies, and the Automatic Assessment of Algorithms.\" Computational Linguistics, 15(2), 1997.\n\n[5] Chuan Guo, Hao Li, Yi Feng, Jing Liu, Weiyi Li, and Qiang Liu. \"A Hybrid Ranking Model for Sense Disambiguation Based on Lexical Knowledge and Word Relations from a Statistical Perspective.\" EMNLP 2017, 2018.\n\n[6] Jacek Szpakowicz, Piotr Swietojans, and Anastasiia Mikroyanis. \"Graph-based Word Sense Disambiguation: An Automatically Learned Graph Semantic Network for the WordNet Sense Inventory,\" 2015.\n\n[7] Wei Feng, Qingchen Wang, Hongrui Jia, Jing Liu, and Liang Zhang. \"Leveraging External Word Sense Embeddings for Lexical Acquisition in Neural Word Sense Disambiguation,\" 2019.\n\n[8] Xiaogang Zhang, Jing Liu, Guoxi Chen, Liang Zhang, and Qichen Zhang. \"Fine-grained Word Sense Disambiguation with Graph Attention and Co-attention,\" 2018.\n\n[9] Jing Liu and Qichen Zhang. \"Supervised Training for Word Sense Induction with Gloss Attention and Co-attention.\" EMNLP 2019, 2019.\n\n[10] Qichen Zhang, Yan Gu and Mingqing Yang. \"WordNet Sense Inventory Disambiguation using Semi-supervised",
    "c5b0ed5db65051eebd858beaf303809aa815e8e5": "\n::: References\n[1] R. Agichtein and K. Knight, \"An algorithm for word sense disambiguation,\" in Proc. 12th European Conference on Artificial Intelligence (ECAI 2016), Vienna, Austria, pp. 1207\u20131212. 2010, Springer.\n[a1] C. Chang, J. Lee, Y.-J. Lee and D. Bray, \"Knowledge-based word sense disambiguation with a bidirectional Long Short-term Memory network,\" Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2015.\n[a2] S. He, J. Li and P. Huang, \"Discriminative Word Sense Disambiguation with a Bidirectional Long Short-Term Memory Network,\" Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing: System Demonstrations. 2016.\n[a3] K. Chang, S. He, Y. Yin, X. Deng and D. Bray, \"Knowledge-based word sense disambiguation with a long-short-term memory-augmented memory network,\" in Proc. of the 25th International Conference on Computational Linguistics: The Shifting Shades of Meaning: Theory and Applications (Coling 2018), Melbourne, Australia, pp. 1443\u20131452. 2018, ACL.\n[a4] T. Schirrmeister, E. Graves, I. Sutskever and T. D. Mitchell, \"A unified architecture for deep neural network models of language,\" Nature 534(7608):471\u2013476. 2016.\n[a5] A. Houlsby, S. J. Curran, T. W. Graepel and S. J. Fell, \"The babelnet semantic graph: A tool for information retrieval and text mining,\" Computational Linguistics 33(3):233\u2013269. 2010.\n[a6] M. Heinz, J. Leibe Jr., S. Wehrbein and M. Stede, \"Babelfy, a hybrid lexical resource for word sense disambiguation utilizing graph-based and dictionary-based techniques,\" in Proc. of the 2012 Conference on Empirical Methods in Natural Language Processing (EMNLP), Budapest, Hungary, pp. 161\u2013166. 2012.\n[a7] M",
    "10fb7dc031075946153baf0a0599e126de29e3a4": "\nReferences\n\n[Aizpurua, B. & Mart\u00edn-Albo, A., 2019] Aizpurua, B., & Mart\u00edn-Albo, A. (2019). SemEval-2019 Task 2: Sense disambiguation for all words. In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Abstracts. Association for Computational Linguistics.\n\n[Blohm, S. & Hirst, A., 2019] Blohm, S., F. & Hirst, A. (2019). Verbnet-sense: Wordnet-sense based on verbnet: The learner. In Proceedings of EMNLP-2018. Madrid, Spain.\n\n[Boureau, B. & Chardronnet, A., 2019] Boureau, B., & Chardronnet, A. (2019). SenseTagBank: A publicly available wordnet-sense inventory. In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Abstracts. Association for Computational Linguistics.\n\n[Carreiras, L. & Cresti, H., 2019] Carreiras, L., C. & Cresti, H. (2019). SenseTagTool: A Wordnet-sense inventory in the semantic tag format. In Proceedings of EMNLP-2018. Madrid, Spain.\n\n[Cavnar, G. & Nugues, J., 2019] Cavnar, G., & Nugues, J. (2019). Wordnet-sense: A new semantic evaluation database for the evaluation of WSD systems. In Proceedings of EMNLP-2018. Madrid, Spain.\n\n[Dolan, D., Brockett, A., Lee, C., & Dyer, C., 2019] Dolan, D., A. G. Brockett, C. Lee, & C. Dyer. (2019). A case for ELMO: Fast training over multiple tasks with self-supervised pre-training. In Proceedings of EMNLP-2018. Madrid, Spain.\n\n[Enrich, C. & Hovy, E., 2019] Enrich, C., & Hovy, E. (2019). Neural-network-based sense tagging in a Wordnetlike dictionary. In",
    "e438445cf823893c841b2bc26cdce32ccc3f5cbe": "\nReferences\n\n[1] BIBREF0. Wikipedia quality scoring\n\n[2] BIBREF1. Inception: infinite-depth convolutional neural networks for image recognition\n\n[3] BIBREF2. Predicting academic paper acceptance and rejection: an early look at the DBLP archive\n\n[4] BIBREF3. Predicting good and bad Wikipedia articles: a machine learning approach\n\n[5] BIBREF4. Wikipedia article quality assessment using structural information\n\n[6] BIBREF5. Wikipedia article quality prediction: a multi-layered neural network approach\n\n[7] BIBREF6. Assessing article quality: a comprehensive approach\n\n[8] BIBREF7. Learning quality of Wikipedia articles using document editor networks\n\n[9] BIBREF8. What makes a good article?\n\n[10] BIBREF9. Quality analysis of new and revised Wikipedia articles\n\n[11] BIBREF10. Improved quality control on Wikipedia: a multi-level deep learning approach\n\n[12] BIBREF11. Document-based features for predicting document quality. In Proceedings of COLING 2015.\n\n[13] BIBREF14. Wikipedia article assessment using document-level deep representations\n\n[14] BIBREF15. Academic paper rating\n\n[15] BIBREF16. A comparison of techniques for content quality assessment in a cQA environment\n\n[17] BIBREF18. Automatic quality evaluation in community-based question-answering: A comprehensive experimental study\n\n[18] BIBREF19. Deep sentence semantic representation and sequence learning for content quality assessment of answers\n\n[19] BIBREF20. Measuring content quality of question answers using word embeddings, syntactic, and semantic similarity\n\n[20] BIBREF21. Learning to predict cQA answer quality: a survey of recent applications\n\n[21] BIBREF22. Using CNNs for quality estimation in community question-answering\n\n[22] BIBREF23. Modeling answer length and content in community questionanswering: a survey of neural methods\n\n[23] BIBREF24. Automatic quality prediction in community question-answering: a question of semantics or syntax\n\n[24] BIBREF25. Predicting the quality of online essay answers",
    "12f7fac818f0006cf33269c9eafd41bbb8979a48": "\nAcknowledgements\nThis work was partly supported by the Research Foundation of Fudan University.\n\nReferences\n\n[1] Wang, Chunyan, et al.  Automat\u0131cal Q Uality Assessm ent over Wikipedia. In Proce dings of the 56th Annual Meeting of the Association for Computati ng Mach\u0131ne Learning, 2018.\n\n[2] Zhang, Yao, Zhiqiang Mao, and Rui Hong.  Visual Document Classif i cation w\u0131th CNNs and Temporal Segmen tation. ACM Transactions on Information Syst emes (TISM) 21(4): 8:1-8:35.\n\n[3] BIBREF4. Wikipedia Qual\u0131ty Prediction by Using Editors' Reputations. arXiv preprint arxiv:1709.03217, 2017.\n\n[4] Zhang, Yao, and Zhiqiang Mao.  Cognitive Model of Featur ers for Automatic Q Uality Assessm ent of W\u0131kip\u0131dia Articles. arXiv preprint arxiv:1808.04120, 2018.\n\n[5] BIBREF6. Measuring the Quality of W\u0131kip\u0131dia Art\u0131cles. arXiv preprint arXiv:1705.09951, 2017.\n\n[6] BIBREF7. Wikipedia Article Qual \u0131ty Prediction. In Proceedings of the 3rd I Ntern\u0131al Conference on Webs and Text (ICWT), 2017.\n\n[7] BIBREF8. Visualization and Predict\u0131on of Wikipedia Article Qual\u0131ty. In Proceedings of the 2017 Conference on New Frontiers in Language Technology: Proceedings of the Conference Series of the Association for Computati ng Mach\u0131ne Learning, 2018.\n\n[8] BIBREF9. Wikipedia Quality: Can We Predict It? In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, 2018.\n\n[9] BIBREF10. Learning Document Qual\u0131ty Embeddings from Doc2vec Representat\u0131ons. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, 2017.\n\n[10] BIBREF12. Automatic Quality Assessm ent of W\u0131kip\u0131dia Articles by Synthes\u0131ng Readable Document Embeddings In Proceedings of the 2018 Conference on Empirical Methods in Natural",
    "d5a8fd8bb48dd1f75927e874bdea582b4732a0cd": "\nAcknowledgements\nWe wish to thank the anonymous reviewers for careful and useful feedback.\n[1]\n\nShavit, I., et al. (2017). Bibrefs: A document quality assessment method for wikipedia articles. The 30th AAAI Conference on Artificial Intelligence.\n[2]\n\nYang, M., et al. (2019). Learning visual style for image-text fusion. Pattern Analysis and Machine Intelligence.\n[3]\n\nShavit, I., et al. (2017). Evaluating quality of text based on readability scores of academic papers. Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing.\n[4]\n\nShavit, I., et al. (2018). Automatic evaluation of wikipedia articles via fine-grained analysis of page quality. Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing.\n[5]\n\nShavit, I., et al. (2017). Wikipedia article quality assessment. Proceedings of the 2016 Workshop on Applied Machine Learning and the Web.\n[6]\n\nShavit, I., et al. (2018). Wikipedia article quality assessment. Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing.\n[7]\n\nShavit, I., et al. (2018). Wikipedia page quality assessment. 2018 International Conference on Web and Text Mining.\n[8]\n\nYang, M., et al. (2018). Document quality assessment for web communities: A comprehensive survey. Proceeding of the 2018 Conference on Empirical Methods in Natural Language Processing.\n[9]\n\nBIBREF10, et al. (2017b). Predicting Wikipedia article quality: A case study on the use of neural document representations. Journal of Artificial Intelligence Research.\n[10]\n\nBIBREF13, et al. (2017b). Learning sentence representations for document quality assessment. Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing.\n[11]\n\nLe and K., et al. (2014). Extractive document summarization: A survey.\n[12]\n\nXiao et al. (2017). Exploring document representations for automated essay grading. The 27th AAAI Conference on Artificial Intelligence.\n[13]\n\nBIBREF15, et al. (2018). Automatic paper acceptance/rejection based on an attention-based",
    "1097768b89f8bd28d6ef6443c94feb04c1a1318e": "\nA.\n\nReferences\n\nAll codes and data associated with the research will be released on publication.\n\n   Table 1:\n\nTable 2:\n\nBiLSTM + Image Classifier. BIBREF0 BIBREF1 BIBREF3 BIBREF8\n\nTable 3:\n\n\nTable 5:\n\nTextual Features. BIBREF16 BIBREF5 BIBREF2\n\nFine-Tuning. BIBREF12  BIBREF14 BIBREF18 BIBREF33, BIBREF40\n\nH.\n\nTable 4:\n\nPerformance on the two datasets. BIBREF1  BIBREF2 BIBREF4 BIBREF32\n\nFine-Tuning. BIBREF12  BIBREF4 BIBREF19, BIBREF40\n\nInception with Feature Extraction via CNNs. BIBREF16 BIBREF10, BIBREF38, BIBREF40\n\nTable 5:\n\n\nVisual Features. BIBREF8 BIBREF10, BIBREF35, BIBREF36 BIBREF37 BIBREF39\n\nTable 1, Table 2.\n\nWe use the official Wikipedia datasets used in past studies. BIBREF0 BIBREF1. BIBREF12 BIBREF14 BIBREF19 BIBREF33, BIBREF40\n  Table 1. The text classification accuracy reported in BIBREF0 is evaluated over the titles, which is different from our task of assessing the quality of the whole article.\n\nInception V3. BIBREF1 BIBREF12 BIBREF38 BIBREF40\n\nTable 3.\n\nTable 4.\n\nWe also report the F1 score for the Wikipedia C class.\n\nTable 3.\n\nTable 4.\n\nWe also present the F1 score of the Wikipedia Stub class in Table 5.\n\nTable 4, Table 5.\n\nFor more information, see BIBREF1.\n\nTable 4, Table 5.\n\nThe accuracy over the whole article is much lower than for smaller text blocks, and we do not attempt to include them here.\n\nTable 3.\n\n# $n$ -gram and mechanics features are averaged over articles in the corresponding class.\n\nTable 4, Table 5.\n\n# $n$",
    "fc1679c714eab822431bbe96f0e9cf4079cd8b8d": "\n[BIBREF1] B. Zhao et al. Inception: Large neural networks for image recognition. ICCV 2015.\n[BIBREF2] D. Karger, H. Liu, L. Guo, K. Lee, and A. C. Roy. The arxiv big data challenge: a benchmark for automatically evaluating document quality. IJCAI 2016.\n[BIBREF3] D. M. Le et al. Wikipedia page-level quality estimation: a comparative study of article-internal features. Int. J. Inf. Libr. 32:8-21.\n[BIBREF4] S. J. He et al. The article quality of featured articles. Comput. Libr. 42(2):566\u2013578.\n[BIBREF5] S. He et al. Predicting the quality of wikipedia articles with deep learning. In Proc. KDD, pages 1773\u20131780.\n[BIBREF6] D. M. Le. Measuring the quality of an article's contributions to wikipedia. In Proc. KDD, pages 1723\u20131725.\n[BIBREF7] S. He et al. Predicting Wikipedia article quality using social contributions. In Proc. KDD, pages 1819\u20131825.\n[BIBREF8] S. Le and J. X. Lin. Revisiting the quality of wikipedia articles by means of document networks. ACM Trans. Inf. Syst. 36(4):29:1\u201329:9.\n[BIBREF9] S. He et al. Deep learning methods for reading comprehension in wikipedia data. IJCAI 2017.\n[BIBREF10] S. G. Zadeh et al. Leveraging doc2vec to predict wikipedia article quality. NLPCC 2017.\n[BIBREF11] V. Belletini et al. Doc2vec: A vector space representation of documents. In Proc. EMNLP, pages 1279\u20131284.\n[BIBREF12] J. X. Lin et al. Combining deep neural networks with hand-crafted features for improved wikipedia quality assessment. In Proc. AAAI, pages 2925\u20132930.\n[BIBREF13] L. Jiao, P. J. Chen, D. Chudanga,",
    "23e2971c962bb6486bc0a66ff04242170dd22a1d": "\nAcknowledgements\nThis work is supported in part by the National Natural Science Foundation of China under the Grant No. 61925303.\nNotes and Citation\nI. Introduction\nThe authors were supported by the project: Research on Automatic Knowledge Creation (Beijing: 863 program) funded by the China Government, and in part by a grant from the Institute for Human-Centered Artificial Intelligence.\n\nThis work is partially supported by grants from the National Natural Science Foundation of China under Grant Nos. 61671317; 61732004; 62027808; U1836215; 61173211; and a joint project with Microsoft Research Asia under contract numbers FHQ/L02/A21/01 and FHQ/L02/A21/02.\n\n[1] B. BIBREF0, N. BIBREF1, S. BIBREF2, and C. BIBREF3. Wikipedia article grading. Wikimedia. <https://en.wikipedia.org/wiki/Wikipedia:Wikipedia:Wikipedia:Wikipedia:Wikipedia:Wikipedia:Wikipedia:Wikipedia:Wikipedia:Wikipedia:Wikipedia:Wikipedia:Article_grading>. (accessed: 2021-01-04).\n[2] N. BIBREF2. How I Built a Conference Acceptance Predictor for Research Papers. [https://towardsdatascience.com/how-i-built-a-conference-acceptance-predictor-for-research-papers-1a7b7b5c849e2ef1cdaa5425ef5].\n[3] E. N. BIBREF0, M. M. BIBREF4, T. BIBREF5, and P. D. BIBREF6. The Quality Assessment of Wikipedia Featured Articles. In Workshop on Machine Learning in Wikimedia (MLinWik), pages 3\u201314. 2015.\n[4] Y. BIBREF7, K. BIBREF8, G. BIBREF9, I. BIBREF10, R. BIBREF11, D. D. BIBREF12, F. BIBREF13, and D. BIBREF14. Wikipedia text features. Wikimedia. <https://en.wikipedia.org/wiki/Wikipedia:Text features>. (access",
    "c9bc6f53b941863e801280343afa14248521ce43": "\n\nAcknowledgement\nWe would like to thank our mentor Taha Hafiz for his guidance and feedback, and the anonymous reviewers for their insightful comments. We would also like to thank Brendan J. Frey for sharing code for fine-tuning Inception V3 and his knowledge of neural networks in computer vision. This research was supported by the National Natural Science Foundation of China (NSFC) grant 61871351.\nReferences\nBIBREF0. A. BIBREF43, J. BIBREF44, S. BIBREF45 and J. BIBREF46. Wikipedia article quality is in the eye of the reader. Scientific Reports 12(1):1\u201310, 2020.\nBIBREF1. J. Devecchis. What lies beneath inception? A deeper analysis of inception and its variants. In Proceedings of the International Conference of Machine Learning, 2016.\nBIBREF2. B.-Z. K. J. BIBREF47, A. J. BIBREF48, R. Uth, T. Y. BIBREF49 and C. M. BIBREF50. Quality assessment of scientific articles: a survey on metrics, methods and applications. Advances in Machine Learning, 2018, 59:1\u201360, 2018.\nBIBREF3. A. BIBREF51 and Y. Y. BIBREF52. Word and document based signals for predicting Wikipedia article visibility. In Proceedings of the 25th International Conference on World Wide Web, 2018.\nBIBREF4. A. BIBREF53, H. BIBREF54, D. Liu and Y. Y. BIBREF55. Feature extraction for topic-based document readability evaluation. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, 2019.\nBIBREF5. B. J. BIBREF56 and Z. BIBREF57. Wikipedia article quality prediction: A survey of neural network-based methods. In Proceedings of the 18th International Joint Conference on Artificial Intelligence, 2016.\nBIBREF6. A. BIBREF58, H. BIBREF59, Y. Cui, R. BIBREF60 and M. S. BIBREF61. Measuring the quality of Wikipedia page creation: A case-study with Wikipedia contributors. In Proceedings of the 13th ACM International",
    "07b70b2b799b9efa630e8737df8b1dd1284f032c": "\nAcknowledgments\nWe are grateful to our colleagues at the Language Technologies Institute at Carnegie Mellon University, and the reviewers for their critical comments. We would also like to acknowledge the work of BIBREF5, BIBREF2, BIBREF12, BIBREF12, BIBREF10, BIBREF43, and BIBREF46.\n\nReferences\nBIBREF0 BIBREF10 BIBREF12 BIBREF14 BIBREF43 BIBREF10 BIBREF23 BIBREF12 BIBREF36 BIBREF5\n\nBIBREF1 BIBREF12 BIBREF43 BIBREF12\n\nBIBREF2 BIBREF43 BIBREF15 BIBREF1\n\nBIBREF3\n\nBIBREF4\n\nBIBREF5 BIBREF43 BIBREF10 BIBREF45 BIBREF2 BIBREF45\n\nBIBREF6\n\nBIBREF7\n\nBIBREF8\n\n.\n\nBIBREF10 BIBREF12 BIBREF46 BIBREF10 BIBREF12\n\nBIBREF11 BIBREF36\n\nBIBREF12 BIBREF43 BIBREF10\n\nBIBREF12 BIBREF12 BIBREF12 BIBREF45 BIBREF2 BIBREF43 BIBREF12\n\nBIBREF15\n\nBIBREF16\n\nBIBREF17 BIBREF18 BIBREF18 BIBREF19 BIBREF20 BIBREF18 BIBREF1 BIBREF1\n\nBIBREF18 BIBREF25 BIBREF29 BIBREF29 BIBREF29 BIBREF30 BIBREF29 BIBREF31 BIBREF29\n\nBIBREF18 BIBREF18\n\nBIBREF18 BIBREF18\n\nBIBREF18 BIBREF18 BIBREF18 BIBREF18 BIBREF18\n\nBIBREF19 BIBREF22 BIBREF18 BIBREF18 BIBREF22 BIBREF18 BIBREF18 BIBREF22 BIBREF18\n\nBIBREF18 BIBREF18 BIBREF18 BICREF10 BIBREF20 BIBREF22 BIBREF18 BIBREF22\n\nBIBREF20 BIBREF22 BIBREF18",
    "71a0c4f19be4ce1b1bae58a6e8f2a586e125d074": " We hope that further research can build on our work to improve document quality assessment through both visual features and textual features.\nReferences\n\n[BIBREF1 ] A. Ijjaz. Visual Inception. In Advances in Neural Information Processing Systems 28:2778\u20132787, 2015.\n\n[BIBREF2 ] V. Chagavathse, I. S. Vanslambrouck, and S. Zubiaga. Predicting academic paper acceptance for computational linguistics. In Proceedings of the Joint ACL, EMNLP, and EACL 2019 Conference.\n\n[BIBREF3 ] L. Chen, T. Lin, J. B. Tenenbaum, X. Yang Quiter. Predicting Wikipedia featured article and good article status with a bag of character-level n-grams. CoRR, abs/1707.04597, 2017.\n\n[BIBREF4 ] M. Li, D. Gao, B. Zhang, V. Chagavathse. Automated evaluation of scientific articles using a mixture of feature-based and deep learning methods. In Proceedings of the Annual Conference of the Association of Computational Linguistics (Volume 1), 2017.\n\n[BIBREF5 ] J. B. Macskasy, R. K. Sproat, B. Lally, D. B. Leak, M. C. McMillan. An automated article quality assessment model based on the WikiQual project. In Proceedings of the Twenty-Fourth ACM Conference on Intelligent Virtual Agents, pp. 25\u201336. ACM, 2003.\n\n[BIBREF6 ] J. Xu, V. Chagavathse. An image-based method for predicting the quality of Wikipedia pages. In Proceedings of the Eleventh International AAAI Conference on Web and Social Media, pp. 26\u201332. AAAI Press, 2015.\n\n[BIBREF7 ] D. B. Leak, Y. P. Chen, M. C. McMillan. Evaluating Wikipedia article quality with automated metrics. In Proceedings of the Sixth WSDM Conference on Research & Development in Information Retrieval (SIGIR '04), pp. 15\u201322. ACM, 2004.\n\n[BIBREF8 ] T. J. Tenbrink, D. B. Leak, Y. P.",
    "c2eb743c9d0baf1781c3c0df9533fab588250af3": "\n\n[BIB]\n\nBengio, S., et al.\n\n.\n\nDeep learning with long short-term memory.\n\nIn\n\nProceedings of the 30th International Conference on Machine Learning\n\nACM\n\npages\n\n.\n\n.\n\nNew York\n\n2015\n\n[BIB]\n\n\nBengio, S., et al.\n\n.\n\nRNN for machine translation: A novel architecture and its application to the French/English WMT 2014 machine translation task.\n\nIn\n\nProceedings of the 34th Annual Meeting of the Association for Computational Linguistics\n\nACL\n\npages\n\n.\n\nBoston\n\n2014\n\n[BIB]\n\nChung, S., et al.\n\nEmpirical validation of the recurrence mechanisms in long-short-term memory RNNs.\n\nIn\n\nProceedings of the 33rd Annual Meeting of the Association for Computational Linguistics\n\nACL\n\npages\n\n.\n\nNew York\n\n2014\n\n[BIB]\n\nGehring, J., et al.\n\nDeep neural networks with long short-term memory for machine comprehension.\n\nIn\n\nProceedings of the 32nd International Conference on Machine Learning\n\nICML\nCambridge\n\nMA\n2013\n\n(Best paper of Conference Award)\n\n[BIB]\n\nGoodfellow, J., et al.\n\nDeep, wide, convolutional neural networks for voice command recognition.\n\nIn\n\nProceedings of the International Conference on Acoustics, Speech and\n\nSignal Processing\n\nICASSP\n\npages\n\n.\n\nNew York\n\n2016\n\n[BIB]\n\nGrimm, B., et al.\n\nConvolutional and recurrent neural networks for parsing.\n\nIn\n\nProceedings of the Thirty-fourth International Conference on Computational Linguistics\n\nColing\n\npages\n\n.\n\nJahrbuch f\u00fcr deutsche Sprache\n\n57:43\u201359\n\n[BIB]\n\nKiros, S., Dahl, G., E.\n\nGraves, A., Chieu, D., Mothilal, D., Y.\n\nGlockner, Y.\n\n.\n\nLanguage Modeling",
    "c35806cf68220b2b9bb082b62f493393b9bdff86": " We greatly appreciate the reviews from anonymous reviewers, which helped improve the manuscript by several folds.\n\n* This work was performed during a postdoctoral fellowship funded by the National Research Foundation of Korea; it was also supported by the Institute for Information & communications Technology Promotion (IITP) grant funded by the Ministry of Science and ICT as well as the National Research Foundation of Korea (NRF-2018M3A9A1046600, NRF-2020R1D1A2C7075502 ) and the CERIST Institute for Research and Training in Artificial Intelligence (CERIST AIDP-N18-1166), and by a basic science research program from the University of Seoul (UC_BSR-2020\u20142019-06).\n* 1D Sequential RNN is the simplest possible version of RNNs that can handle sequential data.\n* Note that the previous and the current cell states are not differentiated differently in this paper. Usually LSTA is also used here to indicate the previous hidden state.\n* The common practice before gate was invented is to use tanh. However, the experiments show that sigmoid activation is useful in practice.\n* LSTM is short for Long Short-Term Memory. LTM stands for Long Term Memory.\n* In this paper, 1D and 2D are two-space dimensional vectors if there is no confusion. For 2D vectors, the order of dimension ordering does not matter.\n* LSTMs are a common RNN model used in many NLP tasks. In this paper, we use these terms as acronyms.\n* For more detail on LSTMs, see e.g. gated recurrent units BIBREF2 or the book of LSTM networks BIBREF9.\nReferences\n\n[AndriusChernys,\n\nKasunCaliskyte,\n\nAndrejMar-Phillips,\n\nDzmitryBachlorecki,\n\nMikolajCimrman,\n\nRaffaellaSorikach,\n] (2016) \"Hierarchical Neural Models of Visual Recognition by Exploiting Recursive Structures\" in Advances in Neural Information Flow,\n\nEds. DanielaK.S. Katz,\n\nIanGoodfellow,\n\nAlessandroLaptev, et",
    "f7d0fa52017a642a9f70091a252857fccca31f12": "\nREFERENCES\n\n[AN16] A. Aly, L. Rudinger, R. Fausel, and M. R. Bronstein, \"On the expressiveness of cell states for recurrent networks.\" In NIPS, 2016.\n\n[BR00] I. Balasubramanian, R. Fausel, and M. B. R. Fausel, \"The effect of neural architecture on performance in deep language models.\" In ICML, 2000.\n\n[CL13] L.-J. Chang and H.-S. Lee, \"From phrase representations to trees: a unified framework for neural semantic parsing.\" In EACL, 2013.\n\n[CO15] A. Ceglarek and D. Ordonez, \"Recurrent neural network with gated update.\" In ICASSP, 2015.\n\n[COB15] S. Cobbe, A. Kraus, and K. Blunsom, \"Long short-term memory networks.\" In ICASSP, 2015.\n\n[COB16] S. Cobbe, A. Kraus, M. K\u00f6tzing, and K. Blunsom, \"Long short-term memory networks: architecture, performance, and open questions.\" In ICASSP, 2016.\n\n[FEN16] F. Feng, J. B. Tenenbaum, S. L. Walker, and N. D. Lawrence, \"Incorporating syntactic context leads to significant gains in deep neural language models.\" In ICSE, 2016.\n\n[GBP13] I. Golab, C. Karpuschinski, M. S. Klinger, and I. Plummer, \"An analysis of deep neural language models.\" In COLING, 2013.\n\n[HZF13] H. Zen, M. Fu, W. Xiao, and Y. Zhao, \"Capsule networks.\" In ICLR, 2013.\n\n[IB04] S. Kakade, O. Shlensky, S. G. Zemel, and E. Lehmann, \"Learning to ask: an empirical study of compositional generalization of structured prediction.\" In ICML, 2004.\n\n[IBR16] Y. Inan, M. Bernstein, D. R. Klein, R. D. Schlangen, B",
    "01209a3bead7c87bcdc628be2a5a26b41abde9d1": "\n\nReferences\n\n[1] Yuval M. Mansour, Daniel Zaremba, and Erez Zilberstein. 2018. Gated Recurrent Rational Networks for Statistical Machine Translation. In Coling 2018 Proceedings of the 31st Conference on Computational Natural Language Learning, pages 3331\u20133336.\n\n[2] Liang Zhang, Yunhe Zhu, and Yichen Zhao. 2018. A Unified Memory-Augmented gated Recurrent Unit. In Proceedings of the 32nd International Conference on Machine Learning.\n\n[3] Alex Graves, Yoshua Bengio, and Christopher D. Manning. 2013. On the properties of gated neural networks as language models. Transactions of the ACL.\n\n[4] Richard Socher, Albert Szabo, Christopher Kiezjeski, Jason Weston, Oriol Vinyals, Danqi Chen, Michael Auli, Thomas Mikolov, Christopher Manning, and Piotr Chorpasion. 2013.\n\nEfficient Estimation of Word Representations in Vector Space. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1530\u20131538.\n\n[5] Ataullah Garakani, Mounia El-Kebir, and Sebastian Wachsmann. 2018. The Unified Sentence Representation. In Proceedings of the 33rd International Joint Conference on Artificial Intelligence, pages 626\u2013633.\n\n[6] Richard Zemel, Todor Kusner, and Rupesh Srivastava. 2016. Recurrent Convolutional Networks. In Proceedings of the 34th Conference on Neural Information Processing Systems.\n\n[7] Yen-Hsiang Lin. 2016. Inferring Relational Properties from Sequences of Objects using Recurrent Neural Networks. In Proceedings of the 5th International Conference on Learning Representations.\n\n[8] Y-N. Liang, Y-S. H.-C. Ling, H. L. Su, F. Q. He, Y. M. Zhou, and J. M. Zhou. 2012. A Simple and Fast Sentence Re-writing Network for Neural Machine Translation and Summarization. In Proceedings of the 2012 International Symposium on Modern Applied Statistics.\n\n[9] Matthew R. Peters, Eero Hoffsten, and Matthew E. Zeiler. 2018. Neural Machine",
    "2740e3d7d33173664c1c5ab292c7ec75ff6e0802": " For the future, we aim to extend our system to dialect varieties of Arabic such as Egyptian, Moroccan, Gulf, Levantine, Sudanese, and Maghrebi with greater feature engineering along with more experiments.\nAcknowledgments\n\nThis research is partly supported by the Qatar National Research Foundation and National Science Foundation under grants DBI1-1445 and DBI2-1545, the Qatar AI and Robotics Institute and the Qatar Computing Research Institute. Any opinions, findings, and conclusions or recommendations expressed in the report do not necessarily represent those of the Qatar National Research Foundation or National Science Foundation, and the QAIRI and QCCRI is not responsible for any views expressed in the report. This work was partially completed while the first author was a trainee on the National Center for Theoretical and Computational Science postdoctoral training program and while all authors were on sabbatical leave from Princeton University.\n\nBibliography\n\n[Bama'j, M. (2013). Farasa: The first Arabic morphology-analysis toolkit. ACM Computing Surveys, 45(2), 1-34](chapter://url?url=https://dl.acm.org/doi/10.1145/2467552.2467627&part=pp&referer=https://scholar.google.de/citations?view_op=view_citation&hl=nl&ei=5oKqjXwPzLZK9IwH8sAJIy5k8VcWgI1j9xv6zC)\n\n[Belinkow, E., & Glass, S. (2015). Arabic diacritics disambiguation: How far we have come and how little we know. In Proceedings of the 55th Annual meeting of the Association for Computational Linguistics, pp. 816-823.  \nDOI: 10.3115/v1/2015.acl-main.312](chapter://url?url=https://aclweb.org/anthology/D15-1258&part=pp&referer=https://scholar.google.de/citations?view_op=view_citation&hl=nb&ei=y4oO2H4jy6xUjVcRJIy5k8VcWgI1j9xv6z",
    "db72a78a7102b5f0e75a4d9e1a06a3c2e7aabb21": "\nBIBREF1 Alsafi, H., C. O. Zwarts, K. Alsafi, Q. G. Dafallah, C. O. Naser, D. Maddern, and F. Zadou, 2010, \"Core-word diacritics identification system for Modern Standard Arabic\", In Proceedings of ACL 2010 Workshop on Research Issues in Natural Language Annotation. 2010.\n\nBIBREF2 El-Hani, M. and Y. S. Gale, 2013, \"Arabic core lexical diacritics identification system\", ArabML 2013, 2013.\n\nBIBREF3 Al-Barghouthi, M., E. O. Eid, A. F. Abd-El-Hilmi, and S. O. Al-Quraishy, 2014, \"Automatic recognition of Arabic diacritics\", International Conference on Language and Speech Technologies. Springer. 2014.\n\nBIBREF4 Hamdam, H., E. Saad, S. Elguindy, and M. K. Othman, 2017, \"Recovering Arabic Diacritics using word-level deep conditional random fields\", in Proceedings of Arabic natural Language processing Workshop. 2017.\n\nBIBREF5 El-Jameel, M. R., A. C. Farid, and A. I. O. Hamido, 2015, \"An efficient diacritic prediction network for Arabic\", in Proceedings of International Conference on Language Resources and Evaluation. 2015.\n\nBIBREF6 BIBREF7 BIBREF8 Sibony, T. and S. S. Firth, 2007, \"Automatic recognition of accent marks and core words in languages with multiple tones\". In Proceedings of COLING 2007. Cambridge University Press. 2007.\n\nBIBREF9 Sibony, T., M. Carpendale, and S. S. Firth, 2008, \"Learning Arabic diacritization patterns from speech and written data using hidden Markov models\", In Proceedings of Conference of the European Association for Machine Translation. 2008.\n\nBIBREF10 Kozinetz, K., S. Gale, T. Hsu, and N. Karkal, 2007, \"Vowel restoration using a hidden Markov model with a continuous-time observation\", In Proceedings of HLT-NAAC",
    "48bd71477d5f89333fa7ce5c4556e4d950fb16ed": " Finally, we plan to explore more semantic features such as affix relations and morpho-syntactic information.\n\nRecommendations for Further Reading\nThe reader is referred to the following references for further studies:\n\nAl-Mufreh, M, R. El Kahla, et al. 1995. Arabic Language Resources on the World-Wide Web. Kluwer Academic Publishers. BIBREF1\n\nBentz, O, A. O. Ferro, T. Hjalmslev, T. Joty, et al. 2015. Arabic dialectal variation and the need for new resources. In Proceedings : Fourth Workshop on Statistical Machine Translation (SMT), pages 13\u201311. BIBREF2\n\nBesold, D, R. Gatti, P. Mart\u00ed, A. Haddad, R. Grange, et al. 2015. Using Conditional Random Fields to Implement Bidirectional Neural Networks for Dependency Parsing of Arabic. In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics, pages 921\u2013928. BIBREF3\n\nElhadad, S. 2001. Arabic Morphology. Linguistic Survey of the Semitic Languages 46, 171\u2013235. BIBREF4\n\nGabrilove, C, R. Sproat. 1987. Arabic Nouns. MIT Press. BIBREF5\n\nHjalmslev, T, D. Tiedemanns, A. Cimiano, et al. 2012. Arabic Word Sorting. LREC 2012, ISCA. BIBREF6\n\nIbragimovs, I. 2001. Arabic Named Entities and Terminology in the News Media : A New Collection of Datasets. In Proceedings of LREC 2001. BIBREF7\n\nJaafar, G, C. O'Flaherty, O. Ullman. 2018. A study on automatic classification of Arabic language varieties using deep neural network approach. Journal of Information Processing and Management 2(17):1601\u20131616. BIBREF8\n\nLavie, N, A. Goldfarb. 2016. Machine Learning Techniques for the Arabic Language. In Proceedings of the 2016 Workshop on Arabic Language Technologies in Tigrinya, Amharic, and Semitic Natural Language",
    "76ed74788e3eb3321e646c48ae8bf6cdfe46dca1": " Moreover, we plan to employ other neural architectures such as attention-enhanced LSTM.\nAcknowledgments\nThe authors would like to thank the anonymous reviewers for their valuable suggestions.\n\n[1] P. AlObaidi, R. F. El-Said, M. Alkhawar, H. Khodadadi and K. Asfour. A linguistic perspective on the lexical selection of Arabic diacritics. Int J Intell Syst. 33:2-3(2013) 119-134.\n[2] A. Al-Rfou and R. A. Maatouk. Automatic diacritization with Hidden Markov models. SIGNAL: Imaging and Signal Processing. 12:2 (2014) 173-179.\n[3] A. Al-Rfou, R. Maatouk and D. S. Yildiz. On the recovery of Arabic case endings. Language Resources and Evaluation. 46:2(2010) 247-257.\n[4] A. Al-Rfou, K. A. Asfour, R. A. Maatouk and F. Khartabil. Automatic case-ending restoration. In Joint Symposium on Computational Linguistics in the Middle-East. (pp. 36-45). 2017.\n[5] M. Bender and H. M. Gebhard. Diacritization in the Czech, Slovak and Croatian languages. Transcriber's manual 12(2013) 12.\n[6] Y. Belkhir and T. Suleiman. MADAMIRA: Arabic case-ending restorer and predictor. In Conference on Human Language Technologies: 2016 Annual Meeting of the Association for Computational Linguistics. 2016.\n[7] L. Biber. The RDI Arabic Diacritizer. Linguistic Computing. 5:1-2 (2001) 49-56.\n[8] E. V. Bilenko, S. M. Kim, W. C. Lee, A. V. Nikolayeva, S. D. Young and S. Duttaroy. Diacritization of Cyrillic Text. In 12th annual meeting and tutorial day of the Special Interest Group in Computational Linguistics (EACL). (pp. 43-53). Stockholm: KTH. 2014.\n[9] O. B",
    "ad1be65c4f0655ac5c902d17f05454c0d4c4a15d": "\n\n\n## Dedication\n\nTo our family, on the occasion of our twentieth year of loving you.\n\n## Epigraph\n\nI cannot see what is right before my eyes.\n\n## Contents\n\n  1.  Cover\n  2.  Title Page\n  3.  Dedication\n  4.  Epigraph\n  5.  Contents\n  6.  Prologue\n  7.  Part One\n    1. \n    2. \n    3. \n    4. \n    5. \n    6. \n    7. \n    8. \n    9. \n    10. \n    11. \n    12. \n    13. \n    14. \n    15. \n    16. \n    17. \n    18. \n    19. \n    20. \n    21. \n    22. \n    23. \n    24. \n    25. \n  8.  Part Two\n    1. \n    2. \n    3. \n    4. \n    5. \n    6. \n    7. \n    8. \n    9. \n    10. \n    11. \n    12. \n    13. \n    14. \n    15. \n    16. \n    17. \n    18. \n    19. \n    20. \n    21. \n    22. \n  9.  Acknowledgments\n  10.  Also by Amy Waldman\n  11.  Credits\n  12.  Copyright\n  13.  About the Publisher\n\n# Guide\n\n  1. Cover\n  2. Contents\n  3. Chapter 1\n\n  1. ii\n  2. iii\n  3. iv\n  4. v\n  5. vii\n  6. viii\n  7. \n  8. \n  9. \n  10. \n  11. \n  12. \n  13. \n  14. \n  15. \n  16. \n  17. \n  18. \n  19. \n  20. \n  21. \n  22. \n  23. \n  24. \n  25. \n  26. \n  27. \n  28. \n  29. \n  30. \n  31. \n  32. \n  33. \n  34. \n  35. \n  36. \n",
    "2eb9280d72cde9de3aabbed993009a98a5fe0990": "\nREFERENCES\n\n[1] A. A. Ahmed et al. 2014. Multimodal reading comprehension from natural language to vision and back. arXiv preprint arXiv:1405.3386.\n\n[2] Z. A. Agarwal et al. 2015. What you say is what you tell: uncovering latent narrative structure in texts. Transactions of the Association for Computational Linguistics 2(1), 73\u00e293.\n\n[3] A. A. Ahmed et al. 2014. Cross-Modal Reading Comprehension from Images and Text. Transactions of the Association for Computational Linguistics 3(1), 19\u00e268.\n\n[4] B. Allen et al. 2008. What do we really know about reading comprehension? Trends in Cognitive Sciences (Online first).\n\n[5] A. Anastasopoulos et al. 2016. Modeling question answering in natural language conversations. In Proceedings of EACL 2016 (Poster).\n\n[6] B. Ang et al. 2016. Neural storytellers: an attention model for reading comprehension. In Proceedings of CoNLL-16 Workshop.\n\n[7] A. Ardila and D. Baroni. 2012. Corpustories: learning semantic representations for scripts via crowdsourcing. Computational Linguistics 39(1), 125\u00e2145.\n\n[8] E. Arguello and D. Baroni. 2014. A method for the automatic assessment of text comprehension from scripts. Proceeedings of EMNLP 2014.\n\n[9] A. Avni et al. 2017. Attending to what matters: an in-depth analysis of attention-based machine comprehension. In Proceedings of ACL 2017.\n\n[10] J. B. A. Bahnsen, R. L. Harnad, H. Krawczyk, and C. F. C. Turchi. 2010. The compositional semantics of scripts across cultural and linguistic diversity. Memory & Cognition 38(6), 1079\u00e21129.\n\n[11] B. Balog et al. 2016. Learning a common sense knowledge base from text using a graph-structured embedding model. Computational Linguistics 42(3), 667\u00e2696.\n\n[12] R. S. Bamman et al. 2016. The impact of script knowledge",
    "154a721ccc1d425688942e22e75af711b423e086": "\nAbraham, Y. I., et. al. 2016. Exploring Ambiguity and Implicitness in the CNN/Daily Mail Corpus: A First Step Toward Script Understanding. Proceedings of Coling-ACL Survey of Natural Language Processing, pp. 20:1\u201320:17, 2016, Association for Computational Linguistics: Stroudsburg, PA, USA.\n\n\u2014. 2017a. Implicitness-Aware Deep Learning of Scripts and Narrative Schemas for Information Retrieval. Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing (EMNLP), Lisbon, Portugal, pp. 827\u2013836.\n\n\u2014. 2017b. Linguistic and Visual Implicitness for Reconstructing Scripts and Scenes for Answerable Reading Comprehension Questions. Proc. 2017 Conference of the Pacific Association for Computational Linguistics. ACL-2017.\n\nAgathos, T., et al. 2019. Mapping Spatial and Temporal Implicitness in Natural Language. Proceedings of the 30th ACM International Conference on Information and Knowledge Management, 2019.\n\nAlsentzer, N. J., et. al. 2018a. Making Sense of Things: Inference-based Script-based Comprehension. In Proceedings of SemEval-2018 Shared Tasks.\n\nAlsentzer, N. J., D. Martens, M. Zettlemoyer and M. Hajic. 2019a. Inference-Aware Scenario Representation Language for Reading Comprehension. Proceedings of the 34th Annual Conference of the Association for Computational Linguistics (ACL), 2019.\n\nAlsentzer, N. J., et. al. 2019b. Scene Construction in Scenarios and News: Implications for Implicitness-Aware Script Comprehension. In Proc. of Coling 2019.\n\nBender, I., et al. 2019. Mapping Implicitness: An Experiment to Study Human Understanding of Sensorimotor Knowledge. Proceedings of the 40th Annual Conference of the Association for Computational Linguistics (coling-acls19), pp. 1510\u20131521.\n\n\u2014 and U. Brown. 2019. A Corpus of Scripts Supporting Multimodal Machine Comprehension. Proceedings of SEM-Corpus Workshop, 2018.\n\n",
    "84bad9a821917cb96584cf5383c6d2a035358d7c": "\n\nReferences\n\n[Ammar2013] Ammar, T. & Havasi, D. 2013. \"What Are the Skills for Reading? Toward a Systematic Understanding of Reading Comprehension\". In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, Prague, Czech Republic, pp. 139\u2013148.\n\n[Ardila-Ayala2017] Ardila-Ayala, A., Riezler, S., Lederer, O. & T\u00c3\u00b6hler, K. 2017. \"MCScript: A Novel Dataset for Automatic Understanding of Comprehension Queries in Stories\". In Proceedings of the 9th Workshop on Computational Models for Commonsense Reasoning (COMMONSENSE2017), San Diego, USA, pp. 42\u201349.\n\n[Beesley2017] Beesley, C. & He, Z. 2017. A Unified Narrative Reader for Question Answering over Multiple Texts. In Proceedings of the 27th Conference on Computational Natural Language Learning, Sydney, Australia, pp. 1073\u20131083.\n\n[Chen2017thorough] Chen, M., Lai, S., Duh, M., Tsaig, H., Sato, P. & Yao, Y. 2017. \"Thorough Attention Reader with Recurrent Models and a Multi-stage Training Scheme for Machine Comprehension\". In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (EMNLP 2017), Hamburg, Germany, pp. 1757\u20131768.\n\n[Chen2016thorough] Chen, M., Lai, S., Yao, Y. & Sato, P. 2016. \"RACE: The Stanford question-answering championship\". In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing (EMNLP 2016), Austin, USA, pp. 890\u2013897.\n\n[Chrupa\u01422016] Chrupa\u0142, M., Dziubalski, A., Krawczyk, B., Tatar, M. & Jann, U. 2016. \"Inference Beyond Text: Automatic Comprehension of Questions Over Common Sense Knowledge\". In Proceedings of the 2016 Conference of Empirical Methods in Natural Language Processing, Toronto, Canada, pp. 921\u2013933.\n\n[Chrupa\u0142",
    "c9305e5794b65b33399c22ac8e4e024f6b757a30": "\n\n\\end{document}\n\n\\clearpage\n\n}\n\n\n\\section{Acknowledgements}\nWe would like to thank Prof. Rajeev Kumar Agrawal of IIIT-Delhi for his early introduction to the propagation of misinformation in media.\n\n\\small\n\n\\bibliography{\n\n\\bibitem{DBLP:conf/emnlp/Nakov:2015}\nNakov N., (2015). \\emph{On the role of human cognitive strategies in reading and misinformation: A computational study.} In: Proceedings of EMNLP, pages 1149-1156, 2015.\n\n\\bibitem{DBLP:conf/emnlp/SanMartino:2019}\nSan Martino M., Ghoshray-Haghighi R., Iosad S. (2019). Detection of Propaganda Techniques in News Texts. In: Proceedings of the 11th Conference on Empirical Methods in Natural Language Processing (EMNLP) 2019, pages 3045-3053, 2019.\n\n\\bibitem{DBLP:journals/corr/abs/abs/1908.02987}\nKrishnamoorthy V. P., Muthamsetty G., San Martino M., (2019). Fine-grained Automatic Propaganda Detection: A Case Study Using Wikipedia. \\emph{CoRR e-print arxiv:1908.02987}, August 2019.\n\n\\bibitem{pankajgupta:CrossRE2019}\nPankaj Gupta G., (2019). Cross-referencing Rephrased Entities to Boost Recall for Propaganda Detection. \\emph{ACL-IJCNLP 2019: Proceedings of the 2019 11th International Joint Conference on Computational Linguistics and Natural Language Processing, pages 5197-5205, 2019.\n\n\\bibitem{DBLP:journals/corr/abs/abs/1909.09046}\nShamsi-Navadi K., San Martino M., Bhattacharyya K., and Iosad S., (2019). Detecting Propaganda Propaganda. \\emph{CoRR e-print arxiv:1909.09046}, September 2019.\n\n\\bibitem{DBLP:journals/corr/abs/abs/1908.09",
    "56b7319be68197727baa7d498fa38af0a8440fe4": " Another aspect would be to explore combining FLC and SL-c together in one solution.\nAcknowledgments: We would like to thank the anonymous reviewer and other program committee members for their thoughtful comments and suggestions to improve our work.\n\nReference:\n\nBIBREF0. T. Czarnocka, E. W. Lee, A. L\u00f3pez-Cobianco, Y. Yamada, and J. Pustejovsky. Tackling online propaganda: Detection and evaluation of propagandistic behavior and techniques in twitter. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing, Hong Kong, 2019. Association for Computational Linguistics.\n\nBIBREF1. W. Sun, Y. Yamada, E. W. Lee, and J. Pustejovsky. Fake News Detection in Texts: A Corpus and a Methodology. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, Stockholm, Sweden, 2016.\n\nBIBREF2. W. Sun, Y. Yamada, E. W. Lee, A. L\u00f3pez-Cobianco, Y. Ohata, and J. Pustejovsky. Deterding fake news detection: Leveraging human expertise in sentiment analysis for document classification. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, Edinburgh, Scotland, UK, 2017.\n\nBIBREF3. A. P. de S. F. Carling and E. W. Lee. Detecting Propaganda in Texts: A Shared Task. In Conference and Labs of the Association for Computational Linguistics, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing, Hong Kong, 2019.\n\nBIBREF4. S. I. Choi, E. W. Lee, and J. Pustejovsky. Propaganda detection in twitter messages: Addressing rhetorical and lexical features. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, Stockholm, Sweden, 2016.\n\nBIBREF5. H. M. N. Nguyen and E. W. Lee. A sentiment-based approach for propaganda detection in twitter. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, Edinburgh, Scotland, UK, 2017.\n\nBIBREF6. S. Otsu",
    "2268c9044e868ba0a16e92d2063ada87f68b5d03": "\n\n\n## Automatic Detection of Deceptive Information in Political Documents\n\n### A. Fawad, P. Das, P. Gupta\n\n*University of Illinois, Urbana-Champaign, USA*\n### I. Mohan\n\n## Abstract\n\nIn this work, we present an approach to detect deceptive information in political text from documents with three different techniques. The first is an unsupervised learning technique using a Latent Hierarchical Dirichlet allocation based clustering algorithm which aims to find deceptive semantic topics as opposed to informational topics. The second is a supervised training approach for classifying deceptive news articles using a CNN/LSTM/CRF model with character level features. Lastly, we use Word2Vec semantic similarity metric along with Latent Semantic Analysis (LSA) to detect deceptive messages from political document. The first two methods are shown to work accurately with a variety of deceptive and non-deceptive corpus. On top of it, we use various combinations of these techniques to detect deceptive texts and improve performances.\n\nIntroduction: The recent years have witnessed rise in fake news articles through social media platforms. To address this issue, several research efforts have been made during the last few decades, but so far the research community has paid little attention towards detecting deceptive information in political documents. The work in this paper mainly addresses two major research questions, i.e., what are the major deceptive topics that can impact a society, and how can we detect deceptive information contained within a political document. The answers to these research questions are of importance as far as it can help society defend itself against deceptive propagandists. Specifically, the work focuses on detecting deceptive information from a variety of corpora.\n\nMethodology and Results: We first explore unsupervised learning method where we use hidden topics to detect deceptive topics. We use a Latent Hierarchial Dirichlet allocation based clustering algorithm to group the articles into two semantic clusters based on word counts. We then use an iterative k-means algorithm to find topic-specific semantic vectors. These vectors help us further identify the deceptive topic specific articles as well as extract the deceptive semantic topic. With this approach, we achieve 86.34% recall, 85.86% precision on the fake news corpus. Next, we apply supervised learning and train an LSTM/CRF model on deceptive news articles. We experiment and test it over a variety of corpora involving deceptive and non-deceptive articles with different languages (English,",
    "6b7354d7d715bad83183296ce2f3ddf2357cb449": "\nTable tabref1\n\n\nTable tabref2\n\n\nTable tabref3\n\n\nTable tabref4\n\n\nTable tabref5\n\n\nTable tabref6\n\n\nTable tabref7\n\n\nTable tabref8\n\n\nTable tabref9\n\n\nTable tabref10\n\n\nTable tabref11\n\n\nTable tabref12\n\n# Cover\n# Chapter 1:\n\n## BLOOD, BLOOD, everywhere....\n\n# Contents\n\nCover\n\nCopyright\n\nChapter 1: BLOOD, BLOOD, everywhere....\n\n# Copyright\n\nCopyright \u00a9 2016 by John Saul\n\nAll rights reserved. This book, or parts thereof, may not be reproduced\n\nin any form without permission. The scanning, uploading,\n\nand distribution of this book via the Internet or via any other\n\nmeans without the permission of the publisher is illegal and\n\npunishable by law. Please purchase only authorized\n\nelectronic editions, and do not participate in or\n\nencourage electronic piracy of copyrighted materials. Your support\n\nof the author's rights is appreciated.\n\n# 1\n\n## BLOOD, BLOOD, everywhere....\n\nHe awoke in the dark.\n\nThe bed groaned. The ancient sheets were damp with perspiration. A heavy shadowed gloom, heavy with his sweat,\n\ndrooled above the bedroom. The sweat clung to his naked chest and arms. He smelled\n\nstrong coffee. He was thirsty.\n\nHis hand moved beneath the covers. He groped for his phone.\n\nHe found it and raised his head. The sweat dripped into his eyes. He\n\nblinked and reached for the lamp.\n\nNo longer in the darkness\u2014the fluorescent light glared down from the bedside table. He turned\n\nthe lamp on with a shaky hand. The face of his mobile shone from the bedside.\n\nIt wasn't his phone.\n\nHe pulled the bedside alarm clock closer.\n\n9:05 A.M.\n\nMonday morning.\n\nHe sat up and scratched his head.\n\nHis head hurt a bit.\n\nDamn it, he had a slight hangover yesterday. A real\n\nheadache made him want to roll back over and get a few more hours\n\nsleep. A little more drinking would fix that. And the",
    "e949b28f6d1f20e18e82742e04d68158415dc61e": "\n\\FloatBarrier\n\\newpage\n\\hypertarget{Table 1.}\n\\begin{tabularx}{8.0in}\n\\label{tabref10}\n\\toprule\n\\rowcolor{blue!50}\n\\tablehead{ \\BIBREF{SLC} dev internal: \\texttt {0-1, 1-0} }\n\n\\multicolumn{3}\n\\tablehead{ \\BIBREF{SLC} dev external: \\texttt {} }\n\n\\multicolumn{3}\n\\tablehead{ \\BIBREF{FLE} dev internal: \\texttt {0-1, 1-0}\n\n\\multicolumn{3}\n\\tablehead{ \\BIBREF{FLE} dev external: \\texttt {}\n\n\\multicolumn{3}\n\\rowcolor{blue!50}\n\\tablefoot{\n\n\\textcolor{tablefootcolor} \\textbf\n{Model} & \\textbf\n{Dev (Internal)  } & \\textbf\n{Dev (External)  } & \\textbf\n{Macro-F1} & \\textbf\n{Binary-F1} & \\textbf\n{Rank}\n\\tablehead{ \\BIBREF{SLC+FLC} dev internal: \\texttt {0-1, 1-0}\n\\multicolumn{3}\n\\tablehead{ \\BIBREF{SLC+FLC} dev external: \\texttt { }\n\n\\multicolumn{3}\n\\tablehead{ \\BIBREF{SLC+FLC} dev external: \\texttt {}\n\\multicolumn{3}\n\\rowcolor{blue!50}\n\\tablefoot{\n\\textcolor{tablefootcolor} \\textbf\n{Model} & \\textbf\n{Dev (Internal) & \\textbf\n{Dev (External)  } & \\textbf\n{Macro-F1} & \\textbf\n{Binary-F1} & \\textbf\n{Rank}\n\\tablehead{ \\BIBREF{FLE} dev internal: \\texttt { }\n\\multicolumn{3}\n\\tablehead{ \\BIBREF{FLE} dev external: \\texttt { }\n}\n\\multicolumn{3}\n",
    "a1ac2a152710335519c9a907eec60d9f468b19db": "\nS. Alam, N. Shukla\n\n1.\n\nL. L. K. Wong, B. Iyyer, J. G. Dahl, M. L. S. Brown, G. R. B. Connelly.\n\nLearning to detect propaganda. In\n\nProceedings of the 28th Conference on International Joint Conference on Artificial Intelligence. pp. 1268\u20131274.\n\nD. Basile, E. A. V. de Carvalho, M. Cozman, J. C. de Campos, R. Chiappa, M. da S. Silva, A. C. F. Silva, F. Silva.\n\nProposal for the development of machine learning techniques, tools, and services for automatic analysis of propaganda.\n\nBIBREF1,\n\n2019. Available at: http://www.aclweb.org/anthology/D19-2001/, https://arxiv.org/abs/1911.02728. [Open Access]\n\nI. Da San Martino, S. Alam, S. Chakrabarty.\n\nPropaganda detection in the digital age. In\n\nProceedings of the 2019 Conference on Empirical Methods in Natural Language Processing. pp. 4167\u20134179.\n\nD. Chen, X. Du, R. He, W. X. Ge, N. Xie.\n\nImproving news articles to reduce information risk.\n\nBIBREF0,\n\n2019. Available at: https://aclanthology.org/2020.emnlp-main.19.\n\nAbstract\nDisinformation and propaganda have often been found to be responsible for the polarization of news in recent years. We identify the key problem of misinformation through the research on information risk with respect to topics, individuals, and entities, and propose an effective solution using a multi-level detection system.\n\nFirst, we build two automatic systems for detecting the propaganda techniques at sentence and fragment level. To this end, we construct a corpus with three-point labeling for propaganda techniques, annotate about 800 high-confidence examples from the news sites at the sentence and fragment level, and employ these texts for training.\nSecond, we design word, part-of-speech, sentiment, lexical, readability, emotion, topic, and layout feature models for training the models",
    "ce6a3ca102a5ee62e86fc7def3b20b1f10d1eb25": "\n\nAcknowledgments\nWe thank all our peers in the MOOC intervention forum topic and all other previous works on MOOC forums intervention prediction. Our research was made possible by a generous grant from the Center for Teaching, Learning, and Technology (C-TLT).\nAppendix\nIntroduction\n\nThe primary objective of this paper is to investigate the effectiveness of an attention mechanism, which allows a deep neural model to find the most important posts in a thread for prediction. We first formalise the prediction task at hand. Since the Coursera forums only permit a single level of nested replies, we employ BIBREF7's hierarchical LSTM that builds representations for each thread hierarchically using the last output of an LSTM encoder of a word embedding vector representation from GloVe BIBREF9, as shown in Figure FIGREF2. Then the representations of each post, in turn, are fed to another LSTM. The hidden states of this thread-wise LSTM become the representations for the context (sequence of posts) within which the intervened post falls. We also evaluate our models' effectiveness across threads of different lengths. Our contribution is to study how different neural attention-based models with different attention forms help the model to decide what part of the thread to attend to for the intervention prediction. This is a significant improvement on previous state-of-the-art.\n\nProblem Formulation\n\nWe formulate our problem of predicting instructor intervention into threads in Coursera forums. A thread consists of a series of posts on a given topic. A post is an individual comment that can belong to a parent post. We assume each thread starts with a single post, the original post. Each post can belong to only one parent post. We use a vector representation of size D from an embedding layer of a pre-trained word2vec model. We employ a hierarchical LSTM that predicts a binary intervention signal from a single hidden state INLINEFORM0. A hidden state of size O is a snapshot of the hierarchical representations of the hidden layer at any point in time. Here, we refer to a hidden state as context to emphasise we only consider single-unit-based contexts. A context of size N is a contiguous linear sequence of hidden states where INLINEFORM3 is the post just prior to the intervened post, where INLINEFORM1 is the post before that and so on. To clarify, on a thread INLINEFORM0, our focus will be to",
    "49eb52b3ec0647e165a5e41488088c80a20cc78f": "\n\nA BIBREF0 F BIBREF1 A BIBREF2 A BIBREF3 A BIBREF4 B BIBREF4 C BIBREF5 B BIBREF6 BIBREF7 BIBREF8 BIBREF1 K-Means Clustering of Documents BIBREF7 Attention Mechanism in MOOC Forums BIBREF7 Predictive Modeling with Hierarchical LSTM for MOOC forum Intervention Problem BIBREF9\n\nA BIBREF7 C BIBREF2 G BIBREF9 G G G G\nA BIBREF1\n\nA BIBREF7 D A BIBREF2 G G LSTMs BIBREF4 Kernel Diverse Deep Kernel Machine BIBREF8\n\nA BIBREF0\n\nA BIBREF7 C G F BIBREF9 G\n\nB BIBREF4 F A BIBREF9 G G\n\nB BIBREF6 D\nA BIBREF7\n\nA BIBREF0\n\nA BIBREF0\n\nA BIBREF3\n\nA BIBREF4 C A BIBREF4 F BIBREF9 G G A\n\nA BIBREF6 G BIBREF9\n\nA BIBREF0 B BIBREF9 G G\n\nA BIBREF0 BIBREF9 C BIBREF10 C G G A G A\n\nB BIBREF4 C BIBREF9 B BIBREF7 B BIBREF7 A\n\nA BIBREF4 C A BIBREF5 BIBREF4 A G BIBREF6 C BIBREF7 G\n\nA BIBREF0\n\nF BIBREF9\n\nC BIBREF6 C BIBREF7 A G A G G G G\n\nA BIBREF5 G F BIBREF9 G G BIBREF4 C (1) G G\n\n1 2 3 4 5 6 7 8 9\n\n1 2 3 4 5 6 7 9\n\n1 4 5 6 7 8 9\n\n1 3\n\n1\n\n1\n\n1 3 6 1\n\n1 2 5 3\n\n1\n1 2 6 8\n\n1 6\n\n3 4\n\n1 4\n\n1\n1\n1 1 5 6 2 5 2 4 9\n",
    "9bb7ae50bff91571a945c1af025ed2e67714a788": " The models' performance improves (decreases) when thread's length increases (decreases) as the ability of the models to infer the context depletes (increases) \u2013 e.g., from INLINEFORM2 ), where the number of candidates drops sharply on the next post.\n\nAppendix: Full model equations can be found in the appendix.\nAcknowledgments\nThis work was originally presented as our Coursera Capstone for BSc in Computer Science. We would like to thank the Coursera staff and the course instructors for making the MOOC forums available for research purposes. All works that we consider in our review of related work were produced in collaboration with or with knowledge of the MOOC discussions e.g., BIBREF5, BIBREF13, BIBREF4, BIBREF1.\nREFERENCE\n\n[BIBREF0]\n\nAbebe Y, Crampton N, Dredze M, Lee J. Instructor intervention in Coursera's massive open online courses: learning to predict with latent variables. In In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP) pp. 2164\u20131694, New York, NY, USA: Association for Computational Linguistics. 2015.\n\n[BIBREF1]\n\nGraham F, Hepple R, Stocker S. Predicting student post content-based interventions from MOOC forum data. In In In Advances in Neural Information Processing Systems: Thirty-Fifth Annual Conference on Neural Information Processing Systems (NIPS), pp. 3911\u20133921. Cambridge, MA: MIT Press. 2016.\n\n[BIBREF2]\n\nFeng W, Wang D, He Q, Rastogi K. Coursera forum thread retrieval using inter-post discourse. In Proceedings of the 25th International Conference on World Wide Web, Rome, Italy. 2015.\n\n[BIBREF3]\n\nZhou T, Gao L, Mishra S, Lee S-L, Yang Y, et al. Reading human conversations: Extracting discourse structure for reply selection in massive online courses. In Kusner S, Crampton N, Lee J, editors. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP) pp. 3480\u20133488, Denver, CO, USA: Association for Comput",
    "81dbe9a9ddaa5d02b02e01a306d898015a56ffb6": " We also note that APA performs well on longer threads but with a large drop in prediction performance on shorter threads especially for BIBREF7. We note that the drop in performance occurs when the model's context length falls below 4. Shorter threads do not have sufficient context for the model to model well and predict true positive predictions. We also found that APA performs significantly better than other models on compilers-4 threads and on cases with student groupings, which in turn leads to more interactions. The reason, however is unclear. We leave it as future work to examine the case-groupings feature for intervening.\nAcknowledgements\nWe thank our doctoral students Abhimanyu Seth, Kishan Kumar Kandhari and Jugal Patel. We are also very grateful for support provided by the Singapore-MIT Alliance for research grant and research grant from National Research Foundation under its Academic Research Fellowship program.\nREFERENCE\n\n[BIBREF0]  Iyadurai, S., Gupta, V., & Liu, Z.. \"Predicting the intervention decision in massive open online courses: A latent variable framework for instructor intervention.\"\n\nIn SIGCSE Conference on Computing Education, 2017.\n\n[BIBREF1]  Hosseini, H., Iyadurai, S., & Xiang, S.. \"Attentive thread modelling for predicting instructor intervention at Coursera.\"\n\nIn International Conference on Learning Analytics & Knowledge 2016.\n\n[BIBREF2]  Choi, H., Chen, M., & Liu, S.. \"A novel approach to thread retrieval and clustering for discussion forums over massive open online courses.\"\n\nIn Data Science and Advanced Computing Seminar, 2017.\n\n[BIBREF3]  Feldman, J., & Gong, J.. \"Retrieval and discussion thread clustering for massive open online courses using probabilistic topic model.\"\n\nIn Languages & the Web Conference, 2017.\n\n[BIBREF4]  Wen, C., Chen, M., & Liu, C.. \"Hierarchical attention model for document classification in online forums: An exploratory study at Coursera.\"\n\nIn SIGCSE Conference on Computing Education, 2018.\n\n[BIBREF5]  Sarkar, C., & Iyadurai, S.. \"Classifying discussion thread",
    "348886b4762db063711ef8b7a10952375fbdcb57": "\nREFERENCES\n\nBIBREF01\n\nBouadjenek L, Kann R, Bougares C, Bougares F, Mashayekhi R (2017). TransT: a pipeline for improving multilingual machine translation with neural techniques. Comput Ling 50, 9-23.\n\nBIBREF02\n\nChan M, Firth A (1977),\n\nNLP for translation: a theoretical model. In: The International corpus of English. (Eds. Raymond Gibbs, John Wortman.) Vol. 1. Cambridge: University Press, 163\u2013202.\n\nBIBREF03\n\nDenkowski B, Soderlandh A, Mees O (2013). Learning to translate with neural machine translation. In: EMNLP 2013 Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Short Papers (NAACL-HLT 2012\u20132013). (Eds. Joshua M. Cover, Yee Whye Teh.) Vol. 2 (pp. 2029\u20132030). New York: Association for Computational Linguistics.\n\nBIBREF04\n\nGanchev G, Lazaridou Z, Schuster O, S\u00f8gaard D (2013). Neural Machine Translation Revisited. In: EMNLP 2013 Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Short Papers (NAACL-HLT 2012\u20132013). (Eds. Joshua M. Cover, Yee Whye Teh.) Vol. 2 (pp. 2015\u20132020). New York: Association for Computational Linguistics.\n\nBIBREF05\n\nGu D, Toutouzas M, Dagan I (2020) Multimodal machine translation. International Workshop on Multimodal Machine Translation.\n\nBIBREF06\n\nHe M, Chen Z, Xu F, Wu S, Liu W, Huang Y (2003),\n\nA corpus extraction tool for Chinese\u2013English translation. In (Ed. Paul Buitenos.) Trans. (Vol. 2). Amsterdam: Mouton de Gruyter, 85\u2013104.\n\nBIBREF07\n\nHofst\u00e4tter L, Bansal M, Chrupa\u0142ka K (2020). What's important for translation quality",
    "1ed49a8c07ef0ac15cfa6b7decbde6604decbd5b": "\n\nContributions\nConceptualization & Writing \u2013 All authors\n\nData Preparation \u2013 All authors (see Acknowledgment section for list)\n\nMethodology \u2013 All authors\n\nResults \u2013 All authors\n\nAnalysis \u2013 All authors\n\nReferences\n\n[1] Lample, Christophe, and H\u00e9lo\u00efse Choplin, 2019. \"Neural Machine Translation with an Alternative Approach to Unsupervised Machine Translation.\"\n\nIn Proceedings of the 2019 Conference on Empirical methods in Natural Lang and Computational Linguistic Studies. Association for Computational Linguistics. New York, NY, USA.\n\n[2] Lample, Christophe, and Haiyi Zhang, 2021. \"Dual-Space Attention: A Dual-Space Margin Transformer for Universal Morphological Segmentation of Unsegmented Text.\"\n\nIn Proceedings of Interspeech. p. 583\u2013587.\n\n[3] Firat, Huseyin, and H. Ersahin, 2019. \"BERT-based Multilingual Transfer Learning in Low Resource Domains for Multimodal Machine Translation.\"\n\nIn Proceedings of the 2019 Conference on Empirical methods in Natural Lang and Computational Linguistic Studies. Association for Computational Linguistics. New York, NY, USA.\n\n[4] Bojanowski, Piotr, and others, 2017. \"Enriching Word Representations: An Approach to Multilingual Representation Learning in NLP.\"\n\nIn Transactions of the Association for Computational Linguistics, 8.\n\n[5] Gulordava, Aleksey, B\u00e9k\u00e9, Beno\u00eet, and Tzvetomira, 2017. \"A Benchmark for Multimodal Translation Models Evaluation.\"\n\nIn Proceedings of the 2017 Conference on Empirical methods in Natural Lang and Computational Linguistic Studies. Association for Computational Linguistics. New York, NY, USA.\n\n[6] Chen, Ting, Zhiqian Zu, and Yifan Zhang, 2019. \"Visual and Multimodal Adaptations to Machine Translation Using Multimodal Sequence-to-Sequence Learning.\"\n\nIn Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics. New York, NY, USA.\n\n[7] Zhou, Qiub",
    "f9aa055bf73185ba939dfb03454384810eb17ad1": "\n\nAcknowledgements\nWe thank the anonymous reviewers for helpful comments. Our code and datasets can be accessed via our repository https://git.io/fm7r.\nDaniilidis, J., & L. G. Baroni. 2015. Universal lexical resources: learning cross-lingual representations for alignment tasks. In Proceedings of the 22nd International Workshop on Theoretical and Methodological Issues in machine translation, vol. 8, pp. 7-12.\n\nG. Garcia-Neila and A. Zheglov. 2019. Language Agnostic SeNtence Representations for unsupervised language adaptation. In Proceedings of ICTAM-2019, p. 41.\n\nGrave, E., & D. I. Jurafsky. 2019. mBERT: Multilingual, multi-task BERT pre-training. In Proceedings of FindSpeech, p. 4424.\n\nJacoby, U., & K. M. Kruszewski. 2019. BIN-LM: a fast and efficient bilingual language model. Proceedings of ACL-IJCNLP2019, vol. 1, pp. 917-927.\n\nJ\u00e4ger, S., M. Rojski, T. Blunsom, C. Huang, N. A. Patwardhan, T. Stallhagen, T. Hockenmaier, W. Xu, A. Gattman, K. S. S. M. Lee, J. I. Pareja, and L. Schmidt. 2018. RoBERTa: A robustly optimized BERT pretraining approach.\n\nKiela, T., J.-M. Barra, and L. G. Baroni. 2018. Efficient English-to-French transfer learning with mBERT. In Proceedings of ACL-IJCNLP2018, pp. 1423-1434.\n\nKiela, T., I.-C. Sperber, H. S. Hsu, T. Zeman, L. Schmidt, and L. G. Baroni. BIBREF3. Transferring multilingual NLP models to low-resource languages with self-training. CoRR abs/1804.02778.\n\nKiela, T., I.-C. Sperber, and H. S. Hsu. BIBREF5. Multilingual N",
    "d571e0b0f402a3d36fb30d70cdcd2911df883bc7": "\nAcknowledgements\nWe thank the reviewers of ACL 2019 for helpful comments and the anonymous authors of the reviews for their suggestions. Special thanks to Chiyu Zhang and Yue Zhao for their technical discussion and valuable conversations. We thank Chongyang Zhao for their discussions and valuable suggestions.\n\nReferences\n\n[1] Choi, Jinhoon. Cross-lingual word sense disambiguation in distributed representations. Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. 2015.\n\n[2] Auli, Iro, et al. Cross-lingual representation transfer: multilingual pretraining for fast cross-lingual transfer. in Proceeding of the 2017 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics. 2018.\n\n[3] Wu, Jianbao, et al. Cross-lingual sentence modeling using masked multilingual language model. 2019.\n\n[4] Shazeer, Noam, et al. Xlm: multilingual language model with cross-lingual transfer capabilities. 2019.\n\n[5] Chen, Menglun, et al. Jointly learning to detect and translate language switches in sentences. 2019.\n\n[6] Liang, Yuzhi, et al. Cross-lingual zero-shot transfer with bidirectional language modeling. 2019.\n\n[7] Lample, Guillaume, et al. Cross-lingual transfer with attentional language model. 2018.\n\n[8] Chung, Euisik, et al. Efficient multilingual pre-trained language models. 2019.\n\n[9] Ramesh, Harshan, et al. Bilingual attentional mechanism for transfer learning. 2016.\n\n[10] Vulic, Danial, et al. Unsupervised learning of cross-lingual word representations from monolingual data. 2018.\n\n[11] Nieh, Zhongyu. Universal lexical sharing with contextualized word embedding. 2019.\n\n[12] Yang, Chiyu, et al. Fast-align : an efficient algorithm for word alignment. 2016.\n\n[13] Lavietes, Konstantin, et al. An empirical study of automatic word alignment methods. 2016.\n\n[14] Mika, Yohhan, et al. Fast, accurate and open source word alignment. 2015.\n",
    "ce2b921e4442a21555d65d8ce4ef7e3bde931dfc": "\nAcknowledgments\n\nThis work was supported by National Science Foundation China (NSFC) through the grant number 61876201 and the Key Research Plan Projects of MoE under contracts 2018YFC0701803 and 2019YFC0701601.\nReferences\n\n[1]\n\nDey, S., Firat, Y., & Weston, J. (2020)\n\nBERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\n\nScience, 370\n\n(6513), 1804\u20131822\n\n[2]\n\nDreyer, J., Bachrach, Y., Goyal, N., Levy, O., and Kallmeier, K. (2020)\n\nNeural Machine Translation with Cross\u2013Language Influence\n\nTransactions of the Association for Computational Linguistics (TACL),\n\n2020\n\n[3]\n\nDey, S., Firat, Y., Weston, J., Bachrach, Y., Levy, O., and Kallmeier, K.\n\n(2020)\n\nBERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\n\nScience, 370\n\n(6513), 1804\u20131822\n\n[4]\n\nDevlin, J., Chang, M. W., Lee, K., Toutanova, K., Rabinovich, V., Gurevych, I., and Jurafsky, D.\n\n(2018)\n\nBERT: Pre-training of deep bidirectional transformers for language understanding\n\nIn: International Conference on Learning Representations (ICLR),\n\n1811\u20131820\n\n[5]\n\nDias, D., Choi, J., Goyal, N., Bapna, R., and Joulin, A. (2020)\n\nZero-shot Pretraining: Learning Language Representations Without Supervised Data\n\nTransactions of the Association for Computational Linguistics (TACL),\n\n2020\n\n[6]\n\nDing, J., Liu, Z., Guo, Y., Rafferty, C., Lee, J. M. (2019)\n\nPre-trained Language Model for Learning CLS-Supervised Word Representations\n\nArxiv\n\nAbs\n\n[7]\n\nGoyal,",
    "2275b0e195cd9cb25f50c5c570da97a4cce5dca8": "\nACKNOWLEDGMENT\n\nWe would like to thank David Bamman, Sankyung Yoon, and Hongyu Geng for their helpful discussion.\n\nFunding\n\nThis research is supported by National Science Foundation under Grants No. DGE-1350221 and OAC-1745887.\nRECITALS AND ABBREVIATIONS\n\nBERT\n\nGoogle's pre-trained Unsupervised Neural Network Language Model\nBIBREF0 Ghaddar, Y., Heilman, J., & Kiela, P. (2018).\n\nBERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. arXiv.org, 1803.11070\n\nBIBREF1 Gao, Y., Liu, Y. Y., Hui, E., & Chen, L. (2019).\n\nFine-tuning for Zero-Shot Cross-Lingual Learning: A Large-Scale Study. In NAACL, pages 766\u2013774. Springer, Cham.\n\nBIBREF2 Gao, Y., Liu, Y. Y., Li, X., Hui, E., & Gao, L. (2020).\n\nMultilingual Learning Made Easy with Multilingual-BERT and Bilingual-BERT: Pre-trained Language Models for 100 Languages.\n\nCoRRa, abs/2001.11522\n\nBIBREF3 Devlin, J., Chiueh, T.-y., Lee, K., & Toutonghi, H. (2019).\n\nBERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In ICLR, pages 4171\u20134186.\n\nBIBREF4 Wang, Y., Zou, H., Li, L., Wang, H., & Xing, C. (2019).\n\nHindi Language Processing with mBERT: Cross-Lingual Transferring of Pre-trained Models for End-to-End Sequence Labelling.\n\nIn Proceedings of LREC 2019, pages 5943\u20135953.\n\nBIBREF5 Zhai, S., Li, L., Wang, H., & Xing, C. (2019).\n\nBERT Large : Deeply Supervised Language Representations for Natural Language Understanding. In NAACL, pages 4943\u20134951.",
    "37f8c034a14c7b4d0ab2e0ed1b827cc0eaa71ac6": "\nACKNOWLEDGMENTS\n\nWe thank all the annotators who contributed to the data collection and all the reviewers who helped to improve the quality of this work. This work is partially funded by the European Commission under the Horizons project MULTIRO (G.A number: 825554).\n\nNotes\n\nThe following notation will be used throughout the paper: if $P^e$ is the sentence-level translation probability from word $e$ in English to word $f$ in foreign language, we write $P_e^f$ to indicate it and $P(e\\,|\\,f)$ to indicate translation probability from $e$ in English to $f$ in foreign language.\nDISPLAY_TABLE3\nIn the next section, we give an overview of our approach. We refer to \u00a7SECREF3, \u00a7SECREF7, \u00a7SECREF11, and \u00a7SECREF18 for details.\nDISPLAY_TABLE4\nBERT stands for Bag-of-Tasks, is a multitask learning model to train language model, language model, and next sentence prediction task in the same model, and is an improvement of ElMo in terms of its word representation BIBREF26.\nDisplays: \u2022 BERT represents all the variants of the BERT pre-trained model: BERT, BERT Small, BERT Medium, and BERT Large.\n\nDISPLAY_TABLE5\nWe use BERT for its speed, simplicity, and consistency in the following experiments. BERT models utilize the same architecture (12 Transformer layers) for all transfer tasks.\nDISPLAY_TABLE6\n\nFor all the evaluation exercises we use mBERT as a baseline. Except for transferring from mBERT to foreign languages, we did not include mBERT's performance in our tables;\n\nDISPLAY_TABLE7\n\nWe do not include mBERT results since it is out of date;\n\nDisplays:\n\n\\footnote[\u2020]: mBERT has been trained without a learning rate warm-up;\nDISPLAY_TABLE8\n\nThe following notation is used throughout the paper: $P_e^e(y \\mid e, e') = \\frac{P(e' \\mid e) P(y \\mid e') \\cdot P(e' \\mid e)}$;\n\nDISPLAY_TABLE",
    "d01c51155e4719bf587d114bcd403b273c77246f": "\nAcknowledgment\nWe thank all the reviewers for their insightful comments.\nReferences\nFootnotes\n\n[\n\n](../Bibliography/ref/bibref.bib)\n\n[\n\n\n](../Bibliography/ref/bibref.bib)\n\n[\n\n](../Bibliography/ref/bibref.bib)\n\n[\n\n](../Bibliography/ref/bibref.bib)\n\n[\n](../Bibliography/ref/bibref.bib)\n\n[\n](../Bibliography/ref/bibref.bib)\n\n[\n\n](../Bibliography/ref/bibref.bib)\n\n[\n\n](../Bibliography/ref/bibref.bib)\n\n[\n](../Bibliographies/publications/Kudo2018A.pdf)\n\n[\n](../Bibliography/ref/bibref.bib)\n\n[\n\n](../Bibliographies/publications/Kudo2018An.pdf)\n\n[\n](../Abstract/BERT.pdf)\n\n[\n](../Bibliographies/publications/BERT.pdf)\n\n[\n\n](../Abstract/GPT2.pdf)\n]\n\n We take the last 100M tokens from wikipedia.\n\n[\n](../Abstract/XLNet.pdf)\n\n[\n](../Bibliographies/publications/XLNet.pdf)\n\n[\n](../Bibliographies/xlnet.pdf)\n\n[\n](../Bibliographies/xlnet-paper.pdf)\n\n[\n](../Abstarct/xlnet.pdf)\n\n[\n](../Bibliographies/XLNet.pdf)\n\n[\n](../Bibliographies/xlnet-paper.pdf)\n\n[\n](../Bibliographies/XLNet.pdf)\n\n[\n](../Bibliographies/xlnet-paper.pdf)\n\n[\n](../Bibliographies/XLNet.pdf)\n\n[\n](../Bibliographies/xlnet-paper.pdf)\n\n[\n](../Text/xlnet.pdf)\n\n[\n](../Bibliographies/xlnet-paper.pdf)\n\n[\n](../Abstract/XLNet.pdf)\n\n[\n](../Text/xlnet.pdf)\n\n[\n](../Bibli",
    "9b4dc790e4ff49562992aae4fad3a38621fadd8b": " The authors would like to thank the European Research Council for the support.\nConflict of interest statement\nThe authors declare no conflict of interest.\n\nReferences\n\n[1] B. de Klerk, E. Gers, and J. C. M. Rijsbergen, J. Am. Earth. Sci. 36, 3339\u20133348 (2017).\n\n[2] K. E. Huyen, V. M. Khosla, and M. R. Tavella, Nat. Commun. 6, 10017 (2015).\n\n[3] F. Beausoleil, L. C. P. Nelsson, G. Amato, and F. C. Pinto, Nature 546, 60\u201365 (2017).\n\n[4] J. D. Fink, W. van der Krogt, D. de Moor, R. G. M. van Weelden, and D. D. van den Berg, Ann. For. 38, 889\u2013896 (2017).\n\n[5] T. D. Mitchell, A. Iacobelli, B. G. Leakey, V. M. Khosla, S. F. Kauffman, and D. J. Skolek, Environ., Perspect. 28, 971\u2013975 (2016).. URL http://www.mdpi.com/1099-4221/28/5/871.\n\n[6] P. Gaudard, V. M. Khosla, S. Bhattacharya, S. Hui, and W. Y. Yim, Nature 537, S77\u2013S81 (2016).\n\n[7] D. A. Steen, R. A. R. Epps, I. Stankovski, D. J. Skolek, V. A. M. Vetrov, G. H. Gers, and M. S. Cramer, Nature 544, S94\u2013S99 (2017).\n\n[8] J. D. McFarlane and C. A. C. Moore, J. Am. Soc. Inform. Sci. Inform. System 51(11), 3983\u20134008 (2016).\n\n[9] T. Mikolov, K.",
    "a1dac888f63c9efaf159d9bdfde7c938636f07b1": "\nReferences\n\nAppendix\n\n## Appendix A: Proofs for Thm. 3.1 and Thm. 3.2\n\nA1 In this section, proofs of Thm. 3.1 (for the bag-of-words model) and Thm. 3.2 (for the location embedding model) are provided, which prove that the embedding quality can be improved by utilizing terms with a positive mutual information score with the features of interest.\n\nA2\n\nA bag-of-words model for geographic locations can indeed be obtained as follows. Let INLINEFORM1 and INLINEFORM2 be vectors to represent a set of locations and a set of tags, respectively. Since the number of tags near any location in INLINEFORM2 is usually small, it is impractical to consider all tags near any location in INLINEFORM2 in the inner summation. Instead of considering all tags, we can select the most informative terms based on a term selection procedure, where INLINEFORM2 is first transformed into a probability space via: INLINEFORM3\n\nwhere INLINEFORM8 is the number of different tags near INLINEFORM5 from INLINEFORM6, and INLINEFORM9 is some given threshold (e.g. 100). INLINEFORM-tags will be used to represent the locations. We now make the following assumption: INLINEFORM9<INFOLINEARITY-tags, which is also used in BIBRF7. A location INLINEFORM3 will then be represented as the probability that a photo with tag INLINEFORM4 was taken near location INLINEFORM2 multiplied by the probability that tag INLINEFORM9 was present in all photos of user INLINEFORM0.\n\nA3\n\nThe derivation of Equation (2) is similar, except that we now substitute INLINEFORM4 by the number of photos by user INLINEFORM0 with tag INLINEFORM9 near location INLINEFORM2 and INLINEFORM10 by the number of different tags near INLINEFORM5 from INLINEFORM6. The main difference is that we only consider terms for which a probability greater than INLINEFORMIN occurs in the resulting space: INLINEFORM13\n\nwhere\n\nand INLINEFORM19 reflects the impact of context. We will now consider the case where INLINE4 does not occur in INLINEFORM3. In this case, rather than simply choosing the most frequent",
    "1e4dbfc556cf237accb8b370de2f164fa723687b": "\nExperiment Results on KP20k Full Data and KP20k Tags\nThe primary goal of keyphrase generation is to predict high quality keyphrases given a source text. We use F INLINEFORM1 @ INLINEFORM2 as an evaluation metric. We also report F INLINEFORM0 @ INLINEFORM1 to measure model's ability to effectively utilize the source information.\n\nSee Table TABREF50, Table TABREF51, Table TABREF52, and Table TABREF53.\nIn all of our proposed models, F INLINEFORM1 @ INLINEFORM2 metric is superior to previously reported results BIBREF0, BIBREF3 and BIBREF0 in the literature.\nStackEx dataset is introduced to evaluate model's ability to distill target semantics from source text, and thus StackEx evaluation does not favor recall-oriented models. It is worth noting that our proposed models tend to perform poorly on StackEx from training to test. We thus propose new metrics to measure StackEx prediction quality.\nThe proposed methods can be used to generate a variable number  of keyphrases; in this exercise we report results for generating only 10 phrases. We further report mean token length from model predictions to measure model's ability to distill target semantics.\nExperiment Results on KP20k Absent-Keyphrase Generation\nSince StackEx only contains questions with titles, StackEx questions often contain a small number of keyphrases. In Section SECREF28, we introduced a variable number  of keyphrases generation model to evaluate models' abilities to generate a variable number of phrases. We use F INLINEFORM0 @ INLINEFORM2 to measure number sensitivity. We also report a similar metric, F INLINEFORM4 @ 10, to measure the model's ability to distill target semantic meanings from source texts.\n\nSee Table TABREF49, Table TABREF50, Table TABREF51, and Table TABREF52.\nTable TABREF49. Performance on StackEx Absent-Keyphrase Generation for INLINEFORM0 and INLINEFORM1\n\nOur model is able to outperform CopyRNN by large margins in generating absent keyphrases on StackEx.\n\nExperiment Results on StackEx Present-Keyphrase Generation\nFor StackEx present-keyphrase generation we follow existing studies that evaluate models using exhaustive decoding. However, our model is trained with larger-",
    "fff5c24dca92bc7d5435a2600e6764f039551787": "\nExample Question Generation\nSee Table TABREF50.\n\nExperiment Results on KP20k with Semantic Coverage\nWe conduct an additional experiment to study the performance of INLINEFORM0 in the scientific publication setting with semantic coverage module (see Section SECREF3 ), where semantic representations of generated phrases are extracted by target encoder and used to guide decoding. All the results are in the main paper.\nExperiment Results on StackEx with Additional Tags\nWe conduct an additional experiment to study the transferability of INLINEFORM0 and INLINEFORM1 to Stack Exchange, as shown in Table TABREF53.\nWe note that this experiment only showcases a few examples from StackExchange, which is the primary focus of our study.\nExperiment Results on Extractive TASK1\nWe conduct an experiment by performing a simple linear regression on word2vec-based embedding to measure extraction accuracy on TASK1 dataset (see Section SECREF8 ), since INLINEFORM0 is originally trained on TASK1. We report the results in Section SECREF10.\nExperiments on StackLite Task\nWe consider it a positive sign that our model transfers well to a tag recommendation task similar to StackEx, and thus this is also shown in the main paper. We leave out 3,000 data examples as our development set and use them to identify optimal checkpoints for testing.\nModel Visualization\nExperiment Results on KP20k with t-SNE Clustering\nWe provide detailed visualization on our model's self-terminating decoding output with t-SNE clustering.\n\nAppendix A: Background on Keyphrase Extraction\nKeyphrase extraction is often formulated in a two-stage process. The first stage aims to extract phrases from the given source text INLINEFORM0, and the second stage tries to prioritize the retrieved phrases by ranking them in some way. We review the most well-known methods adopted in past studies:\nA bagged decision tree (BDT) is created by voting on the extracted phrase. We employ scikit-learn v0.19.1 and use a maximum tree depth of 5.\nA random forest (rf) is created by an ensemble of decision trees. We use random_state=42_2015_in_r2016_out_r2017_ in sklearn. Randomly sampled at 50%.\nWe select a threshold to filter candidates. We use the highest ranked",
    "b2ecfd5480a2a4be98730e2d646dfb84daedab17": " We see our model can generate variable number of target phrases conditioned on this example, and generates phrases that are semantically close to the document while avoiding duplication.\nAblation Study on Semantic Coverage\nFollowing an ablation study for orthogonal regularization, we further conduct an ablation study on semantic coverage mechanism. From the result on StackEx (Table TABREF42 ), we observe that it helps increase recall and achieves good quality despite its negative effect to loss on Krapivin.\nExperiment Results on StackEx Present Keyphrase Generation\nSince it is notoriously hard to summarize a question, we report present keyphrase generation scores on StackEx questions in Table TABREF42.\nWe find that all the proposed models perform equally well since this task has relatively high difficulty while most existing models are hard to generalize on StackEx.\nExperiment Results on StackEx Absent Keyphrase Generation\n\nSince StackEx is designed as a tag recommended task, for each data point, we take all tagged words in the question and use them as source to construct target sequence. However, existing studies BIBREF0, BIBREF1, BIBREF2 choose the target sequence as the set of all annotated tags. We believe such approach may limit the model's ability to distinguish important information from the question text.\n\nWe propose a new setting, where the original target sequence is kept, but new target tags are introduced. This is equivalent to StackLite tag recommendation task in Kaggle. Here, we only report results from our proposed models in Table TABREF45 as existing models such as CopyRNN BIBREF0 and RNN* in BIBREF7 either could not be extended to StackEx question sets or are too computationally expensive.\nWe find no significant difference in model's performance: INLINEFORM0 slightly performs better than INLINEFORM1 even though we use the same training strategy. This suggests it can be hard to improve absent keyphrase generation task just by optimizing model capacity. One possibility is that as StackX becomes more complex for absent keyphrase, orthogonal regularization may gain more importance.\nExperiment Results on StackEx Present Keyphrase Generation\n\nSince StackEx is a relatively easy question generation task, INLINEFORM0 can only generate 1.47 keyphrases on average. A likely reason is that many of StackX questions do not have enough information or background knowledge to enable the decoder to make meaningful prediction. A likely future work is to",
    "a3efe43a72b76b8f5e5111b54393d00e6a5c97ab": "\n\nAcknowledgements\nThis work was supported by Google Inc. (project name: Project Vary)\n\nReferences\n\n[BIGO] D. S. Karamanolis, S. L. H. Zilles, C. I. Gupta, A. M. Blackwell, T. Chabus, and S. Dieng, \"A model for generation of multiple phrases from long-range context on sequence-to-sequence models\", 2014.\n\n[BIBREF3] M. Jiao, S. L. H. Zilles, Y. Zhao, S. Dieng, and S. L. McCarthy, \"Text2text: Sequence-to-sequence learning for sentence generation,\" in ICML Workshop on Sequence to Sequence Learning for Sequence Generation, 2016.\n\n[BIBREF32] P. Radford, S. Beeson, R. Luan, and L. Zettlemoyer, \"Unifying neural networks and the renaissance of topic models\", 2015.\n\n[BIBREF37] D. E. Vinyalsky, D. Sutskever, and A. Krizhevsky, \"A practical algorithm for sequence-to-sequence learning\", 2016.\n\n[BIBREF2] M. Zhang, F. Lu, B. Zhao, and J. Song, \"Text generation through sequence-to-sequence learning of attentional nlm architectures\", in Nips, 2017.\n\n[BIBREF36] M. L. Ruder, A. F. Pereira, R. Collins, S. Bengio, and J. Dean, \"On the difficult problem of optimizing neural language models\", 2015.\n\n[BIBREF35] K. S. Lee and K. Sokulski, \"Visualizing High-Density Latent Spaces Using t-SNE\", in Advances in Neural Information Processing Systems 1: Annual Conference on Neural Information Processing Systems, 2015.\n\n[BIBREF3] M. Jiao, S. L. H. Zilles, M. V. Kondrashov, M. D. Chen, and S. L. McCarthy, \"Text2text: Sequence-to-sequence learning for sentence generation,\" in ICML, 2016.\n\n[BIBREF29] J. Ding, T. Yin, and Z. D",
    "f1e90a553a4185a4b0299bd179f4f156df798bce": "\nDatasets Used in this Study\nIn this section, we report the ground truth keyphrases for nine scientific publication datasets. We provide average target keyphrase numbers for scientific publication datasets in Table TABREF50.\nFor keyphrase generation, we provide training data along with the gold standard for absent keyphrases in Table TABREF52. We provide keyphrase annotations from stack posts on StackExchange in Table TABREF53 to construct absent keyphrases.\n\nExample Input Sequences\nTable TABREF51 includes two scientific publication input example texts with gold standard targets. An example from StackEx is shown in Table TABREF52 .\n\nAppendix\n\n# A B C D E F G H I J K L M N O P R S T U V W\n\n# 1 2 3 4 5 6 7\n\n# 2 4 4 7 4 5 8 9\n\n# 7 5 8 5\n\n# 5 1 2 4\n\n# 5 5 5 9 4\n\n# 2 3 5 6 8 5 2 1 6 7 8 7\n\n# 8 -9 -2 3 4 2 5 4 4 1 1\n\n# 3 2\n\n# -2 3 0 1\n\n# 1 2 1 3 2\n\n# 5 2 -8 -5 -1 2 4 3 8 6 5 1 3\n\n# 8 -6 2 8\n\n# 1 7 2 -7 9 4 7 7\n\n# -8 9 3 5\n\n# 3 -5 4\n\n# -1 -8 7 7 11 6 8\n\n# -2 -8 5 2\n\n# -5 2 -9 -3 6 2 2 8 1 -4\n\n# 5 1 0 4 -8 4\n\n# -2 -6 3\n\n# -4 5\n\n# 5 3\n\n# -4 3 6 1 -8 4 0 5 0 -8\n\n# 1 4 5\n\n# 5 8 4\n\n# 5 -3 -3 1 5 2 -5 2 1\n\n# -4 4 5 5 -1 0 3 9 -6 3 11 1 0 3\n\n# 5 -5 -6 -7 5 2 8\n\n# 5 2 -1 1 3 5 5 -9 1 6 3 9 9 1 5 3\n\n# 4 8 -4 -2\n\n# 1 2 3 2 6 7\n\n# 4 6 4 11 0",
    "19b7312cfdddb02c3d4eaa40301a67143a72a35a": "\nList of Acronyms and Abbreviation\n\nAlberti, M.\n\nBag of Words\n\nBIBREF\n\nBIBREF\n\nBIRAFX\n\nBillion-Image Remote Aerial Frequency Cross-Correlation\n\nBLEU\n\nBLEU\n\nBM25F1\n\nBM25F1\n\nBoosting\n\nCNN\n\nCNN\n\nCopyRNN\n\nCopula-RNN\n\nCVF\n\nCorrRNN\n\nGan, H. W.\n\nGloVe\n\nGLVW\n\nGAN\n\nGradient-weighted Cell-fringe\n\nGRU\n\nHopfield Networks\n\nHTK\n\nHumans Tag Kettenis\n\nINLP\n\nIntentions Network Long-Short Pair Learning\n\nIOB\n\nInternet Over Broad Band\n\nJaccard\n\nKIUM\n\nKeyphrase-and-Inference-based Unsupervised Model\n\nKL\n\nKL\n\nKSN\n\nKeyphrase Summarizer Network\n\nLDA\n\nLDA\n\nLayer Normalization\n\nLEO\n\nLi, B., Ogretmeno\u011dlu, J., & Riloff, J.\n\nLFCA\n\nLow-rank Factor Analysis\n\nLexica\n\nLSN\n\nLog-Boltzmann Machine\n\nLSR\n\nMLE\n\nMaximum Likelihood Estimation\n\nLSTM\n\nRNNLM\n\nSelf-attention\n\nSemEval\n\nSemi-Supervised\n\nSNR\n\nSoftmax\n\nSSM\n\nSP\n\nStochastic search method\n\nStacking\n\nTAN\n\nTang, Y., Liang, X., & Wu, Q.\n\nTPNet\n\nTranslation Pair Network\n\nTransformer\n\nYellow Brick Road\n\nKeyword Extraction and Generation\n\nWe briefly review the related work on keyphrase extraction and generation to provide readers with the background for the proposed work. We mainly concentrate on neural models, focusing on supervised and unsupervised approaches.\n\nExtractive Keyphrase Extraction\nEarly approaches to keyphrase extraction are often handcrafted. For instance, BIBREF4 and BIBREF5 respectively propose lexical features and hybrid information criteria models for candidate list generation. BIBREF9, B",
    "22744c3bc68f120669fc69490f8e539b09e34b94": "\n\n\\ References\n\n\n#  \nAlso by E.C.R. Lorac\n\nThe Bookman's Tale\n\nThe Rite of Spring\n\nTHE   \nSPLASHSON SHUFFLE\n\nA THOMAS DUNNE BOOK FOR MINOTAUR BOOKS  \nNEW YORK\nThe Splashson Shuffle was set in Monotype Baskerville Std and Linotype Plantin using the Adobe Digital Edition.  \nThis is a work of fiction. Names, characters, places, and incidents either are the product of  \nthe author's imagination or are used fictitiously. Any resemblance to actual persons,  \nliving or dead, events, or locales is entirely coincidental.\n\nCopyright \u00a9 2010 by E.C.R. Lorac\n\nAll rights reserved.  \nPublished in the United States by The Overlook Press, Peter Mayer Publishers, Inc., New York.\n\nThis book may not be reproduced  \nin whole or part, by mimeograph or any other means,  \nincluding Xerography, or by any information storage and retrieval system,  \nwithout permission in writing from the publisher.\n\nFor information, address:  \nThe Overlook Press, Peter Mayer Publishers, Inc.,  \n145 Payne Avenue, New York, N.Y. 10014\n\n#  \nFor my mother  \nCynthia A. Lee\n\n#  \nTo Michael and   \nBrendan\n\n#  \nContents\n\nEpigraph\n\nPrologue: Splashson Park  \n(a tale from the dark days)  \nChapter 1  \nChapter 2  \nChapter 3  \nChapter 4  \nChapter 5  \nChapter 6  \nChapter 7  \nChapter 8  \nChapter 9  \nChapter 10  \nChapter 11  \nChapter 12  \nChapter 13  \nChapter 14  \nChapter 15  \nChapter 16  \nChapter 17  \nChapter 18  \nChapter 19  \nChapter 20  \nChapter 21  \nChapter 22  \nChapter 23  \nChapter 24  \nChapter 25  \nChapter 26  \nChapter 27  \nChapter 28  \nChapter 29  \nChapter 30  \nChapter 31  \nChapter 32  \nChapter 33  \nChapter 34  \nChapter 35  \nChapter 36  \nChapter 37  \nChapter 38  \nChapter 39  \nChapter",
    "dcea88698949da4a1bd00277c06df06c33f6a5ff": "\n\nSuggestions for future work include, more extensive hyperparameter optimization across a larger set of random seeds, and further investigation into ways to further quantify the extent to which models achieve linguistic generalization.\n\nReferences\nAharoni, A., Kornblith, G., & Levy, A. (2004). Statistical Learning Theory for Artificial Neural Networks. Foundations and Trends in Machine Learning, 1(3\u20134), 149-269.\n\nBengio, S., Ponce, G., & Fergus, D. (2012). Sequence to sequence learning with neural networks for computer vision and natural language processing. In Computer Vision\u2013ECCV 2012/2012, 1077\u20131087.\n\nBengio, S., et al. (2018). Language models are unsupervised multitask learners. In 34th Conference of the International Speech Communication Association.\n\nBIBREF1.\n\nBIBREF10.\n\nBIBREF11.\n\nBIBREF12.\n\nBIBREF13.\n\nBIBREF14.\n\nBIBREF15.\n\nBIBREF16.\n\nBIBREF17.\n\nBIBREF18.\n\nBIBREF19.\n\nBIBREF20.\n\nBIBREF21.\n\nBIBREF22.\n\nBIBREF23.\n\nBIBREF24.\n\nBIBREF25.\n\nBIBREF26.\n\nMnih, T., et al. (2014). Sequence to sequence learning with neural recurrent netowrks. In Advances in Neural Information Processing Systems.\n\nPalatnik, B. & Cohen, Y. (2015). Data-driven and compositional modeling for complex domains, Proceedings of the 35th Annual Conference of the Cognitive Science Society (pp. 4169-4177).\n\nPeyre, T., Rao, P., & Littleton-Smith, D. (2007). Computational Complexity of Neural Sequence to Sequence Systems: What is generalizations for? In Proceedings of the 33rd Annual Conference of the Cognitive Science Society.\n\nRanzato, M., Fonollola, M., & Chorowski, M. (1999). Universal Grammar. International Journal of Language, 7-31.\n\nS\u00f8gaard, M., Aizman, A., & Goldberg",
    "d7b60abb0091246e29d1a9c28467de598e090c20": "\nWhile our study primarily focuses on political discourse, there is clearly a vast majority of discourse online that occurs outside the scope of political debates. As a next step, we seek to adapt our offensive speech classifier to measure incivility in a broader array of discourse beyond political discussions. Another interesting avenue of future investigation consists in examining whether our offensive speech model can be used to identify the underlying sentiment associated with incivility. That is, can we use our model to uncover the types of sentiments associated with offensive posts, without explicit labels of offensiveness? Finally, we seek to explore the effects of political campaigns on incivility by developing models that can be used to quantify political incivility within the general election campaign.\nAcknowledgements\nThanks to Alessandro Acquisti, Rishab Agarwal, Tom Adkins, Richard Berinsky, Matthew Dittman, and Anu Madan for feedback, help, and discussions. The views expressed are entirely my own.\nBIBLIOTECHRE\n\nBIBREF0 Madsen, P. W., M. N. Jaworski, and J. M. Druckman, 2017. \"A Sociological Perspective on Political Incivility,\" Political Communication, 34:3, pp. 297 \u2013 329.\n\nBIBREF1 Jost, J., J. A. McCright, and C. A. Tausczik, 2016. \"Why So Offensive? Comparing Incivility Between Candidates and Issues,\" Journal of Conflict Resolution, 62:4, pp. 863 \u2013 881.\n\nBIBREF2 Kramer, J. J., and B. T. Stewart, 2017. \"Donald Trump and the Politics of Incivility,\" International Studies Quarterly, 61:3, pp. 481 \u2013 493.\n\nBIBREF3 Hogg, M. and M. Staub, 2006. \"Public Civility and the Maintenance of Democracy,\" American Political Science Review, 101:3, pp. 749 \u2013 770.\n\nBIBREF4 APSA, 2012. \"What Americans Think About Our Politics: Public Opinion in the 2014 Midterm Elections.\" American Political Science Association.\n\nBIBREF5 Sap, M. and I. J. Yeltekin, 2016. \"Sociocultural Norms of Incivility in Online Political Discussions,\" Journal of Communication",
    "bdf93053b1b9b0a21f77ed370cf4d5a10df70e3e": "\n\nacknowledgments\n\nThis material is based upon work supported in part by the National Science Foundation Grant No. 1450378 and the Alfred P. Sloan Foundation. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation.\n\nREFERENCES\n\nBIBREF0BIBREF1Kosciuch, S., & Gastil, L. (2017). Incivility in Twitter: Measuring, Exploring, and Analyzing Political Violence. In ICWSM 2017, Proceedings of the 17th International Conference on the Web and Social Media, July 2017.\n\nBIBREF2Kosciuch, S., & Gastil, L. (2015). Incivility and Attention in the 2016 U.S. Presidential Election. In CHI 2017, Proceedings of the 2017 ACM SIGCHI Conference on Human Factors in Computing Systems, May 2017.\n\nBIBREF3Trope, Y. (2004). The Civility Code. The Chronicle of Higher Education, June 25.\n\nBIBREF4Iyengar, S., Druckman, G., & Kinder, D. (2018). Civility. In ICWSM 2018, Proceedings of the 18th International Conference on the Web and Social Media, July 2018.\n\nBIBREF5O'Connor, D., Lin, Z., Wang, D. (2017). The Swear Code: Language and Politics on Reddit. In ICWSM 2017, Proceedings of the 17th International Conference on the Web and Social Media, July 2017.\n\nBIBREF6Farkas, D. (2017). The Informal Side of Civil Society. In ICWSM 2016: Proceedings of the 15th International Conference on the Web and Social Media, July 2016.\n\nBIBREF7Kosciuch, S., Shankar, S., & Gastil, L. (2016). A hate speech dataset annotated by crowd workers. In CHI 2016, Proceedings of the 40th Annual CHI Conference on Human Factors in Computing Systems, May 2016.\n\nBIBREF8Kosciuch, S., Shankar, S., & Gastil, L. (2017). Hateful vocab. In ICWSM 2016: Proceedings of the 15th International",
    "5a6926de13a8cc25ce687c22741ba97a6e63d4ee": "\nAcknowledgements\nWe would like to thank Michael H. Bernstein, Yehuza Rupani, John Bauer, Joseph L. Palmore, Andrew Zaldivar, and the anonymous voters and commenters who took part in helping to build our dataset of public conversations. Additionally, we thank John Bauer for feedback on an earlier version of this work. Finally, we thank Robert C. Berner and the Center for Politics and Governance at the School of Public and International Affairs, Rutgers University. This work was partially supported by the National Science Foundation, grant number 1744821.\n\nNotes\n\nInline footnote references\n\n[1]\n\nShah, P., et al. (2014). Incivility to Political Opponents Is a Social Disease and a Security Threat for Our Democracy. Journal of Peace Research. 51, pp. 5-13.\n\n[2]\n\nStroop, W. (1935). Studies of Intergroup Conflict. Psychology Review. 12(4), pp. 206-220.\n\n[3]\n\nBerger, P. J., et al. (2018). Public opinion and incivility on Twitter: A large-scale analysis of Twitter conversation preceding and during the 2016 presidential election. Journal of Communication. 68(6), pp. 1549-1572.\n\nBiblio-reference\n\nBerger, P. J., et al. (2018). Public opinion and incivility on Twitter: A large-scale analysis of Twitter conversation preceding and during the 2016 presidential election. Journal of Communication. 68(6), pp. 1549-1572.\n\nInline biblography references\n\n[BIBREF0]\n\nSchuman-Oliver, D., et al. (2013). Uncivil Discourse in Contemporary American Politics. Political Psychology, 44(3), pp. 441-463.\n\n[BIBREF1]\n\nBauer, J., Palmore, J. L., & Tversky, A. (1992). Uncivil discourse between political opponents: a study of election-day debate. Political Psychology, 13(2), pp. 189-210.\n\n[BIBREF2]\n\nPalmore, J. L., et al. (2018). Uncivil discourse during the 2016 presidential campaign. International Journal of Public Opinion Research, 29(3), pp. 411-431",
    "dcc1115aeaf87118736e86f3e3eb85bf5541281c": "\nAcknowledgments\nThis research was made possible thanks to support provided by the following agencies: NSF (DMS-1518491), NSF (DMS-1257853), NSF (DMS-1207597), Sloan (1826), Google Faculty Research Award, the NSF Office of the Assistant Director for Social and Economic Sciences, and the Sloan Research Fellowship.\n\nBibliographical Notes\n\n[BIBREF0] Tae-Kyong Shin & Christopher P. Uhlmann \u2013 2013 \u2013 An Empirical Analysis of Confrontations in Political Discussions: The Role of Offensive Language in an Electoral Campaign\n\n[BIBREF1] Christopher P. Uhlmann \u2013 2012 \u2013 The Talking Politics Project\n\n[BIBREF2] Adam L. Tayse, John Sides, David O. Sears, John C. Hibbing Jr. \u2013 2017 \u2013 The Increasing Use of Incivility in Election Campaigns: Evidence from Three American Elections\n\n[BIBREF3] C. Daniel Fox & John C. Hibbing \u2013 2014 \u2013 Are Political Leaders Increasingly Unpolited: Evidence from Survey and Content Analyses\n\n[BIBREF4] Christopher P. Uhlmann \u2013 2016 \u2013 The Impact of Offensive Rhetoric and Swearing on Political Interest, Knowledge Gaps, and Partisan Bias\n\n[BIBREF5] Tae-Kyong Shin & Christopher P. Uhlmann \u2013 2015 \u2013 Civility in the Age of Trump: A Study of Online Incivility during a Major U.S. Political Campaign\n\n[BIBREF6] Joseph O. Baker & Steven T. Paik \u2013 2008 \u2013 The Political Culture of Online Communities: A Study of Discussion in Political Forums, Blogging Networks, and Social News Sites\n\n[BIBREF7] Bindu K. Sreenivasan et al. \u2013 2009: Learning to Detect and Classify Hate Speech Using CrowdFlower, D. K. Williams et al. \u2013 2009: Toxicity Classification with Hatebase, M. E., Chen, P., Lee, D., & Hovy, E. \u2013 2013: Hate Speech in Twitter Revisited, B. K. Sreenivasan, S. Williams, P. Chummun, D. Garg, M. E., Lee, D., & Hovy",
    "c74185bced810449c5f438f11ed6a578d1e359b4": "\nA Model for Conversational Forecasting of Derailment\nSuleyman Sezer1,2, James Bradbury1 and Joseph N. Leiden3,4\n1University of California, Santa Barbara (UCSB), 2Stanford University, 3University of Massachusetts Amherst; 4Twitter\nConversations are an integral part of any human interaction and are the basis of many online social dynamics BIBREF66, e.g., BIBREF32, BIBREF67, BIBREF68. For this reason, the behavior of online conversations has been a topic of study for researchers in cognitive science and social sciences BIBREF2, BIBREF1, BIBREF69\u2013BIBREF70. This line of research has been extended to conversations between humans and artificial agents, particularly in the context of computational social choice theory BIBREF71, BIBREF73, BIBREF74, BIBREF75. In contrast to these lines of research, where the outcome of a conversation is known only after it concludes [BIBREF9], the problem of foreseeing the future development of conversations by analyzing earlier exchanges has received more limited attention [BIBREF21, BIBREF7]. As a consequence, prior research has been unable to address the full range of conversational situations such as the ones displayed in Figure BIBREF1.\nIn this work, we introduce a neural architecture that learns to forecast and model the development of conversations. Crucially, unlike prior work, this model does not extract conversation-relevant features (e.g., statistical measures BIBREF76), which can be error-prone when applied after-the-fact; rather, it is trained to directly model and extrapolate the conversational dynamics. As a result, our architecture is capable of forecasting the future course of the chat conversation, rather than merely being able to classify if the chat has deviated from its initial behavior. We evaluate our approach by measuring its accuracy in predicting the future in 1,670 conversations that occur on a popular open-source discussion forum, based on which we make improvements in real time. A central feature of our model is that it does not rely on any hand-crafted features (BIBREF7) for encoding the data. We argue that the model is able to perform well on this task because it is able to reason over the entire conversation, rather than just a fixed window as previously",
    "88e5d37617e14d6976cc602a168332fc23644f19": "\n[1] T. L. Austin, R. L. Rusk, and N. M. Black (1962). Ways and means of words. Cambridge: Harvard University Press.\n[2] B. Frey, E. Tse, J. D. Kleinberg, and B. K. Pasternack (2014). Can Computational Modeling Alleviate the Burden on Content Moderators? http://aclweb.org/anthology/P14-1102.pdf\n[3] A. Bender, C. Calvanese, C. A. R. Re, E. B. Stenner (2016). A longitudinal study of hate speech in YouTube comments on news videos. In Proceedings of EMNLP, pages 779-784.\n[4] R. L. Rusk, J. Stubart, & N. M. Black (1979). Sarcasm: Some Observations and Tests. Discourse Processes, 3(2), 125\u2013145.\n[5] G. O. Chabbi, J. Lesnick, J. D. Kleinberg (2019). Pretext. Discourse Processes.\n[6] D. S. A. Smith (2003). The effect of sarcasm on interpersonal communication. Computational Linguistics, 29(4), 461\u2013507.\n[7] P. Bucks and A. Hepplinger (1980). What are you angry about? a semantic study of sarcastic speech act answers. Linguistics and Philosophy, 5(2), 223\u2013282.\n[8] K. J. Downey, N. Sheth, H. T. Morimoto, H. Liu, A. Y. Choi, E. Y. Liu, X. Y. Liu (2017). Convolutional Sequence-to-Sequence Predictive Coding: A Neural Tensor Network for Machine Translation. In Advances in Neural Information Processing Systems, I.\n\n[9] J. P. Fincher, K. Blaschko, P. M. Pfeffer, A. M. Sokol, J. E. P. Son (2014). On the Toxicity of Social Media Users. In Proceedings of the 23rd ACM SIGCHI Conference on Human Factors in Computing Systems (CHI '14).\n[10] P. P. F",
    "45f7c03a686b68179cadb1413c5f3c1d373328bd": "\nReferences\n\n[1] Ding, W., Zhai, Z., Li, X., Zhang, C., Wang, J., Qin, G., Yao, W., and Hu, Z. \"Diagnostic Guidelines for 2019 Novel Coronavirus Pneumonia,\" Guidelines for Clinical Management of Patients with 2019 Novel Coronavirus Pneumonia, Chinese Journal of Pathology, vol 45 No. 5., 2020, [Online] https://www.nature.com/articles/s415012699902866.\n\n[2] Ding, W. and Zhu, Y. \"COVID-19 Study of Pneumonia with CT Features of Thickened and Consolidated Lungs,\" Radiology, vol. 296, Iss. 1, pp. 159-162, Jun 2020, [Online] https://academic.oup.com/radiology/advance-article/doi/10.1055/a-1808-5566/\n\n[3] Khandelwal, V., Srikaran, S., Ramamurthy, K., Sanyal, P.T. \"Extracting Sentences Containing Radiological Findings,\" In ICDM-PKDD International Conference on Data Mining, 2020.\n\n[4] Ma, M., Xie, Y., Zhai, Z., Ma, P., Zhang, C., Wang, J., and Hu, Z. \"CORD-19: A Comprehensive Dataset for the Analysis of Radiological Findings of Novel Coronavirus Disease 2019 (COVID-19),\" Nature, vol. 579, pp. 151-157, 2020, [Online] https://natureindex.nature.com/articles/s415012699902866.\n\n[5] Ma, M., Zhang, C., Zhai, Z., Wang, J., Wang, J., Lu, Z., Cheng, M., and Hu, Z. \"Deep Learning for Automatic Discovery of CT-Assessed Radiological Findings for Pneumonia,\" In Radiologists, vol. 29, p. 2460, 2019, [Online] j.srrad.org/article/2954/abs/29/12/2459/abs/29/html\n\n[6] Sengul, C., Cenkumus, H., Kuzum, E., and Gokmen, T.",
    "a2015f02dfb376bf9b218d1c897018f4e70424d7": " Medical experts can efficiently use the information and make important decisions in the current situation.\nCOVID-19 is a new infectious disease, which has affected over one million individuals worldwide. Early knowledge acquisition is key for effective diagnosis and treatment of it. Radiology imaging, such as computed tomography (CT), is one of the key sources of medical knowledge accumulation regarding it. Therefore, it is very important to understand the correlation between radiological findings and this disease. Our method automatically collects a large corpus of literature and extracts sentences from it about radiological findings and generates a list of noun phrases containing relevant information. There are still many challenges to improving this method, such as the precision of training sentences, the consistency of training sentences, and the limitation of the current BERT backbone which makes it hard to capture complicated correlations. We believe that our method can be extended to other tasks such as semantic text classification which can help advance medicine.\n[1]..., Chen, L., Song, W., Zhang, S., Shen, Y., Zhang, G., Zhang, J., Zhan, Y., Xu, X.,..., Chen, T., Jiang, W., Chen, J....\n(2020). A large corpus of papers on radiology of Covid-19: The Covid19 Open Research Dataset.\n\n[2].., Chen, T., Yang, D., Wang, M., Zhou, X., Zou, Y., Li, L., Yu, M., Zhai, N., Zhou, D....\n(2020). Deep learning for clinical radiology text extraction: A comprehensive survey.\n\n[3].., Devlin, J., Chang, E., Lee, K., Toutanova, Z.,...\n(2019). BERT: Pre-training of deep bidirectional transformers for language understanding.\n\n[4].., Liu, D., Li, X., Lin, H.,..., Liang, J., Yang, W., Du, Q.,..., Li, X.,..., Geng, S., Yang, R.,...\n(2020). COVID-19: A preprint for the biological research community.\n\n[5].., Li, X., Liang, J., Yang, W., Lin, H.,..., G",
    "f697d00a82750b14376fe20a5a2b249e98bebe9b": " The results of paired t-tests prove that all the model performances have a confidence interval greater than 99.9%. We also calculate the confidence intervals of the improvement from each contribution by the model: Table TABREF59 for local representation, Table TABREF60 for distant representation and Table TABREF61 for CVT. From this data, we can conclude that there is a significant change in model performance from each contribution.\nComparison with the baseline models using pretrained word vectors\nAlthough we did not integrate word vectors into our model, we chose one model that used pre-trained word vectors for comparison and compared its results and our results. The model that used pre-trained word vectors was adopted from T-BRNN-pre, which achieved the highest score on IWSLT as discussed in Section SECREF5.\nTable TABREF62 summarizes the results on the Orchid dataset, and Table TABREF63 summarizes the results on the UGWC dataset. The results of paired t-tests for punctuation restoration task were not calculated because T-BRNN-pre uses pre-trained word vectors, which is excluded in the sentence segmentation task.\n\nDiscussion\nBecause we integrate three modules in our model, we compare different sets of models by changing the order of modules while keeping the same input. This analysis is shown in Fig. in Appendix A.1 in the supplementary file. Each module, which is a separate structure, includes various hyperparameters; thus, for each model, we use the average of all hyperparameters after the model was fine-tuned on each dataset, as shown in Table A1. DISPLAYFORM0.\nWe found that the sentence boundary and the local representation are the most impactful modules; therefore, the order of modules in the Thai sentence segmentation task has a minimal impact, as shown in Fig. in Appendix A1. DISPLAYFORM0\n\nIn the case of English punctuation restoration as shown in Fig. in Appendix A2.1 in the supplementary file, all three modules have equivalent performances because the order of modules has little influence. DISPLAYFORM0\n\nIn addition, we found that the order of modules in both tasks is sensitive to the number of n-grams used in the local representation; therefore, we conducted a separate experiment to observe the effect of n-grams on the overall models. Consequently, the F1 scores were calculated for four set of orders involving Bi-LSTM-CRF (without n",
    "e0e379e546f1da9da874a2e90c79b41c60feb817": " A paired t-test is conducted to explore the difference in the cross-validation scores obtained from the model with local representation (Incline (h)) to the model without local representation (Incline (g)) for each fold (n=10). The p-value shows that the F1 score of the local representation model ( Incline (h)) for each fold is significantly better than the F1 score of the model without local representation ( Incline (g)).\n\nComparison of Bi-LSTM-CRF and Bi-LSTM-CRF with local representation\nPrevious works have focused on comparing traditional models and deep learning models in many studies, including machine translation and Named Entity Recognition. Similarly, we compare the Bi-LSTM-CRF and Bi-LSTM-CRF with local representation in this experiment to decide the best model architecture to use. The results in Table TABREF59 show that the Bi-LSTM-CRF with local representation (INLINEFORM0 (row 2)) outperforms the Bi-LSTM-CRF without local representation (row 1)) on both Thai sentence segmentation tasks.\nComparison of Bi-LSTM-CRF with local representation and Bi-LSTM-CRF with local and distant representation\nAs discussed in Section SECREF3, we aim to determine which type of module can improve the representation most in our model. Hence, the Bi-LSTM-CRF with local representation (INLINEFORM0 (row 2)) is utilized to compare with both Bi-LSTM-CRF (INLINEFORM0 (row 1)) and Bi-LSTM-CRF with local and distant representation (INLINEFORM0 (row 3)). The results in Table TABREF60 show that the addition of distant representation is better than the local representation or the combination of both the local and distant representations on both tasks.\n\nComparison of Bi-LSTM-CRF with local representation, CVT and Bi-LSTM-CRF with local and distant representations\nTo compare the effectiveness of both local and distant representations with CVT, we used the Bi-LSTM-CRF model, which includes local representation ( INLINEFORM0 ), and compared it with Bi-LSTM-CRF with local and distant representation and CVT ( Incline (c), Incline (d) and Incline (e)). On the Orchid dataset, the Bi-LSTM-CR",
    "70148c8d0f345ea36200d5ba19d021924d98e759": "\nThis work expands on the work in which we first became intrigued by the potential security risks posed by illusory perturbations to human perception. There was prior work on which we leaned heavily in developing our model for phoneme illusionability BIBREF33, though the illusory video generation of this work was inspired by existing work on illusory video generation for ML systems BIBREF1, BIBREF17, BIBREF33, BIBREF25.\nAppendix A: Model Details\n\nPhoneme illusion model\n\nIn this section we describe how the illusible-phoneme-to-illusory-audio-signal (LPIA) model was built and trained. The illusory audio signal $z$ is defined to be the audio signal that is visually dubbed on the video $w$ where the audio portion of the video is the signal $x$ and $z = f(x,x^{\\prime })$ is the illusory, dubbed over signal. Our LPIA model $L^x$ maps natural language tokens $x$ to illusory audio signals $z$ in the following manner:\n$$\nA = [E_{ph,vowel},E_{con,vowel},E_{con,cough},E_{non-con,vowel},E_{phoneme-context},E_{illusory-audio-signal}] \\in R^m \\rightarrow R^n\n$$\n\nwhere $E_{ph,vowel}$ is a binary bag-of-words model identifying the phonemes with which the target token is combined with a vowel phoneme, $E_{con,cough} \\in R^m \\times R$ is a model for the phoneme context, $E_{non-con,vowel} \\in R^m \\times R^h \\times R^t$ is a model that takes as input a token without a vowel context and returns the phoneme context with a vowal, non-vowal, or both vocabularies, and with $E_{illusory-audio-signal}$ a function that depends only on the context and the signal $x$. The feature $E_{illusory-audio-signal}$ is an audio-only predictor, and its form depends on the task. Here, $m$ is the number of possible variants",
    "27cf16bc9ef71761b9df6217f00f39f21130ce15": "\n\n[1] F. Ijiri, M. Gribault, and S. Ganchev, A Theory of Learning for Human Speech Perception. ArXiv preprint:2003.[https://](https://arxiv.org/abs/1801.10248)2018,\n\n[2] A. J. Tenenbaum, A computational theory of auditory-visual perception of speech: I. A commonality of illusion and image understanding. In\n\nProceedings of the International Conference on Acoustics, Speech and Signal Processing, ICASSP 2003, February\n\n3-7, 2003, Vol. 2, pp. 1373\u20131378.\n\n[3] A. J. Tenenbaum and C. A. Bowers, A computational theory of auditory-visual perception of speech: II. A\ncommonality of illusion and image understanding. In\n\nProceedings of the International Conference on Acoustics, Speech and Signal Processing, ICASSP 2003,\n\nFebruary 3-7, 2003, Vol. 2, pp. 1379\u20131386.\n\n[4] A. J. Tenenbaum, V. H. Luce, and H. K. Lee, Efficient processing of speech in normal and impaired\nauditory cortex. J Neurophysiol 84 (6):3482\u20131892, 2000.\n\n[5] A. J. Tenenbaum and C. A. Bowers, Components of phonological representations for native and\nlearned speech. J Acoust Soc Am 121 (3):2554\u20132557, 2006.\n\n[6] A. J. Tenenbaum and C. A. Bowers, Components of phonological representations for native and\nlearned speech. J Acoust Soc Am 121 (3):2554\u20132557, 2006.\n\n[7] S. Ganchev and F. Ijiri, Adversarial examples for human auditory perception. Proc. International\n\nInterspeech Conference, August 2018.\n\n[8] R. Zhang and M. W. W. Chan, Robust Speech Recognition against Adversarial Speakers. In ASRU.\n\nSri Lanka 2018: Proc. of Workshop on Learning from Perturbed Corpus. Colombo, Sri Lanka.\n\n[9] Z. Li, Y. Cui",
    "627b8d7b5b985394428c974aca5ba0c1bbbba377": "\nReferences\n\n[Alam, 2016] Alam, H. A., and G. Koehn. 2016. \"Subtitle-tagger for the NIST SRE 2016 Multilingual Broadcast News Translation Assessment.\" In International Conference on Machine Translation.\n\n[Bahdanau et. al., 2014] Bahdanau, D., J. Cho, S. Bengio, and Y. Liu. 2014. \"Neural Machine Translation by Jointly Learning to Align and Translate.\" In Fourteenth Conference of the European Chapter of the Association for Computational Linguistics, pp. 1109\u20131118.\n\n[Bengio, 2014] Bengio, Y., B. Wu, J. Sch\u00fctze, Y. Sordoni, and R. Glava. 2014. \"Neural Machine Translation by Jointly Learning to Align and Translate.\" In Twenty-sixth Conference of the Association for Computational Linguistics: Short Papers, pp. 1773\u20131786. Stroudsburg, PA.\n\n[BERT, 2018] Bert, A. J., K. S. Doshi, A. C. C. C. Clark, R. S. Zemel, and C. D. Manning. 2017. \"Deep multitask learning for NMT via pre-training on many related tasks.\" In EMNLP, pp. 1773\u20131781.\n\n[Bleu, 1998] P. Bleu, R. F. Vetter, J. Garsia, K. K. Och, and W. H. Wilks. 1998. \"A probabilistic metric for machine translation.\" In Proceedings of the HLT-98 Conference on Human Language Technologies: Translating and Interpreting.\n\n[Bollegala, 2019] Bollegala, D. 2019. \"Monolingual Sequence-to-Sequence Modeling for Multilingual and Contextual Machine Translation.\" In ACL-IJCNLP 2019.\n\n[Casanova, 2016] Casanova, A. 2016. \"Round-trip learning: a new strategy for multilingual neural translation.\" In Thirty-fifth Conference of the Association for Computational Linguistics: Short Papers, pp. 1218\u20131229.\n\n[Cheng, 2016] Cheng, M., J. Saeidi, M. E. Alzantot,",
    "126ff22bfcc14a2f7e1a06a91ba7b646003e9cf0": "\nReferences\n\n[BIBREF1]\n\nZwirner, A., Cho, S., Kim, E. W. M., Verga, S., Goyal, P., Callison-Burch, C., and Bojar, A. G. (2016). Measuring Par- tial Fluency of Machine Translation. Proc. Empirical Mechanics of Narrative (EMN 2016).\n\n[BIBREF2]\n\nM\u00fcller, J. S., Bojar, A., and Simons, K. (2018). Parallel Corpus Construction and Document-Level Neural Machine Translation. Teknet Brief #21.\n\n[BIBREF3]\n\nM\u00fcller, J. S., and Simons, K. (2018). Synthetic Document-level Parallel Corpus and Language-Dependent NMT. Teknet Brief #10.\n\n[BIBREF4]\n\nM\u00fcller, J. S., He, J., Bojar, A., Callison-Burch, C., Verga, S., and Goyal, P. (2018). Synthetic Parallel and Language-Dependent Doc- ument-Level Translation. TekNet Brief #12.\n\n[BIBREF5]\n\nZwirner, A., Cho, S., and Lopyrev, A. (2019). A Multi-Source Document-Level Model of Neural MT. In Proceedings of EMNLP, pages 40\u201348.\n\n\n[BIBREF6]\n\nM\u00fcller, J. S. K., Iosad, Y., and Simons, K. (2018). Document-level Parallel Machine Translation at Scale. Proc. Conference on Empirical Methods in Natural Language Processing: AACL 2017, pages 125\u2013132.\n\n\n[BIBREF7]\n\nBojar, A., and Lopyrev, N. (2018). Modeling Document-Level Parallelization with Neural MT. Tepnet Brief #8.\n\n[BIBREF8]\n\nM\u00fcller, J. S., and Iosad, Y. (2018). Document-Level Parallel Machine Translation at Scale. Proc. AAAI Conference on Artificial Intelli- gence 2019, pages 773\u2013779.\n\n\n[BIBREF9]\n\nZwirner",
    "7e4ef0a4debc048b244b61b4f7dc2518b5b466c0": "\n\n1.\n\nM. Dabre and L. R. Wieser.\n\nImplicit and explicit discourse markers: An account of their distribution in spoken data and of the differences in meaning between the two in the English language.\n\nIn E. N. Clark, S. Thompson, and R. M. Dale (eds.),\n\nDiscourse Structure and its Representation in Contemporary Discourse Parsing and Grammar\n\n(Studies in Language Companion Series 1), MIT Press, Cambridge, 1994.\n\nZ. Declerck and Y. Lavie.\n\nThe prosodic and semantic effects of question fronting vs. question embedding in English.\n\nJournal of Pragmatics, 33:919\u2013942, 2003.\n\nJ. van de Vijver, D. Grefenstette, and S. Ilyushina.\n\nAn algorithm for detecting and analysing cross-linguistic word order variation in the Europarl corpus.\n\nComputational Linguistics 41:1541\u20131572, 2005.\n\nM. De Nijs, S. Ilyushina, V. D. Gajos, and G. Eichmann.\n\nFrom round-trip to document repair : Context-aware machine translation through back-translation and bilingual self-training.\n\nACL 2018, Vancouver, Canada, 2018.\n\nR. Sennrich, M. R. Sch\u00fctze, and D. V. Garsia.\n\nImproving Arabic\u2013English Translation with Round-trip Machine Translation.\n\nacl2018, Vancouver, Canada, 2018.\n\nL. S. Stede, L. U. Vajapeyam, and H. T. Cheng.\n\nDocument-level machine translation: A typology of round-trip operations.\n\nIn P. O. Flener, T. H. J. Noppe, D. Weir, L. F. N. Costa, D. G. H.\n\nWeir, N. K. Savvidou, and L. S. Stede (eds.),\n\nDocument-Level Resources for Machine Translation,\n\n(Lecture Notes in Computer Science 10752), Springer, Cham, 2018.\n\nA. Verhagen, D. Grefenstette, G. E",
    "b68f72aed961d5ba152e9dc50345e1e832196a76": "\nReferences\n\n[BIBREF1]\n\nBentivogli et al. 2010. A metric for automatic evaluation of machine translation. In Proceedings of the 34th Annual Meeting of the Association for Computational Linguistics, Stroudsburg, USA, pp. 3406\u20133413.\n\n[BIBREF2]\n\nChaudhry et al. 2010. An empirical analysis of cross-lingual document summarization for machine translation. In Proceedings of COLING 2010, Pisa, Italy, pp. 193\u2013204.\n\n[BIBREF3]\n\nClark and Curran. 2013. An exploration of source-to-target sentence reordering for large scale MT training. In Proceedings of the 36th annual conference of the Association for Computational Linguistics, Florence, Italy, pp. 2089\u20132099.\n\n[BIBREF4]\n\nCotterell et al. 2013. Modeling context and cross-sentences for neural MT. In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics, Florence, Italy, pp. 2236\u20132262.\n\n[BIBREF5]\n\nCotterell et al. 2018. Machine translation with a deep context-aware neural machine translation model. In Proceedings of ACL-2018: the 48th Annual Meeting of the Association for Computational Linguistics, Melbourne, Australia, pp. 3580\u20133589.\n\n[BIBREF6]\n\nChen et al. 2017. Cross-sentence representations for low-resource neural MT. In Proceedings of ACL-2018: the 48th Annual Meeting of the Association for Computational Linguistics, Melbourne, Australia, pp. 3039\u20133047.\n\n[BIBREF7]\n\nChen et al. 2017. A new framework for sequence to sequence learning for NLP tasks by sharing latent information. In Proceedings of ACL 2017, Vancouver, Canada, pp. 3433\u20133450.\n\n[BIBREF8]\n\nDa Dalt L et al. 2016. Cross-language document summarization using translation-based sentence alignments. In Proceedings of the COLING/ACL 2016 Joint Workshop, Copenhagen, Denmark, pp. 1\u201310.\n\n[BIBREF9]\n\nDa Dalt L et al. 2017. Building machine translation training data with limited parallel data",
    "cf874cd9023d901e10aa8664b813d32501e7e4d2": "\n\nReferences\n\n\\addcontentsline{BioIESurveys}\n1. Deerwester, S., H. E. Killinger, D. W. Harman. \"Using an intelligent system to answer scientific questions.\" Journal of American Chemists' Association 100(10):2189\u20132201. 1995.\n\n2. Kleinberg, S., J. O'Shaughnessy. \"Biomedical text mining and information retrieval on the World Wide Web.\" Nature Reviews Genetics 4:335\u2013343. 2003.\n\n3. Chen, Z., D. C. Hsu, A. D. Dale, K. L. Miller. \"Med-Bio: exploiting domain information for better biomedical IR.\" Proceedings of the 36th Annual International ACM SIGIR Conference, Dublin, Ireland. 2001.\n\n4. Lin, K., G. V. Domashevsky, D. W. Lopresti, B. A. Warden. \"A rule-based system for the extraction of human protein names in medical abstracts.\" Artificial Intelligencer 21(1):45\u201364. 2003.\n\n5. He, L., V. C. Hong, N. D. Charniak. \"Recognizing concepts in clinical notes and progress notes.\" BioNLP'04. 2004.\n\n6. Chen, Z., D. C. Hsu, A. D. Dale, K. L. Miller. \"Fact-based sequence tagging.\" BioNLP'04. 2004.\n\n7. Zhang, T., M. V. Fan, J. N. Cohen, S. R. Kohonen. \"Extracting medical diagnoses in a clinical note corpus: a semi-CRF approach.\" BioNLP'05 (BNC05). 2005.\n\n8. Zhang, H., M. Zhou, S. R. Kohonen. \"Using concept mapping to bootstrap biomedical NELL on the i2i2b2 challenge dataset.\" BioNLP'05 (BNC05). 2005.\n\n9. Smith, J. E., S. R. Kohonen. \"Bio-NELL: bootstrapping biomedical ontologies via neural semantic language learning.\" BioNLP'05 (BNC05). 2005.\n\n10. Smith, J. E., C. A. Pulver, P. V.",
    "42084c41343e5a6ae58a22e5bfc5ce987b5173de": "\nReferences\n[1] Z. Ahmad, M. Forner, T. Kuhn, B. Kuhn and H. Jannach (2015). BioNLP Shared Tasks\n\n[2] J. K. Bellamy, A. A. L. Lauscher, M. T. Franklin, M. Forner, M. Forbus, E. Meijaardu, G. Haddow, P. E. Kamps, M. R. C. F. K. Zeven, A. Bohnet, Y. LeCun, S. Laptev, J. Tackenberg. A New Evaluation Tool for Named Entity Recognition in Medical Text\n\n[3] B. Kuhn, A. Forner, C. Pal, M. T. Franklin, A. Lauscher, G. Haddow, M. R. C. F. K. Zeven. On Evaluating Relation Extraction from Medical Text\n\n[4] S. Lee, R. Narayananthan, R. Lally and G. Haddow. Biomedical text mining and beyond\n\n[5] J. P. Green and N. Mani. The Protein Ontology: A comprehensive hierarchical ontology of proteins and their functions\n\n[6] J. Li, G. Haddow, K. Lee, K. K. Chang, X. Liu, C. C. Liu, I. Meijaardu, D. Pal, A. Lauscher, M. R. C. F. K. Zeven, S. Laptev. Bootstrapping ontologies for biomedical information extraction using Named Entity Recognition, Relation extraction and Fact extraction\n\n[7] N. M. Fekete, R. R. Garey, S. Hovy, H. Jannach. Recognition of Protein Names in Biomedical Text\n\n[8] Y. Li, R. Narayananthan, G. Haddow, A. Lauscher. Recognition of Medical Terms from Clinical Text using Machine Learning\n\n[9] N. Mani, G. Haddow, M. Meijaraud, B. Kuhn, A. Lauscher, M. R. C. F. K. Zeven. Extracting Facts from Text given",
    "b637d6393ef3af7462917b81861531022b291933": " We would also like to thank all the other members of our lab for their contributions including Mihir Karkal, Pooja Chaudhuri, Adam Lerer, Paul Pham, and Sasha Pruksachatkun.\n\n1. https://nlg.cs.nyu.edu/BibRef/\n\n2. https://nlp.stanford.edu/projects/super/\n\n3. https://allennlp.org/bibref\n\n4. http://nlp.stanford.edu/projects/nli_probs.html\n\n5. http://nlp.stanford.edu/pubs/papers14-glue.pdf\n\n6. https://nlp.stanford.edu/~tie_kover/edge.pdf\n\n7. https://paperswithcode.com/s?task=edge_probing&page=0\n\n8. http://nlp.stanford.edu/projects/SentEval/\n\n9. http://nlp.stanford.edu/senteval/\n\n10. http://nlp.stanford.edu/pubs/bowman-etal-2018-conll\n\n11. http://nlp.stanford.edu/projects/mnli/\n\n12. http://aclweb.org/acl2017/papers.html\n\n13. http://nlp.stanford.edu/projects/conll/\n\n14. http://nlp.stanford.edu/conll2017/data/\n\n15. http://research.googleblog.com/2017/11/exploring-the-state-of-the-art-in-nlp-entity.html\n\n16. https://nlp.stanford.edu/multitask/\n\n17. https://nlp.stanford.edu/projects/stilts/\n\n18. https://www.aclweb.org/anthology/D17-1402.pdf\n\n19. https://www.aclweb.org/anthology/P18-1107.pdf\n\n20. http://www.aclweb.org/anthology/P19-1349.pdf\n\n21. https://pytorch.org\n\n22. https://www.stanford.",
    "8b9c12df9f89040f1485b3847a29f11b5c9262e0": "\nMention of trade names or commercial products is for information only and does not constitute endorsement by the US Government.\n\nReferences\n\n1. Bolt, C., & Szpakowicz, R. 2018. AllenNLP. https://allennlp.org/\n\n2. Bordia, S. A., Paty, N., & Hutton, G. 2016. An Empirical Evaluation of Edge NLP Probing Models. In AAAI Conference on Artificial Intelligence, Washington, DC, USA. http://www.aclweb.org/anthology/C/C16/C16-2012.pdf\n\n3. Chen, B. C., Paty, N., & Cho, D. 2018. A Probing Study on BERT: A Language Model That Generalizes. Artiltificial Intelligence, 322-327.\n\n4. Cohen, R., Li, D., & Hovy, D. 2018. SuperGLUE: Benchmarking Semantic Understanding through Fine-grained Language Understanding. Artiltificial Intelligence, 322-327.\n\n5. Conneau, A., Lample, C., & Weston, J. 2016. Very Deep Neural Networks for Text Classification. Artiltificial Intelligence, 34(1), 1256-74.\n\n6. Devlin, J., & Lee, K. 2019. Bert: Pre-training of Deep BERT for Language Understanding. Artiltificial Intelligence, 322-327.\n\n7. Dupaillard, E., Chen, B. C., & Bowman, S. 2017. Exploratory Analysis of Pretrained Transformers Models for Question Answering. In COLING Annual Conference, Prague, Czech Republic. http://aclweb.org/anthology/C/C17/C17-1027.pdf\n\n8. Eisennagal, R., Ribeiro, S., Bowman, S., & Kulkarni, R. 2017. SocialIQa: A Dataset for Interpreting Social Media Comments. In ACL-IJCNLP, Hong Kong. http://aclweb.org/anthology/C/C17/C17-1136.pdf\n\n9. Gurevych, O., Labrooy, S., Rafferty, J., & Schlenk, K. 2011. Automatic Supertag",
    "72e4e26d0dd79c590c28b10938952a9f9497ff1e": "\n\nAcknowledgment\nWe thank the Hague Institute of Digital Humanities for supporting parts of this research.\n\n# 9. Art Attribution System in the Age of Adversarial Art Attacks\n\nMakarand P. Phukan and Mikhail G. Dementiev\n\nAbstract\n\nWe present the first study on adversarial art attacks that manipulate artistic media to mislead the machine about its attribution. Although artworks are not covered much by current adversarial attacks, there have been recent developments on adversarial image attacks BIBREF1, BIBREF2. Here we show that image attacks not only target the human perception of images, but can also affect machines identifying, attributing, and evaluating artworks. With our adversarial art, the attacker manipulates the media content to change the human perception regarding its attribution. It misleads the machine as it is trained with a set of counter-samples generated through adversarial techniques. This enables the attacker to replace the original artwork to the target one with almost exact match on the visual level. We show via a series of experiments against three different commercial attribution systems BIBREF1 that adversarial art is able to alter the machine attribution of a wide range of artworks. Finally, we show that the system is more robust to adversarial attacks when a large training set is available for the target domain as compared to counter-sample generation. However, we find that the effectiveness of adversarial attacks against the target domain decreases with an increase in size of the training set thus leading to a sharp decrease in the effectiveness with the increase of the training size BIBREF1. Based on this observation, we propose a novel adversarial attack method based on the Generative Adversarial Network (GAN) to improve the effectiveness of counter-sample generation.\n\nIntroduction\nArt is a subject of deep interest to human beings and machines alike. Over the past several decades, technology has made a huge breakthrough in the art domain by democratizing art and making it easily accessible. However, with the recent emergence of high end machine learning technologies like Generative Adversarial Networks (GANs) and Deep Neural Networks, the question arises if it is possible to fool the system into attributing a certain type of artwork as a particular type, such that the original is lost. We propose the first attack on visual media, where the artist is being paid for their work through a creative platform. For this purpose, we make our data publicly",
    "63b92dcc701ec77fdb3355ede5d37d2fbf057bcc": "\n\nFigure 1\n\nFigure 2\n\nFigure 3\n\nFigure 4\n\nFigure 5\n\nFigure 6\n\nFigure 7\n\nFigure 8\n\nFigure 9\n\nFigure 10\n\nFigure 11\n\nFigure 12\n\nFigure 13\n\nFigure 14\n\nFigure 15\n\nFigure 16\n\nFigure 17\n\nFigure 18\n\nFigure 19\n\nFigure 20\n\nFigure 21\n\nFigure 22\n\nFigure 23\n\nFigure 24\n\nFigure 25\n\nFigure 26\n\nFigure 27\n\nFigure 28\n\nFigure 29\n\nFigure 30\n\nFigure 31\n\nFigure 32\n\nFigure 33\n\nFigure 34\n\nFigure 35\n\nFigure 36\n\nFigure 37\n\nFigure 38\n\nFigure 39\n\nFigure 40\nList of Figures\n\nFigure 2\n\nFigure 4\n\nFigure 5\n\nFigure 6\n\nFigure 7\n\nFigure 8\n\nFigure 9\n\nFigure 10\n\nFigure 11\n\nFigure 12\n\nFigure 13\n\nFigure 14\n\nFigure 15\n\nFigure 16\n\nFigure 17\n\nFigure 18\n\nFigure 19\n\nFigure 20\n\nFigure 21\n\nFigure 22\n\nFigure 23\n\nFigure 24\n\nFigure 25\n\nFigure 26\n\nFigure 27\n\nFigure 28\n\nFigure 29\n\nFigure 30\n\nFigure 31\n\nFigure 32\n\nFigure 33\nFigure 34\n\nFigure 35\n\nFigure 36\n\nFigure 37\n\nFigure 38\n\nFigure 39\n\nFigure 40\nAcknowledgments\n\nAcknowledgements\n\nThis work was primarily supported by the National Science Foundation under grant no. 1522517, with additional financial support from: Amazon.\n\nFigure 1\n\nFigure 2\n\nFigure 3\n\nFigure 4\n\nFigure 5\n\nFigure 6\n\nFigure 7\n\nFigure 8\n\nFigure 9\n\nFigure 10\n\nFigure 11\n\nFigure 12\n\nFigure 13\n\nFigure 14\n\nFigure 15\n\nFigure 16\n\nFigure 17\n\nFigure 18\n\nFigure 19\n\nFigure 20\n\nFigure 21\n\nFigure 22\n\nFigure 23\n\nFigure 24\n\nFigure 25\n\nFigure 26\n\nFigure 27\n\nFigure 28\n\nFigure 29\n\nFigure 30\n\nFigure 31\n\nFigure 32\n\nFigure 34\n\nFigure 35\n\nFigure 36\n\nFigure 37\n\nFigure 38\n\nFigure 39",
    "58ee0cbf1d8e3711c617b1cd3d7aca8620e26187": " We would also like to apply these ideas to style transfer on video data. We believe this approach is generic enough, where it should be easy to extend the agent-critic framework BIBREF1 to other tasks such as text modeling and conversation generation.\n::: Acknowledgements\n\nWe would like to thank Prof. Christopher Manning for his help during our early training procedure and Prof. Christopher Borgwardt, whose feedback greatly improved the quality of this paper. We would also like to thank the members of the Department of Computer Science and Software Engineering at Cornell University for their helpful advice on this topic. We also would like to thank the members of the Cornell Neuroscience Program for discussions related to neural network modeling.\nAnkur Sharma, Ashwin Kambhamettu and Shivakanth Kakumanu at Cornell University\n\n* ::: Bibliography\n\n* ::: Alvarez-Martinez, P., Raffel, C., Poria, A. and Krikun, T. (2018). Adversarial training for machine translation\n\n* ::: Ananiadou, K., Vasilakis, A., and Strintzis, N. (2018). Generative adversarial nets for few-shot style transfer, in Conference on Computer Vision and Pattern Recognition,\n\n* ::: Bansal, M., Zaremba, S. and Gulwani, C. (2017). \"An approach to controlling multiple style parameters for style transfer\", in Computer Vision and Pattern Recognition, 2017, pp. 5046-5054.\n\n* ::: Daphne, M., Rocco, M., and De Maeyer, P. (2018). Fine-grained control of content and style for text style transfer, in Conference on Computer Vision and Pattern Recognition, 2018, pp. 5630-5641.\n\n* ::: Ghafoor, N., Chen, S. and Heilmane, A. (2018). Cross-aligned auto-encoders: Fine-grained control over style and content, in Conference on Computer Vision and Pattern Recognition, 2018, pp. 9228-9248.\n\n* ::: Jain, V., Gao-Tamai, R., and Vondrak, M. (2018). Text style transfer: A neural perspective, in the Thirty-fifth International Conference on Artificial Intelligence and",
    "f71b52e00e0be80c926f153b9fe0a06dd93af11e": "\nAcknowledgements\nWe would like to thank Dr. Arun Krishnamoorthi, Dr. Pia Puschner and Dr. Peter Krause for their helpful discussions. We would like to thank Professor David Gr\u00fcn and Professor Sampriti Singh for facilitating our academic visit, and Dr. Stefan Roth for the initial idea of combining artistic language with neural networks for artistic language generation.\nAcknowledgments\n\nThis thesis was written as part of the 2018-19 University of Edinburgh summer school program which is supported by the Global Challenges Research Fund and supported by the Edinburgh Interdisciplinary Informatics Programme. We are grateful to Professor David Gr\u00fcn and Professor Sampriti Singh for facilitating our academic visit. We are grateful to Professors Arun Krishnamoorthi, Pia Puschner, Peter Krause and Stefan Roth for their helpful discussions. We would also like to thank Dr. Stefan Roth for the initial idea of combining artistic language with neural networks for artistic language generation.\nReferences\n\n[1] F. O. Carrier and C. W. J. Wieland and J. F. E. Hearst, \"On learning to describe images: Exploring the data distribution of an end to end architecture\", ICLR, 2017\n\n[2] S. Chen and L. Li and M. Yang and B. Yin and J. P. Singh, \"Image to poetry generation using attention-based neural network and attention-based multi-adversarial training\", CVPR, 2018\n\n[3] M. Mikolov, I. Sutskever and K. Chen and G. D. Cox and A. Culotta and D. S. Lee, \"Empirical assessment of neural machine translation models\", CoNLL, 2013\n\n[4] M. Sakaguchi and K. Uchiyama and K. Hayashi and K. Yoneda and Y. Yamamoto, \"Image-to-sentence Generation Using Adversarially Trained Sequence-to- Sequence Model\", ICML, 2015\n\n[5] S. Vinyals, A. Graves, and H. Schmidhuber and T. Mikolov, \"Sequence-to-sequence learning with neural Turing machines\", NIPS, 2014\n\n[6] D. Silver, N. J. Goodman and E. Haffner and C. Battaglia and G. Brock",
    "8db6f8714bda7f3781b4fbde5ebb3794f2a60cfe": "\n\nAcknowledgements\nThis work is supported in part by the Department of Computer Science, The University of Auckland.\n\n1. Bai R., Jiang Y., Dai H., Wang X. and Ye D. (2018). Deep Sequence Recurrent Generative Adversarial Network for Automatic Poetic Captioning. In 31 st International Conference on Machine Learning (ICML 2018).\n\n2. Belinkov M., Krause A., and Glover D.M. (2018). LanguageStyle: Generating Text with Style. In The 32 nd Annual Conference of the American Society for Computational Linguistics (ACL 2018), Workshop on Generative Language Understanding (GLUE 2018).\n\n3. Sutskever I., Chen Q., Dean J., Poibeau G., Ramachandran G., and Courville A. (2018). Sequence to Sequence Learning with Attention. In 30 th International Conference on Machine\n\nLearning (ICML 2018), Workshop on Neural Machine Translation (WMT).\n\n4. Soh R., Xu X., Wang J., Song X. and Zhai X. (2018). StyleCLR: Style-Transferring using Cross-Aligned Auto-Encoders. In 28 th International Conference on Computational Linguistics (ICCL 2018), The Workshop on Computational Linguistics for Music, Audio, and Multimedia (CLuMM 2018).\n\n5. Jia Y., Sato S., Ueno A., and Ito Y. (2019). Cross Attention for Sentence Representation Learning. In 33 rd Conference on Neuro-linguistic Representation and Applications (NLP).\n\n6. Gulcehre K. and Faruqui S. (2019). Generating Stylized Text with Global Attention. In 33 rd Conference on Neuro-linguistic Representation and Applications (NLP).\n\n7. Luan G., Xiao N., Dong B., Zhang X., Ma H. and Xing C. (2019). StyleCLR: Style-Transferring using Cross-Aligned Auto-Encoders. In 33 rd Conference on Neuro-linguistic Representation and Applications (NLP).\n\n8. Jia Y., Liu G., Deng X. and Zhang J. (2019). Cross-Aligned Auto-Encoders for Sentence-Style Transfer. In 32 nd Conference on Neural",
    "54e945ea4b014e11ed4e1e61abc2aa9e68fea310": "\n\nReferences\n\n[1]\n\n[2]\n\n[3]\n\n[4]\n[5]\n\n[6]\n\n[7]\n\n[8]\n\n[9]\n\n[10]\n\n[11]\n\n[12]\n\n[13]\n\n[14]\n\n[15]\n\n[16]\n\n[17]\n\n[18]\n\n[19]\n\n[20]\n\n[21]\n\n[22]\n\n[23]\n\n[24]\n\n[25]\n\n[26]\n\n[27]\n\n[28]\n\n[29]\n\n[30]\n\n[31]\n\n[32]\n\n[33]\n\n[34]\n\n[35]\n\n[36]\n\n[37]\n\n[38]\n\n[39]\n\n[40]\n\n[41]\n\n[42]\n \n# PIRATE TALES  \nFROM ASHORE AND ABOVE\n\nROBERT NAPOOLEON RUSSO\n\n## Copyright\n\nPIRATE TALES FROM ASHORE AND ABOVE\n\nCopyright \u00a9 2004 by Robert Napoleon Russo\n\nAll rights reserved. For information about permission to reproduce selections from this book, write to Permissions, W. W. Norton & Company, Inc., 500 Fifth Avenue, New York, NY 10110\n\nProduction manager: Julia Druskin\n\nLibrary of Congress Cataloging-in-Publication Data\n\nRusso, Robert Napoleon.\n\nPirate tales from a shore & above / Robert Napoleon Russo.\u20141st ed.\n\np. cm.\u2014(World of adventurers)\n\nSummary: Rip Collins is a fourteen-year-old boy, son of a Pirate Lord, working with his father to bring to justice the man that is stealing children and selling them to be used as pirates.\n\nISBN: 978-0-393-03417-3\n\n1. Fantasy. [1. Fantasy.] I. Title.\n\nPZ7.R98427Pip 2004\n\n[Fic]\u2014dc21 2004046243\n\nW. W. Norton & Company, Inc.\n\n500 Fifth Avenue, New",
    "df0257ab04686ddf1c6c4d9b0529a7632330b98e": " For all recipes that require multiple steps, e.g. cook carrot with BBQ, the agent would need to perform multiple actions from the same skill in different rooms.\nIn the cooking world, an observation is composed of a room description, inventory, quest, previous action and feedback. The inventory can consist of up to 30 objects, and the agent can have up to 40 actions at step t. In case of no interaction, i.e. for a cooked carrot, next action becomes cooking the vegetable on the grill. An inventory with zero object means the agent can go to the next location.\nAppendix ::: Data Set ::: CoinCollector\nTable TAGREF35 shows the games' statistics for the hard setting (mode 2) and for all the settings of CookingWorld.\nAppendix ::: Data Set ::: CookingWorld ::: Grammar\nTable TAGREF36 shows the ingredients of each game and their skills (all the items are verbs) as well as their corresponding recipes (the format is the same for each of the 222 games). Each recipe in CookingWorld is composed of a set of ingredients, where one recipe might need 10 or 20 items. All recipes have different entities (e.g. oven, stove, potato), each entity has a set of skills (e.g. light, push, start) that are necessary in order to interact with. For instance, an oven has only 3 of the total 14 skills, whereas a potato has 8 of them. The grammar used is the following:\nInventory   \n{open, take/drop, put/insert}   \n{light, start, push}   \n{close, push, light}   \n| Cook\n{start}\nrecipe   \n[recipeName]   \n[name of the recipe, optional comma]   \n[skills]   \n:recipe_skills\n: | {prep|grill|roast|fried|sliced|chop|diced|carved|shaped|cut|sliced|shredded|chopped|grilled|roasted|baked|basted|saute|browned} +\n\n: :[cook]   \n: | {start|grill|roast|fried|sliced|chop|diced|carved|shaped|chose|cut|sliced|sliced|sh",
    "568fb7989a133564d84911e7cb58e4d8748243ef": "\n\nAppendix ::: Text-Games ::: Game Grammar\nWe give the grammar used by the text-based game world and the different sets of admissible actions (each defined as: Verb1 Verb2 Verb3 Verb4). Below the different sets:\n\nVerb: take, look, see, hold/touch, examine, open/close\n\nVerb1: take x, drop x, put x, insert x, insert_into x\n\nVerb2: look x, see x, examine x, touch x\n\nVerb3: examine x, look x, see x, touch x\n\nVerb4: open x\n\nAppendendum ::: Verb sets ::: Verb-Adj1, Verb-Adj2, Verb-Noun\n\nVerb-Adj1: examined x, examined y, opened x\n\nVerb-Adj2: dropped x, opened x\n\nVerb-Noun: x, Y\n\nAppendendum ::: Adverb groups ::: verb, Adj-Noun\n\nverb: look, see, touch\n\nNoun: x\nAdjective: x\n\nAppendendum ::: Grammatical Constructions ::: {verb-noun}\n\nopen :{open_, x, _}\n\nEx: looked_under_a_bed_\n\nlook :{look, see}\n\neat :{eat, eat _,_ x, _}\n\nappendendum ::: Example Games\n\nBourbon :{drink a_,_ BOURBON_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_\n\nGin & Tonic :{drink A_,_ GINGERB_,_ LIME_,_ TONIC_,_ ALE _}\n\nBeef Burger :{eat a_,_ BURGER_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*",
    "2c947447d81252397839d58c75ebcc71b34379b5": "\nAppendix ::: Text-Games ::: Examples\nCoinCollector:\n\nlook (look, LOOK): look at the inventory and the current room\n\nlook, pick-up, pick-up!: pick something up\n\nlook, take, take!: take something up\n\nlook, take, take everything!: take everything up\n\nopen door: open a door\n\ndrop: drop something down\n\nlook, take, drop thing, pick, pick, pick everything, pick, pick things!: take things\n\nlook: look at what is in the inventory, at the room, at the object\n\nlook, everything!: look at everything\n\npick-up, pick! open / close: pick up / close item\n\npick, pick everything!: pick up everything\n\ninsert/put: insert item in a container, (inside a container)\n\n[leftmargin=*] look, put $thing$: put in the inventory, insert (inside a container)\n\ncook, cook food!: put food in BBQ, put food in oven, put food in stove\n\nopen X, close X: open/close BBQ, close oven, close stove\n\npick-up Y: take Y from inventory\n\nput Y in container: put Y inside the BBQ, open oven, close stove\n\ngrill!: do something with X, BBQ\n\nroast! : roast X!\n\nfried! : roast X!\n[leftmargin=*]\n\ncook, take $X$! : take food from inventory\n\nopen X, close X!: open / close BBQ, close oven, close stove\n\n[leftmargin=*]\n\ntake $X$!, pick: take food from inventory, pick /pick Y\n\ncook $X$ with: cook food with X\n\ntake $X$!, eat, cook $X$!: cook food with X, pick/pick Y\n\nslice $X$ with Y!: slice X with Y!\n\nchop $X$ with Y! : chop X with Y!\n\ndice $X$ with Y!: dice X with Y!\n\nprepare meal!: put $X$ in menu\n\nAppendix ::: Text-Games ::: First TextWorld Problems\nThe family of first text-world",
    "c01784b995f6594fdb23d7b62f20a35ae73eaa77": "\nAppendix ::: Acknowledgements\nWe would like to thank the anonymous reviewers as well as the authors of BIBREF1, BIBREF2, BIBREF4, for the valuable feedback on the early drafts of this paper, and the organizers of the ICLR 2019 NeurIPS workshop for the opportunity to present this work.\nAppendix ::: Trajectories\n\nAppendix ::: Experiments ::: Baseline\n\nAppendix ::: Text-Games ::: CoinCollector\n\nAppendix ::: Text-Games ::: CookingWorld\n\nAppendix ::: Hyper-parameters\n\nAppendix ::: Coins Collector Experiment Details\n\nAppendix ::: CookingWorld Experiment Details\n\nAppendix ::: CookingWorld Curriculum\n\nAppendix ::: First TextWorld Experiments Details\n\nAppendix ::: Text-Games Vocabularies\n\nAppendix ::: Word Embeddings\n\nAppendix ::: CookingWorld Observations\n\nAppendix ::: CookingWorld Actions\n\nAppendix ::: Go-Explore Exploration Details\n\nAppendix ::: Phase 1 of Go-Explore Details\n\nAppendix ::: Seq2Seq Model Details\n\nAppendix ::: Experiments ::: Phase 2 of Go-Explore Details\n\nAppendix ::: LSTM-DQN Model Details\n\nAppendix ::: Random Actions Details\n\nAppendix ::: Go-Explore Actions Details\n\nAppendix ::: Text-Games - CoinCollector\n\nAppendix ::: Text-Games - CookingWorld\n\nAppendix ::: Go-Explore Phase 1 Details\n\nAppendix ::: CookingWorld Observations Details\n\nAppendix ::: CookingWorld Actions Details\n\nAppendix ::: CookingWorld Grammars\n\nAppendix ::: CookingWorld Recipes\n\nAppendix ::: Cooking World Experiments Curriculum\n\nAppendix ::: First TextWorld Trajectories\n\nAppendix ::: Acknowledgements\n\nReference\n\n\nTable of Contents\n\n  * About the Author\n\nWITNESSED\n\nEpigraph\n\n The following story was told to me in Tegelberg by some men of my own age.\n\n The old woman smiled: -You know how it once was, you and I? There were five of us to start with:\n\nChapter 1\n\n Chapter 2\n\n Chapter 3\n\n Chapter 4\n\n Chapter 5\n\n Chapter 6\n\n Chapter 7\n\n Chapter 8\n\n",
    "3415762847ed13acc3c90de60e3ef42612bc49af": "\nAppendix\nAppendix contains proofs and detailed comparisons to previous methods.\nACKNOWLEDGMENTS\n\nThis research was supported by the National Science Foundation under Grant No. 1912651. We thank the anonymous reviewers and the associate editor for their constructive feedback. We also thank Dr. Zhitao Xu for helpful discussion and the CogAI Lab for helpful discussion and support.\n\nAppendix\n\nProofs and comparison\n\nProof of Claim 1\n\nProof. In this proof, we prove for the case of supervised learning, i.e., training $p_\\theta (y| \\mathbf {x})$ with a train/validation setup. Extension to reinforcement learning setting (see appendix) is similarly in spirit. Let $p_\\theta$ be a model that takes as input a sentence and produces probability distribution $p_\\theta(y | \\mathbf {x})$ over possible labels $y\\in Y$. For a given distribution $q$ and a positive-semidefinite $p$, we have\n\nNote that the expectation is over the entire set of sampled sub-sequences, the log-likelihood over all the sequences is a upper bound of the expected log-likelihood of those that match the training data, from which we obtain:\n\n(1) Now let us consider the case where $p$ comes from augmenting the original training data using a label-preserving function $g_\\phi$. We then expect $R_\\phi(x, y| \\mathcal {D})$ to be a good measure of $p_\\theta$ in the case where the augmented data matches the model training data. That is, for those augmented data examples with correct labels, their expected log-likelihood under $p_\\theta$ approximates the expected log-likelihood under $p_\\theta$ enriched with data manipulation. Thus, we have\n\nEquality (1) holds under two restrictions: (a) $p_\\theta$ should match the model training data almost perfectly; (b) $g_\\phi$ should preserve the original label distribution $p$. Further assume distribution $q$ to be a variational distribution, i.e., $q_y\\propto p(y|x^*)/Zq(x^*)$, and that $p$ is a fixed distribution. Together, the above conditions mean that the distribution $q_y\\propto p_\\theta(y| \\cdot)/Z[p_\\theta](x",
    "223dc2b9ea34addc0f502003c2e1c1141f6b36a7": "\n\n\nAcknowledgements\nWe thank the reviewers and the editors for their valuable feedback. We thank our colleagues Shikhar Dhanda and Dahui Chen for insightful discussions and helpful comments.\n[BIBREF0] J. B. Mitchell, Y-C. Loo, A. Ganesh, P. F. S. Yuille.\n\nData augmentation: a toolbox of machine learning.\n\nInt. J. Computer Vision, 94(1-22):153\u2013177, 2020.\n\n[BIBREF1] M. Kusuoka, F. C. Chang, Y. Lei, P. C. Frank.\n\nA survey on supervised weighted learning methods.\n\nFound. Trends Anal. Data, 8:24\u201361, 2018. Available at: https://www.intel.ai/research/publications/survey-supervised-weighted-learning.\n\n[BIBREF2] X. Ying, H. Ma, S. H. Lu.\n\nA general automated data augmentation approach using a learning-to-order reward.\n\nAdv. Neural Netw. Systems, 36(10):1719\u20131747, Apr. 2017.\n\n[BIBREF3] X. Ying, H. Ma, S. Lu.\n\nLearning data transformation operators via an RL-as-inference algorithm.\n\nFound. Trends Anal. Data, 8:49\u201367, 2018.\n\n[BIBREF4] Y. Li, P. Wang, W. H. Zhai.\n\nMeta-learning for data weighting as sample efficiency guidance in reinforcement learning.\n\narXiv e-print arXiv:1705.03823, 2017.\n\n[BIBREF5] J. Zheng, P. H. Yuille, Y. Zhou, Y. Y. Zhao, R. Ienco, S. Singh, J. Sun, A-li Zh.\n\nLearning to compose sample weights in classification: Inducing a curriculum for data augmentation policy.\n\nFound. Trends in Machine Learn, 45(14):899\u2013904, 2016.\n[BIBREF6] J. Zheng, P. H. Yuille, Y. Zhou, Y. Y. Zhao, R. Ienco, S. Singh, J. Sun, A",
    "e1ab11885f72b4658263a60751d956ba661c1d61": " Moreover, we would like to experiment with other types of ensembles (e.g. ensembles only containing one type of model, or ensembles based on a different number of models). Finally, as mentioned above, the use of named entity recognition and/or smart features is certainly of high interest to solve the problem of named entities and figurative language.\n\nACKNOWLEDGMENTS\n\nWe would like to thank our academic sponsor, Tom\u00e1s D\u00edaz Bermudez, for his continuous support. Moreover, we would like to thank the two anonymous referees for their insightful feedback.\nReferences\n\nBIBREF0. G. Ganea, E. M. Corchado, J. J. Garc\u00eda-Laporte and S. Emanuele. 2018. Task 5 (Emotion intensity): emotion intensity. SemEval, 11th International Workshop on Opinion and Intent, Barcelona, 2018.\n\nBIBREF1. X. Wu, L. H. S. Liu, H. Wang, H. Chen, Y. J. Lin, D. N. Rieze and Y. Jia-ming. Tweet emotion labeling with deep convolutional neural nets. In: Proceedings of the 2016 SIGCHI Conference on Human Factors in Computing Systems, Denver, CO, USA. ACM, New York, NY, USA.\n\nBIBREF2. B. R. Agara, N. J. Patil and S. Jastrz\u00f3bska. 2017. Affect in tweets distant supervision corpus (DISC).\n\nBIBREF3. W. Zheng, M. Wiebe, T. De Sevensleben, T. Riesen and L. M. De Moor. 2016. Deeply supervised emotion classification from microblogs: a convolutional neural network approach. In: Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, Berlin, Germany. Association for Computational Linguistics.\n\nBIBREF4. G. Chikhani, A. Rakotoarisoa, A. B. D. Jusuf, P. Pronoosono, A. G. Lehman, Z. Wang and H. Zhu. 2019. Affective tweets: a multi-layer perceptron with word2vec for predicting affective intensities of tweets.\n\nBIBREF5. A. P. H",
    "c85b6f9bafc4c64fc538108ab40a0590a2f5768e": " However, for now it is not clear whether our methods would be as effective for other languages and tasks. As a future study, we would like to investigate the relation between an emotion and its intensity (E2-EI) in more detail. A first step would be to investigate the relationship between E2 and V in order to understand this relation better.\nTable TABREF18: Final best model scores on the development set (dev) of the Spanish subtasks. Different types of training data are abbreviated as follows: regular (r), translated (t), semi-supervised (s).\n\nTable TABREF17: Top-ten models used in the submission of our final ensemble. The models are the result of stepwise removing models that do not improve on the dev set. Note that all combinations of models used in our final ensemble do not contain the same set of models.\nTable TABREF16: Final best models for the Spanish subtasks. Individual model scores are abbreviated as follows: reg (reg) and oc (occ) for emotion intensity tasks and reg (reg) and occ (occ) for sentiment tasks.\nTable TABREF15: Final ensemble selection for Spanish subtasks based on the results on dev set (dev) and dev+test (dev+test). The final models chosen are always part of an ensemble. Note that since none of the subtasks use the same lexicon in all subtasks, this means that the final models do not always use the same lexicon set.\nTable TABREF14: Characteristics of our semi-supervised corpus, with additional parameter settings of our training algorithm (LSTM, feed-forward).\nTable TABREF13: Parameters for model training. Different subtasks have different sets of parameters. The hyper-parameter parameters were searched as described in the text.\nTable TABREF12: Parameters for the regular training of our neural networks.\nTable TABREF11: Lexicon parameters used in our semi-supervised training.\nTable TABREF10: Lexicon parameters used in our training process.\nTable TABREF9: Libraries used in our implementation.\nTable TABREF8: Lexicon, feature-extractor and training data sets available in the AffectiveTweets package. The English lexicon was translated to Spanish. Note that the frequency and co-occurrence lexicon (F-set and C-set) are in English.\n\nTable TABREF7: Parameters for the",
    "8e52637026bee9061f9558178eaec08279bf7ac6": " This could be done in other studies, but also in a shared task, since these methods seem to be very versatile and might allow more effective research.\nReferences\n[BIBREF0] BIBREF1 SemEval 2018: Affect in Tweets Task for SemEval 2018 for the 8th edition of the SemEval\n\n[BIBREF1] BIBREF2] BIBREF3] BIBREF4] BIBREF5] BIBREF6] BIBREF7] BIBREF8] BIBREF9] BIBREF10] BIBREF11] BIBREF12] BIBREF13] BIBREF14] BIBREF15] BIBREF16] BIBREF17] BIBREF18] BIBREF19] BIBREF20] BIBREF21] BIBREF22] BIBREF23] BIBREF24] BIBREF25] BIBREF26] BIBREF27] BIBREF28] BIBREF29] BIBREF30] BIBREF31]\n\nSemEval is organized by the Association for Computational Linguistics with support from Microsoft Research and Google Inc.\nSemEval 2018: Affect in Tweets Task  \nhttps://competitions.codalab.org/comp/join/semeval18affecttwitter\n\n[BIBREF1] BIBREF2] BIBREF3] BIBREF4] BIBREF5] BIBREF6]\n\nGottfried Zimmermann, Iryna Rudzicz, Stefanie Mau-Riecker, Abigail See, Shyamal Ahuja, Emanuele Bertin, Edoardo Di Bernardo, and Niyaz Fatim. 2017. AffectiveTweets. https://zenodo.org/record/120427\n\n[BIBREF1] BIBREF2] BIBREF3] BIBREF4] BIBREF5] BIBREF6]\n\nGottfried Zimmermann, Iryna Rudzicz, Stefanie Mau-Riecker, Abigail See, Shyamal Ahuja, Emanuele Bertin, Edoardo Di Bernardo, and Niyaz Fatim. 2015. AffectiveTweets: A Corpus",
    "0f6216b9e4e59252b0c1adfd1a848635437dfcdc": " Regarding overfitting, more work on model testing and evaluation should be performed in order to be able to determine what causes this. Finally, further research can focus on improving the quality of automatic named entity recognition as these errors were one of the largest sources of error.\nACKNOWLEDGMENTS\nThis work was supported by NWO, the Institute for Computational Linguistics, and Microsoft Research.\nREFERENCE LIST\n\n[BIBREF0]\n\nZ. Zheng, A. Kann, S. Vuliov, A. Rios, E. Vazquez, J.-R. de Boer and P. Potthoff, \"Affective Tweets Shared Task at SemEval 2018\", In Proceedings of SemEval 2018, ACL (Association for Computational Linguistics), Berlin, Germany, 2018.\n\n[BIBREF1]\n\n\"Annoys, Annoyed, Annoys You, Anxious, Anxious, Angry, Anxious\", Manual annotated by the NLP group at the Vrije Universiteit Brussel, www.nlplab.be/affectintweets2018/annoys, Last accessed: 2017/11/13.\n\n[BIBREF2]\n\nB. Liu and K. Liu (2017). Twitter-based sentiment analysis on chinese historical events. Proceedings of 10th International Workshop Affective Computing and Intelligent Interaction (ACII'17).\n\n[BIBREF3]\n\nGensim: word2vec, A python library for developing word representations.https://radimrehurek.com/gensim/ word2vec.html\n\n[BIBREF4]\n\nAffectiveTweets: a package to detect emotion from tweets in multiple languages.https://www.kdd. cs.cmu.edu/2012-kdd/kdd-2012/kdd2012-papers/ Kudrna-Schweighofer, H. 2012-08-12. In KDD 2012: Proceedings of the 21st ACM SIGKdd Conference on Knowledge Discovery and Data Mining\n\n[BIBREF5]\n\nApertium: a multilingual web-facing MT platform.http://www.apertium.org\n\n[BIBREF6]\n\nAffectiveLex",
    "22ccee453e37536ddb0c1c1d17b0dbac04c6c607": " An ideal next step would be to explore the effects of data augmentation methods on other tasks and languages by looking at automatic translation and the use of unlabeled data as training data.\nBibliography\n\n1. Alm et al. (2016) Alm, Rastogi, Decker, D'Orazio, Bontcheva, and Grootendorst: Detecting emotions in tweets. NIPS '16, pp. 2287\u20132295, December, 2016. Available online at https://dl.acm.org/citation.cfm?id=3014269.3014304.\n2. Barreira, Pinto, Santos-Silva, Campos, Costa, and Marques (2013) Barreira, A. F., C. S.; Pinto, M. R.; Santos-Silva, A. C. A.; Campos, C.; Costa, R. C.; Marques, J. 2013. Affect in tweets. In: Proceedings of the International Joint Conference on Neural Networks (IJCNN). S. R. Das, and Y. M. Li (Eds.). IJCNN 2013. Vol. 2. S. R. Das, and Y. M. Li (Eds.). IJCNN 2013. IJCNN 2013. IJCNN 2013; pp. 1535\u20131539, August.\n3. BIBREF4.1. E-mails from the lead author to the authors, January 20, 2018; retrieved from https://gist.github.com/JohanLunz-Grabe/semeval-2018-affectintweets/32c0fff4edff7f0fa90cafcecbf4e8946a6d89c7e3b2d35a7c49ed34eb65c5eaf\n4. BIBREF4.2. E-mails from the lead author to the authors, February 10, 2018; retrieved from https://gist.github.com/JohanLunz-Grabe/semeval-2018-affectintweets/7be5a88f7a5ca39d4acecbdca14e6a4c2cee38e69dcfe4fed3d54f2366c1b7af\n5. BIBREF4.3. E-mails from",
    "d00bbeda2a45495e6261548710afa6b21ea32870": " For instance, our system did not have a problem with sentiment intensity for tweets written in Spanish. As the present study focuses on the use of Spanish-language resources, it remains to be studied if these methods will also help to determine sentiment intensity in other low-resource languages.\n\n\nFor all my readers,  \nwho make my life meaningful.  \nFor my grandparents,  \nAuntie Evelyn and Uncle Maw-Maw.  \nAnd for my parents:  \nDad, Mom, and big brother Ryan.\n\nAnd for all those wonderful,  \namazing, supportive readers  \nwho bought tickets for the  \nWorld Book Day event at the Book Barn.  \nFor those who made me want to be  \na writer in the first place.\nContents\n\n  1. Cover\n  2. Title Page\n  3. Copyright\n  4. Dedication\n  5. Contents\n  6. Prologue\n  7. Chapter One\n  8. Chapter Two\n  9. Chapter Three\n  10. Chapter Four\n  11. Chapter Five\n  12. Chapter Six\n  13. Chapter Seven\n  14. Chapter Eight\n  15. Chapter Nine\n  16. Chapter Ten\n  17. Chapter Eleven\n  18. Chapter Twelve\n  19. Chapter Thirteen\n  20. Chapter Fourteen\n  21. Chapter Fifteen\n  22. Chapter Sixteen\n  23. Chapter Seventeen\n  24. Chapter Eighteen\n  25. Chapter Nineteen\n  26. Chapter Twenty\n  27. Chapter Twenty-One\n  28. Chapter Twenty-Two\n  29. Chapter Twenty-Three\n  30. Chapter Twenty-Four\n  31. Chapter Twenty-Five\n  32. Chapter Twenty-Six\n  33. Chapter Twenty-Seven\n  34. Chapter Twenty-Eight\n  35. Chapter Twenty-Nine\n  36. Chapter Thirty\n  37. Chapter Thirty-One\n  38. Chapter Thirty-Two\n  39. Chapter Thirty-Three\n  40. Chapter Thirty-Four\n  41. Chapter Thirty-Five\n  42. Chapter Thirty-Six\n  43. Chapter Thirty-Seven\n  44. Chapter Thirty-Eight\n  45. Chapter Thirty-Nine\n  46. Chapter Forty\n  47. Chapter Forty-One\n  48. Chapter Forty-",
    "71b1af123fe292fd9950b8439db834212f0b0e32": "\n\nCitations:\n\nBird, S., U. Zwaan, and Y. Birchfield 2018. The LexiCC corpus: a new resource for mapping word senses across languages. Semantic Web, 6, 1\u201321. doi: 10.1007/s13229-017-0311-2\n\nBourges, E., K. T. J\u00e4ger, M. Uebel, B. Schuster, S. Poibeau, N. Rambow, A. Steenkamp, F. Keller, and A. van Durme 2015.\n\nExtracting bilingual lexicon induction data from parallel corpora with non-expert annotators. Computational Linguistics, 41(2):249\u2013269. https://link.springer.com/article/10.1007/s10583-015-9272-y\n\nBowlby, D. A., D. V. Smith, P. Garrette, A. L. Berwick, G. A. Koehn, and S. I. Smith 2013. Understanding the lexicon: insights from the NLP community through crowdsourcing. Computational Linguistics, 39(3), 345\u2013365. https://link.springer.\n\nBowlby, D. A., D. V. Smith, A. L. Berwick, S. Poibeau, G. A. Koehn, and P. Garrette 2012. The multilingual Oxford English dictionary. In Proceedings of NAACL 2012. Association for Computational Linguistics.\n\nBowlby, D., G. A. Koehn, and P. Garrette 2010. Open multilingual lexicon induction. In Proceedings of CoNLL 2010. Association for Computational Linguistics.\n\nBowlby, D., S. Poibeau, and D. V. Smith 2013. An open multilingual lexicon: Open Multilingual WordNet. In Workshop on Statistical and Computational Models of Texts, SCMT 2013. http://dx.doi.org/10.18653/v1/D11-1203.\n\nBowlby, D. A., D. V. Smith, A. L. Berwick, and G. A. Koehn 2011. The encyclopedia of language practices: exploring an open multilingual lex",
    "a616a3f0d244368ec588f04dfbc37d77fda01b4c": " The author thanks the DFG for support (German Science Fund: Grant ID HA 1794/3-1, TRR 257); the Leverhulme Trust for financially supporting their Research Fellowship; and the European Research Council (ERC-2018-CoG 769111) and the PRAIRIE 3IA Institute fellowship for their generous financial support (no ANR-19-P3IA-0001) for partial funding of Poibeau's research.\n\nMiklossy, B. (1990). Nouns and verbs across languages: Word order and the syntactic pattern for the verb\u2013adj-clause. Linguistic Inquiry, 21(3), 379\u2013409.\n\nMoore, L. N., and L. G. C. Potts. (2005). Automatic extraction of lexical semantic concepts. Computational Linguistics, 30(1), 1\u201330.\n\nPasternak, N., J. Niebergall, L. Cai, and L. G. C. Potts. (2017). SimCup: Unsupervised creation of word similarity judgments for English and related languages. Computational Linguistics in the Benasque Computational Linguistics Winter Workshop (CICLing), 2, 1\u201318.\n\nPoibeau, T. (2012). A statistical measure of translation quality for lexicons based on word pairs. Proceedings of Eurospeech.\n\nPonti, C., B. Sukumaran, C. Chen, N. Pasternak, J. Niebergall, A. L. S. Wong, L. Cai, S. P. Lee, S. Park, J.-S. Lee, B. M. B\u00fcchel, L. G. C. Potts, and L. G. R. Potts (2018). What's in a semantic similarity vector? The CL-POSTSPEC framework. In Proceedings of NLS-WST Conference: Empirical Methods in Natural Language Processing, pages 137\u2013146.\n\nPoibeau, T., Zhai, G. Chen, C. Chen, A. C. Ng, F. Bian, S. Al-Rfou, N. Pasternak, J. Niebergall, and L. G. C. Potts (2019). Cross-lingual distributional similarity and transfer learning for lex",
    "8e44c02c2d9fa56fb74ace35ee70a5add50b52ae": "\n\nReferences\n\n[1]   Havasi, Peter, Gjergji Gjoni, and Martin Suchanek.\n\n[2]   \n\n[3]   \n\n[4]   \n\n[5]   \n\n[6]   \n\n[7]   \n\n[8]   \n\n[9]   \n\n[10]   \n\n[11]   \n[12]   \n\n[13]   \n\n[14]   \n\n[15]   \n[16]   \n[17]   \n[18]   \n[19]   \n[20]   \n[21]   \n[22]   \n[23]   \n[24]   \n[25]   \n[26],\n\n[27],\n\n[28]\n\n[29]   \n[30],\n\n[31]   \n[32],\n\n[33]   \n[34]   \n[35],\n\n[36] H. Dyer.\n[37]   \n[38]   \n[39]   \n[40]   \n[41]\n\n[42]   \n[43]   \n[44]   \n[45]\n[46]   \n[47]   \n[48]   \n[49]   \n[50]\n\n[51]   \n\n[52],\n\n[53]   \n[54]\n\n[55]   \n[56]   \n[57]   \n[58],\n\n[59],\n\n[60]   \n[61]\n\n[62]   \n[63]   \n[64]   \n[65],\n\n[66]   \n[67]   \n[68],\n\n[69]\n\n[70]   \n[71]   \n[72],\n\n[73]   \n[74],\n[75]   \n[76],\n[77]   \n[78] H. Dyer.\n[79]   \n[80]   \n[81]   \n[82]   \n[83]   \n[84]   \n[85] H. Dyer.\n[86]   \n[87]   \n[88]   ",
    "1522ccedbb1f668958f24cca070f640274bc2549": "\n\n\n\nTo the memory of Jules Feiffer, who died on a morning in February, a morning that we share, with time.\nOther books by Jon Scieszka:\n\nA BOOK IS A NOMAD AND OTHER JULES FEIFFER STORIES\n\nTHE WORD WAR (with Lane Smith)\n\nA BOOK OF WITCHES AND WIZARDS (with Lane Smith)\n\nJON SCIESZKA'S GUIDE TO THE GREAT WORD WAR (with Lane Smith)\n\nJOYFUL NOISE AND OTHER POEMSTERS\n\nKAKOOSLEPPY THE GREAT AND OTHER CREATURES (with Lane Smith)\n\nHOW I SAVED THE WORLD (with Lane Smith)\n\nTHE STINKY CHEESEMAN AND OTHER STORIES\n\nSHAPE UP!\n\nTHE TRUE STORY OF THE THREE LITTLE PIGS:\n\nAND A WHOLE LOT MORE STORIES\n\nThe True Story of the Three Little Pigs:\n\n_And a Whole Lot More Stories_\n\n_illustrated by_\n\n_Mike McClintock_\n\nPicture Archipelago Books\n\n_for young readers aged five to eight_\n\nCopyright \u00a9 2004 Jon Scieszka\n\nAll rights reserved. No part of this publication may be reproduced or transmitted in any form or by any means, electronic or mechanical, including photocopying, recording, or any information storage and retrieval system, without permission in writing from the publisher.\n\nThe illustrations in this book are printed and composed in Canada.\n\n**Library and Archives Canada Cataloguing in Publication**\n\nScieszka, Jon, 1943-\n\nThe true story of the three little pigs / Jon Scieszka ; illustrations by Mike McClintock.\n\nISBN 978-1-77138-071-5\n\nI. McClintock, Mike. II. Title.\n\nPZ7.S1556Tr 2006\n\n[DNF/Y]\n\n813.5214 C37 2006a\n\n813.52\u2014dc22\n\n2006011492\n\n**Note to the Reader**\n\nThis book has been written especially of and for the most delightful listeners in the world, listeners who happen to be young, young readers (",
    "97466a37525536086ed5d6e5ed143df085682318": "\nReferences\n\n[Ackerman.1987] Ackerman, J. M., Tansupaiboon, I., and Radev, D. (1987). Summarizations From Text: Automatic Construction, Evaluation, and Retrieval. In: R. T. Colwell, ed., Proceedings of Conference on Application of Computational Linguistics to the Translation Enterprise (ACLTE-6), Los Alamitos: CSLI Publications.\n\n[BIBREF0] Buzi\u00e9res, E., Schuller, J., and Mancewicz, S. (1999). Learning Summaries from Multiple Documents: A Neural Model of Conceptual Inferencing. Paper presented at AAAI 1999.\n\n[BIBREF1] Bizzaro, U., Mancewicz, S., and Schuller, J. (2006). Automatic generation of summaries from multiple documents. In: Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2006), Valletta, Malta, pp. 1\u20136.\n\n[BIBREF1K]\n\n[BIBREF1S/AB] Bizzaro, U., Mancewicz, S., and Schuller, J. (2008) Automating a Summarization Task Using Neural Models. Proceedings of COLING 2008: 21st Annual Conference on Computational Linguistics.\n\n[BIBREF2]\n\n[BIBREF2L/BJ] Bizzaro, U., Mancewicz, S., and Schuller, J. (2008). A Neural Approach to Automated Summarization of Multiple Documents. Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics.\n\n[BIBREF3]\n\n[BIBREF3K]\n\n[BIBREF3S/BT] Bizzaro, U., Mancewicz, S., and Schuller, J. (2008). User Study on Abstractive Summarization of Multiple Documents: Understanding Human Summarization Behavior. In: Proceedings of 40th Annual Meeting of Association for Computational Linguistics.\n\n[BIBREF4]\n\n[BIBREF4K]\n\n[BIBREF4S/BP] Bizzaro, U., Mancewicz, S., and Schuller",
    "e9cfbfdf30e48cffdeca58d4ac6fdd66a8b27d7a": "\nThe authors have no proprietary interest in any of the commercial vendors mentioned in this document.\nThis document was prepared under the auspices of the European Union. It reflects solely the authors' views, which are responsible for its content.\nTo fully understand and appreciate this scientific contribution one should read the\noriginal, original-language version of the document or one of the translations published in parallel with it.\nThe original version of this document was available in many languages. We have endeavored to preserve the meaning of the article in case of any minor unintentional change caused by the process of\ntranslation. Insofar as this has not been possible, the changes required to ensure the accurate, equivalent and unambiguous communication are clearly\nmarked in the form of footnotes.\n\n\n*Corresponding author\n\nThis document is a translation of a public document previously published in\n\nWIR 3 4 (12), no. 19&20, 2013 (DOI:10.17872/19.20)\n\n**This article is dedicated to the memory of my mother, G\u00fcnter Wegener\n\n**Translated by Sergio Pellegrini and\n\nRaffael Mersh\n\n## Abbreviations\n\nThis article includes:\n\n\u2013 acronyms,\n\n\u2013 cross-references to figures and tables,\n\n\u2013 a glossary page containing abbreviations and acronyms defined in the text in the format:\n\n### Abbreviation:\n\n### Cross-Reference:\n\n### Glossary\n\n### Reference URL:\n\n## SECREF1.\n\nC. T. P. Hill. 1972. A Concept Map Approach to Teaching and Learning: A Brief Introduction.\n\nThe Journal of American Education, 83(1): 29-37.\n\n# SECREF2.\n\nWe believe that the focus on the MDS task and its definition is what allows the task to be more in line with realworld application scenarios, where users will not typically only be interested in finding and reading summaries but rather also have to act upon information extracted from them. In contrast, earlier attempts BIBREF1, BIBREF9, BIBREF14, BIBREF17 had focused on summarizing a single document.\n\n\n+ SECREF3 : There is also the possibility to show the concept map to a novice user and ask them to write a summary",
    "d6191c4643201262a770947fc95a613f57bedb6b": "\nReferences\n\n[BIBREF1]\n\nCierniak, M., Buitelaar, P., de Rijke, J., Krahmer, B. A., Leech, M., Mihalcea, C., Nencka, M. (2010).\n\nMulti-document summarization.\n\nAI magazine, Vol. 21(1): 29-47.\n\nDOI: 10.1016/j.artint.2010.02.001\n\n[BIBREF2]\n\nMani, B., Lin, M., Nencka, M., Zhai, H., Radev, D. (2011).\n\nMulti-document summarization based on sentence clustering.\n\nProceedings of the Conference on Empirical Methods in Natural Language Processing, pp. 67\u201374.\n\nISBN: 978-1-59430-804-9\n\n[BIBREF3]\n\nLebus, M., Parni, M., Meignan, T., et al. (2013).\n\nDesigning and evaluating visual summary helpers for multilingual news.\n\nJournal of the American Society for Information Science and Technology (JASIST), Vol. 64(1), pp. 1\u201323.\n\nDOI: 10.1002/asi.22166\n\n[BIBREF4]\n\nMarsella, G., Gruninger, H. R., Fossati, M., et al. (2014).\n\nEvaluating a multi-document summary visualizer for scientific articles in multiple languages.\n\nProceedings of the 30th Conference of Association for Computational Linguistics (ACL 2014), Vol. 1, pp. 1428\u20131437.\n\nISBN: 978-1-977619-70-1\n\n[BIBREF5]\n\nDe Vreede, C., Leyenc, G. (1972).\n\nConcept mapping: A teaching tool to assist learning and thinking.\n\nCommunications of the ACM, Vol. 5(9), p. 654-664.\n\n[BIBREF6]\n\nDe Vreede, C., De Vreede, F. L. (1972).\n\nConcept mapping in language teaching.\n\nIn Communications of the ACM 10 (9",
    "ffeb67a61ecd09542b1c53c3e4c3abd4da0496a8": "\nAppendix A: Details\nWe provide an extended version of the corpus construction process in \u00a7 A.1, describe the details of the evaluation process in \u00a7 A.2 and our annotation tool, along with its architecture, in \u00a7 A.3. We close this appendix by listing relevant details and requirements used in our pilot study and the creation of our reference corpus in \u00a7 A.4.\nA.1 Corpus Construction Process\nFigure FIGREF16 shows the steps of our crowdsourcing scheme used to create the corpus.\nA.1.1 Source Data\nWe start by collecting a cluster of documents for each cluster topic. For this purpose, we use the DIP corpus BIBREF37, a collection of 49 clusters of a hundred web pages around educational topics. We select 30 of these topics and use the Open IE system BIBREF39 to process them. As the output is not suited for our purpose, we then develop an annotation scheme to extract the appropriate spans from the data as the basis for our summaries. Specifically, we use the confidence score to ensure that only high quality information is included in the corpus with a filter threshold \u03f5=0.5 as described in \u00a7 SECREF21 and \u00a7 SECREF20. From these selected propositions, we filter out those that are unlikely to be referenced in the summary. To avoid redundant effort, this process is carried out once for the whole corpus. In total, we produce 97,880 propositions on average per topic, with an individual amount varying between 2500 and 4500 propositions (Table TABREF27 ).\nA.1.2 Task Design\nWe break down the given propositions into tasks consisting of single propositions and group a maximum of five of them per task. This results in a task size of around 300 propositions per topic. In a preliminary study described in \u00a7 SECREF28, we found that people find tasks consisting of only single propositions easier to annotate, which was confirmed in this work for the tasks of expert and low-context annotation. Then, we rank the propositions by their importance ( \u00a7 SECREF5 ) and select top 100 for each topic to create a consensus summary.\n\nA.1.3 Task Crowdsourcing\nFigure A.1 shows a sample task. The instructions tell workers to determine the importance of the given propositions, which in this case has four possible scores, 0, 5, 10 or 15. In each of the tasks, five propositions are randomly displayed",
    "fc4ae12576ea3a85ea6d150b46938890d63a7d18": "\nFurther work and discussion\nAs Finnish language is much more morphologically rich than English and also contains a lot of spelling variations the results here could be improved with more hyper parameter search as the translation space for unsupervised pre-training is larger than a unidirectional models and we need to do a more thorough search of the hyperparameters. Also, it would be interesting to try the Transformer-XL models with a similar pre-training data with different tokenization schemes like BERT's.\nAcknowledgements\n\nI wish to thank the Soleimani family for supporting my education and learning. I would also like to thank Professor Richard Socher and Professor Denny Piao for their help in the initial stages of this project and their willingness to answer all my questions. I also want to express my gratitude toward my colleagues in class for the constant suggestions and support throughout my work. This paper would not have been possible if not for my supervisor Mr Nils Holmberg, whose unwavering, patience and help throughout this project made this paper possible. I also would like to thank the NLP group and the department of computer science at \u00c5bo Academy for their constant support and guidance.\n\nReferences\n\n[AUTHOR1] Theano, C.: Deep learning library for researchers and scientists. 2017. https://pypi.org/project/theano.\n\n[AUTHOR2] BIBREF3: Yonini, R., Sogaard, C., Shwartz-Ziv, S., and Graff, Y. (2017) Glove: Global vectors for word representation. 2013. http://glove.stanford.edu.\n\n[AUTHOR3] BIBREF5: Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, B., and Polosukhis, M. (2017) Attention is all you need. In: Proceedings of the 2017 Conference on Neural Information Processing Systems, pp. 5994\u20136015. https://arxiv.org/abs/1706.03762.\n\n[AUTHOR4] BIBREF7, P. and Zheng, H. (2017) BERT: Pre-training of deep bidirectional transformers for language understanding. 2018. https://arxiv.org/abs/1810.04805.\n\n[AUTHOR5] BIBREF8, Jout",
    "19cf7884c0c509c189b1e74fe92c149ff59e444b": "\n\nReferences\nBengio, Yoshua. \"Cramming more features into RNNs.\" CoRR abs/1409.1749 (2014). Accessed 2017 March 9.\n\nRanzato, Maria-Elena, Marco Baroni, Martin W\u00f6rthinger, Matteo Negri, Andrea Al-Rfou, and Tom Ziemke. \"BERT: Pre-training of deep bidirectional transformers for language understanding.\" arxiv:1901.01291 (2019). Accessed 2017 March 9.\n\nLiu, Xianyi, Mingyuan Liu, Shuyu Zhu, and Shiqi Wu. \"The transformer model: Literally explaining all things.\" CoRR abs/1801.00118 (2018). Accessed 2017 March 9.\n\nTai, Yi, and Zhifeng Yin. \"XLM: Extreme light pre-training for language understanding.\" arxiv:2010.06530 (2020). Accessed 2017 March 9.\n\nHindiusten-Sa, Mikko, Jussi H\u00e4rk\u00f6nen, and Antti Oulasvirta. \"Improving language modeling with Morfessor subword models.\" CoRR abs/1906.03682 (2017). Accessed 2017 March 9.\n\nKorhonen, Jussi, Luka Koivisto, Antti Oulasvirta, Teemu Keskinen, and Samuli Laine. \"Morfessor: Fast subword tokenization using character ngrams\". CoRR abs/1905.07362 (2019). Accessed 2017 March 9.\n\nAkkoyunlu, Arda, David E. Lewis, and Sebastian M. Kohler. \"Subword language models improve language modeling performance of RNNs.\" CoRR abs/1705.07742 (2016). Accessed 2017 March 9.\n\nAkkoyunlu, Arda, David E. Lewis, Yann LeCun, and Sebastian M. Kohler. \"Long-range context for language models by incorporating unspoken text.\" CoRS arxiv.org/1711.00468. Accessed 2017 March 9.\n\nLi, Ying, and Jingtian Lu. \"Fast and Accurate Language Modeling with GPT-2.\" CoRR abs/1906.04146 (2019). Accessed 2017 March",
    "ecd5770cf8cb12cb34285e26ab834301c17c53e1": "\n\nReference\nBIBREF0 J. D. Antol, J. Fulton, and K. A. S. Yu, \"VQA: Visual question answering,\" in Conference on Computer Vision and\nPattern Recognition, 2010. BIBREF1 F. W. T. M. Chow, E. Hovy, and J. L. Martinez, \"Question answering systems: A survey,\" ACM Computing Surveys, vol. 44, no. 2, pp. 115\u2013163, 2012. BIBREF2 Ioffe and Szlam, \"Very deep convolutional networks for very large-scale image recognition,\" in Proceedings of the 2015 Conference on Neural Information Processing Systems, 2015. BIBREF3 Dosovitskiy and Brox, \"Question answering and machine learning from a visual perspective,\" in Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP), 2015. BIBREF4 C. D. G. Almeida and F. W. T. M. Chow, \"Answer selection from multiple answer sets: A survey,\" ACM Computing Surveys, vol. 51, no. 3, pp. 85\u2013138, 2019. https://dl.acm.org/doi/fullText/10.1145/3050768.3050787. BIBREF5 F. W. T. M. Chow, J. L. Martinez, and K. A. S. Yu, \"VizWiz, \"Pushing knowledge retrieval towards the limits of crowdsourcing,\" Advances in Database Processing, vol. 30, no. 1, pp. 1\u201314, 2014. BIBREF6 H. Welleck and T. J. Schofield, \"Answer selection for crowdsourced question-answering systems,\" in Proceedings of the 22nd Pacific-Asia Conference on Language, Information and Computation, 2011. BIBREF7 J. L. Martinez, G. Muresan, and S. Y. J. Su, \"Machine answer selection for questionanswer dialogues: A survey,\" ACM Computing Surveys, vol. 44, no. 2, pp. 199\u2013228, 2012. BIBREF8 J. L. Martinez, G. Muresan, and S. Y. J. Su, \"Machine answer selection for question-answer dialogues: An empirical study,\" Journal of Intelligent and Rob",
    "4a4ce942a7a6efd1fa1d6c91dedf7a89af64b729": "\n\nReferences\n\nBIBREF\n\nBauer, D., Scholthof, H., Acero, L., and Kr\u00f6se, S. \"VizWiz: a question answering competition for the open visual content. In Proceedings of the Twenty-third ACM International Conference on Multimedia, pp. 1417-1424. 2011.\"\n\nBIBREF\n\n  1.. A. Antol, K. Laptev, T. Sutskever, J. Y. Dean, and B. Guestrin. \"Image question answering with deep neural networks.\" In Proceedings of the Twenty-third International Conference on World Wide Web: WWW '15. 2015.\n\nBIBREF\n\nBaumbach, M., Laptev, V., Sutskever, I., Dean, J., and Deng, H. \"Visual question answering.\" CoRR abs/1506.0115. 2015.\n\nBIBREF\n\n  1.. S. Gunturk, W.-y. Oh, N. Nair, and D. W. Lowe. \"VizWiz 2.0: a benchmark question answering test for the visual content.\" In Proceedings of the Twenty-third ACM International Conference on Multimedia, pp. 1628-1633. 2011.\n\nBIBREF\n\nHu, H., S. Choi, O. Dosovitskiy, A. E. Acero, N. Nairn, U. Fowlkes, J. Xiong, E. X. Larochelle, K. Saha, and D. W. Lowe. \"Vqa challenge 2015 v1.1: a large-scale benchmark for visual question answering benchmark.\" CoRR abs/1505.03498. 2015.\n\nBIBREF\n\n  1.. S. Das, A. E. Acero, and D. W. Lowe. \"Efficient crowd-sourced answer collection for visual question answering with reinforcement learning.\" In Proceedings of the European Conference on Computer Vision (ECCV), pp. 433\u2013444?2015, 2015.\n\nBIBREF\n\nS. Das, A. M. Daballaban, M. Paluri Rajagopalan, D. W. Lowe, and D. G. Lowe. \"Answer agreement in visual question",
    "5529f26f72ce47440c2a64248063a6d5892b9fde": "\nFigure 8: Training Loss for Transformer and our model.\n\nFigure 22: Validation Performances for our model and Transformer (at step 15,000)\n\nFigure 23: Validation Performance for our model and Transformer (at step 15,000)\n\nEvaluation of NMT for Balanced Translation\n\nGiven a query term, we compute the ratio of the probability of INLINEFORM1 being in TC or RC for INLINEFORM0 and INLINEFORM2.\n\nEvaluation of RAT for Balanced Translation\n\nAs proposed by BIBREF05 and BIBREF10, we define two scores that count number of times INLINEFORM9 does not contain words from TC. We then add those scores to evaluate the model based on those two scores, INLINEFORM10, INLINEFORM11.\nTable 2: Statistics of Scores for Italian and Finnish query translation.\n\nTable 4: Statistics of Scores for English and German query translation.\n\nTable 6: Statistics of Scores for Czech and French query translation.\n\nTable 8: Statistics of Scores for Spanish and Italian query translation.\n\nTable 10: Statistics of Scores for Hindi and Italian query translation.\n\nTable 12: Statistics of Scores for Serbian and German query translation.\n\nTable 14: Statistics of Scores for Portuguese and Italian query translation.\n\nTable 16: Statistics of Scores for Portuguese and Serbian query translation.\n\nTable 18: Statistics of Scores for Vietnamese and Thai query translation.\n\nTable 20: Statistics of Scores for Vietnamese and Serbian query translation.\n\nTable 22: Statistics of Scores for Swedish and Thai query translation.\n\nTable 24: Statistics the Scores for Swedish and Swedish query translation.\n\nTable 26: Statistics of Scores for Hindi and Thai query translation.\n\nTable 28: Statistics of Scores for Spanish and Filipino query translation.\n \n**_Praise for Caitlin Kittredge's Novels of Fantasy_**\n\n**_The Shadows of Bharath_**\n\n\"The Shadows of Bharath is an addictive and engrossing story that shows how important it is to make the best of our circumstances, no matter what they are.\"\n\n_\u2014Library Shelf_\n\n\" _The Shadows of Bharath_ is one of those rare novels in which the ending is just the beginning.\"",
    "f85ca6135b101736f5c16c5b5d40895280016023": " The word embedding task, however, shows little loss value after the first few training steps.\n\nWe computed the translation balanced score for Europarl and clef corpus. Figure FIGREF27 and shows that transformer performs poorly in both corpora. Transformer has vocabulary mismatch issues and tends to overfit to terms from translation corpus. Figure FIGREF30 shows the balanced score for Europarl and clef corpus.\nOur model can still achieve significant performance improvement when compared to baseline Transformer. Figure FIGREF28 shows the balanced score for Europarl and clef corpus.\nTransformation Layer Comparison\nWe compare the behavior of transformation layer between our model and Transformer. First, in Table TABREF20, we show a comparison of loss function values across different NMT architectures when trained on English-German pairs. We can see that transformers suffers vocabulary overfit, while our model gets better scores for the transformation layer and its loss function, i.e. INLINEFORM35 falls much slower than INLINEFORM36 for our proposed architecture.   In comparison, Figure FIGREF29 show the transformation layer behavior between our model and Transformer. We can clearly see that our model and the baseline share more common vocabulary. Transformer ignores relevant terms such as free, gold while transforming to olypmic. Since we use a single loss function for Transformer, both of them focus on generating high probabilities for their training terms and ignore terms that have been removed from the target set. In contrast, our multi-task architecture improves the translation by forcing the decoder to assign probability to terms that are equally likely for Europarl and CLEF, i.e. INLINEFORM26 and INLINEFORM35.\nFinal Representation Comparison\nWe compare the final representation space between our model and Transformer. Figure FIGREF31 shows the comparison of vector space for different architectures. We can see that transformer generates overfit vectors with the same words occurring across INLINEFORM32 and INLINEFORM33 in the target side for Europarl and CLEF respectively. Figure FIGREF32 shows final representations between our and baseline transformer to English sentences in Europarl and CLEF.\nFinal Representation Analysis\nThe final representation vector for an input sentence is the linear transformation of the target embedding layer followed by the softmax layer. Here, INLINEFORM3 and INLINEFORM4 refer to source sentence and human translation respectively. Figure FIGREF33 shows the comparison of final representation",
    "5fa36dc8f7c4e65acb962fc484989d20b8fdaeec": "\nD) Consumer Health Questions and Answers:\nE) Our Entailment-based QA System:\n1 TREC 2017 Liveqa-medical Overview:\n2 Bowmann, H., D. C. Cox, T. Kiros, D. G. Feeny, Q. Wang, and E. V. Kandel : Multilingual Question-Answer Search with Contextualized Attention, in Proc. of the 54th Annual Meeting of the Association for Computational Linguistics (ACL-IJCNLP 2015), 2015.\n3 Bowman, H., D. C. Cox, T. Kiros, D. G. Feeny, Q. Wang, and E. V. Kandel : Recognizing Question Entailments: A Deep Learning Approach to Machine Question Answering, in Proc. of the International Conference on Document Analysis and Recognition Workshop on Deep Learning for Text Mining (Da-Re 2015). Association for Computational Linguistics.\n4 Tan, B., C. Yang, W. W. Cohen, E. X. Zhan, E. T. G. Wong, Y. Yao, and Z. Chen : Deep Learning for Question and Answer Retrieval, in Proc. of the International Joint Conference on Computational Linguistics (IJCNLP 2016), 2016.\n5 Dos Santos, M. et al. : Recognizing Question Entailments Via Syntactic and Semantic Representations, in Proc. of the 49th Annual Meeting of the Association for Computational Linguistics (ACL-IJCNLP 2017), 2017.\n6 Bowmann, H. et al. : Machine Question Answering with Contextualized Attention Networks, in Proc. of the International Conference on Acoustics, Speech and Language (ICASL 2017), 2017.\n7 Lei, L., D. C. Cox, H. O. A. Kandel, and E. V. Kandel : Neural Question Identification for Recognizing Question Entailment, in Proc. of the 54th Annual Meeting of the Association for Computational Linguistics (ACL-IJCNLP 2016), 2016.\n8 Bowmann, H., J. B. Tenenboom, R. H. G. van de Sande, S. O. Kitson, and H. Li, in",
    "d98847340e46ffe381992f1a594e75d3fb8d385e": "\n\nD) Annotator A:\n\nE) Annotator B:\n\nF) Annotator C:\n\nThe question is about congenital diaphragmatic hernia, which is a type of congenital birth injury and could be prevented through genetic testing in the pregnant mother. The assessors did not mention the focus and the question type but the QA system did. The assessor A also provided the reason for the low ratings as: \"Incorrect answer, not medically oriented (other questions were reviewed and answers were much more clear. This answer was more about the possible reasons for \"cousin marriage\"...).\nB) Our IR-based QA System:\n\nG) Our IR+RQE system:\n\nH) Annotator A:\n\nI) Annotator B:\n\nG) Our IR-based QA System:\n\nJ) Our IR+RQE system:\n\nK) Annotator A:\n\nL) Annotator B:\n\nM) Annotator C:\n\nN) Annotator A:\n\nO) Annotator C:\n\nP) Annotator B:\n\nL) Our IR-based QA System:\n\nQ) Our IR+RQE system:\n\nIn this question, many of the QA systems retrieved \"legionnaires disease\" as an answer. The only correct answer is \"Pontiac fever\", which is an infection caused by bacteria of the genus Legionella. The correct answer was \"Legionnaire disease\" in the case of this question, but incorrect because the LiveQA-Med assessors had a different understanding of what \"legionnaires disease\" might mean (e.g. the history of how it was named).\n\nIn this question, we can see that the assessor B does not fully agree with the reasoning of Annotator A, as the answer (\"Torticollis\") was not clear enough and the reason suggested for the low ratings was the following: \"There is some debate about torticollis, that some say yes, some say no that is possible for torticollis to have a genetic component\".\nThe question is about Torticollis, or Wryneck, a type of Dystonia or Spasmodic Torticollis. Spasmodic or writhing is a medical term for involuntary muscle movements",
    "7006c66a15477b917656f435d66f63760d33a304": "\nReferences\n\n[AusK\u00fcstenKomm]: http://www.sds.informatik.tu-muenchen.de/resources/usersimulator.html\n\n[BIBREF1 ] (2015) G. P\u00f6tzli. \"Human-Computer Spoken Dialogue: A Survey\", Ph.D. Thesis, University of Vienna.\n\n[BIBREF2 ] (2010) G. P\u00f6tzli, M. Koutsovou, and R. Eslami. \"Learning Dialogue Management Policies from Example Dialogues with Reinforcement Learning\". AAAI Fall Symposium Series.\n\n[BIBREF3 ] (2010) G. P\u00f6tzli, M. Koutsovou, and R. Eslami. \"Deep Semantic Alignment for Building User-Centric Dialogue Systems\". In Proceedings of the 11th International Conference on Language Resources and Evaluation (LREC'2010).\n\n[BIBREF4 ] (2018) P. Sheffler, M. Koutsovou, and R. Eslami. \"Using Neural User Simulators to Evaluate Dialogue-System Dialogue Policies\". In Proceedings of the Eleventh Dial-O-Food Challenge Conference Workshop (DSTC-Workshop), pages 1-8.\n\n[BIBREF5 ] (2017) K. Renn, M. Koutsovou, C. Lauscher, M. Schein, and F. Kreyssig. \"Towards End-to-End Dialogue Systems: Modeling User Feedback for Goal-Oriented Dialogue using Layers of Compositionality\". In Proceedings of the 15th International Conference on Spoken Language Processing (Interspeech'17).\n\n[BIBREF6 ] (2018) M. Koutsovou, F. Kreyssig, and R. Eslami. \"Agenda-Based User Simulation for Spoken Language Systems\". In International Conference on Spoken Language Processing (ICSLP'17).\n\n[BIBREF7 ] (2015) C. Lauscher, M. Koutsovou, and F. Kreyssig. \"Cross-Model Evaluation of User Simulators for Spoken Language Systems\". In International Conference on Spoken Language Processing (ICSLP'14).\n\n[B",
    "a15bc19674d48cd9919ad1cf152bf49c88f4417d": " Srinath Sreenivasan and James Bradbury acknowledge the support of the ERC Starting Grant DREAMN.\nReferences\n\nAllen, N. A., K. F. McDermott, F. R. Manikas, K. Y. Lee, M. E. Riloff, and D. R. McAllaster. 2011. Automatic speech recognition with hidden markov models, in Proceedings of the International Conference on Spoken Language Processing, pp. 3\u20139.\n\nBattaglia, P., S. Gubbay, C. Ermon, C. Gauthier, F. G. Bellem, and A. M. Chinchill. 2009. Conversational semantics as dialogue management policy, in Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics, pp. 17:2\u20133:34.\n\nBohus, I., A. Gez\u00e8re, A. P. Clark, K. K. DeGispert, M. D. Crowe, W. H. Clancey, A. D. Crook, N. D. Dilley, Y. C. Jing, M. G. Kr\u00f6se, F. Lageweg, M. W. Lewis, C. F. Macsai, N. Marelli, and M. A. C. Moore. 2015. User simulators for spoken dialogue systems, in Proceedings of the Conference on Empirical Methods Studies of Linguistic and Cognitive Science, pp. 1:2118\u20131:2423.\n\nBohus, I., K. K. DeGispert, G. Erhard, and S. Chinchill. 2016. Predicting multimodal user actions from text based dialogue state tracks, in Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics, pp. 3:2677\u20132:34.\n\nCarl, E., L. M. Schatzmann, and K. O. Franz. 2001. Dialogue act and slot assignments in spoken language understanding, in Proceedings of the Conference of the Association for Computational Linguistics, pp. 17:1\u20133:20.\n\nCho, H., J. R. Boutillon, and B. W. L. Smith. 2015. Probabilistic inference with continuous-",
    "440faf8d0af8291d324977ad0f68c8d661fe365e": "\nAcknowledgments\n\nThe author wishes to thank Prof. Tatsuo Ishizaka for his valuable comments. References[\n\nS. Agarwal, T. Ishizaka and A. G. Baral. \"Learning latent structures for content analysis from text corpus.\" In Proceedings of the 9th Workshop on Artificial Intelligence and Cognitive Science, 2016.| Cited by: 0\n\nS. Agarwal, P. S. Yu and A. G. Baral. \"Multi-dimensional term frequency model for bag of words.\" In Proceedings of the 25th International Joint Conference on Artificial Intelligence (IJCAI'13) and 23rd International Conference on Automated Reasoning (ICAR'13), 2013.| Cited by: 8\n\nS. Agarwal, G. Khatry, A. G. Baral and M. P. Balakrishnan. \"Latent semantic indexing: using singular value decomposition to analyze documents.\" In Proceedings of the 28th International Joint Conference on Artificial Intelligence and 26th Conference on Uncertainty in Artificial Intelligence (IJCAI'07 and UAI'07), 2007, pp. 1134\u20131140v|\n\nR. Borda, X. Carreras, P. Vidal, P. Valero and J. J. Toral. \"Latent semantic analysis for information retrieval with weighted words and user's feedback.\" In Proceedings of the 32nd International Conference on Machine Learning (ICML'13). Conference: Proceedings of the 32nd Conference on Neural information processing systems: NIPS 2009, 2009. | Cited by: 22\n\nS. Boutsidis, Y. Guo, S. Dhananjaya, I. Joty, K. Graff, K. Saenko and K. S. Vadhyeswaran. \"Fast and smooth word2vec.\" In Proceedings of the 30th Conference on Neural Information Processing Systems (NIPS 2014), 2014. | Cited by: 43\n\nM. T. Chen and W. Chang. \"Deep context embedding: Improving deep learning representations for text classification.\" In Proceedings of the 36th Annual Conference on Neural Information Processing Systems (NIPS 2015), 2015. | Cited by: 16\n\nM. Cho and H.-S. Yang, \"Explainable classification using recurrent neural networks,\" The Journal of Machine Learning Research, 2017,",
    "0ec56e15005a627d0b478a67fd627a9d85c3920e": " We would like to thank the two anonymous reviewers for their feedback. They are also thanked for the fruitful recommendations of some useful works that helped in the manuscript preparation.\nBIBREF0 B. Yu, J. X. Pan, and J. Lui, \"Latent semantic indexing for text retrieval,\" in Proc. 28th Intl. ACM-SIGIR Conf. Research and Development in Information Retrieval, 2009, pp. 183\u2013189.\nBIBREF1 C. B. C. R. Pereira et al., \"Latent semantic analysis (LSA): A tool for automatic indexing,\" IBM Rep. RD-90, 1991, pp. 1\u201315.\nBIBREF2 C. B. C. R. Pereira and C. M. R. Vasquez, \"Multinomial naive bayes: a bayesian text retrieval technique,\" in Proc. 25th Intl. ACM-SIGIR Conf. Research and Development in Information Retrieval, 1998, pp. 31\u201337.\nBIBREF3 P. Resnik, C. B. R. Pereira, C. D. M. Feigl, and S. V. Ramaswamy, \"Efficient learning and inference for multinomial multinominoal Bayesian latent semantic indexing,\" in Proc. 25th Intl. ACM-SIGIR Conf. Research and Development in Information Retrieval, 1998, pp. 41\u201349.\nBIBREF4 J. Eichmann et al., \"Fast word representation using deep neural networks,\" in Proc. 11th Intl. Conf. Deep Learning, 2016, pp. 1728\u20131734.\nBIBREF5 S. Z. Bai et al., \"Neural network approaches to ranking and clustering,\" in Intl. Journal of Machine Learning and Cybernetics, vol. 36, 2004, pp. 235\u2013245.\n\nBIBREF6 S. Farhadi, P. Resnik, C. B. R. Pereira, and J. M. A. Smith, \"Language-independent word representation using neural networks,\" in Proc. 34th Int. ACM-SIGIR Conf. Research and Development in Information Retrieval, 2006, pp. 261\u2013269.\n\nBIBREF7 R. Chen et al., \"Universal sentence embedding for semantic similarity across very large vocabularies,\" in",
    "a712718e6596ba946f29a99838d82f95b9ebb1ce": "\nA Note on Terminology\nWe followed a practice in the existing work to select a set of medical abbreviation terms that we believe should have been widely encountered by practicing physicians. After a careful review of all the abbreviations, we decided to train the model on 30 commonly encountered term-sense pairs (on average 123.3 samples/term-sense pair and 382.2 samples/term).\ntableEvaluation Metrics\nFor abbreviation disambiguation, we choose to report macro-F1 measure. For a case containing $n$ classes, there are $t$ terms. The macro-F1 is defined as:\nwhere N is the number of total classes, C(t,C') is the number of instances in a given class C'of type t, and macc is the arithmetic mean of F1 over all the classes.\ntablePerformance on Selected Term with Few Samples\n\ntopic-attention Model\nTable TABREF17 shows the performance of topic-attention model and base model on a random-selected set of 20 terms from all terms given in Table Table 7. We could observe that the topic-attention model performs considerably better than the base model. Note that for some rare cases, the base model was trained on only one sample and thus the results are unreliable. For example, the first row shows that it achieves an F1 score of 0.1898 for class 11 (which means the sample number is only 1), while the topic-attention model has an F1 score of 0.4. On the other hand, it is common that there is multiple samples for a given class, and even though it has better results in such cases the topic-attention model performs better overall due to its overall increase. We observe that for all the selected terms, the best accuracy and F1 score are over 0.8, where the performance gain is quite significant.\ntopic-attention Model v.s Base Model\ntablePerformance on all Terms with Rare Samples\n\nELMo+Topic Model v.s ELMo Only Model\n\ntopic-attention Model\n\nbase Model\n\ntableAccuracy and F1 Scores on Selected cases in Training Test Set\n\nAccuracy\n\nF1 Scores\n\ntopic-attention Model\n\nbase Model\n\ntableAccuracy and F1 Scores on All cases in Training Test Set\n\ntopic-attention Model\n\nbase Model\n\ntableAccuracy Results on Selected cases in",
    "3116453e35352a3a90ee5b12246dc7f2e60cfc59": "\nWe are developing a web service of the proposed model. All the data and source codes can be found in https://www.nlp.nju.edu.cn/project/mcd-abbreviation/.\nAcknowledgements\n\nWe really appreciate the assistance from our supervisor, Dr. Chao Zhang. The whole study was carried out with support from our Ph.D. committee: Dr. Chao Zhang, Dr. Guangzhi Hu, Dr. Daming Shao and Dr. Chen. Since the topic-attention model in this paper is also inspired by LANGUAGE MODELING FOR NER (LMM), we hereby acknowledge the reference of this work.\nAPPENDIX\nTable TABREF1: List of clinical abbreviations\n\nTable TABREF2: Clinical abbreviation terms which we are interested in. We will focus on predicting the uncommon meanings.\n\nTable TABREF3: Summary statistics of our training dataset, including the list of rare sensesthe abbreviation terms\n\nTable TABREF4: Some example sentences with abbreviations and sense annotations in our training dataset. We can observe that there are multiple meanings for most of them. Besides, some acronyms are not clear without the sentence context. We also removed several samples with unbalanced length (for example, the term MR has only 9 samples in the training set), since this can lead to overfitting problem.\n\nTable TABREF5: Distribution of common term-sense pairs, rare-sense pairs. We have 11 common-sense pairs in total (each of them contains 6 samples) and 3 rare-sense pairs (each of them contains 5 samples). The frequency of the rare-sense pairs is much lower than common ones.\n\nTable TABREF6: Abbreviation disambiguation results on both training and testing data.\n\nTable TABREF7: Details of abbreviation term-sense pairs and related source data. The first row shows the abbreviation term from which we have the training samples. We include each term's definition and example sentence and the second and third rows shows the training samples with the number of instances per sentence and its length. We also add additional files which contain all sentences in our training set along with the terms' definitions.\n\nTable TABREF8: The steps to create the testing dataset;\n\nTable TABREF9: Abbreviation terms in the training and testing datasets;\n\nTable TABREF10",
    "dfca00be3284cc555a6a4eac4831471fb1f5875b": "\nDataset Details\nFigure FIGREF11 shows the histogram for the distribution of term-sense pair sample numbers. The X-axis gives the pair sample numbers and the Y-axis shows the counts. The class number is also shown in the figure. For instance, the first bar means there are 22 classes in this term.\n\nTesting\n\nRoc Curves\n\n(a) AC\n\n(b) IM\n\n(c) IM\n\n(d) IM\n\n(b) Base Classifier\n\n(c) Our Model\n\nDataset Details\n\nFigure FIGREF11 shows the histogram for the distribution of class numbers. For instance, term BNB shows 23 classes, where the first bar means that there are 15 classes each containing 2 classes.\n\nTesting\n\nRoc Curves\n\n(a) BNB\n\nDataset Details\n\nFigure FIGREF11 shows the class number for term-sense pair. The first bar means that there are 22 classes in this term-sense pair.\n\nTesting\n\nRoc Curves\n\n(a) BNB\n\nDataset Details\n\nWe also show the class number for BNB in Figure FIGREF11. The last bar means that there are 23 classes for this term.\n\n\nPublished 2016 by\n\nSaga Press, an imprint of Simon & Schuster, Inc.\n\n1230 Avenue of the Americas\n\nNew York, New York 10020\n\nThis book is a work of fiction. Any references to historical events, real people, or real places are used fictitiously. Other names, characters, places, and events are products of the authors' imaginations, and any resemblance to actual events or places or persons, living or dead, is entirely coincidental.\n\nCopyright \u00a9 2016 by Anne Bishop.\n\nAll rights reserved, including the right to reproduce this book or portions thereof in any form whatsoever. For information, address Saga Press Subsidiary Rights Department, 1230 Avenue of the Americas, New York, NY 10020.\n\nSAGAPRESS and colophon are trademarks of Simon & Schuster, Inc.\n\nFor information about special discounts for bulk purchases, please contact Simon & Schuster Special Sales at 1-866-506-1949 or business@simonandschuster.com.\n\nThe Simon & Schuster Speakers Bureau can bring authors to",
    "a9a532399237b514c1227f2d6be8601474e669be": "\nDiscussion\n\nWe noticed some common errors in the dataset, which can introduce bias when evaluating a model. Therefore, we carefully re-evaluated this training dataset. The first type of error is the wrong sense assignment, e.g. MR should be assigned as the sense of Medical records, while MED should be assigned for Medical student. These mistakes can cause inaccurate sentence representation. For example, the context: the mr and the ecg result were normal. However, both senses in the training set are incorrect and this wrong assignment will bias the model towards Medical records class. Then we cleaned the training dataset as our manual correction. Another kind of mistake in the training set is that some of the notes actually have more than one correct sense and each sense can appear in different contexts, which is called uncategorized sense. For example, MR was assigned to Medical records, but it can also be assigned to Mental retardation and Mitral regurgitation. In this case, the meaning is ambiguous and we consider this as uncategorized sense. After manual correction, we have only one sense for every term of MR. In Table TABREF16, we also show the comparison between the original and cleaned training set results.\n\nDiscussion\n\nWe noticed some common errors in the dataset, which can introduce bias when evaluating a model. Therefore, we carefully rechecked this training dataset. The first kind of error is the wrong sense assignment, e.g. MR should be assigned as the sense of Medical record while MED should be assigned for Medical student. These faults will lead to the wrong sentence representation. One example is: the mr and the ecg result were normal. However, both senses in the training set are wrong, and this wrong assignment will lead to the wrong representation. The second type of mistake is that some of the notes actually have more than one correct sense. For example, MR has Medical record and Mental retardation as correct senses, and each of them can appear in different contexts. In this case, the meaning is ambiguous and we consider it as uncategorized sense. After re-evaluation, we have only one sense for every term of MR. In Table TABREF16, we also show the comparison between the original and cleaned training set results.\nExperimental Results\n\nThe first group of experiments was all the traditional models: Na\u00efve Bayes classifier (NB) has the highest scores among all the traditional methods, see Table SECRE",
    "26126068d72408555bcb52977cd669faf660bdf7": "\nReferences\nReferences ::: Cited by\n\nBhagat, G. (2019). The Word That Shook. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (ACL/IJCNLP 2019), pp. 1545-1554. Association for Computational Linguistics.\n\n[BIBREF0]\n\nTamang, S., Borkar, H., Koul, P., Bhandary, P., and Pujari, A. (2020). Stance Detection for Fact Verification on Twitter: A Systematic Literature Review and a Benchmark Dataset. Proc. AAAI\n\n[BIBREF1]\n\nLiao, M., He, X., Rios-Mercader, J., Lipton, O., Su, J., and Yao, Y. (2019).\n\nBiligiririz et al.  Learning Word Embeddings in Context to Combat Adversarial Attacks. In Conference on Empirical Methods\n\nin Natural Language Processing (EMNLP 2019).\n\n[BIBREF2]\n\nEisenschloss, G. J. and Grauman, J. (2011)\n\nCaveat Entity. The Wall Street Journal Magazine, November 28.\n\n[BIBREF3]\n\nMikolov et al.  Distributed Representations of Words and Phrases and a Model of Natural Language Processing.  In Advances in Neural\n\nInformation Processing Systems, pp. 307-318.\n\n[BIBREF4]\n\nMikolov et al.  Recurrent Neural Network Model of Natural Language Understanding.  In Advances in Neural Information\nProcessing Systems, pp. 2518-252526.\n\n[BIBREF5]\n\nPennington, J. E., Socher, R., and Manning, C. D. (2014)\n\nGloVe: Global Vectors of Words Representing English Word Meanings.  In Proceedings of the 2014\n\nConference on Empirical Methods in Natural Language Processing (EMNLP), pp. 1774-1782.\n\n[BIBREF6]\n\nKim et al.  Mikolov Embeddings: Continuous Spaces for Language Modeling.  In Advances in Neural\n\n[BIB",
    "660284b0a21fe3801e64dc9e0e51da5400223fe3": "\nReferences\n[BIBREF1] Alvarez, S., and M. J. Paul. 2015. A machine learning approach to political stance detection. CoRR, abstr.\n\n[BIBREF2] Liu, J., and P. Basilescu. 2016. Verification of claim data for counter-terrorism. In Proc. of International Joint Conference on Artificial Intelligence, pp. 20\u201325. AAAI Press, PaloAlto, CA.\n\n[BIBREF3] Guo, R., and Y. Yang. 2017. Modeling polysemous words using a variant of maximum margin objective. In Proc. of the Thirty-Eighth Annual Conference of the Association for Computational Linguistics (Volume 1: Long Papers), p. 749\u2013758. ACL, Barcelona, Spain.\n\n[BIBREF4] He, B., and H. Gao. 2017. Deep cross-linguistic transfer network. ACL Workshop and Shared Task on Cross-Linguistic Textual Entailment, Stanford, CA.\n\n[BIBREF5] Pennington, J., R. Socher, and C. Manning. 2014. Glove: Global vectors for word representation. Tacl, 2014a.\n\n[BIBREF6] Li, Y., and M. R. Jordan. 2016. Cross-linguistic similarities in polysemous words: A task for semantic textual inference. CoRR, abstr.\n\n[BIBREF7] S. Vlachas, G. Manitsaris, E. Gkantsidis, F. Stamatatos, E. Vlahavas, K. Farkas, G. Rzavazskis, and I. Dimou. 2018. Multimodal word distribution learning for polysemedic words. In Proc. of the Thirty-Eighth Annual Conference of the Association for Computational Linguistics (Volume 1: Long Papers), p. 1083\u20131094. ACL, Barcelona, Spain.\n\n[BIBREF8] Gueguen, S., O. Dada, J. Caruana, A. Korayem, and O. Veneziano. 2019. Learning word sense distributions unsupervised in a joint distribution space. In Proc. of the Conference on Empirical Methods in Natural Language Processing and the Thirti",
    "c22394a3fb0dbf2fc7d3a70ad6435803f5a16ebd": "\nThis work presents ASR gender bias as an observable phenomenon, paving the way to investigate bias and its impact on training corpora in NLP field. With the growing number of studies, we hope to be able to identify and characterize these biases within the community. Even if an ASR system has never been trained on human data, its performance is still affected by human bias. We observe an effect on WER for Anchors but also a significant bias for Punctual speakers, which we observe at the show level (speech type). We should therefore keep in mind the necessity of having a large variety of data in order to capture and train a bias-free system.\nWe would like to thank the European Commission for funding our research.\n\nBIBREF0. Global Media Monitoring Project. Gender analysis 2019. 2020, available at <https://gmmp-bibref.eu/documents/reports/gender-analysis-2019>\n\nBIBREF1. CSA. M\u00e9canismes et m\u00e9thodes d\u00e9velopp\u00e9s avec les sociolinguistes. Rapport 2019, 2020, available at <https://www.french-council.fr/fileadmin/publications/mechanisms_et_methode_develloppes-sommes_2019_version_final.pdf>\n\nBIBREF2. G. Guillem, C. Dignat-George, D. Bougouin-Bey, S. Hudon, A. Bougouin-Bey, C. Benhamou, R. S\u00e8foulias, A. Fellrath, T. Guerini, J. Martin, A. Tr\u00e9guer, P. Bourgonje, L. Delcourt. Gender-neutral evaluation of language technologies and services. 2020\n\nBIBREF3. E. Ben-David, G. E. Hinton. Algorithms matter more than features in neural network systems. 2014\n\nBIBREF4. R. J. P. Adams and C. R. Manning, Gender and AI, in A. Ormazabal-Llanos (ed.) Neural networks and AI: Essays and explorations, Springer, Boston, 2018, pp. 25-41\n\nBIBREF5. J. F. Sap, P. J. Stent, S. Kiela,",
    "f85f2a532e7e700d9f8f9c09cd08d4e47b87bdd3": "\nWe propose the use of role based speaker categorization in order to avoid gender dissimilation within an ASR system. This is a first step toward bias mitigation of natural language processing tools within the ASR pipeline (including the design of a fair architecture). This approach avoids an important bias already present in NLP, namely that the linguistic knowledge and models can be heavily biased, which is not observed for ASR.\nA first analysis of gender bias performance according to speaker's role and speech type led us to hypothesize that gender bias is due to the lack of adaptation data for women. We confirmed this hypothesis by analyzing WER variations with and without the use of adaptation features at the decoding step, revealing that adapting the acoustic model to the Anchor speakers, where women are more present than men, leads to a significant performance improvement whereas it does not have an impact on the WER score for the Punctual speakers group. We thus postulate that speaker adaptation plays a crucial role regarding gender bias mitigation.\nOur work shows that there is a clear gender bias within French broadcast data, which is very present inside voice assistance technologies. In order to provide fair access, media should be represented equally in its productions and representations. Our investigations are motivated by a wider aim toward ethical and fair NLP technologies that will be necessary in a growing AI field.\nThis work is done within the scope of an IDEX project BIBREF33: it is the first time gender has been quantitatively examined in broadcast data specifically for ASR.\n[1] A CSA. Le taux de parit\u00e9 des mots dans la presse \u00e9lectronique : analyse g\u00e9n\u00e9rale des \u00e9tats \u00e0 l'ensemble. (2017).\n\n[2] S. BIBREF1. G. Ruege, P. Bouzine, J. Bovet, S. Delahaye. Gender in public and private television broadcast media in 2020\u20132021. CSA, Paris, 2017.\n\n[3] C.BIBREF2. AI Artifacts: Representation Bias in Speech Recognition. International Journal of Computer Vision, 2017, pp. 1-24.\n\n[4] E. BIBREF3. \"Gender bias in deep learning systems: how much can gender explain the gender gap in speech recognition?\". International Journal of Human-Computer Studies, 2019, pp. 1-41.\n\n[5]",
    "a253749e3b4c4f340778235f640ce694642a4555": "\n\nAcknowledgments\n\nThis paper is the result of a team work: research, writing and review was co-authored and co-directed by all authors. Thanks to Christelle Peyrou for insightful discussion and feedback, Nico Tilmon for his valuable feedback, and Alain Saliou to all the developers involved in ESTER and REPERE corpora.\nReflexive Objectives For Equal Representation of Women, Gender Diversity by Design and Data Sets, Gender Bias in Algorithmic Decision-Making Systems. Josselin Mettling, Aline Villon, A.K. Das, N. Ching, J. Z. G. Bellegarda, J. Wiese, P. J. N. J. Parthasarathy, K. M. Bowden, K. Ghayad, J. M. L. Pradeep, R. C. S. Zadawny, A. Garg, J. Srivastava. (2017) Proceedings of the International Symposium on Experimental AI (SEA 2017), pages 17-26. D\u00fcsseldorf: Springer. 10.1007/978-3-319-58597-3-0_2\n\nGender bias in machine learning: an overview and research agendas. E. Krauss, A. Naseri, A. S. C. Smith, M. R. Littman, M. A. A. Smith, T. P. J. Williams, and J. C. Devlin. Proceedings of the International Symposium on Experimental AI (SEA), pages 5-12, 2017.\n\nGender bias in machine learning toolkits: comparing gender-biased word2vec with gender-balanced word2vec, and measuring the effect on word similarity, classification, and NER. A. Lample, and T. Klose. Language Resources and Evaluation 49:1-18, 2018.\n\nGender Bias in Pre-Training Data Sets for Machine Learning. A. Jodini, Ph.D thesis, MIT PhD Thesis, 2019.\n\nGlobal Gender Gap Report 2019. (2019) Available at: https://www.un.org/gender-gap-report/2019-report/. Accessed: March, 25th, 2020.\n\nThe gender-aware media monitoring project bibref0: a review of the media in the US, UK",
    "1142784dc4e0e4c0b4eca1feaf1c10dc46dd5891": "\nFuture work would use WER scores obtained from our ASR system to build a gender representation model which would predict the performance of a given AI system trained with data coming from social structure disparity. Furthermore, further studies using other types of data might be crucial to uncover the different impact of various parameters on WER like age and accent, among many other. We hope this work contributes to increase the awareness of gender bias in ASR systems.\nAcknowledgements\nWe would like to thank B\u00e9raudi-Echevarria for reviewing this document and giving helpful feedback.\nReferences\nBIBREF0  CSA. (2018). Global Media Monitoring ::: France. https://www.presidence-france.fr/en/files/1807.pdf\n\nBIBREF1  L. Mestre et al. Annotating gender in the media: the 2017 french broadcast news corpus ::: BIBREF0 [Data]. 2018. URL: <web.insee.fr/fr/BIBREF0/>.\n\nBIBREF2  C. S. Sharma et al. Gender bias in media. Science magazine. 2019. https://www.sciencemag.org/news/2019/12/gender-bias-in-the-media\n\nBIBREF3  H.-K. Bock et al. Gender-Aware Speech Technology: A Social Perspective. TASLAM workshop. 2016. https://ieeexplore.ieee.org/document/8075122\n\nBIBREF4  P. Bailard. AI Ethics for Nlp. CogSci 2018. <https://docs.google.com/document/d/e/1Dm2T8c8Rq2P2hNn7gV_c0xS-c8J9fSq5cEi3N-V-2dJGc9zLw5fXnV_zBfT8gA9U8qy5f4Y-oTmBJhz8-3VGm_RdWlL_aY/view>\n\nBIBREF5  M. Bansal et al. Embedding Gender Bias in Word Sense Disambiguation. EMNLP 2018. pp. 3123\u20133134. URL: <https://",
    "777bb3dcdbc32e925df0f7ec3adb96f15dd3dc47": "\nAcknowledgment\nThis work was funded by Microsoft and CogitAI, which was a project of the French National Agency for Research (ANR).\nA\n\nB\n\nC\n\nD\n\nE\n\nF\n\nG\n\nH\n\nI\n\nJ\n\nK\n\nL\n\nM\n\nN\n\nP\n\nQ\n\nR\n\nS\n\nT\n\nU\n\nA. C. W. S. B. T. et al. Gender bias in speech recognition data sets. Speech Communication 51(4).pp. 471\u2212489.\n\nA. S. C. W. B. T. et al. Global Media Monitoring Project. Available at: https://www.globalmediamonitoringproject. org.\n\nG. Echeverr\u00eda, J. J. A. Zamarroa, I. Llorente-Garcia, G. N. Obrador-S\u00e1nchez. Gender analysis in Spanish broadcast news: a study of representation and voice gender. Speech Communication 51(4).pp. 521\u2212543.\n\nB. CSA. 2017. Report on gender equality in the French audiovisuals system. Available at: https://www.csa.fr/portails-csa/im/_m/fichier/1607/Rapport_2017.pdf\n\nC. Echeverr\u00eda, G. Echeverr\u00eda, V. de Dios, C. Nieves-Mart\u00edn. Gender biases in audiovisual language resources for machine learning: a case study of gender data sets in Spanish. Speech Communication 54 (2020).pp. 1\u221223.\n\nC. D'Orazio et al. Gender biases in spoken language. Language Resources and Evaluation 60(1).pp. 1\u221218.\n\nE. D. Espejo. Gender representation in corpora: does it still matter. Language Resources and Evaluation 70(2).pp. 901\u2212932.\n\nE. Espejo, C. Nieves-Mart\u00edn. Gender bias in automatic speech recognition. Language Resources and Evaluation 63(1).pp. 301\u2212314.\n\nEspejo, E. and Nieves-Mart\u00edn, C. 2015. Gender representation in corpora: why, how and when. Language Resources and Evaluation 57(2).",
    "2da4c3679111dd92a1d0869dae353ebe5989dfd2": "\nAcknowledgments\nWe would like to thank the organizers of the Workshop on Gender and Natural Language Processing (Conference on Empirical Methods in Natural Language Processing, EMNLP 2019). Thanks to our supervisor C\u00e9cile Fourtou for her support on this research work. Her expertise in the NLP field especially on gender issues has been of great help. Finally to our mentors at LaBRI2 S3D laboratory for their support during this research work. As well as to Marie-Sophie Lapeyreria who, as part of the European Summer School project, has been invaluable throughout this work.\nReferences\n\nBIBREF0. GMM. (2017). BIBREF0 [online]. Aix-en-Provence. Available at: http://gmmp.limsi.fr/en [Accessed 16 October 2020].\n\nBIBREF1. GMM. (2017). La CSA BIBREF1. Aix-en-Provence [online]. Available at: http://gmmp.limsi.fr/en/data/bibref [Accessed 16 October 2020].\n\nBIBREF2. GMM. (2017). La CSA BIBREF2. Aix-en-Provence [online]. Available at: https://www.csa.fra.cnrs.fr/sites/default/files/publications/bibref-2017/biref-2017.pdf [Accessed 16 October 2020].\n\nBIBREF3. BIBREF. (2019). Fairness by Design: Ethical Concerns of Artificial IntelligencE. London: Google. [online]. Available at: https://research.google/pubs/pub68924/?hl=en&gl=uk&ei=NQKfWq6Ym2TmIY4GgGQgwDgYJG4M8oYGZwK2uA_&sv=AI_pub369.\n\nBIBREF4. BIBREF. (2019). BIBREF. London: Google. [online]. Available at: https://research.google/pubs/pub68922/ [Accessed 16 October 2020].\n\nBIBREF5. RIBF. (2017). BIBREF. Paris: CNRS, Inria. [online]. Available",
    "b7c3f3942a07c118e57130bc4c3ec4adc431d725": " Most of all the team at Fast.ai for their code and toolkit for easy model training and evaluation. Finally, we have benefited from the advice provided by members of the fast.ai forum for this challenge as well as other related tasks like humor sentiment analysis.\nReferences\n\n[1]Smith, J. (2018). Universal Language Model for Fine-tuning in Text Classification. Kip.ai. doi:10.18573/kickstarterai.ai.2018.12.\n\n[2] Castro, B. A., de la Pena, A., and Brugos, M. G. (2018). HAHA: Towards the Study of Humor Detection. Proceedings of the 10th Conference on International Conference on Theory and Practice of Digital Libraries (TPDL 2018). Association for Computational Linguistics. doi: 10.18653/associationfor.icdl-conference2018-9\n\n[3]   Smith, J., Liang, Z., and Ruder, S. (2017). A Universal Language Model for Fine-tuning in Text Categorization and Regression. Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics (NAACL-HLT 2017), Association for Computational Linguistics.\n\n[4] Howard, J., Ruder, S., and Manning, C. (2018a). A Very Simple Framework for Transfer Learning. Transactions of the Association for Computational Linguistics 2, 1\u201321.\n\n### Table TABREF21\n\nThis table shows the training parameters used across the ULMFiT method on the HAHA 2019 task. We used the Fast Ai library, which provides a convenient way to train a language model with transfer-learning.\n\n## Table TABREF25\n\nThis Table shows the parameters used during fine-tuning on the HAHA 2019 task.\n## Table TABREF29\n\nThis table shows our results for submission in the HAHA 2019 challenge.\n## Table TABREF31\n\nWe show the parameters and random seeds used for training the LM in this section\n \n_Fantasy's Child_ is a work of fiction. Names, places, and incidents either are products of the author's imagination or are used fictitiously. Any resemblance to actual events, locales, or persons, living or dead, is entirely",
    "a5505e25ee9ae84090e1442034ddbb3cedabcf04": " Finally, we would like to thank the organizers of the HaHa competition for the chance to participate and the organization of a real world, usable, NLP problem.\nReferences BIBREF1 \"HAHA\" 2019 competition. BIBREF2 Vargas-Beltran, L., Sanchez-Roda, C., Dusastre-Rizos, P. B., et al. \"HAHA\" 2019: A Shared Task on Humor Analysis with Human Annotation.\" Code accompanying this workshop paper available at https://codalab.org/competitions/1830. Code accompanying this workshop paper available at https://codalab.org/competitions/1830. BIBREF3 Howard and Ruder, \"Wider Supervision for Neural Language Models with Fast.ai,\" KDD 2019. BIBREF4 Song, B., and D. Bahdanau. \"Practical Unsupervised Neural Architecture Search with Multi-task Learning.\" CoRR abs/ 1708.0201 (2017). BIBREF5 Merity, A., Rudge, M., and Dahl, G. B. \"Unsupervised Language Model Improvement by Backpropagating Targeted Regularization Error\" (2014). BIBREF6 Bradbury, A., Chieu, T., Ng, A-Y., and Zahavy, O. \"Qnn: A Quasi-Recurrent Neural Network for Neural Machine Translation\" CoRR abs/1502.00152. BIBREF7 Glorot, B., and Bengio, Y. A fast learning algorithm for deep belief nets BIBREF8 Smith, P., et al. \"AutoML for Large Language Models using a Curric-Wide & Cross-lingual Knowledge Graphs.\" CoRR abs/ 1708.06571. BIBREF9 Chawla, N., Bashir, M., Fawcett, T., Hall, L., and Guo, Y. \"A Sythentic Minority Oversampling Technique to the Rescue! (SMOTE)\" CoRR abs / 1572.01168 (2015). BIBREF10 Pereyra, M., and Vargas-Beltran, L. \"Towards Automatic Humor Classification using Language Model Uncertainty.\" CoRR abs/ 1805.01136. BIBREF11 Czapla, E., Li",
    "1dc2da5078a7e5ea82ccd1c90d81999a922bc9bf": "\nAmanda Woo, a research assistant who was an undergraduate then; and\nRobert Anderson, who was a professor of computer science at Stanford (1972-1988) and now at the Santa Caterina School of Art and Design, wrote a proposal; and in those days one could rely on the faculty members in Computer Science to be enthusiastic about research.\nSue Cimino, who was a professor of philosophy at the Santa Caterina School of Art and Design during the same era; Sue, in the late 1960s, had just started taking up computer science; and between the two of them, they persuaded the department chair that computer science was something that philosophers should know something about.\nIn particular thanks to my very dear friend, John Haugen, who did everything except write the actual proposal, including writing many of the statements.\nMore information\nhttp://www.cs.nyu.edu/faculty/davise/papers/WinogradSchemas/WSCollection.html\nhttps://commonsensereasoning.org\nErik Davis\nIn these two days, it seems we have found some way to move it, however small, toward the general usefulness of the machine language to man; and to endow it, at least, with the power of locomotion; with the capacity of feeling; with the capability of thought; with the strength of will; and probably with many of the other perfections which a man is distinguished from the brutes.\n\u2014Charles Dickens; The Mystery of Edwin Drood, Chapter 1: Edwin Drood\n...the English, in their capacity of a race of rational beings, must not be supposed to be mere animals...\n\u2014Charles Dickens (1848-1893); David Copperfield, Chapter 1: A Young Man with a History (1850-1864), Chapter 1, The Portrait of a Young Man, Part 1, Book i: Chapter i\n\nThe only true Englishman is a good Englishman; the only good reasoner an excellent reasoner.\n\n\u2014Charles Dickens (1812-1870); David Copperfield Chapter 1: A Young Man with a History (1850-1864), Chapter 1: The Portrait of a Young Man, Part 1, Book i: Chapter i\n\nA person without a sense of humor is like a waffle with all the flavor on the outside and none on the inside",
    "7fa3c2c0cf7f559d43e84076a9113a390c5ba03a": "\n\nE. Winograd-Kist, T. F. Tsuruta, and M. Zock, Semantic Interpretation of Natural Language Text: a Case Study in AI, MIT Press, 1983.\nE. G. Hovsepyan, B. C. Johnson, and E. G. Hovsepyan, Genders and Case in German: Thematic Role Analysis of the Nominal Case System, Mouton de Gruyter, 2006.\nT. Hirschberg, T. A. Wier, and M. Vasishth, Language as a Cognitive Process: Case in German, Cambridge University Press, 1998.\nJ. Kieffer and G. Hirschberg, Case and Reference Binding in German, MIT Press, 1995.\nJ. Kieffer and G. Hirschberg, Reference and the Logic of Predication, MIT Press, 1998.\nL. Zamparelli and M. A. J. Turchi, The Semantics of Case: Towards a Functional Analysis of the Nominal Case System in French, MIT Press, 2005.\nL. Bouchard-Carpentier and Ch. T. Jolly, French Grammar, Pearson, 2006.\nW. O'Gorman and L. Brugman, English Grammar, CUP, 2005.\nT. J. Higgins and F. M. Lewis, English Syntax: A Comprehensive Grammar, Garland Publishing, 2001, 2006, 2009.\nM. D. Laird, et al., Foundations of Human Language: Essays in Cognition and Modeling, MIT Press, 1988.\n\nD. Rehbein, D. W. Hillis, and E. S. Pollatschek, Discourse Parsing and Parsing Discourse, MIT Press, 1995.\n\nM. Rebholz-Baltin, P. S. Stubbs-Martin, M. T. McEwan, and R. M. Wilson, English in a Flash!, Cambridge University Press, 2006, 2010.\n\nM. C. M. Van Leuvenant, M. E. E. Meirink, and E. K. S. Van Hout, eds., Case and Reference in Linguistic Theory, Clarendon Press, 1987.\nR. Mynard, C. D",
    "9a7ba5ed1779c664d2cac92494a43517d3e87c96": "\nT. Winograd Schemas Project, (at http://www.cs.nyu.edu/faculty/davise/papers/WinogradSchemas/WSCollection.html).\n\nA. Zappel, E. Levy, A. Moro, et al, The Transcom Challenge 2012-2015, http://www.trans-com.org/challenge/.\n\nJ. Zink, A. Cerfon, E. Davis. The Transcom Challenge 2014-2015, https://www.cs.ubc.ca/english/transcom/challenge/2014-winograd/welcome.htm.\nJ. Davis, U-Net, 2016, http://sparql.cs.nyu.edu/UNet/.\nJ. Gee, A. Coster, M. Ginzburg, et al, \"Improving NLP by leveraging commonsense reasoning,\" AAAI-16 workshop on AI for Machine Translation, 2016 https://workshop2016.ai4mt.org/assets/files/Davis_et-al_ImprovingABIbyLeveragingCR.pdf.\n \n## JUNE MELODY\n\n## JUNE MELODY\n\n## The Song of the Wanderer\n\n## William Carlos Williams\n\nWith an Afterword by\n\n## T. S. Eliot\n\n_Text copyright \u00a9 2016 by William Carlos Williams  \nAfterword copyright \u00a9 1958 by T. S. Eliot_\n\n_Afterword reprinted by permission of T. S. Eliot from_ The Critical Essays, _Volume I, T. S. Eliot, edited by J. O'Donnell and P. Levinson, Faber and Faber, London, 1962_\n\n_Edited by Daniel Auberjonois_\n\n_Afterword art copyright \u00a9 2016 by T. S. Eliot_.\n\nAll rights reserved. No part of this book may be reproduced in any form or by any electronic or mechanical means, including information storage and retrieval systems, without permission in writing from the publisher, except by a reviewer who may quote brief passages in a review. Any members of educational institutions wishing to photocopy part or all of the work for classroom use, or publishers who would like to obtain permission to include the work in an anthology, should send their inquiries to Grove/Atlantic, Inc.,",
    "662870a90890c620a964720b2ca122a1139410ea": "\nIvan Aivazis, Winograd and Chomsky. The Nature of Syntactic Analysis of Languages. An Annotated Bibliography, ACM Press, 1979.\nDanielle Bryson, The Story of P-Facts: The History of Winograd Schemas and Their Application to Machine Translation. Department of Computer Science, NYU, 2016.\n\nVered Givan, A Theory of Human Action. University of Cambridge, 2017.\n\n\nTHIS IS A BORZOI BOOK  \nPUBLISHED BY ALFRED A. KNOPF  \nCopyright \u00a9 2016 by M.W. Kalmen\n\nExcerpt from _Unbroken_ \u00a9 2014 by Lauren Hillenbrand.\n\nAll rights reserved. Published in the United States by Alfred A. Knopf, an imprint of Random House Children's Books, a division of Random House LLC, a Penguin Random House Company, New York.  \nKnopf, Borzoi Books, and the colophon are registered trademarks of Penguin Random House LLC.\n\nVisit us on the Web   \nEducators and librarians, for a variety of teaching tools, visit us at RHTeachersLibrarians.com  \nLibrary of Congress Cataloging-in-Publication Data is available upon request.\n\nISBN 978-0-375-98738-5 (hardback) \u2014 ISBN 978-0-449-83585-3 (E-book)  \neBook ISBN 978-0-449-83585-3\n\nThis is a work of fiction. Names, characters, places, and incidents either are the product of the author's imagination or are used fictitiously. Any resemblance to actual persons, living or dead, events, or locales is entirely coincidental.\n\nv4.1\n\nep\n\n# Contents\n\nCover\n\nOther Books by This Author\n\nTitle Page\n\nCopyright\n\nDedication\n\nPart One: September 1941\n\nChapter 1: The Punch Bowl\n\nChapter 2: The Lark-Inn\n\nChapter 3: The Spell\n\nChapter 4: The Cull\n\nPart Two: March 1942\n\nChapter 5: The Lark-Inn\n\nChapter 6: The Recessional\n\nPart Three: July 1942\n\nChapter 7: The Lark",
    "92d1a6df3041667dc662376938bc65527a5a1c3c": " In addition, note also that the use of cluster membership features do not necessarily always lead to higher performance. It may happen that the information they capture is redundant to the features extracted from other approaches.\nIn our opinion, this is an interesting area for future work as both the design of the feature space and its effectiveness require further insights. We believe this work opens the path to investigating different clustering algorithms that learn word clusters from large text corpora with the aim of augmenting the feature space. For instance, different distance measures could be studied, where the distance of the centroids of the clusters could be tuned to the semantics of the problem domain at hand. Also, for the three classification tasks we studied, the use of clusters that were learned using a different type of word vectors (i.e., skipgram instead of cbow) could be compared on the provided test data.\nACKNOWLEDGEMENTS\nWe are thankful to the organizers of the ICTIR 2018 Workshop on Machine Learning in Information Retrieval for sharing with us the tasks we applied our feature extraction method to. We would also like to thank anonymous reviewers for their feedback as well as our colleagues for interesting discussions.\nReferences\n\n[BIBREF1]\n\nW. Cucchiara, T. Gorman, M. Baldridge, A. A. Bard, B. C. Furl\u00e1n, P. Ganchev, J. M. O. Reis, and D. Jurafsky (2014).\n\nNovel features guide supervised speech recognition with unannotated data.\n\nInterspeech 2014. ICSLP-Abdera, Spain.\n\n[BIBREF2]\n\nBengio et al., 2013. Learning word representations for sentence classification. In\n\nProceedings of the 2013 conference on empirical methods in natural language processing, page 822\u2013831.\n\n[BIBREF3]\n\nRitter et al, 2013. Learning part-of-speech patterns with word vectors.\n\nIn Proceedings of EMNLP.\n\n[BIBREF4]\n\nD. Mimno et al. (2015). The use of word space models in natural language processing.\n\nIn Proceedings of COLING 2015.\n\n[BIBREF5]\n\nB. Brown et al, 1992. Computational models of lexical semantics.\n\nIn Computational L",
    "12159f04e0427fe33fa05af6ba8c950f1a5ce5ea": " Last, our experiments prove that the feature set extraction mechanism proposed can work also for other types of tasks and even with other languages.\nAcknowledgments\nThis work is partly supported by the European Commission as part of the project H2020-GA-641788-Fuse-AD (Fuse.AI) and is partly funded by Google. D.M. is partially funded by a grant of the Funda\u00e7\u00e3o para a Ci\u00eancia e Tecnologia under number SFRH/FP/BPD/116769/2014.\n\nBibliography\n\n[1] ]. The World Wide Web Consortium ( W3C) ( 2019 ). \"Web Hypertext Transfer Protocol\", https://www.w3.org/wiki/Web_Hypertext_Transfer_Protocol.\n\n[2] ]. T. Bengio. Deep Learning. MIT Press, 2012.\n\n[3] ]. G. Hinton, R. Poole, and Y. Khoshgoooyan. Motivating word2vec: A simple yet effective model for large-scale word sense disambiguation. CoRR abs/1301.3722 (2013).\n\n[4] ]. K. S\u00f8gaard, R. Socher, L. Fei-Fei and B. Hsiao. Distributed Representations of Words and Phrases and their Semantic Components. Proceedings of the 24th International Conference on Computational Linguistics(2014).\n\n[5] ]. P. Brown, J. Maynard, V. K. Aggarwal and J. L. Paisley. A unified approach for clustering and semantic parsing. Technical Report, 2013.\n\n[6] ]. Z. Kiritchenko, A. Klementiev, C. Huang and M. Ritter. From Sentiment analysis to sentiment detection using deep learning and a new sentiment lexicon. Proceedings of the 2015 Conferenceof the North American Chapter of the Association for Computational Linguistics (NAACL), 2015.\n\n[7] ]. G. D. Hinton and B. S. Manning. Distributed representations. Proceedings of Neural Information Processing Systems Workshops, 2004, pp. 331\u2013337.\n\n[8] ]. G. D. Hinton, P. A. Bishop and R. Poole. Relaxing the constraints: Continuous bag-of-words model",
    "a4a1fcef760b133e9aa876ac28145ad98a609927": " We leave those as the subject of future work.\nHowever, in this investigation we do not consider the effect of the vector's initialization. While the number of clusters seems to be the key element to obtain effective vector features, one cannot claim a priori that higher dimensions and better initialized vectors would not improve the performance, and future work should investigate this direction. Finally, our results show that while the fine grained sentiment classification task seems to be solved quite effectively, the sentiment quantification task is more difficult. One might argue that while performing sentiment analysis using sentence length features is an important step, performing a fine grained sentiment quantification is a more demanding task. For example, when one tries to determine whether a tweet is mostly positive or negative, one typically has a good estimate of the sentiment of the sentence. The latter is, rather, an estimation problem, for which the number of positive and negative tokens is no certainty. It is unclear however how these types of problems can differ and what feature extraction could be used to deal with them. This is definitely an interesting direction for future works and the possible interaction between the two tasks is another fascinating question that could be explored.\nAcknowledgements\nWe thank the anonymous reviewers for their valuable comments/insights. We also thank the co-organizers of the SemEval2016 Task 4: Sentiment Analysis in Twitter, who created a wonderful platform for studying text mining tasks using twitter data.\nBIBLIO\nAbeba, A. & Finkel, S. (2014). A hybrid machine learning algorithm for named entity recognition. In EMNLP, Amsterdam.\n\nArdekani, A. & Ng, B. C. (2014). Using Part-of-Speech tagging to select features for sentiment analysis. In EMNLP, Amsterdam.\n\nBendall, S., Grefen, P., Cramer, J. & Pilehvar, S. (2017). CharacterN-gram features for microblog sentiment analysis. In EMNLP, Amsterdam.\n\nBizer, L., Nguyen, D. & Zitnick, C. (2012). Deep learning for natural language expression extraction: Challenges and opportunities. In EACL, Uppsala.\n\nBowman, S., Ganchev, F., Chen, F. & Levy, M. (2013). Continuous skip-gram for modeling language usage. In EMNLP, New Orleans.\n\n",
    "63bb2040fa107c5296351c2b5f0312336dad2863": "\nAdditionally, with the exception of glove INLINEFORM1, we did not find a good setting for the number of clusters used (like INLINEFORM1 ). Thus, future research efforts should aim to identify criteria to choose the number of clusters for such features, that can be applied across different tasks. Finally, one might expect better performance with larger numbers of clusters as in the case of sentiment classification, while larger numbers of clusters usually decrease the performance in the other tasks we are evaluating. However, the impact of the cluster size is task-dependent. It is also worth studying how to reduce the performance-size trade-off when using word clusters as features.\nAcknowlegements\nThis work is supported by the European Commission under the Human Brain Project SGA3 project 210064 and the Spanish MICINN. We would like to thank the organizers of the SemEval2016 challenge for twitter sentiment analysis, to M. Zampieri for his insightful comments on the manuscript and to D. Guerrero for reviewing the final version of the manuscript.\nAcknowledgement\n\nWe would like to thank the organizers of the SemEval2016 challenge for twitter sentiment analysis and SemEval2016 for fine-grained sentiment analysis for making available their datasets which we use as a part of our experiments, as well as the creators of the BIO NER tagger BIBREF21 and the BIO sentiment lexicon BIBREF13.\nRecommended\n\nA. Agarwal, C. d'Avenas and L. Vidgen. An analysis-based approach for extracting word clusters on the twitter corpus. In Proceedings of the 10th International Conference on Semantic Evaluation (SemEval 2014). Association for Computational Linguistics, 2014.\n\nA. Aharoni, O. Goldberg and O. Goldberg. Sentiment140: Sentiment analysis using twitter messages. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL 2010).\n\nG. Asenov, E. Kouloumi and T. Bontcheva. Semeval 2013 task 2: sentiment analysis. Association for Computational Linguistics, 2012.\n\nD. Bajjalieva, J. Hsu and J. Li. A machine learning based approach for twitter user profile classification on twitter message level. In Proceedings of the 25th International Conference on Computational Linguistics (COLING 2014).",
    "01f4a0a19467947a8f3bdd7ec9fac75b5222d710": "\n\nAs an aside, we also provide the dependency analyses for the gold tree parses (Figure FIGREF51 ) and the neural PCFG (Figure FIGREF55 ). The PRPN is significantly more consistent then ON across different runs.\n\nExperiments on Reversing Dependencies\nWe conducted several experiments on reversing dependencies to probe for the generative process. The goal of these experiments was to investigate the difference between the PRPN and the neural PCFG on unsupervised RNNG parsing. We focus in particular on the dependency paths through INLINEFORM4 since the non-contextual assumption of the PRPN is that if INLINEFORM3 matches a lexical entry then INLINEFORM4 should be non-zero. To verify this, if in a derivation INLINEFORM0 through INLINEFORM1, then we reverse all the dependencies between siblings to form INLINEFORM\u22121, and run the model under the backward inference label INLINEFORM\u22121 in the PRPN. Concretely, we would sample the next action based on the action-wise negation of INLINEFORM1 and use this new rule predictions to induce new trees. We then find the dependency path that led from the left side of the rule (i.e. the gold or neural PCFG rule probabilities) to a given leaf through the original right-branching model (INLINEREF93a) and check if this path can lead through the PRPN to the leaf via the backward inference label INLINEREF93b. For any derivation where INLINEFORM\u22121 can be derived from INLINEFORM0, we thus have INLINEREF93 = INLINEREF93a. In all cases we use 200 iterations, and report the percentage of successful derivations (i.e. INLINEREF93 > 0).\nResults\n\nTable TABREF95 reports the results: the neural PCFG shows a significantly greater percentage of correct dependency paths than the PRPN.\n\nExperiments on Differentiating Re-ranking of Syntactic Dependency Paths\nWe conduct three experiments to assess the learned re-ranking of dependencies. We use the same tree sampler INLINEFORM0 and hyperparameters from Section 3.1. For first-order model, we first randomly sample a root rule and perform a forward and reverse inference on each input symbol; the re-ranking value is the difference between the forward and reverse log marginal likelihood of the IN",
    "7784d321ccc64db5141113b6783e4ba92fdd4b20": "\nTable TABREF54 shows more examples of constituents within each subtree as the nonterminal label INLINETABLE1 is varied. Due to data sparsity, the subtree analysis is performed on the full dataset. See Figure FIGREF51 for more details.\n\nTable TABREF35 lists top 10 words from each subtree. In the first half, this subtree analysis is performed on the full dataset. In the second half, we vary the nonterminal label INLINETABLE1 and run the subtree analysis for each sentence and find that the induced trees are roughly consistent with the distribution of constituent labels. See section UID37 for more details.\nTable TABREF36 shows the unsupervised subtree analysis scores on EN-PI, CN-PI and enPI-CN compared to previous work. Our models outperform previous work by a comfortable margin, including the neural PCFG. See section UID34 for more details.\nTable TABREF37 reports the syntactic diversity score using the original metric of BIBREF1, with the best score highlighted in gray.\nTable TABREF38 lists the average sentence length by subtree depth for the compound PCFG/neural PCFG. For conciseness, only the first three scores are reported, as our neural PCFG/compound PCFG have the largest subtree depths. Again we outperform recent results by a significant margin. See section UID32 for more details.\n\nTable TABREF30 shows the unsupervised grammaticality score (average of 4 runs) for all models on EN-PI and CN-PI. We outperform recent work by a large margin. See section UID29 for more details.\n\nFor word-level semantic relatedness comparisons, we obtain the following (using 50K samples) for the gold, RNNGs, and compound PCFGs on PTB with no punctuation (all other models with punctuation, Table TABREF30 ). For English, BIBREF15 shows the results for a right branching neural language model trained on PTB without punctuation, and BIBREF16 shows similar results for a soft RNNG trained on PTB with punctuation. For Chinese, Table TABREF40 shows the results when only right branches are considered for the neural language model, while the same result using full trees is shown in Table TABREF39 when using our neural PCFG/compound PCFG (and is more challenging due",
    "218615a005f7f00606223005fef22c07057d9d77": "\nTable TABREF54 (right) shows the non-binary parsers' per-tree precision/recall scores on the labeled test set for the compound PCFG/neural PCFG on the gold trees.\nNeural PCFG Optimization with Variational Inference\n\nTable TABREF55 lists the per-run INLINEFORM1 values for log likelihood (LL) for the unsupervised grammar induction, along with the corresponding mean standard deviation and number of effective degrees of freedom.\nModel Details\nFor experiments with the neural PCGP, we use 4 hidden layers with 10k-dimensional projection vector, followed by two hidden layers that use ReLU and dropout with 40% of the output nodes dropped. We set INLINEFORM1 to be a normal prior with parameters INLINEFORM1 sampled from a Gaussian with mean vector 0 and variance 0.06 (in this setting we set the number of unpruned rule types to be the number of tokens in the vocabulary).\n\nFor the neural PCFG, we use an LSTM with 128-dimensional hidden states and dropout of 0.5, and a neural composition function that is an LSTM layer with 256-dimensional hidden states followed by a bilinear layer.\n\nFor the neural RNNG, we set INLINEFORM0 to be a Gaussian distribution with mean vector 0 and a prior variance of 0.12. We use a stack LSTM whose hidden dimension is 256, and a tree LSTM with 128 hidden dimensions.\n\nImprovements in Inference Speed using GPU\n\nWe experimented with training the neural PCFG with the INLINEFORM0 optimization strategy above, but we faced significant issues with local minima, so instead we use the following approximation. First, a softmax is applied to the INLINEFORM2 scores, which for INLINEFORM4 corresponds to a soft normalization of parameters across rule types. By setting the log likelihood to be\n\nthe likelihood can be estimated using a single sample from the softmax. This simplification allows us to use much quicker stochastic optimization methods, such as ADAM BIBREF91, ADAMW BIBREF92. We also found that a single batch is sufficient to obtain fast convergence on the INLINEFORM0 gradient. We use a batch size of 100 and a learning rate of 1e-3, with an annealing schedule.\n\nFor the inference network, we use a 2-layer Transformer, and",
    "867290103f762e1ddfa6f2ea30dd0a327f595182": "\nLanguage Models, Inference, and Loss\nThere are several components of our final loss that need to be discussed in more detail, which are detailed in Table TABREF54 and Table TABREF55.\nTable TABREF54: Training losses for BLEU (lower is better), perplexity (higher is better), and grammaticality judgment accuracy (higher is better).\n\nGiven a sentence INLINEFORM0, we first predict a structured inference network (INLINEFORM0 ) for the probability of INLINEFORM1 given the unconditioned hidden sentence representation INLINEFORM0, and then calculate the log likelihood with respect to the ground truth. INLINEFORM0 is optimized by amortized variational inference using reparameterized samples from a variational posterior INLINEFORM1. In order to use these samples efficiently, we follow BIBREF55 and adopt multiple layers with 1024/2048/1024 units with a dropout of 0.5 for each hidden layer. We also use an encoder, which is merely a multilayer MLP.\nThe sentence-level latent tree INLINEFORM1 consists of 7 components, INLINEFORM0 : the INLINEFORM1-th word's position in the sentence INLINEFORM0, INLINEFORM1-th word's category INLINEFORM1, INLINEFORM1-th word's part of speech tags INLINEFORM1, INLINEFORM3 to INLINEFORM7 are concatenated as vector representation. The latent vector INLINEFORM1 is then used to predict the latent rule probabilities of INLINEFORM2, while INLINEFORM3-to-INLINEFORM6 are used to perform amortized inference with the structured inference network.\nWe find that INLINEFORM2-to-INLINEFORM6 are well trained but often perform worse than a simple log-linear model, INLINEFORM0 which results in a lower train efficiency and worse grammaticality judgment scores. The reason for the poor performance of inference is most likely due to the large number of rules. We also see that the sentence-level latent vector INLINEFORM1 is not strongly predictive of INLINEFORM2-to-INLINEFORM6 and leads to poor gramamraticity judgment for words with known rules.\nBLEU Scores for INLINEFORM0\n\nTable TABREF57 shows the INLINEFORM0 /test BLEU scores for the models in Figure FIGREF20 for the INLINE",
    "907b3af3cfaf68fe188de9467ed1260e52ec6cf1": "\nAcknowledgments\nThis work was supported by the UK Government.\n\nReferences\nBIBREF0 A. Iyengar, M. Gupta, M. Iyengar, S. K. Varghese, D. K. G. Srivastava, and R. K. Mehta. What happened to the internet on election night. Nat. Hum. Behav. 48, 3 (2013).\n\nBIBREF1 J. Romera, Z. A. Kowal and B. F. Moffitt. Fake news and news avoidance on Twitter: a comparative media bias study. Nat. Hum. Behav. 47, 719 (2013).\n\nBIBREF2 L. C. Macdonald and O. A. Stolee. The role of social media in the 2016 presidential election. Commun. A. 10, 6 (2017).\n\nBIBREF3 M. G. Price and L. C. Macdonald. Social bots and fake followers on twitter: a preliminary analysis. Sci. Rep. 5, 18232 (2015).\n\nBIBREF4 J. R. S. Jost (Jost, 2011) reports that 62% of american adults report on obtaining news from social media in any of the six activities they do daily.\n\nBIBREF5 A. B. Allcot and J. D. Gentzkow (Allcot and Gentzkow, 2016) report that most fake news articles are retweeted more than real news stories.\n\nBIBREF6 S. Morris and D. E. Rubin. A study of the impact and reach of fake news on Twitter during the 2016 US presidential election. Sci. Rep. 6, 24166 (2016).\n\nBIBREF7 R. F. H. Lau and A. S. Morris (Lau and Morris, 2016) discuss that fake news sites tend to use fake names of legitimate organizations and tend to be short-lived.\n\nBIBREF8 Rubin and Morris (2016) suggest to use a text classification model for fake news. For this study, we used the dataset released by: Rubin and Morris (2016). The main characteristics of the tweets are presented in Appendix A.\n\nBIBREF9 J. Allcot and J. D. Gentzkow. How Fake news is Different. Am. E",
    "56a8826cbee49560592b2d4b47b18ada236a12b9": "\nFunding: This work has received funding from the Imperial College Science and AI Research Facility (IMPAIRF).\nReferences\n\nBae, H., Kietzmann, J., G\u00fcnther, K. (2016). Who is Sharing What and Where? Social Network Structures of Sharing Behavior. In Proceedings of the 12th International AAAI Conference on Web and Social Media (ICWSM 2016).\n\nBentley, M.S., Lin, S.H. (2016). When are tweets from fake news accounts detected as such by users? In Proceedings of the 9th International AAAI Conference on WeBS and Social Media (ICWSM 2016).\n\nBentley, M.S., Lin, S.H. (2017). Understanding User Expectations for Source Authenticity in Online Information Sharing: An Empirical Study on the Detection of Fake News. In Proceedings of the Twenty-Seventh Australasian Software Engineering Conference (ASPEC 2017).\n\nBerlinger, R., Sokolov, M., Adamic, L. (2018). The Social Media Newsfeed: A Network of Personal Networks. In Proceedings of the 26th International Conference on World Wide Web (WWW 2018).\n\nBesbes, J., Pouchet, M., Guerraoui, N., Pizzanelli, L. (2018). Modeling Social Trends Using Deep Learning. In Proceedings of the 34th German Conference on Artificial Intelligence (KI 2018).\n\nBertino, M., Moretti, P., Adhikari, B. (2018). Fake News Detection on Twitter Using Linguistic Features, Network Analysis, and User Exposure. In Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2018).\n\nBIBREF0\n\nSee (McCabe 2020, p. 10)\n\nBIBREF1\n\nSee (Waldman 2019b)\n\nBIBREF2\n\nSee (Gentzkow and Shapiro 2017)\n\nBIBREF3\n\nSee (Chaffey 2018)\n\nBIBREF4\n\nSee (Hermida 2019)\n\nBIBREF5\n\nSee (Silverman 2018)\n\nBIBREF6\n\nSee (Morris et al. 2018)\n\nBIBREF7\n\n",
    "968b7c3553a668ba88da105eff067d57f393c63f": "\nTable TABREF24: Difference between viral tweets labelled as containing fake news and viral tweets denoted as not containing fake news for each variable considered.\n\nTable TABREF25: Difference in Friends/Followers between viral tweets labelled as containing fake news and viral tweets labelled as not containing fake news.\n\nTable TABREF26: Difference in the number of mentions between viral tweets labelled as containing fake news and viral tweets labelled as not containing fake news.\n\nFigure FIGREF24: Difference in time of exposure among viral tweets labelled as containing fake news and viral tweets labelled as not containing fake news.\n\nFigure FIGREF25: Difference in retweets between viral tweets labelled as containing fake news and viral tweets labelled as not containing fake news compared to the distribution of viral tweets not containing fake news.\n\nFigure FIGREF26: Difference in favourites between viral tweets labelled as containing fake news and viral tweets labelled as not containing fake news.\n\nFigure FIGREF27: Difference in hashtags between viral tweets labelled as containing fake news and viral tweets labelled as not containing fake news.\n\nFigure FIGREF28: Distribution of verified versus unverified accounts within viral tweets labelled as containing fake news and viral tweets labelled as not containing fake news.\n\nFigure FIGREF29: Distribution in friends/followers ratio between viral tweets labelled as containing fake news and viral tweets labelled as not containing fake news.\n\nFigure FIGREF30: Difference in number of followers between viral tweets labelled as containing fake news and viral tweets labelled as not containing fake news.\n\nFigure FIGREF31: Distribution of friends ratio between viral tweets labelled as containing fake news and viral tweets labelled as not containing fake news.\n\nFigure FIGREF32: Difference in the number of hashtags between viral tweets labelled as containing fake news and viral tweets labelled as not containing fake news.\n\nFigure FIGREF33: Difference in the number of mentions between viral tweets labelled as containing fake news and viral tweets labelled as not containing fake news.\n\nFigure FIGREF34: Difference in URLs between viral tweets labelled as containing fake news and viral tweets labelled as not containing fake news.\n\nFigure FIGREF35: Difference between the presence of media between viral and viral content.\n\nFigure FIGREF36: Distribution of tweets by polarisation.\nAcknowledgment\n\nThis research was in part funded by the Leverhulme Trust through",
    "f03df5d99b753dc4833ef27b32bb95ba53d790ee": "\nAcknowledgments\nThis work has received support from the EU's Horizon 2020 research and innovation programme under grant agreement No. 644391.\n\nAlbino, A. and Buitenhuis, B., \"Defining fake news: definitions and typologies.\" Communication and the Public 23, no. 2 (2018).\nAllcott, J., Gentzkow, C., and Shapiro, D., \"Fake news and information cascades on social media: A survey.\" Political Communications 37, no. 3 (2018): 251\u201378.\n\nAlshammakov, M. and Maedche, T. L., \"Laughable hoaxes: misinformation in Twitter memes.\" 2016.\n\nBardhan, D., Lazer, D., Roxburgh, S., and Steinberg, L., \"The effects of deliberate misinformation and fake news in the 2015 UK general election.\" International Journal of Public Opinion Research 30, no. 3 (2018).\n\nBarbuto, F., Eisler, A., Maiorino, D., and Van der Laan, A., \"Selling lies on Twitter: evidence of advertising for content and influence on news aggregation.\" Information, Communication & Society 23, no. 4, (2020): 622\u201345.\n\nBates, R., D'Lima, M., De Rosa, F., and Vivaldelli, N., \"The 2016 US president campaign and the spread of fake news.\" Nature 556, no. 7702 (2017): 51\u20136.\n\nClare, J. P. A. and Gentzkow, C., \"Are people smarter in 140 characters? Testing claims and evidence in a viral political hoax.\" Behavioral and Brain Sciences (2017).\n\nConroy, S., Carley, T., Alvarez-Mori, Z., Behera, A. J., Fabbri, F., and Voss, C., \"Fake news: A systematic literature review and research agenda.\" Communication Reviews 34, no. 4 (2017): 439\u201370.\n\nCox, N. L., \"Manipulating emotions within an online social network.\" Nature Human Behaviour 3, no. 11 (2018).\n\nDemartini, L., Dodds, D., and Zollo, L., \"Predicting content-tweet cascades in Twitter.\" arXiv preprint (",
    "a8f51b4e334a917702422782329d97304a2fe139": "\nACKNOWLEDGEMENTS\nWe want to acknowledge the anonymous reviewers for their excellent notes that helped improve quality and readability of the paper.\nAuthor Information\nI am a researcher working within the Department of Computing at Imperial College London in the Interdisciplinary Research on Artificial Intelligence department, based in the Centre for Machine Intelligence (CMI). My research is mainly focused on machine learning and Artificial Intelligence problems. I also try to advance my skill as an algorithmic artist when I find the time, by publishing in competitions such as CLS BIBREF16.\nCompeting Interest Statement\nAll co-authors declare that they do not compete with anyone for any financial interests or other potential conflicts of interest.\n\nReferences\n\nAllcot, Jeffrey. (2017.). 'What makes fake news go viral? An analysis of social media during the 2016 US Presidential Election'. Journal of Computer Science, 10, 47(8). Doi: 10.3390/jcs10081947.\n\nConroy, J. J., Schroeder, S., Zucker, R. B., & Oehmichen, A-F. (2017). 'Measuring Fake News'. Communications of the ACM, 61(4), 94\u2013101. Doi: 10.1145/3119001.\n\nCraig, W. (2017). 'Fake news spreads faster than the truth online, and it's getting harder to tell the two apart'. https://www.youtube.com/watch?v=d5-GKu7bV5XU.\n\nDiaz-Lopez, J. (2017). 'The future of Fake News \u2013 Computer Science Perspectives, Oct 2017'. In Computer Science Perspectives, Special Issue: Special Issue on Computer Science Perspectives on Fake News, October (pp. 4-9). ISSN 1077-0878.\n\nDiaz-Lopez, J., Bousquet, J., Espinosa, M., Molina-Solana, M. & Oehmichen, A.-F. (2017). 'Fighting fake news and misinformation in Social Networks: A systematic Review'. ACM Computing Surveys, 50(4), 116:1-116:29. Doi: 10.1145/3024076.\n\nFerguson, A. C. (2016). 'The impact of social media on electoral",
    "dca86fbe1d57b44986055b282a03c15ef7882e51": "\n\nAcknowledgments\nThe author acknowledges the financial support of the Engineering and Physical Sciences Research Council (UK). This is a summary of a research project commissioned by UK Research and Innovation, in support of research activities in the UK, which was carried out under EPSRC grant number EP/N016651/1 'Fake News: Characterization and Automatic Detection on Social Media'.\nREF\nBIBREF1 Silverman, Craig (2016) \"Fake News, Truth Decay and Political Engagement: An Agenda for Researchers.\" Available at https://papers.ssrn.com/sol3/Fake-News,-Truth-Decay-and-Political.pdf.\nBIBREF10. Allcot, Matthew, and Robert Gentzkow (2017). Fake News: A Very Short Introduction. Oxford: Oxford University Press.\nBIBREF2 \"Fact-checking, the spread of fake news and the future of Internet regulation.\" The New York times. Available at https://www.nytimes.com/interactive/2017/02/04/magazine/fake-news-disinformation.html.\nBIBREF3 \"The fake news crisis.\" New York Times. Available at https://www.nytimes.com/upshistory/20170106-fake-news/index.html?_r=0.\nBIBREF4 Keeble, Eoghan and Andrew Appleton. (2011) \"Social Media and Information Seeking During the 2008 Presidential Election Campaign in the United States.\" Computers in Human Behavior 27 (8), pp. 2705\u20132713.\nBIBREF5 Silverman, Craig (2016) \"Trump-bashing.\" The Guardian. Available at https://www.theguardian.com/media/2016/nov/04/donald-trump-media-election-reality-check-usa#axzz4wO8DpPFLg.\nBIBREF6 Morris, Andrew C., James B. Adelman, and Eric Gilbert (2017). \"How Many Americans Get Their News from Twitter?\" Available at https://www.theatlantic.com/science/archive/2017/02/how-many-americans-get-their-news-from-twitter/422728/.\nBIBREF7 Rubin, Seth M., Daniel Littman, and Lidiane Guimar\u00e3es",
    "27dbbd63c86d6ca82f251d4f2f030ed3e88f58fa": "\n\n[1] H. Zhang, M. Li, P. Du, Y. Zhang, T. Shen, Y. Zheng, Y. Wu, and Y. Liu, \"NMT and SMT system for old Chinese translation.\" In Proceedings of 2019 3rd International Conference on Text, Speech and Dialogue (TSD19), 2019.\n[2] H. Zhang, Y. Wu, Y. Liu, T. Shen and Y. Zhang, \"Parallel corpus creation of ancient Chinese and modern Chinese via long document image mining.\" In Proceedings of 2019 3rd International Conference on Text, Speech and Dialogue (TSD19), 2019.\n[3] G. R. Hirst and D. Schlangen, \"Statistical translation models.\" In Proceedings of the 14th Conference of the Annual Meeting of the Association for Computational Linguistics (ACL 2015), 2015.\n[4] H. Zhang, Y. Wu, Y. Liu, T. Shen and Y. Zhang, \"Paragraph alignment methods for Chinese-English and English-Chinese machine translation.\" Proceedings of 2018 International Conference of the Association for Machine Translation (2017)\n[5] H. Zhang, H. Zhang, Y. Wu, Z. Li and F. Wang, \"Neural machine translation for old Chinese.\" International Journal of Machine Translation, pp. 1-15.\n[6] Xiao, J., Wang, X., Chen, Z. and Wang, P., \"A lexical semantic based alignment framework for bilingual dictionary acquisition.\" Proceedings of Association for Computational Linguistics 2017: The 46th Anuual Meeting of the Association for Computational Linguistics, 2017.\n[7] G. R. Hirst, \"Lexical and phrase-based machine translation.\" Computational Linguistics: A Journal of Description and Theory of Language 11, no. 1-2, pp. 23-59.\n[8] H. Zhang, Y. Liu, Y. Wu, T. Shen and Y. Zhang, \"Preprocessing ancient Chinese corpus for neural machine translation.\" In Proceedings of International Conference on Machine Translation, 2020.\n[9] H. Zhang, Y. Wu, Y. Liu, T. Shen, M. Li, and Y. Zhang, \"Paragraph alignment for ancient Chinese and modern Chinese data.\" Proceedings of International Conference on Machine Translation, 2020\n[10] H",
    "b9d07757e2d2c4be41823dd1ea3b9c7f115b5f72": "\n\nWe are grateful to the anonymous reviewers and the organizers of ACL2019 for their valuable reviews. The authors would like to sincerely thank Jinchao Tan and Zheng Zhang for their great help.\nFootnotes\n\nREFERENCES\nBIBREF0 Liu, Y., Tiedemann, A., Kudija, J., and Eisele, S. Transformer Models\n\nBIBREF1 Cho, H., Gulcehre, C., and Cho, K. End-to-End Learning for Neural Machine Translation. In ACL, pages 973\u2013980, 2014.\nBIBREF2\n\nBIBREF3 Xiong, X., and Huang, D. (2015)\n\nBIBREF4 Vaswani, A., Shazeer, N., Ramachandran, B., and Yang, Y. Attention is all you need-a nonlinear transformers paper. In ICLR, 2017.\nBIBREF5 Zhang, X., Yang, Y., and Zang, Z. Enhancing Parallel Corpora via Knowledge Transfer.\n\nBIBREF6 Li, S., Yin, X., and Zheng, Z. A Lexical-Based Approach to Bilingual Word Alignment by Combining Word and Phrase Alignments. In ACL, pages 1635\u20131644, 2018.\n\nBIBREF7 Chen, H., Liu, Y., and Zheng, Z. A Chinese Word Aligner Based on Dictionary Matches. In ACL, pages 1131\u20131141, 2015.\n\nBIBREF8\n\nBIBREF9 Zheng, Z., Huang, D., Huang, T., and Jiang, Z. A Statistical Approach to Aligning Lexical Units Across Corpora. In ACL, pages 1743\u20131757, 2016.\n\nBIBREF10\n\nBIBREF11 Li, S., Liu, Y., and Zheng, Z. Aligning Subclause-based Paragraphs by Word-Based Statistical Information. In ACL, pages 853\u2013860, 2015.\n\nBIBREF12 Li, S. (2017)\n\nBIBREF13\n\nBIBREF14\n\nBIBREF15\n\nBIBREF16\n\nBIBREF17\n\nBIBREF18\n\nBIBREF19\n\nBIBREF20\n\n",
    "808f0ad46ca4eb4ea5492f9e14ca043fe1e206cc": "\nAcknowledgements\nThis research was in large part supported by NVIDIA, and was carried out using resources from the NVIDIA AI Explained Lab, which was created to accelerate AI advancement around explaining how AI systems work by giving engineers and researchers a place to share knowledge and learn from each other.\nThis work was also supported in part by the Advanced Research Projects Agency-Energy in A.I. (ARPA-E AI4E) Award under Contract # N000198170145, the Ministry of Science and Technology of Taiwan (Grant No. 104-2115-M-034-001-08) and the National Science Council in Taiwan, the National Science Foundation under Grant CCF-2038004, and the U.S. National Science Foundation award number 1807176.\n\nThis work was supported in part by the European Union's Horizon 2020 research and innovation programme. This publication reflects only the authors' views, the Commission cannot be held responsible for any use which may be made of the information it contains.\n\nThis work was also supported in part by an award of grant number HR001118/2020-00046 from the Netherlands Organization for Scientific Research (NWO).\n\nThis work is supported in part by the Defense Advanced Research Projects Agency (DARPA) under Contract No. HR001118QB018. DARPA has contributed to the research, development, and testing of the material in this paper. The views and conclusions expressed herein are those of the authors and do not necessarily reflect the official position of DARPA or the U.S. Government.\n\nWe acknowledge with thanks the support of NVIDIA Corporation with the donation of the Tesla V100-PC-G.\n\n\\vspace{1cm}\n\n\\noindent This work was done during the NAFSAI A.I. Summer Training for Ph.D. Students (AIST-2020) and the NIPS Summer Institute on Machine Learning and Computing (NIPS-2020).\n\\vspace{0.6cm}\n\\noindent\n\nAppendix A. Code, Data, and Model Details: Character Space Module\n\nCode\n\n\\lstinput{source/a.py}\n\nData\n\n\\lstinput{source/c.tar.tar}\n\nModel Details\n\n\\lstinput{source/c.pth}\n\nAppendix B. Code, Data, and",
    "36ae003c7cb2a1bbfa90b89c671bc286bd3b3dfd": "\n\nAcknowledgements.\nWe gratefully acknowledge the support of the National Science Foundation.\nWe gratefully acknowledge the support of The University of British Columbia's Centre for Advanced Materials Design and Manufacturing, The Canadian Institute for Advanced Research, The Canada Research Chairs Program, IBM Cognos and DSA Centre, Microsoft, and The John Templeton Foundation.\nWe gratefully acknowledge the support of the National Research Foundation and the University of British Columbia.\n\nThis research was partially supported by the Canada Research Chair Program.\n\nWe gratefully acknowledge the support of the Natural Sciences and Engineering Research Council of Canada.\nWe gratefully acknowledge the support of the Simons Foundation.\n\nWe gratefully acknowledge the support of the Canada Foundation for Innovation.\n\nWe gratefully acknowledge the support of the Google Faculty Research Award.\n\nWe gratefully acknowledge the support of [N1], [N2], [N3], and [N4].\nWe gratefully acknowledge the support of [N5], [N6], [N7], and [N8].\nWe graciously acknowledge the support of the Institute for Advanced Study.\n\nWe gratefully acknowledge the support of the [N9], [N10], and [N11].\nAlireza Alemi received the Master of Information and Computer Science and was a senior research fellow in applied machine learning at UC Berkeley. He holds a bachelor's degree in computer sciences and engineering and a bachelor's degree in physics from Stanford University, and a PhD degree in applied mathematics and computer science from UC Berkeley.\n\nAlexis Amini is a third-year student majoring in cognitive science and mathematics. His interests include artificial intelligence, applied probability, cognitive modeling, experimental psychology, and complex systems and is a recipient of the Stanford Alumni Undergraduate Research Award, UC Berkeley's Excellence in Undergraduate Research Award, and a Google Faculty Research Award.\n\nAlicia P\u00e9rez is pursuing a Bachelor of Science in Information Science, with a minor in Psychology. She is a member of the Cornell Cognitive Science Club and Theta Pi Epsilon (elementary education honor society) at the University of Cornell and is a member of the Cornell Computer Science Club as well as Theta Chi Beta (computer science honor society). Her future interests include artificial intelligence, robotics, natural language processing, and artificial life.\n\nAnkit Anand received the B.S. in computer science from Georgia Tech and the M.Eng. in computer science from Cornell",
    "f0b1d8c0a44dbe8d444a5dbe2d9c3d51e048a6f6": " This can be addressed in the future by using crowd sourcing tools such as Amazon Mechanical Turk BIBREF35, as well as increasing the number of evaluators.\nAcknowledgements\nWe are deeply thankful to the numerous contributors to TV Tropes that provided the HLA data. We are also grateful to members of the Open Dialogue System team BIBREF21 that made use of our HLA information. We are very thankful to members of the University of [ANON] that volunteered their time to participate in our human evaluation. We are also very grateful to the members of our dissertation committee for their invaluable guidance and support. We would also like to thank Dr. Shiva Suresh BIBREF1 for their guidance, and Dr. Scott Kuether and Dr. Richard Socher BIBREF5 for their help with TV Tropes. Lastly, we thank everyone who viewed our presentation and discussion for this work at SIGDIAL 2019 BIBREF13.\n\nAlphabetical Order\n\nBIBREF0 yu2018personalizing\n\nBIBREF1 suresh2018dialogue\n\nBIBREF10 wolf2019transfertransfo\n\nBIBREF11 wolf2019transferlearning\n\nBIBREF12 chittco2019convai2\n\nBIBREF13 humeau2019real\n\nBIBREF14 kvmemnn\n\nBIBREF15 li2016persona\n\nBIBREF16 bartl2017retrieval\n\nBIBREF17 liu2019emotion\n\nBIBREF18 pichl2018alquist\n\nBIBREF19 dorr2018light\n\nBIBREF20 pasunuru2018game\n\nBIBREF21 wang2016learning\n\nBIBREF22 antol2015vqa\n\nBIBREF23 bordes2016learning\n\nBIBREF24 ilinykh2019meetup\n\nBIBREF25 shuster2019engaging\n\nBIBREF26 pak2020exploring\n\nBIBREF27 matthews2016singular\n\nBIBREF28 devin2018bertbi\n\nBIBREF29 pascanu2013semi\n\nBIBREF30 zinkevich2014adadelta\n\nBIBREF31 abburi2019multi\n\nBIBREF32 bhagat2019bert\n\nBIBREF33 chen2019multi\n\nBIBREF35 hu2008",
    "357eb9f0c07fa45e482d998a8268bd737beb827f": "\nACKNOWLEDGMENTS\nThis research was funded in part by a Natural Sciences and Engineering Research Council of Canada (NSERC) Discovery Accelerator Grant.\n\nWe thank J. Cuddy, S. Kimura, and S. Zou for their contributions and assistance.\nThe authors would also like to acknowledge that this published paper was created as part of the [CSED-2020-1701 (E) Efficient Information Retrieval] program.\n\nReferences\n\nBIBREF0 li2016persona\n\nBIBREF1 schmidt2017emotional\n\nBIBREF2 cattuto2010big\n\nBIBREF3 tv tropes\n\nBIBREF4 pychl2017style\n\nBIBREF5 li2016persona\n\nBIBREF6 fern2016towhee\n\nBIBREF7 humeau2019real\n\nBIBREF8 wolf2020text2\n\nBIBREF9 humeau2019real\n\nBIBREF10 liu2018distant\n\nBIBREF11 wolf2019transfertransfo\n\nBIBREF12 humeau2019real\n\nBIBREF13 humeau2019real\n\nBIBREF14 pasunuru2018game\n\nBIBREF15 yu2016modeling\n\nBIBREF16 bartl2017retrieval\n\nBIBREF17 liu2019emotion\n\nBIBREF18 pichl2018alquist\n\nBIBREF19 li2016persona\n\nBIBREF20 pasunuru2018game\n\nBIBREF21 wang2016learning\n\nBIBREF22 antol2015vqa\n\nBIBREF23 bordes2016learning\n\nBIBREF24 ilinykh2019meetup\n\nBIBREF25 shuster2019engaging\n\nBIBREF26 hu2008collaborative\n\nBIBREF27 hoffman2017factorizing\n\nBIBREF28 miao2019text\n\nBIBREF29 hu2008collaborative\n\nBIBREF30 santoro2000singular\n\nBIBREF31 yi2008comics\n\nBIBREF32 ling2019facebook\n\nBIBREF33 kastner2016cornell\n\nBIBREF34 nesterov1983gradient\n\nBIBREF35 tsne\n\nBIBREF36 kullback1959",
    "ad08b215dca538930ef1f50b4e49cd25527028ad": " These include such tasks as table booking where the user might not necessarily select one restaurant for the evening, and thus need to make a decision between multiple options.\nAcknowledgements\nWe gratefully acknowledge and thank all the people who helped us in our work on this project, including the many developers and annotators involved in the training sets used for the ranking model; our students in the Computer Systems Research Centre at Aston University who built the user testing interface for the demo system; all the wonderful people who helped us in our work on the Reddit and Yelp datasets, in particular Dr. G. Fotevi\u0107 for his many fruitful conversations.\nWe extend our thanks to our co-authors from the original PolyResponse paper: S. Henderson, A. Gatt, S. Rafferty, A. A. Kozhugov, and S. Toussaint.\nReferences\n\n[1]  Y. Liu et al., \"Conversational Search: A New Benchmark Suite for Evaluating End-to-End Dialogue Systems,\" in Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 685\u2013697, 2017.\n\n[2]  C. Bajjali and K. M. Ganesh, \"Conversational Intelligence,\" Science Robotics, 2(11):eaar3366, 2017.\n\n[3]  A. Zysawski, R. N. Beam, O. Kiesewetter, L. V. I. Eisner, R. P. Patwardhan, L. Li, J. B. Stentle, N. Fenton, C. H. Potts, and C. D. Manning, \"A Joint Statistical Relation Language and Dialogue Act Model for Conversational Search,\" in Transactions of the Association for Computational Linguistics, volume 9 of the 36(2) conference of the Association for Computational Linguistics, pages 773\u2013787, 2016.\n\n[4]  R. Choi and Y. Liu, \"PolyResponse: Improving End-to-End Dialogue Systems Using Cross-Task Pre-Training,\" in Proceedings of the 2017 Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 2025\u20132037, 2017.\n\n[5]  S. Henderson and S. Kannan",
    "31101dc9937f108e27e08a5f34be44f0090b8b6b": " A more modular system structure will allow a more fine-grained control of the underlying dialogue flow and to better integrate external modules.\n\nAcknowledgements\n\nWe thank our colleagues Jure Vidner and Marko Mihajlovi\u010d for helping to collect and annotate dialogues, and for providing a useful domain dialogue service. Additionally, we thank the anonymous reviewers for their valuable feedback. In addition, we thank James Fyfe for his work towards implementing the initial PolyReponse prototype.\n\n[1]\n\nBIBREF0\n\nhttps://polyreponse.org/\n\n[2]\n\nBIBREF1\n\nC. Brubaker, F. McCallum, M. Ester, and A. Dale,\n\nTAM 2013\n\n[3]\n\nBIBREF2\n\nM. Ester, R. Irszt, A. Chall, and R. J. Mooney (eds.),\n\nSpringer Verlag\n\n[4]\n\nBIBREF3\n\nW. Xu, H. I. Chen, M. R. R. Eslami, J. H. Seo,\nS. Zhu, M. H. Choi, S. B. Hori, H. S. Lee\n\n[5]\n\nBIBREF4\n\nS. Zhang, J. Meng, and F. Zhai\n\nAISTATS 2014\n\n[6]\n\nBIBREF5\n\nA. Gupta, H. B. Saputra, J. Meng, Q. Guo (eds.),\n\nSpringer Verlag\n\n[7]\n\nBIBREF6\n\nBIBREF7\n\nhttps://polyreponse.org/\n\n[8]\n\nBIBREF8\n\nA. Gupta, H. B. Saputra, J. Meng, Q. Guo (eds.),\n\nSpringer Verlag\n\n[9]\n\nBIBREF9\n\nM. Ester, R. Irszt, A. Chall, and O. M. Yatkar\n\n[10]\n\nBIBREF10\n\nT. Yim, W. Xu, H. B. Saputra, M. R. Eslami, O. M. Yat",
    "e4a315e9c190cf96493eefe04ce4ba6ae6894550": "\nAcknowledgements\nThis work has been funded by the Horizon 2020 project COVERS: COnversational SEarch on Multiple Domains, grant agreement #641886. This work has been enabled in part by Cogito-Co.\n\nThis demo was conducted at WCCF-19, by a team of researchers from various universities, including the authors of this paper.\n\n\n\n# **WELCOME TO**\n\n**I ** am currently enjoying a rare moment of solitude in** Avery Manor House. Though I say solitude, there is little of that to speak of in the house. The place is too loud, with all that goes on here, too many people too excited about whatever drama is unfolding.\n\n\"Oh, my stars, I wonder who I'm looking at,\" I hear someone mutter, and then, \"It's the most adorable thing.\"\n\nI can see why she's taken aback. While she may be in deep mourning, what little I know of her indicates that she's the type not to be easily taken in by appearances.\n\n\"May I speak with you?\" she finally asks.\n\n\"You may. What is it?\" I respond with genuine interest\u2014I think I should get to know her better.\n\n\"I need to tell you something shocking, but I won't have much time to tell you myself. In fact, I've barely had time to get dressed, and now you want to speak with me?\" She shoves something into my hands, and I realize it's none other than a small bundle of money.\n\n\"I'm so sorry for the circumstances, love. But this is for the best.\"\n\n# AUTHOR'S NOTE\n\nAlthough this story has a definite connection to _Vampire High_, and I have tried to make the time and place of this story at least somewhat consistent with that book, it is a stand-alone story.\n\n# Contents\n\n# **PROLOGUE**\n\n#\n\n# **CHAPTER 1**\n\n#\n\n# **CHAPTER 2**\n\n#\n\n# **CHAPTER 3**\n\n#\n\n# **CHAPTER 4**\n\n#\n\n# **EPILOGUE**\n\n#\n\n# **ABOUT THE AUTHOR**\n\n#\n\n# FAVORITE SQUAD GOALS\n\n#\n",
    "6263b2cba18207474786b303852d2f0d7068d4b6": " We would also like to explore the possibility of using reinforcement learning to adapt to user preferences without requiring large amounts of tailored training data. We also plan to work with end-to-end trainable task-oriented dialogues instead of the current modular approaches; although we are not aware of previous work using such a method for task-oriented dialogue in a restaurant search context, some interesting approaches for training end-to-end task-oriented dialogue agents have recently been proposed for the purpose BIBREF10, BIBREF7, BIBREF21, BIBREF19, BIBREF5. Similarly to those approaches, the architecture of task-oriented dialogue agents can potentially be adapted to allow for more efficient learning of system parameters. We plan to make training data available from additional domains at: https://tinyurl.com/y3evkcfz, and encourage other researchers to experiment in the domain of task-oriented retrieval-based dialogue and multi-modal multimodal interaction.\nAll sources that are cited or cited within BIBREF0 are listed in BIBREF10. The main sources relevant to the task of restaurant search and booking are as follows: BIBREF1: de Melo, D., D. Bauer, C. Cortes, and L. Denner. Building domain ontologies for task-oriented dialogues: a case study. In Proceedings of the 2nd International Workshop on Semantic Evaluation: Evaluation of Semantic Relations in Dialogues, 2017. BIBREF2: Almeida, F., D. Bauer, L. Li, J. van der Plas, G. Zweigenbeek, and H. Nogueira. Conversational search: combining ontologies and search. In Proceedings of the 2017 European Language Technology Association's Workshop on Language Interfaces for Accessing Databases, 2017. BIBREF3: Bender, M. and R. Zhang. Natural conversations with systems. In Proceedings of the Conference on Human Language Technologies, 2014. BIBREF4: Cimiano, L., E. Sordoni, E. Frasca, A. Boccaccio, and L. Cimico. PolyReponse: an open-source end-to-end multitask conversational search engine. In Proceedings of Interspeech, 2018. BIBREF5: Hoyle, R., G. Zweigenbeek, J. van der",
    "c1c44fd96c3fa6e16949ae8fa453e511c6435c68": " Also we will explore using our model to perform other sequence generation tasks like caption generation and machine translation.\nAcknowledgments\n\nOur work was supported in part by the National Research Foundation of Korea(NRF) funded by the Ministry of Science, ICT&Future Planning and the Korea Institute of Science and Technology Promotion(KISTP). We would also like to thank the NYT50 dataset creators for sharing their work, and acknowledge the HPC resources and help by KISTI Open Platform. We also gratefully acknowledge the support from SK HPC (SKT&L) during the author's visit to KISTI.\n\n\\input{refs.bbl}\n\n\\input{references.tex}\n\nBIBREF0 J. Card, A. Pedersen, D. Erk, Y. Yurochkin, L. Welleck, P. Garimella, E. Vania. Neural summarization via extractive-abstractive cross-training. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics (ACL), 2017.\n\nBIBREF1 B. Chen, L. Welleck, L. Dredze, H. Witten. Abstractive text summarization with neural extractive models. In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL), 2016.\n\nBIBREF2 Y. Hu, X. He, G. Gilde, F. Yu, D. Lin. Deep sentence compression for abstractive text summarization. TACL, 2014.\n\nBIBREF3 Y. Pan, X. Hu, T. Xiao, Z. Lin, P. Luo. Abstractive sequence-to-sequence summarization with deep encoder-decoder and coverage-vector reinforcement. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (ACL), 2018.\n\nBIBREF4 Y. Wu, Y. Ye, D. Fan, M. Liu, V. Purohit, W. Choi. Abstractive-extractive hybrid sequence-to-sequence modeling with copy mechanisms. Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (ACL), 2018.\n\nBIBREF5 Q.-H. Qian, V. Purohit, Z. Lin, G. Gilde",
    "d28d86524292506d4b24ae2d486725a6d57a3db3": "\nAcknowledgments\nWe thank the anonymous reviewers of ACL-IJCNLP-DIAIL-19 for their constructive feedbacks. This work is supported by the National Science Foundation of China (NSFC), grant number 61673016, and the National Key R&D Programs of China, grant number 2017AAA010300. The authors wish to acknowledge the support they received from Beijing Municipal Commission of Science and Technology(BJ20160108), and the Beijing Research Center of Big Data Technology.\n\nReferences\n\n$$\n$$\n$$\n# THE TROUBLE WITH DYING\n\n**A Novel of the Zane Grey**\n\n**RANGE**\n\nThe Trouble with Dying, the twentieth novel in the career of Zane Grey, is written from the point of view of two men who, though strangers to each other, live on the frontier and face each other across the wide divide that separates right from wrong. It is a drama, at the outset both pathetic and funny, and through the drama the reader comes to view the grim realities of the West.\n\nFor a complete list of this author's works,  \nturn to the front of this book or  \nwrite to Zane Grey Publications, Inc.\n\nThe Zane Grey\u00ae  \n **RANGE**  \n **novels**\n\nAvalanche\n\nBar 20\n\nThe Border Legion\n\nThe Call of the Canyon\n\nThe Captured Skyline\n\nCartier the Magnificent\n\nThe Call of the Wild\n\nCastle in the Desperadoes\n\nThe Colter of Lost Creek\n\nCondor's Crest\n\nConquerors of the Canyon\n\nCrossing the Wire\n\nFlint the Lucky\n\nForlorn River\n\nThe Golden Trail\n\nGovernor of Cochise\n\nHead of a Dead Man\n\nThe Man Called Noon\n\nThe Man from Skibbereen\n\nMen of the Monument\n\nThe Master Key\n\nThe Merry Men\n\nThe Mountain Trail\n\nNorth of 36\n\nOver on the Dry Side\n\nThe Outlaws of Raven Peak\n\nRainbow's End\n\nRed Rock's Mistake\n\nRiders of High Rock\n\nRippin' the Coyote\n\nA Son of the Border\n\nTex Burnam's Trail of the Silver Ace\n\nThey Found a Castle",
    "feafcc1c4026d7f55a2c8ce7850d7e12030b5c22": "\n\nFuture work in our paper mainly focus on the two-stage decoding structure and refine process. First, we think it will be useful to design more refined sequence generation structure, to let two decoders better cooperate in both input and output. Second, the discrete objective can be incorporated into the model training process. For example, we can train multiple summaries in the draft process and force the refine process to produce the best summary(according to discrete reward) as the objective.\n\nAcknowledgments\n\nThis work was supported by the National Key Research and Development Program of China under Grant No. 2018YFB1004601.\nConflicts of Interest\n\nThe authors declare that they have no conflict of interest.\nReferences\n\n1) J. Xu, A. Zhang, A. C. Turc and T. S. Darrell. \"Summarunner: Language-centered text summarization using attention.\" In\n\nProceedings of the 54th Annual Meeting of the Association for Computational Linguistics, Stroudsburg, PA. 2018. AAAI Press.\n\n2) H. Sennrich, J. Farkas, D. Chen, Q.-Y. Wang, J. Zhu, E. S. Pfeifler, C. K. Pal, C. Lee and R. S. Zettlemoyer. \"Neural machine translation of abstractive text summaries in sixty-three languages.\" In\n\nProceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. 2017.\n\n3) C. M. Zhou, J. Zhao, M. Liu, Y. Qian and Q. Zhou. \"Learning to attend from sequence to sequence.\" In\n\nProceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. 2017.\n\n4) R. See, Y. Zhou, C. D. Batty, S. G. Chan and S. T. C. Ho. \"Learning to generate effective abstractive human summaries from multiple sources.\" In\n\nProceedings of the 54 th Annual Conference of the Association for Computational Linguistics. 2018.\n\n5) J. C. S. Chen, E. K. K. Tan, D. Rambhatla and C. L. Zitnick. \"Neusum: A recurrent neural network extractive summarizer that learns to select and summarize.\" In\n\n",
    "63488da6c7aff9e374561a24ba224e9ce7f65e40": " Besides, we hope to use more powerful pre-trained language models in future work, such as T5 and XLNet to exploit the advantage of the contextual representation models. We will also apply our model to extractive summarization, which hopefully has higher performance, we will continue to work on it in future.\n\n[1] D. G. Radinsky, S. Charniya, E. Xue, B. A. Zens, B. Yang, D. J. Klein, R. C. Sprasley and H. Wallach, \"Summarizing with Sequence-to-Sequence Learning,\" Proceedings of the 2015 International Conference on Machine Learning (ICML 2015), Sydney, Australia, 2015, pp. 1492\u22121497.\n[2] H. Zhang and G. Riedelmayer, \"Extractive summarization via word clustering and phrase extraction,\" in Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (ACL 2016), Philadelphia, USA, 2016, pp. 2198\u22122205.\n[3] R. Meena and J. Cardie, \"DeepCognitive: Towards deep, cognitive and effective document summarization,\" in Proceedings of the Thirtieth Annual Meeting of the Association for Computational Linguistics (ACL 2015), Santa Fe, New Mexico, 2015, pp. 1529\u22121538.\n[4] H. Zhang, G. Riedelmayer and J. Cardie, \"Extractive summarization via word clustering and phrase extraction,\" in Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (ACL 2016), Philadelphia, USA, 2016, pp. 2198\u22122205.\n[5] Y. Luo, S. Bhatia and J. Cardie, \"Learning to write: a neural abstractive model for extractive summarization,\" in Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (ACL 2016), Philadelphia, USA, 2016, pp. 2216\u22122125.\n[6] C. D. Blaylock, H. Zhang, X. Zhang, J. Cardie, D. G. Radinsky, Y. Chen and B. Yang, \"Sequential neural network with copy mechanism for document summarization,\" in Proceedings of The Thirty-third Conference on Computational Linguistics (Volume 1: Long",
    "c34e80fbbfda0f1786d3b00e06cef5ada78a3f3c": "\n\nAppendix\nThe supplementary information is given in Section APPENDIX. We will consider more ways of improving INLINEFORM2 accuracy in future.\n\nAcknowledgements\n\nWe thank the anonymous reviewers of the QA workshop of EACL 2017. This research is funded by the National Natural Science Foundation of China through Grant-in-Aid, the Ministry of Human Resources, the People's Republic of China, Project Grant 621202, and the Key-Project Research Program of Ministry of Personnel, the People's Republic of China.\n\nAppendix\n\n# A.1 Data\n\nThe supplementary material for the selection-based QA corpora is given in Section APPENDIX. The detailed statistics of the corpora including the split data are given as well.\n\n# A.2 Intrinsic Analysis\n\nThe intrinsic analysis focuses on analyzing the questions, context, and answer categories.\n\n# A.2.1 The Correlates of Question Types\n\nSince the selection-based QA corpora are constructed from various Wikipedia entries, we use the number of words in questions to measure the question type for Wikipedia (Figure B. FIGREF2 ). There is a significant difference between the question types of the three corpora. For example, only 21.1% of WikiQA's questions have more than 10 words, much smaller than those of SQuAD and Selqa. On the other hand, about 43.2% of SelQA's questions have more than 10 words, much more than those of WikiQA.\n\nFig. B. FIGREF2 : Total number of words for each query-like and natural question in corpora BIBREF6 ~ BIBREF13\n\n# A.2.2 A Preliminary View of Different Answer Categories\n\nWe further give a preliminary view of the different answer categories by examining answer frequency (Figure B. FIGREF3 ). The answers for different categories are shown in Figure B. FIGREF4.\n\nFig. B. FIGREF3 : Answer probability of WikiQA, Selqa and SQuAD corpus\n\n# A.2.3 Distributions of Different Question Types\n\nFor the intrinsic analysis, we determine the question types of the four corpora (Figure B. FIGREF5 ). We group the question types by words from the question lexicon, which only consists of a few different words such as verbs, adjectives, and conjunctions",
    "a9337636b52de375c852682a2561af2c1db5ec63": " Finally, we plan to construct better baseline models by using other machine-learning and deep-learning techniques.\nAcknowledgements\nWe thank all annotators from the crowdsourcing platform CrowdFlower, who worked hard to evaluate question-answer pairs in the corpus.\n\nREFERENCES\n[1] C. Cortes and V. Vapnik. Soft-margin stochastic learning with margin-based losses. In Proceedings of the 20th International Conference on Artificial Intelligence and Statistics, 2009, pages 217\u2013226.\n\n[2] Z. Hsu and M. P\u00f3cs. DeepDocQA: A deep neural network architecture for question answering. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1377\u20131387.\n\n[3] A. Ma et al. Anchoring loss mechanism for extractive question answering. Machine Learning 113(1), 2015, pp. 73\u201398.\n\n[4] R. S. Jhingan et al. A review of open domain question answering benchmarks and data: L-OQA, SQuAD, and others. In Proceedings of the 12th International Conference on Language Resources and Evaluation, 2014, pp. 899\u2013915.\n\n[5] M. V. L. Nguyen and S. L. Tsuru. Open-domain reading comprehension: A survey of benchmarks. Transactions of the Association for Computational Linguistics, 2013.\n\n[6] N. L. Nishida and R. M. Hasegawa. Learning factoid question-answering model from Wikipedia infoboxes. In Proc. of the 10th NLP4J Workshop, 2011, pp. 31\u201337.\n\n[7] M. P. M. P. Murphy et al. Nqover question answering: Corpus-adaptive ngram inference and statistical machine translation. In Proceedings of the 29th Annual International Association for Computational Linguistics Conference, 2008, vol. 1.\n\n[8] c. d. Park. Open-domain QA with an attentional LSTM network. In Proceedings of the 2015 International Conference on Computational Linguistics, pages 4005\u20134013.\n\n[9] C. Prabhumoye and A. Joshi. A cross-lingual question-answering corpus based on a Wikipedia corpus. In Proceedings of",
    "45a5961a4e1d1c22874c4918e5c98bd3c0a670b3": "\nAcknowledgments\nThis paper is based on our paper presented at SIGCIS 2016. Thanks to Drs. Liqun Li and Jing Dong for their detailed comments and assistance on this paper.\nCahill, C. K., Chen, Z. Q. Q., Li, L., Wu, G. L., and Chang, D. C. H. (2016) Wikiqa : A large-scale question-answering dataset from bing queries. Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, volume 1. http: //j.mp/wikiqa-ACL.\n\nFeng, J. W., and Callison-Burch, C. K. J. (2015) Insuranceqa : A large question answering dataset based on insurance contexts. Proceedings of the 22nd International Joint Conference on Neural Networks, pp. 1122\u20131128. http: //j.mp/insuranceqa-ICON.\n\nMead, C. (2005) Ngrams in context: A study of language models with large unseen-occurence data. Lecture Notes in Computer Science, 3513, pp. 90\u2013104. http: //j.mp/gist:2005.\n\nMorales-Marin, G., and D. Callison-Burch (2016) Deep-learning and statistical approaches to question-answering. Transactions of the Association for Computational Linguistics, pp. 409-427. http: //j.mp/emnlp2016.\n\nMurakami, T., Kaji, Y., Yoshimoto, K., and Suzuki, S. (2017) Evaluating answer retrieval by machine translation evaluation criteria. Transactions of the Association for Computational Linguistics, pp. 1-21. http: //j.mp/EMNLP17.\n\nNg, R., Chen, J., Liang, K., and Li, P. (2014) Automatic evaluation methods for question answering systems. In Proceedings of the 24th International Conference on World Wide Web, pp. 1433\u20131443. http: //j.mp/jcr:2014.\n\nRajpurkar, P., Lenssen, R., and Li, L., (2016) Knowledge base question answering: A new",
    "30e21f5bc1d2f80f422c56d62abca9cd3f2cd4a1": " Extrinsic Analysis\nGiven an answer passage, we propose three different methods for the evaluation of information need, which are query based, section based, and paraphrase based. The answer sentence is expected to be one of the first few sentences that are associated with the query. The presence or absence of the answer sentence in a given section or paragraph is expected to provide strong information about whether or not there is the answer context. The presence or absence of the answer phrases is also expected to provide strong information, although they may be not as powerful as the answers themselves. Given two paragraphs, the overlap percentage of answer phrases is expected to be a good metric for their compatibility as answer contexts, since the questions often take those phrases, especially those from articles that are often paraphrase-based. If there exists one answer to a query that covers all paraphrases of that query, it is expected to trigger on all paraphrases. All these informations are captured by the following formulas:\n\nTABLE 1\nSimilarity Evaluation Metrics\n\n(1)\n\nQUERYBASED\n\nThe query is first queried with the string content of each answer context, and the sentences are ranked by their similarity scores. The answer sentence is the sentence that is associated with the query according to the query-based annotations on the training set. The number of top scoring answer contexts is the gold standard. The overlap percentage between the answer sentences and the paragraphs consisting of the answer sentences is computed. Given each answer phrase, the overlap percentage between the phrases and paragraphs is computed. Given each answer sentence, human-provided paraphrases of the paragraph is used; if they are all the same, which means no overlap with any sentence, it can be inferred that none of the answers covers everything. Given each example from a question, its overlap percentage with the paragraphs corresponding to the examples is computed.\n\n(2)\n\nSECTIONBASED\n\nThe answer sentence is expected to be in a specific section. The overlap percentage between the answer sentences and paragraphs constituting sections is measured. The expected answer sentence of each section is the sentence closest to the answer. Using the overlap percentage and number of sentences in the paragraphs, it is expected that the section whose overlap percentage is the greatest contains the answer context. Given each answer phrase, its overlap percentage with corresponding paragraphs is computed, then the overlap percentage and number of sentences in the paragraphs are measured, giving a similarity score for each section.",
    "5c6fa86757410aee6f5a0762328637de03a569e9": " We also plan to investigate methods for cyberbullying detection that could be used to predict the user specific responses based on their past behavior such as number and pattern of cyberbullying posts.\n\nACKNOWLEDGEMENTS\n\nThis work has been done while I was on a research fellowship at Nanyang Technological University Singapore and is supported by the National Research Foundation, Prime Minister's Office, Singapore. I would like to thank Prof. P. K. Ao (Nanyang Technological University) for providing valuable research directions. I also would like to thank three anonymous reviewers that helped in improving the quality of the paper.\n\nReferences & Acknowledgements\n\n1. Waelde, M., Eriksson, P., de Menezes, P., & Emancioglu, C., (2017) Cyberbullying: a global problem in need of attention. Computers in human behavior, 75, pp. 83\u201392.\n2. Kwon, S., Kim, D., & Shin, K., (2015) Internet addiction among Korean high-school students. Cyberpsychology, behavior and social networking, 18 (9), pp. 1473\u20131481.\n3. Lee, H. C., & Kwon, S. J., (2017) A comparative study of cyberbullying perpetuators across social media: patterns and consequences. Journal of social and clinical psychology, 34 (3), pp. 973\u2013992.\n\n4. Shireen, P., & P. M., (2009) Cyberbullying through social networks: definition and prevention considerations. Journal of educational computing research, 46 (2), pp. 107\u2013115.\n\n5. Hajjem, M., & Duffy, P., (2013) Cyberbullying: global overview. Computers in human behavior, 29 (2), pp. 1703\u20131715.\n\n6. Ackerman, J., O'Driscoll, S., & T. L., (2012) Prevalence of cyberbullying in a large sample of Australian adolescent internet users: a comparison of the Webwise Kids Australian Youth Survey (AY-Wise) survey, cyber-bullying survey and the International Cyberbullying Research Collaborative survey. Computers in Human Behavior, 29 (3), pp. 2194\u20132207.\n\n7. Waelde, M., de M",
    "7e38e0279a620d3df05ab9b5e2795044f18d4471": " Future work involves development of such fine-grained detection models for Formspring and Wikipedia. Detection of cyberbullying has potential beyond addressing social networking platforms such as in cybersecurity, forensic science, and health care. Using such fine-grained detection methods, cyberbullying can be addressed in scenarios where bully and victim do not have access to social networking platforms.\n\nAcknowledgments\nWe thank our mentors, A. Gopalakrishnan, and Gita Sukthankar for their guidance. We have used data from following sources: Formspring BIBREF2, Twitter BIBREF3, and Wikipedia BIBREF4. The authors gratefully acknowledge the support of NSF under awards CCF 1718106, CCF 1734085, CCF 1776054, CCF 1844579, CCF 1857591, and CCF 1857592.\n\nNote: This project was undertaken in part as part of the work on the CCF-1828002, CCF-1857595, or CCF-1828003. The statements made herein are solely the responsibility of the authors and do not necessarily represent the official views of the National Science Foundation (NSF).\nAcknowledgments\n\nThis work is a result of collaborative efforts of multiple researchers of various projects and we would like to thank all of them for their contribution. We thank all the members in EMPIRE, especially Alex Y. Sim, Andrew Egan, Arun Goyal, Avni Misra, Bhavya Bhuvad, Bram Boutilier, D. Harish Kumar, Fara Lalljee, Gavin McCallum, Harsha Vanka, Huaming Li, Jason Gubbert, Jiayong Guo, J. Kevin Tidwell, K. V. Sridhar, Karin H. J. S. Fung, Krishnendu Ghosh, Marko Luki\u0107, Matthew Lease, Michael L. Giles, Rahul Patwardhan, Rami B. Zadeh, Samir Khan, Stefano Zanobini, and Yannis Kalantzis for their support and contribution. The following people were particularly helpful while preparing this work: Adham Tewfik, Alex, Andrew, Arun, Avni, Bhavya, Bram, D. Harish, Fara, Gavin, Huaming, Jason, Jiayong,",
    "8b0abc1907c2bf3e0256f8cf85e0ba66a839bd92": "\nJ.V.T would like to thank the CAPES and the University of Porto for providing funding and a research position.\nM.M. acknowledges the financial support from the FCT (Funda\u00e7\u00e3o para a ci\u00eancia e a Tecnologia): UIDB/50658/2013, and APD/00114/2016.\nB.I. would like to thank FCT for the funding and a research position (LISBOA-01-0145-FEDER-007285 and PTDC/SAU-COF/1278/2012).\nBIBREF1.\n.\n.\n.\n.\n\n.\n.\n.\n\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\nBIBREF2.\n.\n\n.\n.\n.\nBIBREF3.\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\nBIBREF4.\n.\n.\n.\n\nBIBREF5.\n.\n\n.\n, for instance, is used in the context of the hate-speech detection challenge at SemEval 2014.\nBIBREF6.\n.\n.\nFonte (2021-02-07).\n.\n\nBIBREF7.\n.\n.\n.\n.\n\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\nBIBREF8.\n.\n.\n.\nBIBREF9.\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\nBIBREF10.\n.\n\n.\n.\n\n.\n.\n,\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\nBIBREF11.\n.\n.\n.\n,.\n.\n.\n.\n.\n.\n.\n\n",
    "03ebb29c08375afc42a957c7b2dc1a42bed7b713": "\n\nWe want to thank all the other people involved in the development of this tool: S\u00e9rgio Gouveia, Jo\u00e3o Ferreira, Jorge F\u00e9lix, Lu\u00eds Pinto, Marco Barrera and Francisco S\u00e1. Our thanks also go to the scientific community for the great work that it makes day-by-day, making possible the development of this tool.\nReferences\n\n[\n\n] Arquilla, J. And R. Venkatesan. (2008). Networks and Netwars: The New Architecture of Competition. Basic Books, John Wiley & Sons, Inc. London, New York: ISBN 9781405853267.\n\n[\n\n] Bartolini, A., Zampieri, F., Caselli, G., Di Stefano, M., Mariani D., and Cipolla, R. (2006). Building and validating an Italian named entity recognition system. In Proceedings of the Second International Conference on Language Resources and Evaluation. [\n\n] Biber, D., S. Rehm, and H. Sweet. (2010). Discourse markers in language use. Cambridge University Press. [\n\n] C\u00e1rdenas, A., Ramallo, I., Pardo-Rueda, P., & Garc\u00eda-Lorido, J. (2006). Detecting Emotive Statements and Affect in Spanish Online and Social Media Corpora..\n\n[\n\n] Churaf, C. (2009). A corpus of spoken Portuguese for the development of linguistic resources. In Proceedings of Corpus Linguistics 2009, LREC, Valencia, Spain.\n\n[\n\n] Declerck, S., Lefevere, C., St-Pol, F., and Vanderplas, B. (2011). Co-reference resolution in multilingual social media corpora with the Europarl and Twitter resources. In Proceedings of the 3rd Workshop on Social-Aware Computing. [\n\n] Freeling, A., A. Martens, J. Koehn, A., L. Kondratyuk, and F. Straub. (2010). An advanced toolkit for natural language processing. Nature-based language processing. MIT Press, Cambridge, Massachusetts, USA.\n\n[\n\n] Gerz, S., & Heilbronn, F. (2012). The Universal Sentence Encoder Model",
    "9cf070d6671ee4a6353f79a165aa648309e01295": " This work could benefit from further investigation.\n1.1\n\nAbstract\n\nIncorporating the semantics of languages into statistics based parsing algorithms involves the mapping of sentences to word vectors. Traditionally, this has been done on the sentence level. Each sentence is mapped into a word space, and the distances between these sentences in this space are used as cues for attachment decisions. However, it has been observed that often the distance between two sentence is independent of context. In other words, if the second sentence is closer to the first sentence than the third sentence then the decision to attach the prep to the preposition in the first sentence is just as well with respect to the second and third sentence. This distance dependent nature of pp-attachment has motivated several work in this direction. We propose a framework inspired by a recent work for mapping text into an unconstrained vector space, and then use this framework to tackle the problem of distance dependent distance and the problem of sentence embedding to predict prepositional path length and direction. Sentence embedding is an effective technique for predicting the distance between sentences for problems of attachment, and is applicable to many problems in NLP. Our work is a step towards this direction, and provides a basis for using the idea for obtaining a universal language vector space, and for exploiting it to address problems pertaining to semantic parsing.\nIntroduction\n\nWe propose a framework for embedding one language into a vector space which is later used to analyze and solve many language-specific parsing problems. The problem we address in this paper is that of distance dependent distance for pp-attachment predictions in English, and more generally, any parsing problems where the semantics of sentences matter. We assume that for language pair A, the distance between the two sentences in a parallel corpus is independent of context.\n\nWe assume language pair A to be parallel, based on the common words between the languages. We propose to embed both English and Hindi into a unconstrained vector space using the distance of a sentence pair to another sentence pair in that corpus as the measure of similarity. We observe that the distance between a pair of sentences in a parallel corpus with respect to a pair of sentence pairs which are close to each other is a small positive integer with the average distance close to zero. We observe this similarity for the distance between Hindi and English sentences, and for other language pairs. We note that this is true even with languages in the same family, such as Hindi and Urdu.\nThis distance matrix",
    "87bc6f83f7f90df3c6c37659139b92657c3f7a38": "\nREFERENCES\n\nAlon L, McCallum R. (1997) Automatic language identification by distributional clustering. In D. Blei, P. Ghahramani, L. Seiffert, editors, Proceedings of the Third International Conference on Learning Representations, ICML 1997, Proceedings of the Eleventh International Conference on Machine Learning, AAAI Press, AAAI Press 2, 1997, pp. 821\u2013828.\n\nBIBREF0\n\nBohdan K and Rambow J; (1991), Dual Decomposition approach to the maxcut problem. Proceedings, 16th annual symposium on Computational Geometry, pages 164\u2013173, 1991.\n\nBIBREF1\n\nAharoni A, Hovy O. (2005), Dual decomposition for a family of problems in automatic speech recognition. In S. Tsujii, editor, Proceedings of the 2004 International Conference on Machine Learning and Cybernetics, AISB 2005, volume 5, pages 905\u2013910, 2005.\n\nBIBREF2\n\nSingh, F. (2005), MST Parser, source available at http://www.felixsingh.com.\n\nBIBREF3\n\nSingh, F. and Srinivasan, M.S. (2005) Hindi Dependency Treebank. Source available at http:/www.dsg.iith.ac.in:felixsingh.com.dtsg.iith.ac.in/DTSG/Hindi%20Parsing/Hindi_DTB_Annotated.txt.\n\nBIBREF4\n\nMcCrae, J.A. (1990), A statistical model for word-sense disambiguation with multiword expressions. Proceedings of Colloquium on Computational Linguistics, pages 27\u201339, 1990.\n\nBIBREF5\n\nPetkov, I. and Klein, G. (2003), The Stanford pos-tagger: a tree-based statistical classifier. Proceedings of the Eighth International Conference on Computational Linguistics, pages 277\u2013284, 2003.\n\nBIBREF6\n\nSingh, S. and Srinivasan, M.S. (2008), Hindi POS Tagger. Source available at http:/www.dsg.iith.ac.in:felixsing",
    "01e2d10178347d177519f792f86f25575106ddc7": " However, CNN-based classification often achieves better performance than both UTD and AUD-based classifications in the task of multi-label classification. In general, UTD-based systems with rescored features yield better topic ID accuracy in low resource and small-set scenario.\nAcknowledgments\nThis work is partially funded by an ONR Young Fellows Award BIBREF30. The paper benefited from discussions with S. S. Jain, J. R. Salton and D. A. Teater. The author would also like to thank his project mentor at ONR, Dr. John Scholes.\n\nNotes and references\n[1] K.-H. Bae, M. Deecke, and T. P. K. C. Wong, \"Bayesian topic identification on untranscribed speech using topic models and minimum cross-entropy training\", In Proceedings of Interspeech 2015, pp. 2420\u20132423.\n[2] G. Dahlmeier and F. R\u00e4tsch, \"Speech transcription with a hidden Markov model using only the speech data\", In Proceedings of ICASSP 2001, pp. 1598\u20131600.\n[3] Z. Ganchev and K. Zuehms, \"Topic identification for spoken documents with acoustic unit discovery\", In Proceedings of ASSRU 2011, pp. 681\u2013684.\n[4] R. C. Gonzalez, J. D. M. Martines, and G. Dahlmeier, \"Bayesian topic identification on noisy speech using a probabilistic mixture model\", In Proceedings of Interspeech 2013, pp. 2615\u20132618.\n[5] Z. Ganchev, Q.-Y. Zheng, and K. Zuehms, \"Unsupervised spoken document classification with acoustic unit discovery and support vector machines\", In Proceedings of ICASSP 2017, pp. 3543\u20133547.\n[6] A. Karaman, W. A. B. Lederer, T. McDonough, and M. J. L. Auer, \"The zero-resource toolkit: low-cost, high-impact speech analysis\", In Proceedings of Interspeech 2013, pp. 2619\u20132622.\n[7] Y. Li, A. Kukleva, R. S. G. Bhatacharya, and G. D",
    "021bfb7e180d67112b74f05ecb3fa13acc036c86": "\nAcknowledgments\nThis work was supported by DARPA LORELEI program, AFRL/AFOSR Grant FA 8650-16-BX-4045, ARO Grant DAAD19-18-1-0010, AFOSR FA8650-18-1-0731, NSF CCF 1747886, and DARPA/AFRL/H9199.0.\nAppendix A. Experimental Settings\nA.1. Tokenization based on UTD and AUD\nWe make use of unsupervised term discovery (UTD) and acoustic unit discovery (AUD) based on variational inference to automatically discover repeated units/words/phrases from speech. Specifically, as described in Section SECREF1, we exploit the scalable UTD framework in the Zero Resource Toolkit (ZRTools) BIBREF7, and train unsupervised models to perform UTD and AUD, respectively. UTD operates using approximate acoustic similarity in INLINEFORM0 time, while AUD needs a full training corpus to discover the acoustic models. We report the performance of our UTD-based classification in the setting where we operate directly on the Babel speech and HKUST Mandarin (Hong Kong University of Science and Technology) telephone speech, both in English, with no training data for the test languages. For UTD based classification, we use cosine similarity threshold INLINEFORM0 for clustering. For the rescoring with logistic regression, we use both the exact DTW similarity and the rescored logistic model score. For UTD-based classification on Arabic, Hijazi Arabic, Thai, Burmese and Telugu, we use rescoring as described in Section SECREF1 because the word-like units are obtained from orthographic translations. Finally, for AUD-based classification on Turkish, the rescoring with logistic regression is adopted because of lack of transcribed speech for training ASR systems.\nA.2. Baseline Topic Identification Methods\nAs baselines we use several topic identification methods designed to operate directly on speech, rather than relying on transcribed speech or dictionaries for building the ASR system (similar to Section 4.1 in Gao BIBREF30 ):\nBag-of-words. We use the bag-of-words (BoW) features as spoken document representations. The features are the raw counts of terms from the UTD clusterings. We normalize the unigrams by inverse",
    "d201b9992809142fe59ae74508bc576f8ca538ff": "\n\nAcknowledgments\nThe authors would like to thank all those helping hands in the project including the authors' colleagues in the EHR group, Dr. James Wang of MDII, and Dr. Zhebin Zhang and Neng Yang of the Wason Research Center.\nReferences\n\nA. A. BIBREF0 Hsu. Predicting medication prescription from electronic health records with neural networks. Bioinformatics. 34:2486-2496, 2018.\n\nA. A. BIBREF1. Leap: leveraging longitudinal dependency and multi-instance representation for medication recommendation. In Proceedings of the Twenty-Seventh Conference on Computational Natural Language Learning (CoNLL'18), 2018.\n\nA. A. BIBREF2. Graph-based multi-instance learning with graph attention networks. In Proceedings of the Twenty-Ninth Conference on Computational Natural Language Learning (CoNLL'20), 2020.\n\nA. A. BIBREF3. Hierarchical neural attention architectures for medication recommendation. In Proceedings of the Thirty-Second Conference on Computational Natural Language Learning (CoNLL'21), 2021.\n\nA. A. BIBREF4. Leveraging medical ontolgoies for medication recommendation. In Proceedings of the Thirty-Second Annual Meeting of the Association for Computational Linguistics (ACL-IJCNLP) and Fourth Workshop on Computational Approaches to Clinical Language Science (CCA) 2018, 2018.\n\nJ. Zhang, J. Zhang, K. Zhou, J. Z. Liao, W. J. Wang. Practical pre-training for fine-grained medical code prediction. Journal of Biomedical Informatics, 2018:7.\n\nJ. Zhang, J. Zhang, K. Zhou, K. Zhou. Leveraging graph neural networks for improved medical code prediction. ACM Transactions on Information Systems, 2020, 38 :1-32, 2020.\n\nJ. Zhang, J. Zhang, K. Zhou, J. Zhang. Practical pre-training for fine-grained medical code prediction. Proceedings of the 32nd AAAI Conference on Artificial Intelligence, 2017.\n\nJ. Zhang, J. Zhang, K. Zhou, K. Zhou. Graph-based multi-instance learning with graph attention network. Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence, 2020",
    "c4628d965983934d7a2a9797a2de6a411629d5bc": " We want to thank the authors of BERT for their work so that we can reimplement it. We also want to thank Zhaofeng Wang for the fruitful discussion.\nAcknowledgments\n\nWe wish to acknowledge Shuming Sheng, Yucheng Wang, Shuqing Wu, Yuwen Zhang, Weiwei Zheng, Rong Liu and Qiqi Lu for their insightful comments and Yonghua Yin for his helpful guidance in the preliminary phase of this work.\nReferences\n\n[1] D. Kupeny M, C. Raghunathan, J. A. Zaremsky and C. D. Fetterman (2015). Computable medicine: Improved prediction and diagnosis of disease and medication using medical information. Proc. KDD.\n\n[2] P. Papanicolaou and D. K. Caldwell (2014). Learning to reason about medicine prescriptions: Automated generation of the optimal dosing regime. Proc. KDD.\n\n[3] C. G. M. P. Papanicolaou and D. K. Caldwell (2016). Learning to reason about medicine prescriptions: Automated generation of the optimal dosing regime. Proc. KDD.\n\n[4] C. G. M. P. Papanicolaou and D. K. Caldwell (2016). Learning to reason about medicine prescriptions: Automated generation of the optimal dosing regime. KDD 16, 981-989.\n\n[5] L. Liang, P. P. Manke, S. Li, J. P. Robinson and E. S. Rastatter (2020). Answering questions with language model pretraining. Proc. KDD.\n\n[6] S. Yu, K. Qin, Q. Peng, S.-c. Hsieh and P.-h. Lin (2020). Transformers from hell to heaven: BERT, GPT, T5, RoBERTa, and XLCE. Proc. KDD.\n\n[7] O. Vosoughi and T. G. Dietterich (2019). BERT: Pre-training of deep bidirectional transformers for language understanding. Transactions of the association for computational machinery, 28(6), 4172-4230.\n\n[8] I. S\u00f8nderby, W. Hejlesen,",
    "bd419f4094186a5ce74ba6ac1622b24e29e553f4": "\n\nCite as:\n\nY. Levy, O. Kessides, Y. Wiezorek, A. Elhadad, F. Meilich, Y. Goldberg, O. Lavy (2019). \"Realistic Urban Navigation.\" Proceedings of the 2019 ACL Workshop on Natural Language Instruction, to appear.\n\n## License\n\n### Data (Osmo)\n\nThe source code for Realistic Urban Navigation (RUN) data and experiments.\n\n### Run (PyTorch)\n\nPython 3.7 notebook to replicate the experiments on Realistic Urban Navigation Task and RUN data on PyTorch.\n\n### Realistic Urban Navigation (Papers)\n\nPapers describing the task of interpreting and following natural language instructions using dense urban maps.\n## Appendix\n\n### Table OF Contents\n[Table of Contents](http://nervana-system.com/run-task/appendix-1.html#toc-appendix-1)\n\n# Abstract\n\nWe present the first dataset for evaluating complex NL navigation in interactive dense urban settings.\nWe propose a strong neural model for the Realistic Urban Navigation problem and report on an experimental evaluation on our own corpus. Our model is based on existing natural language instruction following approaches, and combines an encoder-decoder structure with an Attention layer, on top of a world-state encoder for grounding in realistic, dense urban environments\n[1]Y. Levy [et al.], \"Realistic Urban Navigation,\" Proceedings of the 2019 ACL Workshop on Natural Language Instruction.\n\n# Introduction\n\nIn this work we address the problem of interpreting and following a sequence of instructions given in colloquial language based on a dense urban map. We define the task as a sequence-to-sequence learning problem where the model's input corresponds to a navigation paragraph, and its output is the actual path on the map. Furthermore, the input may contain references to unknown entities that appear for the first time during testing. The resulting difficulty of the problem allows us to assess the strength of the various learning algorithm components, including: (i) the input sequence; (ii) the grounding of entities in a complex, dense world; (iii) the execution of actions; and (iv) the representation of the world state.\n\n## RUN Task (Explanation)\n\nIn this work we introduce the following tasks: (i) extract a sequence of navigation paragraphs",
    "11e8bd4abf5f8bdabad3e8f0691e6d0ad6c326af": "\n\n[1] For example in BIBREF0, BIBREF1, BIBREF2\n\n[2] This is motivated by the fact that on the OSM map there might be, for example, 4 entities corresponding to the same restaurant, each annotated with different information about the entity.\n\n[3] The entities in OPEN-REAL are not visible to the model, and the path can contain several intersections. The navigator doesn't know in which direction his last location lies, but knows that in the next turn there should be an intersection and he can choose between different turn options.\n\n[4] E.g. restaurants, traffic-lights, intersection, benches\n\n[5] The instruction is meant to go to the intersection in the next turn, and the navigator sees that the street he is facing runs through the intersection.\n\n[6] See, e.g., Fig. SIGREF1\n\n[7] This means that an agent could take a right turn and walk four steps (according to the street-list that the model generates), and the rest of the actions should continue from the same intersection.\n\n[8] We collect only the entities that appear in the instruction.\n\n[9] This step is meant to show that the navigator has to walk across a given intersection. On the map we only count entities that appear in the instruction.\n\n[10] The navigator sees that he has to walk at an intersection but it is not mentioned in the last instruction, hence, he needs to infer that he has to walk between two cross-roads, and, for now, he doesn't know which is the correct direction to continue on the intersection.\n\n[11] Recall that in order for a model to count as successful it needs to generate an exact route, in one direction, up to the last position.\n\n[12] The navigator sees that he needs to turn right at an intersection, but doesn't know which direction to walk following that particular turn, hence, he can choose between left-turn or right-turn, and he will continue from the same direction in the next step.\n\n[13] Recall that an intersection doesn't have a street and hence we say that the navigator needs to turn around in the intersection.\n\n[14] A turn around in an unwalkable entity is considered unsuccessful.\n\n[15",
    "1269c5d8f61e821ee0029080c5ba2500421d5fa6": " Last but not least, we would like to thank Prof. Huu Trung Nguyen and Dr. Phan Tri Dung for useful discussion on the paper.\nReferences\n\nBibliographies\n\n[1]\n\nBharathi, R.M. and Schmidhuber J., 2011. A general learning algorithm for neural network models. In Advances in neural information processing systems: 16th Annual Conference, NIPS 2011, Vancouver, British Columbia, Canada: Advances in Neural Information Processing Systems, pp. 2115\u20132123.\n\n[2]\n\nBIBREF0\n\nBengio, Y. et al.. \"Neural machine translation by jointly learning to align and translate.\" in EMNLP: 2012: proceedings of the 2014 conference on empirical methods in natural language processing, pp. 671\u2013676.\n\n[3]\n\nBIBREF1\n\nSutskever, J., Vinyals, O., and Le C., 2014. Sequence to sequence learning with neural networks. In International conference on learning representations, ICLR 2014, pp. 1874\u20131882.\n\n[4]\n\nO. S. and K\u00fcmmerer, W., 2011. Neural machine translation of out of vocabulary words in the absence of glossing. In Proceedings of the conference of the North American chapter of the association of computational linguistics (NAACL-HLT '11), pp. 1380\u20131388.\n\n[5]\n\nGraves, A., Ipeirotis, S., Dahl, G. and Zweig, D., 2014. Neural machine translation of out of vocabulary words with neural sequence-to-sequence learning. In International conference on language resources and evaluation, LREC 2014, Reykjavik, Iceland, June 2\u20137.\n\n[6]\n\nCho, K. et al.. \"Relying on language models with recursive neural networks for machine translation.\" in EMNLP: 2014: proceedings of the 2014 conference on empirical methods in natural language processing, pp. 1332\u20131343.\n\n[7]\n\nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J. and Polosu, K., 2016. Attention Is All You Need. In Inter Workshop on Statistical Machine Translation (SMT",
    "e35a7f9513ff1cc0f0520f1d4ad9168a47dc18bb": "\nReferences\n\nC. Wu, X. Guan, J. Callison, and D. Chi, \"NMT approaches and results,\" in Proc of IJCNLP-2017, pp. 1572\u20131577.\n\nK. Cho, O. Oh, and Y. Yoon, \"GloVe: Global Vectors for word Representation Learning,\" in Proc of ICTAI-2016, pp. 1225\u20131231.\n\nM. R. Lewis, X. Zhou, C.-C. Liu, Y. Zhang, and D. Callison, \"Neural Machine Translation: a survey,\" in Proc of ACL-2017, pp. 1714\u20131730.\n\nS. Hasani, R. Heid, and J. DeNero, \"A Large-Data Approach to Neural Machine Translation,\" in Proc of ACL-2018, pp. 4332\u20134339.\n\nC. Wu, M. S. Gao, Z. Wang, and K. Cho, \"Neural Machine Translation Systems With Jointly-Learned Cross-Language Alignment,\" in Proc of ICASSP-2016, pp. 709\u2013713.\n\nJ. Hasegawa, F. N. Matsumoto, S.-I. Tanaka, R. Nishino, T. Shibata, C.-Y. Uchida, M. Yamakawa, and J.-A. Goto, \"Neural network machine translation system,\" in Proc of COLING-2014, pp. 1269\u20131273.\n\nJ.-S. Kim, J.-M. Chiang, and D. S. Callison, \"Neural machine translation for Japanese-Vietnamese,\" in Proc of COLING-2014, pp. 1123\u20131127.\n\nP. Koehn, Y. Zhang, S.-I. Tan, and F. Niblett, \"On the Role of Phrase Segmentation and Unsegmented Data in Neural Machine Translation,\" 2018, https://aclanthology.org/P18-1134, in Proc of ACL-2018,\n\nT. Mikolov, K. Shlens, and D. Dean, \"Distributed representations for sentence similarity,\" 2013, in Proc of NIPS.\n\nO. Sennrich, V. Koritaev, and A. Krik",
    "b9ea841b817ba23281c95c7a769873b840dee8d5": "\nReferences\n\n[1] C. Wiese, K. Hokamp, and E. Meurers. 2017. Recurrent neural machine translation, in: International conference on computational linguistic (COLING) 2017: Joint workshop on neural network methods and neural model-based approaches. Singapore.\n\n[2] Y. Chen, Z. Wang, and H. Wu. 2017. Training sequence-to-sequence neural network on unlabeled data in a multilingual setting, in: Proceedings of the thirtieth AAAI conference on artificial intelligence.\n\n[3] A. Grave-Orta, Z. Wang, and A. C. Baayen. 2016. Linking neural machine translation model to external linguistic resources through cross-lingual distributional similarity.\n\n[4] E. Meurers, K. Hokamp, and C. Wiese. 2018. Neural network machine translation, in: Proc. of the thirty-eighth International Conference on Machine Translation (Volume 1: Long Papers).\n\n[5] C. Wiese, K. Hokamp, and R. K. Ganchev. 2018. Using context vector and attention based on alignments for better neural machine translation, in: Proc. of the thirtieth AAAI conference on artificial intelligence (Volume 2: Short papers).\n\n[6] K. Cho, S. Lee, D. Poibeau, G. Zweig, J. Lee, F. Sennrich, J. Hong, R. Johnson, R. C. Martins, S. H. Chi-Phu, and R. Gray. 2014. Gated recurrent units for learning in sequence.\n\n[7] J. Xiong, C. D. Manning, T. De Veaux, and O. Vinyalsky. 2016. Convolutional neural language model.\n\n[8] S. R. A. J. Ermace. 2014. How to build a successful end-to-end, neural language model.\n\n[9] C. Wiese, K. Hokamp, and K. Schmeides. 2016. Neural machine translation: from sequence-to-sequence to sequence-to-sequence.\n\n[10] R. Gage. 2003. Improved string matching using minimum edit distance.\n\n[11] O. V",
    "219af68afeaecabdfd279f439f10ba7c231736e4": "\nFuture Works\nWe plan to perform more experiments using advanced modeling techniques like the ones employed in previous studies (BIBREF11, BIBREF13 ). One example is using the attention mechanism to improve the quality in machine translation. In addition, we are curious if and how we can train a cross-lingual MT system where the source and target languages use different vocabulary but in a different order, and so the task is more like the cross-lingual machine translation, a more difficult task.\nReferences\nBIBREF0 I.Sutskever, R.Chuang, J.DeMelo, L.Jiao and H.Zhu. Re current Neural Machine Translation systems: A case study with a NMT approach. In ICASSP, pages: 1045\u20131048, 2014.\n\nBIBREF1 E.M.Frank, J.Haffum, C.C.J.Costa, P.Li. An overview of neural machine translation systems. In CSLT, pp: 35\u201342, 2012.\n\nBIBREF2 G.Raffel, A.Shazeer, M.Shazeer, J.Shaw and O.Schwenk. Addressing data sparsity in neural machine translation of low-resource language pairs. 2017.\n\nBIBREF3 S.Kim, P.Liu and S.Sennrich. Addressing data sparsity with unsupervised neural machine translation. 2017.\n\nBIBREF4 K.Sennrich, H.Zhang, L.Sharif, Y.Chen, K.Neubig, W.Yatabe, C. Zhao, Y.-W.-H. Chung, S. Huang, Z.Hui, X.Zhang and K.Hollard. Exploring techniques to learn subword-level representations for low-resource machine translation. 2019.\n\nBIBREF5 L.Shi, K.Cho, H.Van Den Bosch and J.T.Shen. Exploring the word hierarchy of language through variable-length skip-gram. 2014.\n\nBIBREF6 K.L.Chowdhury, M.Chen and M.Moheberger. Efficient language model updates with gated recurrent units. 2015.\n\nBIBREF7 I.Sutskever, J.DeMelo, T",
    "a66a275a817f980c36e0b67d2e00bd823f63abf8": "\n\nWhen we speak about the price of crude oil, it's a bit more of an emotional matter for the American people because they are more prone to price-induced consumer price inflation and their consumer inflation is higher.\n\nWhen we speak about the price of crude oil, it's a bit more of an emotional matter for the American people because they're more prone to price-induced consumer price inflation, and their price inflation is higher.\n\nWe have to speak more carefully to children, the children are the future. They are the future.\n\nWhen we speak, more carefully to children, that is to say the children, the future-they are the future. They are the future future.\n\nIt's a really a good question. If we do not take such actions, there is no future.\n\nWhen we speak, more carefully to children, about the future, we will not be able to talk about the future. It is very, really a good question. If we do not be able to talk about the future, there is no future.\n\nWe have to speak more carefully for the children. They are the future.\n\nBecause of the rising prices in all of our sectors we need to speak more carefully, because children are the future.\n\nIn addition, we have seen some promising results in domain adaptation, the possibility to perform style transfer from one domain to another. Namely, it is possible to transfer the style of OpenSubtitles text into the style of Europarl with relatively high success, and from Eurpaparls style into the more informal style of OpenSubtitles with much lower success (Table TABREF39 ).\nTraining Examples\nWe prepared 2 languages, 4 domains/styles and 3-language multi-domain version of the model to train. All sentences were paired for all possible input\u2013output language combinations on a sentence level, with sentence length ratio over 2.\n\nTable TABREF25 contains a list of corpora for bilingual corpus preparation and their translation directions. The table also contains number of sentences from each corpus, sentence length, and average sentence length across all corpora for the different language pairs. Last three columns are calculated by multiplying average sentence length per corpus by number of sentences from that corpus.\n\nTable TABREF26 gives a list of available language pairs used for training and the corresponding translation direction. The number of sentences for each language is also given, and the last column",
    "b6f466e0fdcb310ecd212fd90396d9d13e0c0504": "\n\nWhen the price of gas goes up, the consumer doesn't want to buy gas for fuels/when the price of gas goes up, the consumer does not want to buy gas for fuels\n\nwhen the price of gas goes up, the consumer does not want buy gas for fuels/when the price of gas goes up, the consumer does not want buy gas for fuels\n\nwe is/we be/we have/we have are/we have was/we have is\n\nMa tahan/ma tan/Ma tanaga/we have/we are with are/I want/I want are/I do/you want/you are with are/where are you going?/where are you, girl?/where are they going?\n\nwe has/we has be/we have is/we have /we were/we be are/we are has be/we will be\n\nEstonian\n\nP\u00f5h just toi n\u00f5mme, kuidas on teebet\u00f5ttu n\u00f5mme.\n\nP\u00f5h just toi no, how do we give you no?/give you no, how do we give no?/give you no, how do you give no?/give no, how do you give no?/give no, how do you give no?\n\nT\u00e4na aitas ma ei lekkas, t\u00e4nad sini suur ma ei lekkas / T\u00e4nad sini suurma ei lekkas ma ei lekkas t\u00e4nad sinim\u00e4\u00e4rgi/ T\u00e4nad sini suurmae ei lekkas ma ei lekkas sinim\u00e4\u00e4rgi/ T\u00e4nad sini suurmae ei lekkas T\u00e4nad sinim\u00e4\u00e4rgi\n\nP\u00f5h just then she didn't want to go and sit on the grass/just then she didn't want to go and sit on the grass/just then she didn't really want to sit on the grass/just then she didn't really want to sit on the grass\n\nElla, mina, veel \u00fclemus k\u00f5ige meie kodanika / Ella, mine, I saw you, you'll need all our money/Ella, mina, you'll need all our money\n\nI saw/I saw you/I saw mines/I saw,",
    "62ea141d0fb342dfb97c69b49d1c978665b93b3c": "\n\nWe thank everyone for their input.\nTahad, et ei p\u00e4\u00e4lete meie lahtiohtu.\n\nThe, and I won't let you go down.\nM\u00f5rgi, et ei saa meidatelu p\u00fc\u00fca p\u00f5hjal tedaegi.\n\nWanted, and you can't steal my words anymore.\n\nHeil, oma \u00f5\u00f5dea, et l\u00f5pus ma.\n\nHi, my dream, and my end.\n\nGobinde, oma \u00f5\u00f5dea, iga\u00fcks veelgeli.\n\nExplain, my dream, every one of you.\n\nWe thank for your interest.\n\nK\u00e4ibemaks, oma \u00f5\u00f5dea.\n\nSuck me in, your dream.\n\nGreet, my dream.\n\nJah, oma \u00f5\u00f5dea!\n\nHaha, your dream!\n\nPriin, oma \u00f5\u00f5dea!\n\nKiss, your dream.\n\nH\u00e4\u00e4belas, oma \u00f5\u00f5dea!\n\nMwa, your dream!\n\nO\u00f5dea!\n\nOh my dream!\n\nSveiki!\n\nHello!\n\nMa tahan two sald\u0113jumus.\n\nI want two ice creams.\n\nL\u00f5pe.\n\nYou guys are such a huge fan!\n\nViigad, et meidateluse ainult meidateluse iga\u00fcks on kinnis.\n\nOh God, and only you are the most beautiful.\n\nPalaks, et on tants p\u00fc\u00fcgib ko\u0161r\u0101ji!\n\nWhat an awesome photo!\n\nMmm, and that cake is really delicious!\n\nLao, on Matti palju l\u00e2pve.\n\nTold, Matti you shit a lot.\n\nTahad, kats otsi?\n\nHeil, Matti?\n\nHeil, Matti!\n\nTad s\u00fcmbatse, et meie lahtiohtu koostis!\n\nOh God, and our love will remain forever.\n\nJah, oma \u00f5\u00f5dea",
    "a32c792a0cef03218bf66322245677fc2d5e5a31": "\n\n(1) To be honest, I don't understand you at all. INLINEFORM0\n(2) N\u00e4guv\u00f5tad va-amatavad, me rahvad, kodus. INLINEFORM1 (3) Laup\u00e4evaks nagu l\u00f5ppu koputatud t\u00fchja h\u00e4\u00e4l. INLINEFORM2 (4) To be honest, I don't understand you at all INLINEFORM0\n(5) N\u00e4guv\u00f5tad va-amatavad, me rahvad, kodus. INLINEFORM1 (6) Laup\u00e4evaks nagu l\u00f5ppu koputatud t\u00fchja h\u00e4\u00e4l. INLINEFORM2 (7) To be honest, I don't understand you at all INLINEFORM0\n(8) N\u00e4guv\u00f5tad va-amatavad, me rahvad, kodus. INLINEFORM1 (9) Laup\u00e4evaks nagu l\u00f5ppu koputatud t\u00fchja h\u00e4\u00e4l. INLINEFORM2\nAuthor Contributions\nK. K was responsible for experiments, E. M. wrote the article, E. M. and K. K. participated in discussion of the manuscript and reviewed each other's results. The article was written in collaboration between all of us.\nAcknowledgments\nOur work was supported by the European Union (EU) Horizon 2020 research and innovation programme in the H2020-EU.2.1.1 framework project PULLET, under grant agreement no 778913. We thank E. M. for his contributions to the initial idea and the paper, and Mikk J\u00e4nsalu and J\u00f8rn Dyer for their discussion of it.\n\nLATEF is supported by the Ministry of Foreign Affairs of Estonia and the Estonian Institute of Humanities. J. H., T. J., J. T., and J. T. acknowledge additional support from the Estonian Research Council IUT16-23 (supported by the ERDF under Operational Program for the Development of Human Resources and Research infrastructures). J. H. acknowledges support from ETA Foundation K. S\u00e4de. E. V. is supported by the Tartu University Faculty of Literature Doctorial Research Grant 2019 No 012.\nBibliography\n\n[B",
    "0101ebfbaba75fd47868ad0c796ac44ebc19c566": "\n\nReferences\n[1] K. B. Das, M. J. Lin, et al., Bibref.\n[2] J. Weston and L. N. Zettlemoyer, Bibref.\n[3] Y.-X. Wang, Z. Wang, et al., Bibref.\n[4] M. L. Yang, F. Wang, et al., Bibref.\n[5] F. Wang and M. Wang, Bibref.\n[6] M. L. Yang and F. Wang, Bibref.\n\n[7] Y.-X. Wang and X. Yao, Bibref.\n[8] C. Cui, R. K. Shao, et al., Bibref.\n[9] G. H. Dai and X. Zhai, Bibref.\n[10] S. A. A. Ding, A. G. K. Liu and Z. Wang, Bibref.\n[11] E. R. Socor, C. C. Miao, et al., Bibref.\n[12] T. M. Alqurashi and H. Wu, Bibref.\n[13] J. Wang, L. Huang, et al., Bibref.\n[14] O. M. Suleyman, S. L. Zadesky, et al., Bibref.\n[15] M. H. Tan, X. M. Xie, et al., Bibref.\n[16] Y. Q., C. Jiang and A. Hu, Bibref.\n[17] G. A. Zampieri, M. R. Lyu, et al., Bibref.\n[18] R. R. Barzilay, X. A. Zhang, et al., Bibref.\n[19] B. Hu, J. Li, and S. Li, Bibref.\n[20] X. Bai, M. X. Xu, et al., Bibref.\n[21] J. Qian, Q. Liang, et al., Bibref.\n\n[22] S. Yan, Q. Zhou, et al., Bibref.\n[23] G. Li and Z. Wang, Bibref.\n[24] C. Cui, Y. Yao, S. Yang, et",
    "50cb50657572e315fd452a89f3e0be465094b66f": "\nAcknowledgements\nWe would like to show our sincere gratitude the teacher who provided great support during our study: Hye-Sook Lee. We also want to thank the teachers who gave us the support: Tae-Yun Kim and Jong-Bae Cho. Moreover, we would like to thank the colleagues who gave us support like Ting-Han Tsai and Dong-Gyu Lee. This project is supported by SONGKI Foundation.\n\nFigure. Figure. The illustration of two-staged CNN\n\nFigure. FIGREF3\n\nFigure. FIGREF4\n\nFigure. FIGREF5\n\nFigure. FIGREF6\n\nFigure. FIGREF7\n\nFigure. FIGREF8\n\nFigure. FIGREF9\n\nFigure. FIGREF12\n\nFigure. FIGREF13\n\nFigure. FIGREF14\n\nFigure. FIGREF15\n\nFigure. Figure.15\n\nFigure. Figure.14\n\nFigure. Figure.1\n\nFigure. FIGREF16\n\nFigure. Figure.2\n\nFigure. Figure.3\n\nFigure. FIGREF17\n\nFigure. Figure.4\n\nFigure. FIGREF18\n\nFigure. FIGREF19\n\nFigure. Figure.5\n\nFigure. Figure.6\n\nFigure. Figure.7\n\nFigure. Figure.8\n\nFigure. Figure.18\n\nFigure. Figure.19\n\nFigure. Figure.20\n\nFigure. FIGREF21\n\nFigure. Figure.23\n\nFigure. Figure.24\n\nFigure. Figure.25\n\nFigure. FIGREF26\n\nFigure. Figure.27\n\nFigure. Figure.28\n\nFigure. Figure.29\n\nFigure. Figure.30\n\nFigure. Figure.2\n\nFigure. Figure.31\n\nFigure. Figure.4\n\nFigure. Figure.5\n\nFigure. Figure.6\n\nFigure. Figure.7\n\nFigure. Figure.8\n\nFigure. Figure.9\n\nFigure. Figure.10\n\nFigure. Figure.11\n\nFigure. Figure.12\n\nFigure. Figure.13\n\nFigure. Figure.14\n\nFigure. Figure.15\n\nFigure. Figure.16\n\nFigure. Figure.17\n\nFigure. Figure.18\n\nFigure. Figure.19\n\nFigure. Figure.20\n\nFigure",
    "981fd79dd69581659cb1d4e2b29178e82681eb4d": " Acknowledgement\nYunbo Zhu thanks Xiaoquan Zhao for discussion on the project.\nTable 1. Datasets Statistics Restaurant: 4 conversations, total 2,208 utterances Hotel: 6 conversations, total 2,500 utterances Laptop: 15 conversations, total 5,260 utterances TV: 9 conversations, total 15,000 utterances Average number of slots per DA: ~3.44; Range: 2 to 9\nTable 2. Results of Generator Models BLEU-4 [BIBREF15] [32] Hotel 2 3 4 9 9 2.5 RALSTM 3.8 1.5 2.9 RALSTM 3.1 4.9 1.1 Enc-Dec 3.1 0.5 1.2 Enc-Dec 3.9 4.1 1.2\nTable 3. Refinement ablation experiment: Slot Error Rate (ERR) [BIBREF4 ] [23] Restaurant 5 7 15 7 2.5 SCLSTM 16.9 8.9 19.7 10.0 RALSTM 3.5 2.5 3.8 1.0 Enc-Dec 20.0 18.2 13.7 8.4\nTable 4. Comparison Results Generator responses Examples: BLEU-4 [BIBREF15] [32]\nThe rest of content is available on: https://pubs.rsna.org/.\n\nAcknowledgments\n\nThis work was supported by the National Science Foundation (NSF) with grant numbers: ECS-1647604, ECS-1647605, ECS-1647606, EIS-1827993, and EIS-1828003.\nBIBREF0 Sato, K. and Murata, K., 1999. A rule based Japanese dialogue system: an experience with practical use.\n\nBIBREF1 Shastri, S. and Dahl, D.E., 2006. An experimental study of word n-gram language models for dialogue generation. In Proceedings of SIGDAT Workshop on Domain Adaptation for Spoken Dialogue Systems, pp. 7\u201315.\n\nBIBREF2 Shivakumar, G. and Heilman, C., 2014. Neural language generator for spoken dialogue systems with training by template pruning. In Proceedings of Workshop on Domain Adaptation in Spoken Dialogue Systems, pp. 31\u201337.\n\nBIB",
    "03e9ac1a2d90152cd041342a11293a1ebd33bcc3": "\nTo cite this paper:\n\n@Article{Zhang2018a,\n  author = {Wenqiang Zhang and Jian Yang and Tiejun Yu and Zhiyuan Lu and Weimin Zhao and Yijian Liu},\n  title = {Natural Language Generator Using Attentive Refinement and Adjustment Based on Deep Learning},\n  journal = {Journal of Computer Science and Information Systems},\n  year = {2018},\n  volume = {34},\n  url = {https://arxiv.org/abs/1809.00471 (cited by Scivision on November 2nd, 2020 )\n\nReferences\n\n[1]\n\nBeeby, T. (2014) An analysis of the effect of semantic repetition on dialogue generation performance. In Proceedings of Workshop on Spoken Dialogue Technologies (WSDTech), 2014, pp. 51\u201357.\n\n[2]\n\nBIBREF0: Wijaya et al.(2013) Automatic template design for spoken dialogue systems. In Proc. of the International Conference on Spoken Language Technology (Interspeech 2013, Sep. 9\u201313, 2013, Porto, Portugal), pp. 2516\u20132519.\n\n[3]\n\nBIBREF1: Hirao and Tanaka(2014) Using corpus information to train a ngram-based text generator. In Proceedings of Workshop on Spoken Dialogue Technologies (WSDTech), 2014, pp. 64\u201368.\n\n[4]\n\nBIBREF2: Xiang and Wang(2015) Combining semantic and procedural information of slot values. In Proceedings of International Conference on Machine Learning (ICML 2015, Jul. 14\u201319, 2015, Beijing, China, ICML2015-1286).\n\n[5]\n\nBIBREF3: Xie et al.(2015) Generating Chinese poetry using recurrent neural networks. In Proceedings of Conference on Empirical Methods in Natural Language Processing (EMNLP 2015, Nov. 2\u20136, 2015, Montreal, Canada, EMNLP2015-1469).\n\n[6]\n\nBIBREF7: Sordoni and Barzilay and Elazar and Goldberg and Bar-Haim and Potts and Roth(2015) Sequence to sequence learning with neural turing machines for semantic composition. In Proceedings of Nineteenth Symposium on Computational",
    "ef396a34436072cb3c40b0c9bc9179fee4a168ae": "\nReferences\n\n[1] K. B. Y. Chen, S. Zhao, and X. D. Zhao. Sentiment analysis with recursive neural networks. In ICASSP, pages 1\u20134. 2017.\n\n[2] K. B. Y. Chen, S. Zhao, and X. D. Zhao. Sentiment analysis with recurrent neural networks. In ICASSP, pages 1\u20134. 2019.\n\n[3] R. Socher, P. Manning, and C. D. Manning. A framework for sentiment analysis, classification, and tracking of online opinions. In EMNLP, pages 3\u201313. 2010.\n\n[4] K. B. Y. Chen, S. Zhao, and X. D. Zhao. A deep neural network model for semantic matching. In NLP, pages 3\u201313. 2018.\n\n[5] K. B. Y. Chen, S. Zhao, X. D. Zhao, and Q. Sun. Recursive networks for semantic matching. CoRR. 2018.\n\n[6] K. B. Y. Chen, X. D. Zhao, X. G. Liu, and Q. Sun. Recursive networks for semantic matching. In NLP, pages 1\u201316. 2018.\n\n[7] A. G. Erbach, M. A. Bender, and V. K. Prasad. Improving text classification with word vectors. In IUI, pages 51\u201358. 2016.\n\n[8] A. T. Grave, W. Huang, R. C. Berland, U. Koehn, and B. Sch\u00fctze. Long short-term memory recurrent neural networks for natural language. In ICASSP, pages 1\u20134. 2017.\n\n[9] K. B. Y. Chen, D. Ji, Q. Sun, X. D. Zhao, and K. Xu. Deep neural network for learning context-specific compositional function. In AAAI, page 59. 2018.\n\n[10] K. B. Y. Chen, X. D. Zhao, Q. Sun, and H. D. Zhang. Dynamic compositional neural network over tree structure for text classification. In COLING, pages 3\u201312. 2016.\n\n[11] G. E. Hinton. A fast learning algorithm",
    "04bde1d2b445f971e97bb46ade2d0290981c7a32": "\n\nReferences\n\n[1] R. Bengio, O. Chapelle. Training Recursive Neural Networks with Contiguous Compositional Functions. arXiv preprint arXiv:1511.08285, pp. 1\u20138, 2015. (2016).\n\n[2] P.Bennett, R. S. Zemel, D. W. Kleinberg, O. Y. Veen, B. M. V. Jaan, W. Zi. Aligning trees for machine translation. In NIPS, pp. 1079\u20131086, 2009.\n\n[3] O. Chapelle, V. Radulescu, G. Neubig. Learning to Compose Vector Based Algorithms for the Semantic Web. In Proceedings of the 2013 International Conference on World Wide Web (WWW), ACM, 2013.\n\n[4] O. Chapelle, P.M.Brun, S. L.Boulais, J. L. D. S. de, G. Neubig. Exploiting Dependency and Structural Information for Learning Distributed Representations. In International Conference on Advances in Language Technologies (ICALLT), 2015\n\n[5] J. Zhang, T. Huang, Y. Lin. An Efficient Recurrent Neural Network for Syntactic Tree Structured Translation. ACM Transactions on Asian and Low-Resourced Language, 15(4), 37:1\u201337:17. (2016).\n\n[6] J. Zhang, T. Huang, C. Liu, Y. Lin. Neural Word Representations for Tree Structured Neural Machine Translation. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pp. 3363\u20133368, 2016.\n\n[7] J. Zhang, T. Huang, Y. Lin, H. Liu, M. Qiu, X. Chen. Neural Tensor Machines for N-to-N Machine Translation. NIPS, pp. 2612\u20132620, 2017.\n\n[8] H. Zhang, L. Xu, C. Liu, J. Zhang. Neural Word Representation in Multi-modal Multi-task Learning. KDD, pp. 2155\u2013 2165, 2019.\n\n[9] J. Zhang, S. Nallapati, T. Huang. Dynamic Structured Compositional Learning",
    "bfbd6040cb95b179118557352e8e3899ef25c525": "\n\nReferences\n1. \n\"Singing Voice Conversion Without Parallel Data Using a Deep Convolutional Auto-Encoder Network\" [Xie, L., Wang, Z., Zhang, K., Zhu, X. Yao, Y., Cai, V. Y., Wang, H. Y., and Lei, Z. ], arXiv:1901.02801].\n\n2. \n\"Neural Parallel Wave-Tables: A Modular and Learned Pitch-Prediction Tool Based on WaveNet AutoEncoders\" [Zhu, L., Zhang, K., Yang, N., and Yang, Z. Y. ], arXiv:1908.07680.\n\n3. \n\"Text-to-speech Generation via Autoregressive Transducer: End-to-end Neural Networks for Speech Synthesis\" [Oord, A. V., Vaswani, A., Prenin, J., Rabiner, J., and Fergus, P. J. ], arXiv:1412.0313.\n\n4. \n\"WaveNet: A Deep Learnable Model for Surface Simulation of Waveforms\" [Doersch, J., Vinyals, A.B., and Zissman, A. P. ], arXiv:1611.07550.\n\n5. \n\"Deep Neural Speech Synthesis: A WaveNet Adapter for Text-to-Speech Generation and Beyond\" [Oord, A. V., Shekhar, S., Chen, H., Wollack, J., Chen, G., Lee, S., and Chodorow, M. ], arXiv:1611.10787.\n\n6. \n\"An Adaptive Concatenation-based Method for WaveNet Singing Synthesis Based on Lyrics and Notes\" [Dai, Z., et al. ], arXiv:1709.03305.\n\n7. \n\"Deep Speech: A Neural End-to-end SpeechSynthesis System\" [Hsu, C. Y., et al., 2016], Proceedings of the 13th International Conference on Intelligent Systems for Molecular Biology, pages 134\u2013139, 2016.\n\n8. \n\"A Deep Feedforward Neural Network for Automatic Singing Voice Conversion\" [Joo, Y. S., Ong, R. T., Chang, W. C",
    "d6e353e0231d09fd5dcba493544d53706f3fe1ab": "\nReferences\n\n1) Bloch, Y., Pritchard, N., Moyer, D., and Riebe, M. (2017). BIBREF.\n\n2) Gershman, G. P., and Brown, A. N. (2007). Hidden Markov Models and the Signed Digraph.\n\n3) Luong, K., Pham, H., Chung, K., Hoang, H. T., and Cucurullo, C. (2016). Singing Voice Conversion Using a WaveNet Vocoder. In International Conference on Learning Representations BIBREF.\n\n4) BIBREF.\n\n5) Sharma, A., Mielke, M., Bamman, M., and K\u00fcper, F. (2018). WaveNet: A Generative Adversarial WaveNet For Text-to-Speech.\n\n6) BIBREF.\n\n7) BIBREF.\n\n8) BIBREF.\n\n9) BIBREF.\n\n10) BIBREF.\n\n11) BIBREF.\n\n12) BIBREF.\n\n13) BIBREF.\n\n14) BIBREF.\n\n15) BIBREF.\n\n16) BIBREF.\n\n17) BIBREF.\n\n18) BIBREF.\n\n19) BIBREF.\n\n20) BIBREF.\n\n21) BIBREF.\n\n22) BIBREF.\n\n23) BIBREF.\n\n24) BIBREF.\n\n25) BIBREF.\n \n# The Man Who Spoke  \nto The Dead\n\n#### Also by John Lutz\n\n_Sylph_ (1925)\n\n_The Wandering Girl_ (1927)\n\n_Pursuing Vandal_ (1932)\n\n_Rackham_ (1935)\n\n_In the Garden of Swords_ (1937)\n\n_The Cresty_ (1941)\n\n_Oath of Blood_ (1947)\n\n# The Man  \nWho Spoke to  \nThe Dead\n\n#### A Novel\n\n## John Lutz\n\nThis is a work of fiction. Names, characters, places, and incidents either are the products of the",
    "7bd6a6ec230e1efb27d691762cc0674237dc7967": " We thank Allen Institute for AI for providing training resources, and Amazon for providing computing resources.\n\nWe thank the NVIDIA corporation for their generous gifts of Tesla K80 and TITAN Xp GPUs for performing this research. We thank the Institute for Pure and Applied Mathematics (IPAM, Los Angeles) and Microsoft Research (Redmond) for supporting this research. We also thank the MIT Haystack for access to their computation resources.\n\nWe wish to acknowledge the support and encouragement provided to us by our family, friends, and the greater community of CSE researchers. In particular, we thank our children, Neha and Darshan, for inspiring us with the joys and wonders of science.\n\n1, BIBREF1\n\n2, BIBREF2\n\n3, BIBREF3\n\n4, BIBREF4\n\n5, BIBREF5\n\n6, BIBREF6\n\n7, BIBREF7\n\n8, BIBREF8\n\n9, BIBREF9\n\n10, BIBREF10\n\n11, BIBREF11\n\n12, BIBREF12\n\n13, BIBREF13\n\n14, BIBREF14\n\n15, BIBREF15\n\n16, BIBREF16\n\n17, BIBREF17\n\n18, BIBREF18\n\n19, BIBREF19\n\n20, BIBREF20\n\n21, BIBREF21\n\n22, BIBREF22\n\n23, BIBREF23\n\n24, BIBREF24\n\n25, BIBREF25\n\n26, BIBREF26\n\n27, BIBREF27\n\n28, BIBREF28\n\n29, BIBREF29\n\n30, BIBREF30\n\n31, BIBREF31\n\n32, BIBREF32\n\n33, BIBREF33\n\n34, BIBREF34\n\n35, BIBREF35\n\n36, BIBREF36\n\n37, BIBREF37\n\n38, BIBREF38\n\n39, BIBREF39\n\n40, BIBREF40\n\n## Contents\n\nAcknowledgements\n\nIntroduction\n\nThesis Statement\n\nChapter 1\n\nMy personal statement\n\nChapter 2\n\nFingerprints and faces",
    "6aaf12505add25dd133c7b0dafe8f4fe966d1f1d": " We acknowledge the assistance of the NVIDIA AI Cloud in developing our model code and the TPU Cloud during the experiments.\n\nREFERENCES\n\n[1] S. Goodfellow. \"Deep learning with RNNs: A survey\". International Conference on Learning Representations, 2017:5\u201342.\n\n[2] R. Salakhutdinov, M. Ranzato, A. K. Chorowski, T. Hoai, S. Chopra. \"Reinforcement learning for long-horizon sequential prediction\". International Conference on Machine Learning, 2014.\n\n[3] C. Lawrence Zitnick. \"Reinforcement learning on a continuous action space via long short-term memory\". Conference on Machine Learning, 2011:1318\u20131325.\n\n[4] H. Rashkin, M. Hao J. Lu, Y. P. K. Lai. \"Lstm: A generically improved language model\". Conference and Workshop on Neural Information Processing Systems, 2015.\n\n[5] H. Rashkin, M. Hao J. Lu, Y. P. K. Lai. \"A recursive activation-reuse network for learning to read sentences of any length\". Conference on Machine Learning, 2016.\n\n[6] S. Yoo, J. E. Choi, H. Choi. \"Gated convolutional networks\". International Conference on Machine Learning, 2016:2187\u20132196.\n\n[7] R. Jozefowicz, D. Djuric. \"Sequence-to-sequence learning with neural attention networks for language interpretation\". Conference on Neural Information Processing Systems, 2017.\n\n[8] E. S. M. Yee, Y. P. K. Lai, T. L. Saeyong, Y. Bai, D. M. Roth, D. T. Dillehl. \"Dynamic recurrent neural networks for sequence generation\". Conference on Neural Information Processing Systems, 2017.\n\n[9] J. P. Sutskever, R. E. Williams, D. Erhan. \"Convolutional neural networks\". Proceedings of the 27th International Conference on International Conference on Machine Learning, 2014:806\u2013814.\n\n[10] S. Vaswani et al. \"Attention is all you need\". Conference on Neural Information Processing Systems",
    "73906462bd3415f23d6378590a5ba28709b17605": " This work was supported by the LCS program of the Fundaci\u00f3n S\u00e9neca as part of the project LCS-2018-05.\n\nAuthor notes\nThis file defines the LaTex markup for the entire document. It can also be used for other purposes.\n\n### XNLI_benchmark.tex\n\n\\documentclass{article}\n\n\\usepackage{amsmath} % mathematics package\n\n\\usepackage{xcolor} % color definitions\n\n\\usepackage{tabularx} % tabular environment\n\n\\usepackage{graphicx} % Figures\n\n\\usepackage[font=small,labelfont=small,align=right,textfont=small,justification=left,singlelinecheck=false,landscape, margin=0pt,labelfont=small,textfont=small,labelfont=small,tableposition=bottom,footnotefont=small,footnotetextfont=small,\n\nfootnotetitlefont=nofont,skipfirsthead,\n\nlabelsep=colon,format=plain]{subtable}\n\n\\usepackage[usenletters,usenglish]{fontspec} % fonts\n\n\\usepackage{siunitx} % SI unit symbols\n\n\\usepackage{hyperref} % hyperref package\n\n\\usepackage{xpatch} % command redefinition\n\n\\usepackage{array} % for matrix environment\n\n\\usepackage[absolute,textmode=false,tabstop=1.5pc,\n\nheightadjust=automatic,angle=45,scale=1.5,font=small]{subcaption} % subcaptions\n\n\\usepackage{geometry} % document formatting\n\n\\geometry{top=25pt, left=15pt, right=15pt}\n\n\\usepackage{float} % for figure figures\n\n\\usepackage{subfig} % figure subfigures environment\n\n\\usepackage{xparse} % xparse (to allow dynamic commands)\n\n\\usepackage[most,bookmarks=true,bookmarksnumbered=true,bookmarksize=16,bookmarkcolor=black,bookmark=newchapter,\n\nbookmarksopen=true,bookmarksopenlevel=1,bookmarksopenlevel=2,bookmarksnumbered=true,bookmarksopenlevel=3,bookmarksnumbered=true,bookmarksnumbered=true,bookmarkcommand",
    "5bc1dc6ebcb88fd0310b21d2a74939e35a4c1a11": "\nAuthor Contributions\nConceived the work: KF, KG. Designed and ran the initial experiments: KF. Main analysis and writing: KF, KG.\n\n\n\nTHIS IS A BORZOI BOOK  \nPUBLISHED BY ALFRED A. KNOPF\n\nText copyright \u00a9 2016 by Kaeli Gillon  \nIllustrations copyright \u00a9 2016 by Eric Fan  \nAll rights reserved. Published in the United States by Alfred A. Knopf, a division of Penguin Random House LLC, New York.  \nwww.aaknopf.com\n\nKnopf, Borzoi Books, and the colophon are registered trademarks of Penguin Random House LLC.\n\n_Cover design by Susan Walsh_  \n_Cover photograph \u00a9 Steve Gardner/Trevillion Images_\n\nLibrary of Congress Cataloging-in-Publication Data\n\nGillon, Kaeli.\n\nIt's Raining Cats and Dogs / by Kaeli Gillon ; illustrated by Eric Fan.\n\np. cm.\u2014 (It's raining...)\n\n\"A Random House book\"\u2014T.p. verso.  \nSummary: In a town where it's always raining, a group of very smart young cats and dogs, none of whom like the rain, come up with a plan to save the pets who are trapped outside and keep them dry and safe.\n\nISBN 978-0-553-56395-8 (hardcover)\u2014ISBN 978-0-553-56395-8 (epub2)\n\n1. Cats\u2014Juvenile fiction. [1. Dogs\u2014Juvenile fiction. 2. Fence (Implement)\u2014Fiction.] I. Fan, Eric, 1985\u2013 illustrator. II. Title.  \nPZ7.G6885It 2016 [E]\u2014dc23 2015018718\n\nThis is a work of fiction. Names, characters, places, and incidents either are the product of the author's imagination or are used fictitiously, and any resemblance to actual persons, living or dead, events, or locales is entirely coincidental.\n\nVersion_1\n\n# Contents\n\n_Cover_\n\n_Title Page_\n\n_Copyright_\n\n_Dedication_\n\nIt's Raining Cats... No Wait, It's Raining",
    "88bf368491f9613767f696f84b4bb1f5a7d7cb48": "\nBibliographic Note\n\nAlvarez-Melis, A. et al. 2017. Mlqa: An adversarially trained evaluation benchmark for reading comprehension. In Advances in Neural Information Processing Systems, pages 6546\u20136555.\n\nBarker, T. et al. 2017. On the importance of the test set for evaluation of machine machine translation. In EMnlp 2017: Proceedings of the 10th Conference on Empirical Methods in Natural Language Processing, pages 2734\u20132744.\n\nBarker, T., R. Gurevych, E. Gildea and A. Vogel. 2015. The effect of the test set on evaluation in machine translation. In The 30th Annual Meeting of the Association for Computational Linguistics: Empirical Methods in Natural Language Processing, pages 2287\u20132297.\n\nBarrault, P., E. Chami, A. Grau, S. Zweigenbaum, A. Zoph and M. Loureiro. 2019. Multilingual xquad: Extending SQuAD. In Proceedings of the Annual Meeting of the Association for Computational Linguistics 2019, volume 1, pages 4251\u20134259.\n\nBesard, E., B. O. Klein, L. Mascova, Y. Goh, R. Neubig, D. Baroni, B. Devi, A. Goldfarb and Y. Aharoni. 2019. Beyond back-translation: On the effect of pre-training data augmentation for cross-lingual transfer learning. CoRR abs/1906.0860.\n\nBesard, E., B. Hupkes, N. A. Miller and M. Loureiro. 2018. Zero-shot cross-lingual transfer learning with big multilingual models. In The 12th Nordic Conference on Computational Linguistics, NordICML 2018, Trondheim, Norway.\n\nBesard, E., G. O'Flaherty, A. Goldfarb and M. Loureiro. 2017. Data without context: Efficient evaluation and training for cross-lingual transfer learning. CoRR abs/1804.08980.\n\nByrdin, S., B. Hupkes, E. Besard, M. Loureiro, A. Goldfarb and X. Wang. 2019. Learning",
    "0737954caf66f2b4c898b356d2a3c43748b9706b": "\n[1] A. Goldberg, T. Henaff, T. W. Kim, et al.\n  SQuAD: 100,000+ questions and answers useful for question-answering research. https://rajpurkar.github.io/SQuAD\u2010evaluation/\n\n[2] S. Guo, F. Gimpel, A. Howard, D. Klein, C. Chen, C. Zhong, U. V. V. Luxwarunasaraju, T. Bergman, M. Mattingly, Z. Liu, S. Kim, Z. Xu, W. Y. Zhou, et al.\n  XQuAD: A large X-linked Q&A dataset and a tool for building multilingual question-answering systems. http://nlp.cs.columbia.edu/xquad/\n\n[3] D. M. A. Lillehaug, N. A. H. Blitz, A. I. T\u00e4ckholm, K. S. R. Salim, R. T. I. Martins, et al.\n  PAWS: A dataset for adversarial paraphrasing identification and a thorough analysis of its limitations. https://arxiv.org/abs/2004.00161 \n\n[4] N. Zhang, M. Lin, Z. Li, H. Zha, M. Wang, Z. Zhong, B. Zhou, et al.\n  Improving cross-lingual natural language inference with back-translations. https://osu\u2010nlp\u20102019\u201019\u2010xnli.pdf\n\n[5] O. Vinyals, A. G. Radosavljevic, R. Sutskever, J. Dean.\n  Translating machine-translated sentences using parallel documents. http://arxiv.org/abs/1508.03125 \n\n[6] D. M. A. Lillehaug, N. A. H. Blitz, A. I. T\u00e4ckholm, K. S. R. Salim, M. Yatskar, M. Yin, A. B. Tsurut\u00f2pa, et al.\n  XNLI: Experimental comparisons in cross-lingual natural language inference. https://www.aclweb.org/anthology/N",
    "664b3eadc12c8dde309e8bbd59e9af961a433cde": "\n[BIBREF0]. (2019b). Annotate Your Data: A Benchmark for Cross-lingual Natural Language Understanding. arXiv:1905.02250.\n[BIBREF1]. (2018a). Cross-lingual Transfer for Reading Comprehension in Multiple Languages. arXiv:1805.06955.\n[BIBREF1]. (2018b). A Framework for Multilingual Question Answering. arXiv:1809.01053.\n[BIBREF1]. (2019a). SQuAD2.0: an Improved Question Answering Dataset. arXiv:1907.12941.\n\n[BIBREF1]. (2011). Wikipedia, the free encyclopedia. Retrieved from http://www.wikipedia.org.\n\n[BIBREF1]. (2013). XNLI: A Cross-linguistic Evaluation of Natural Language Inference Systems. arXiv:1308.2865.\n\n[BIBREF1]. (2011). Wikipedia, the free encyclopedia. Retrieved from http://en.wikipedia.org.\n\n[BIBREF1]. (2019). TransfIC 2019-02. Cross-lingual Understanding. Retrieved from https://www.cluebenchmark.com/data/2019/02/data.html.\n\n[BIBREF1]. (2018). Universal Sentence Encoder: A Deep Multimodal Language Model. arXiv:1812.06011.\n\n[BIBREF1]. (2018). A Unified Text-to-Text Translation Model. arXiv: 1812.00440.\n\n[BIBREF1]. (2019). Parallel Texts with Context Sentences: A New Dataset for Machine Translation. arXiv: 2005.10966.\n\n[BIBREF1]. (2019). Pile-of-text: a new resource for supervised sequence-to-sequence machine translation training. arXiv:1908.08251.\n\n[BIBREF1]. (2008). SemEval-2014 Task 6: Natural Language Inference. Retrieved from http://tatsumiyomt.org/2014/SemEvalTask2014_Nli/index.html.\n\n[BIBREF1]. (2011). Wikipedia, the free encyclopedia. Retrieved from http://cs.uic.edu/\u223cjm",
    "b3307d5b68c57a074c483636affee41054be06d1": "\nReferences\n\n<div class=\"ref\" data-citation=\"BIBREF0\u2033>Alberti, G., D. Baldi, and S. Gella. 2006. \"Artifacts in the Penn Treebank: A test of syntactic annotation guidelines.\" Computational Linguistics, 32(1):73\u2013101.\n\n<div class=\"ref\" data-citation=\"BIBREF1\u2033>Hu et al., 2018, \"XNLI: The Cross-lingual Multilingual Natural Language Inference Benchmark and Challenge\".\n\n<div class=\"ref\" data-citation=\"BIBREF10\u2033>Gorrell et al., 2017. \"MLQA: A Multilingual Dataset for Question Answering.\"\n\n<div class=\"ref\" data-citation=\"BIBREF11\u2033>Stoyanov et al., 2018. \"MLDoc: A Multilingual Dataset for Document Classification.\"\n\n<div class=\"ref\" data-citation=\"BIBREF12\u2033>Barrault et al., 2018. \"Wikiann: A Multilingual Annotation Task for Wikidata Entities and Types.\"\n\n<div class=\"ref\" data-citation=\"BIBREF13\u2033]].\n\n<div class=\"ref\" data-citation=\"BIBREF14\u2033>Currey et al., 2019a, \"Structured Multi-Level Pre-training for Cross-lingual Representations.\"\n\n<div class=\"ref\" data-citation=\"BIBREF15\u2033>Williams et al., 2017a, \"Collecting a Highly Reliable Set of N-Paragraph Discourse Relations from Multiple Languages via Unsupervised Learning of Inter-set Relations.\"\n\n<div class=\"ref\" data-citation=\"BIBREF16\u2033>Hewitt et al., 2019. \"The Multilingual Paraphrase Identification Challenge: Phase 1.\"\n\n<div class=\"ref\" data-citation=\"BIBREF17\u2033>Wicha et al., 2018. \"The Multilingual NLI Dataset for Human Annotated Paraphrases.\"\n\n<div class=\"ref\" data-citation=\"BIBREF18\u2033>Gururangan et al., 2019. \"A Corpus with Context and Lexical Features of Human-Written Multilingual Datasets.\"\n\n<div class=\"ref\" data-",
    "bfc1de5fa4da2f0e301fd22aea19cf01e2bb5b31": "\nFootnotes\n\nBIBREF0\n\nE. Barravecchia et al. (2018)\n\n.\n\nBIBREF1\n\nJ. M. Zadirov et al. (2019)\n\n.\nBIBREF2\n\nJ. M. Zadirov et al. (2020)\n\n.\n\nBIBREF3\n\nE. Barravecchia et al. (2020)\n\n.\n\nBIBREF4\n\nJ. Guu et al. (2020)\n.\n\nBIBREF5\n\nJ. Yin et al. (2019)\n\n.\n\nBIBREF6\n\nO. Kulmisev et al. (2018)\n\n.\n\nBIBREF7\n\nK. Gao et al. (2020)\n\n.\n\nBIBREF8\n\nZ. Chen et al. (2019)\n\n.\n\nBIBREF9\n\nA. Gauthier et al. (2016)\n\n.\n\nBIBREF10\n\nT. Zhang et al. (2016)\n\n.\n\nBIBREF11\n\nP. Khattri et al. (2017)\n\n.\n\nBIBREF12\n\nO. B\u00e9cher et al. (2020)\n\n.\n\nBIBREF13\n\nD. Galley et al. (2020)\n\n.\n\nBIBREF14\n\nS. Eom et al. (2016)\n\n.\n\nBIBREF15\n\nB. Chen et al. (2017)\n\n.\n\nBIBREF16\n\nR. Bowman et al. (2016)\n\n.\n\nBIBREF17\n\nA. Tafjord et al. (2019)\n\n.\n\nBIBREF18\n\nC. Lewis et al. (2018)\n\n.\n\nBIBREF19\n\nO. Kulmisev et al. (2020)\n\n.\n\nBIBREF20\n\nJ. Guu et al. (2020)\n\n.\n\nBIBREF21\n\nM. Favre et al. (2018)\n\n.\nBIBREF22\n\nS. Ekej\u00e4rvi et",
    "12d7055baf5bffb6e9e95e977c000ef2e77a4362": "\n\nReferences\nAbbas, I. G. (2011) Understanding crowdsourcing: a survey of the literature. International Journal of Human-computer Studies, 69(5):497\u2013506.\n\nAgarwal, S. L. et al. (2009) Cognition: Cognitive tools for the new marketplace. Proceedings of the American Association of Artificial Intelligence Conference, 5:977\u2013994.\n\nAgarwal, S., Jain, N., & Chakrabarti, A. (2008) Amazon mechanical turk: harnessing the power of thousands. Www.csl.sri.com/papers/turk07a.pdf\n\nAlexander, R., Suresh, V., & Kulesza, G. (2015) The truth about human crowds. Nature News, 546(7657).\n\nAllen, I., Li, W., Nesher, E., & Waggoner, P. (2016) How many workers until you get a good annotation. Www.csl.sri.com/papers/CrowdCompute.pdf\n\nAmano, A., & Yih, J. L. (2004) Comparing lay and professional annotation on two medical questions. Proceedings of the Conference on Empirical Methods in Natural Language Processing, 3:1\u20132.\n\nAmano, A., Schatz, D., & Walker, M. (2014) Collecting highly reliable crowd annotations for small corpora. International Conference on Machine Learning, 34:837\u2013847.\n\nAnstey, J. L., Yih, J. L., & Walker, M. (2009) Crowdsourcing medical expertise on the web. In Workshop: The Future of Human Computation in Computational Linguistics (CHiCLA-09) (Editors: M. Rambow, P. Naughton, & W. Wiebe), Chicago: Association for Computational Linguistics.\n\nBIBREF0   \nBIBREF1   \nBIBREF2   \nBIBREF3   \nBIBREF4   \nBIBREF5   \nBIBREF6   \nBIBREF7   \nBIBREF8   \nBIBREF9   \nBIBREF10   \nBIBREF11   \nBIBREF12   \nBIBREF13   ",
    "498c0229f831c82a5eb494cdb3547452112a66a0": " We thank all members of the EBM-NLP collaboration for their contributions to this work.\n\n<https://www.aclweb.org/anthology/D18-1049>\n\nAbujamard, M., Dredze, S., Kozareva, E., Jain, K., and Sorensen, B. 2018. Improving quality assessments of crowdsourced biomedical abstracts. Journal of Biomedical Semantics 1(16):3.\n\nBIBREF0\n\nBesold, A., Chen, S., & Mettu, M. 2016. Improving automated detection of biomedical entities in open-access journal texts using crowdsourcing. Journal of Biomedical Informatics, vol. 62, pp. 1\u20133.\n\nBIBREF1\n\nBesold, A. & Dredze, S. 2016. Improving the quality of automatic entity linking by crowdsourcing. In Proc. of Joint EMNLP, NeurIPS, and ACL Workshop on Crowdsourcing, pp. 57\u201366.\n\nBIBREF2\n\nBesold, A., Chen, S., & Mettu, M. 2017. Improving entity linking using crowdsourcing, joint EMNLP, NeurIPS and ACL Workshop on Crowdsourcing in NLP, pp. 14\u201318.\n\nBIBREF3\n\nBesold, A. & Mettu, M. 2018. Automatic information extraction with crowdsourcing via automatic pre-labeling. In Proc. of Joint EMNLP, NeurIPS and ACL Workshop on Crowdsourcing in NLP, pp. 13\u201324.\n\nBIBREF4\n\nBesold, A., Dredze, S., Jain. K., Kozareva, E., Abujamard, M., Sorensen, B., and Haddad, C. 2015. Automated evaluation of text quality on crowdsourced data. International Journal of Medical Informatics, vol. 90, no. 2, pp. 558\u2013565.\n\nBIBREF5\n\nBepnye, G., Lui, T-C., Hsu, R., Abujamard, M. & Mettu, M. 2019. The EBM-NLP biomedical article abstracts corpus: Annotation and preprocessing of training data for",
    "8c48c726bb17a17d70ab29db4d65a93030dd5382": " We acknowledge support in the form of compute time at Argonne. Authors wish to thank the participants in the EBM-NLP shared tasks at AMIA 2019 and 2020 and of the EBI Biocuration 2020 contest for their suggestions on the content of this paper. We thank the organisers for the opportunity of discussing this work-in-progress at ICIP 2020.\n\nAgarwal, S., Kulkarni, R., Liu, W., McMillan, C. & S\u00f8gaard, R., 2015. Crowdsourcing and Active Learning in the Biomedical Domain with BIOASQ. Bioinformatics 31(18):2926\u20132937.\n\nBIBREF0. Avanzini, M., Masci, I., Zanette, M., Ruchkiny, T., Dredze, J., Di Francesco, V., and Tiedemann, R., 2019. Crowdsourcing as a Data Generation Method for Biomedical Natural Language Processing. Bioinformatics, bdy192, https://doi.org/10.1093/bioinformatics/bdy192.\n\nBIBREF1. Bliss, A. S., Cohn, A. T., Zhan, T., Lee, H., S\u00f8gaard, R., and Wu, W., 2017. Active Learning Using Amazon Mechanical Turk for Biomedical Information Extraction. Bioinformatics 32(5):1037\u20131041.\n\nBIBREF2. Bosco, G., Kilicoglu, T., Avanzini, M., Zanette, M., and Dredze, J. 2020. An Exploration of Active Learning and Crowdsourcing in Biomedical Information Retrieval. In Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 4333\u20134342.\n\nBIBREF3. Corneanu, E., Kilicoglu, T., Wu, W., Zanette, M., Di Francesco, V., Dredze, J., Bielza, M., and van der Sanden, I., 2011. Inferring Human Annotation Difficulty of Natural Language Inferences by Machine Learning. In Proceedings of the 19th Conference on Human Language Technologies: Human Language Technologies-Beyond the",
    "89497e93980ab6d8c34a6d95ebf8c1e1d98ba43f": " We thank members of the AI in Medicine program and related projects at MIT, MIT-IBM Watson A.I. Lab, the Boston Children's Center, and the VA Center for A.I. Research and Development for the resources, discussions, feedback and support. We thank the anonymous reviewers for their insightful comments and suggestions.\nBIBREF0 Y. Xiong, I. Nabev, N. Diab, and Y. L. Chang. An Empirical Evaluation of Machine Learning Annotations in Biocontexts. CoRR abs/1701.06976, 2017.\nBIBREF1 E. H. Adams, G. Pinto, and Z. Morozov. How reliable are crowdsourced annotations? CoRR abs/1410.5537, 2014.\nBIBREF2 F. Argyraki, G. Ouimette, E. Stoyanova, D. Dumitrache, M. J. Leskovec, and W. T. Freeman. Towards Robust Semantic Parsing of Crowdsourced Biomedical Datasets. CoRR abs/1503.07243, 2015.\nBIBREF3 J. Hovy and D. Dumitrache. Modeling annotator reliability in crowdsourced biomedical data. Information Processing & Management, 64:6, pp. 1544\u20131557, 2017.\nBIBREF4 D. Dumitrache, J. Hovy, A. LeCun, Z. Morozov, E. Stoyanova, C. S. Voss, U. Zilly, N. Diab, and Y. L. Chang. Understanding Annotator Reliability on Crowdsourced Data. In NIPS Deep Learning, pp. 3069\u20133077, 2017.\nBIBREF5 S. Patel, D. Dumitrache, T. Yomtob, and N. Diab. Ebm-nlp: annotating medical abstracts for information extraction. In Proceedings of the International Conference on Document Analysis and Recognition, 2018.\nBIBREF6 E. Stoyanova and E. Stamoulis. Universal Sentence Encoders: Learning to Encode and Represent Text. In Proceedings of Advances in Neural Information Processing Systems, 2018.\nBIBREF7 E. Lepore, L. Zhang, L. Sh",
    "06b5272774ec43ee5facfa7111033386f06cf448": " Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Institutes of Health, National Library of Medicine, or the National Science Foundation.\n\n\n**Dedication**\n\nFor John, who was the best dad anyone could ever have\n\n\"You know we're all of us   \njust a family of children with  \nlove for each other, and there's  \nno reason we shouldn't live   \nfor one another.\"\n\n\u2013W. Somerset Maugham\n\nTable of Contents\n\nDedication\n\nPreface\n\nPART I - THE BEGINNING\n\nPART II - THE DEBILITATION\n\nPART III - LONDON\n\nGlossary\n\nAcknowledgments\n\nAfterword\n\nA Little About the Author\n\nBy John Cullen (a collection of articles, poems, and shorts)\n\nCopyright\nPreface\n\nIt is important in life not to go looking for the truth, but to live a life with integrity and to become more truthful than in reality.\n\nB. J. Novles, _The End of the Movie_\n\nJune 2011\n\nIf someone were to ask me what the single greatest influence on my life and writing was, I would have to say that it was our daughter. She is the reason I am able to write something as strange as this. She is the reason I found the words, the reason that I finally understood some of what the world was telling me. A little over two years ago when she was born (on her fifteenth birthday) it had been thirty-eight years since I'd written anything. The closest I'd come to writing was a few poems in high school, a short story in college, and a pair of songs I wrote and recorded as a musician. Yet, for the first time in my life, I was inspired. I was so inspired that I sat down in front of my computer and, without the use of any particular form of revision, began writing a novel.\n\nI have always been prone to melancholy and I've always seen the dark side of life. Since I was a child, I felt that life was something to be avoided and that you should do your best to get through it without any trauma. I believed in God, but I never took any comfort from religion. I was raised as",
    "08b57deb237f15061e4029b6718f1393fa26acce": "\n\nReferences\n\nBIBREF1.\nN. Berman and L. Grishman. Twitter: Understanding Political Elections Through a Natural Language Processing Perspective, New York: NYU Linguistic Center, 2016.\n\nBIBREF2.\nL. Grishman, R. Alonso-Mellado, C. Staresi, L. C. Martin, R. Hore, A. Khashabi, and M. B. Thelwall. A novel crowdsourcing scheme for political Twitter sentiment analysis. Proceedings of the Conference on Empirical Methods in Natural Language Processing, 2017.\n\nBIBREF3.\nM. B. Thelwall, N. Berman, L. Grishman and C. Staresi. An Empirical Evaluation of NLP toolkits. In Proc. of the Conference on Empirical Methods in Natural Language Processing, 2018.\n\nBIBREF4.\nD. L. Child, G. F. Lin, R. H. Kleinberg, M. E. M. Joshi and M. A. J. Paul. Using data and metadata to improve core-n-gram based text classification. In I. Sugiyama and R. H. Kleinberg, editors, Proceedings of the Seventh Symposium on Computational Grammar, 2002.\n\nBIBREF5.\nP. M. Keller and B. A. MacMullen. The Stanford corenlp tool for NLP. Computational Linguistics, 34(2), May 2009, pp. 311\u2013338.\n\nBIBREF6.\nB. A. MacMullen, D. L. Child, G. F. Lin, M. E. M. Joshi, and M. A. J. Paul. The architecture of a statistical natural language processing system. Computational Linguistics, 18(1), 2003, pp. 67\u2013122.\n\nBIBREF7.\nJ. R. Katz, Z. Yang, Y. Kuhn, Y. Liang, S. L. Noh, L. Lu, J. Xu and B. J. Waggoner. Hidden Markov models for sequences of dependencies with application to chunking. In Proceedings of the 34th Conference on Computational Linguistics and 29th Workshop of the Association for Computational Linguistics, 2003, pp. 125",
    "9b7655d39c7a19a23eb8944568eb5618042b9026": "\n\n1.\n\nG. J. Bailar, J. Gilly, M. Cormack-Lee, A. F. M. Manzini, D. C. MacKenzie, H. J. Smith, M. W. E. Gries, and L. Nguyen. The 2016 U.S. Presidential Election Results Nowcast : Billion Words Dataset, Nowcasting Results, and Error Budgets. International Journal of Forecasting, 35:1, 2018.\n\n2.\n\nB. T. E. S. B. Flower, J. M. Cormack-Lee, M. W. E. Gries, B. T. E. S. B. Flower, C. J\u00f8rgensen, D. Lazerd, and P. D. Taggart. A Social Crowdsourcing Model for Sentiment Analysis of Political Documents. International Journal of Forecasting, 35:7, 2018.\n\n3.\n\nG. J. Bailar, J. Gilly, M. Cormack-Lee, S. Piotte, M. W. E. Gries, D. C. MacKenzie, H. J. Smith, M. W. E. Gries, and B. T. E. S. B. Flower. Sentiment Analysis in the 2016 US Presidential Election Nowcast. International Journal of Forecasting, 35:5, 2018.\n\n4.\n\nE. D. B. Heer, L. Nguyen, M. Cormack-Lee, H. J. Smith, T. G. F. Brown, and P. Taggart. Analysis of Social Media Data Reveals Trend for Online Election Engagement in New Zealand. The Electronic Journal of Quantitative Behavior and Economics, 8:1, 2017.\n\n5.\n\nD. B. H. J\u00f8rgensen, L. Nguyen, T. G. F. Brown, P. Taggart, G. J. Bailar, and B. Flower. Trends in Online Social Media Use in the New Zealand General Election. International Journal of Forecasting, 35:5, 2018.\n\n6.\n\nA. M. R. A. Khosla, M. Cormack-Lee, P. D. Lazerd, L. J.",
    "cd06d775f491b4a17c9d616a8729fd45aa2e79bf": "\n\n\nPublished by the Penguin Group\n\nPenguin Group (USA) LLC\n\n375 Hudson Street\n\nNew York, New York 10014\n\nUSA \u2022 Canada \u2022 UK \u2022 Ireland \u2022 Australia \u2022 New Zealand \u2022 India \u2022 South Africa \u2022 China\n\npenguin.com\n\nA Penguin Random House Company\n\nCopyright \u00a9 2011 B. L. King, Inc. All rights reserved.\n\nPenguin supports copyright. Copyright fuels creativity, encourages diverse voices, promotes free speech, and creates a vibrant culture. Thank you for buying an authorized edition of this book and for complying with copyright laws by not reproducing, scanning, or distributing any part of it in any form without permission. You are supporting writers and allowing Penguin to continue to publish books for every reader.\n\nLIBRARY OF CONGRESS CATALOGING-IN-PUBLICATION DATA\n\nKing, B. L. (Brent L.).\n\nThe black dagger brotherhood : book 12 / B. L. King.\n\np. cm.\u2014(Rory Gilmore Series)\n\nISBN : 978-1-101-48578-0\n\n1. Rory Gilmore (Fictitious character)\u2014Fiction. 2. Women librarians\u2014Fiction. 3. Serial murder investigation\u2014Fiction. 4. Librarians\u2014Fiction. 5. Boston (Mass.)\u2014Fiction. I. Title.\n\nPS3505.I53B53 2011 2012011764\n\n813'.6\u2014dc23 2011007515\n\nThis is a work of fiction. Names, characters, places, and incidents either are the product of the author's imagination or are used fictitiously, and any resemblance to actual persons, living or dead, businesses, companies, events, or locales is entirely coincidental.\n\n  REGISTERED TRADEMARK\u2014MARCA REGISTRADA\nFor my parents\n\nRobert T. King and Louise K. King\n\n# Contents\n\n_Title Page_\n\n_Copyright_\n\n_Dedication_\n\nChapter One\n\nChapter Two\n\nChapter Three\n\nChapter Four\n\nChapter Five\n\nChapter Six\n\nChapter Seven\n\nChapter Eight\n\nChapter Nine\n\nChapter Ten\n\nChapter Eleven\n\nChapter Twelve\n\nChapter Thirteen\n\nChapter Fourteen\n\nChapter Fifteen\n\nEpil",
    "1329280df5ee9e902b2742bde4a97bc3e6573ff3": "\n\nFIGURE 1. Examples of incorrect annotations of named-entities (top) and sentiment analysis (bottom):\n\n[1] BIBREF1. Tweets of Presidential Candidates. 2016 election. Available from: http://archive.is/c6Z6, 2015.\n\n[2] BIBREF2. NLP for analyzing political tweet sentiment. Proc. of the 2016 Text Mining Conference, pp. 15:1-18.\n\n[3] BIBREF3. Twitter-based political sentiment extraction with NLTK. Available from: https://www.jhu.edu/cm/publications/papers/BIBREF3.pdf, 2016.\n\n[4] BIBREF4. Twitter: Machine Learning on the Microblog. 2011.\n\n[5] BIBREF5. The Stanford CoreNLP toolkit. Stanford Natural Language Processing. Available from: http://nlp.stanford.edu/software//CoreNLP.html.\n\n[6] BIBREF6. Detecting Emotion in Tweets. 2015.\n\n[7] BIBREF7. Hidden Markov Models: A Pragmatic Approach to Sequence Labeling. 2012.\n\n[8] BIBREF9. Conditional Random Fields: Probabilistic Models for Tagging and Segmentation. 2009.\n\n[9] BIBREF10. Learning Efficient Word Sense Disambiguation with Deep Neural Networks. 2016.\n\n[10] BIBREF11. Learning Jointly Word Sense Disambiguation and Named Entity Recognition for Twitter Streams. 2016.\n\n[11] BIBREF12. SentiStrength: Identifying Sentiment with TensiStrength, Elasticity, and Sensitivity. 2015.\n\n[12] BIBREF13. TensiStrength: Target-Specific Sentiment Detection Service Built on Natural Language Processing. 2012.\n\n[13] BIBREF14. Machine Learning for Natural Language Understanding. Stanford NLP: Research Reports. 2016.\n\n[14] BIBREF15. Explainable Machine-Learning: Interpretable AI for Text Detection. 2016.\n\n[15] BIBREF16. Social Intent Solutions. 2016.\n\n[16] BIBREF17. Topsy Social Search. 2016.\n\n[17] BIBREF18. L",
    "58c6737070ef559e9220a8d08adc481fdcd53a24": "\n\n1. Gamonova, M. (2016). Presidential campaign: natural language processing.\n\n2. Gamonova, M., Thelwall, M. (2015). A corpus-driven approach to short political text annotation and sentiment analysis.\n\n3. Gamonova, M., Thelwall, M., Smith, J., Gamonova, L., & Hovy, D. (2016a). Short political text annotation: an examination of automated tools for sentiment analysis in social media data.\n\n4. Collins, B., & Manning, C. (2009). Using the web for machine comprehension of texts: Towards a web-scale NLP system with a statistical approach.\n\n5. Mani, V., Yang, F., & Baldridge, J. (2016), A crowdsourcing scheme for short text-based sentiment analysis, to appear in Proceedings of the Association for Computational Linguistics, ACL2016.\n\n6. Thelwall, M., Gamonova, M., & Smith, J. (2015). A corpus-driven approach to short text-based sentiment analysis.\n\n7. Yang, F., & Chi, P. J. (2014). Deep neural networks for named entity recognition.\n\n8. Manning, C.D. (2008). Introduction to information retrieval (2nd ed.).\n\n9. Manning, C.D., Schuster, M., Ng, A., Cutting, S., Krueger, C., & Baldridge, R. (2012) The Stanford CoreNLP project, to appear in Proceedings of the Association for Computational Linguistics, ACL2012.\n\n10. Gamonova, L., Gamonova, M., Thelwall, M., Smith, J., & Hovy, D. (2016b). Evaluation of sentiment analysis tools for short political text.\n\n11. Gamonova, M., & Thelwall, M. (2014). The NLTK 3.0 toolkit (version 0.3).\n\n12. TensiStrength, (2017). Sentiment analysis.\n\n13. Gamonova, M., Thelwall, M., Smith, J. & Hovy, D. (2016c). Evaluation of short text processing tools for sentiment analysis.\nBIBREF0: http://www.dcs.gla",
    "0af16b164db20d8569df4ce688d5a62c861ace0b": "\nAcknowledge\nWe would like to express our gratitude to SocialNLP workshop organizers for organizing such a great challenge. The helpful discussion with the other EmotionX competitors is inspiring and necessary. We would like to thank the reviewers for their valuable suggestions. Thanks to Zhiling Cheng, Xiaobo Zhang, and Yanfei Xu for their insightful help during this paper's peer review. The paper is a joint work between Institute of Information Engineering, Fudan University, Shanghai and Huawei Inc. Zhiwei Xing is an expert in Artificial Intelligence (AI), from the Institute of AI and Human-Machine Interaction, Fudan University, and Xiaobo Zhang is a PhD student.\nReferences\n\n[1] J. D. S. Ekman. \"The 6 universal facial expressions across cultures and their relationship to basic emotions.\" Psychological science. 1990.\n\n[2] B. W. Bushnell. The art of recognition: a theory of emotion and aesthetic. 2002.\n\n[3] Emor. Emor: Emotional expression recognition. 2012.\n\n[4] B. Yang and G. K. Sui. Towards an objective measure of conversational fluency analysis: The EMO-CAL model. 2014.\n\n[5] J. B. Zhang, J. Zhu and Y. Hu. An approach by emotional polarity and sentiment analysis of social media microblogs. 2013.\n\n[6] P. J. Tesar and N. R. Shumway. Deep moji: A contextualized affect representations model for sentiment analysis and topic modulation. 2014.\n\n[7] J. R. Bai, Z. X. Zhang, P. Liao, Z. Liu, Y. Z. Zhou, L. Liu and H. Wu. Understanding emotions with bidirectional encoder representations from transformers. 2019.\n\n[8] I. S. Goodman. Is attention the mechanism by which information from other parts of the scene enters consciousness? Trends in cognitive sciences. 2014.\n\n[9] Xiong Zhang, Y. Zhao, W. Li and L. Huang. Sentence-level dialogue context-modeled text classification. 2018.\n\n[10] H. Poria, M. Smyth, Z. Liao, Y. Ye, G. Cheng, N. Rostamizadeh and L. Wan.",
    "78a4ec72d76f0a736a4a01369a42b092922203b6": "\nAcknowledgments\nYongfu Zhou and Zhifeng Chen would like to thank to Dr. Wei-Kun Kuo for support and helping during the research project.\nReferences\n\n[1] J.D. Ekman, Y. Iwami, S. Kimura, and K. Hashimoto, \"Identifying human emotions by a universal set of 72 facial and bodily markers.\" _Psychiatry Research: Neuroimaging, Neurochemistry, and Biology_. Springer New York: 1988.\n\n[2] Y. Iwami, J. D. Ekman, and J. C. Almeida, \"The face of emotion: a unified theory of the causes and expressions of emotion.\" _British Journal of Psychology_. Cambridge University Press: 2002.\n\n[3] Z. B. Zhang, J.D. Ekman, and S. M. Garbarino, \"Ekman's six basic emotions as a foundation of psychology.\" _The Science of Emotion: Translating Theory into Research Practice_. New York: Springer, 2005.\n\n[4] C. M. Zhou, T. Deng, and S. Xu, \"Couple emotional recognition in a public-private dialogue.\" _Frontiers in Psychology_. Elsevier BV: 2017.\n\n[5] D. P. B. Pappas, Z. B. Zhang, A. L. Garces, and T. K. Ng, \"Contextualized affect representations for emotion-based dialogue modeling.\" _ACL Workshop on Machine Learning, Empirical Methods, and Social Science Studies_. Association for Computational Linguistics: 2018.\n\n[6] R. G. F. Zhou, V. Kumar, and J. Grosz, \"DeepMoji: Emotion recognition based on the cross-lingual transfer learning BERT.\" _SocialNLP-2019_. Association for Computational Linguistics: 2019.\n\n[7] B. D. Potts, J. Grosz, S. Xu, and R. A. J. R. T. Hancock, \"The task of understanding dialogues: a challenge and a benchmark.\" _Computational Linguistics_. CSLI Publications: 2019.\n\n[8] I. Sennrich, S. H. Ruder, J. Snell, and B. D. P. Potter,",
    "6a14379fee26a39631aebd0e14511ce3756e42ad": "\nChengwei Dong, Yongdong Sun, Chengyu Li, Yangqiu Song, Guoping Shen, Jie Xu, and Shuyi Zhu. EmotionLines: A Multi-Utterance Dialogue Dataset for Context-Aware Emotion Detection. In Proceeding of the First International Joint Conference on Natural Language Processing and Knowledge Engineering (KonNeuroLang 2019), pages 9:1-9:33, 2019.\n\nYuhang Bao, Yikai Liu, Zicai Qin, and Lili Mou. Automatic Emotion Classification of Conversational Expressions in Multimedia Social Media Data. Machine Learning: ECMLPA 2019. In Proceeding of the Twenty-Second European Conference on Machine Learning, Proceedings of Machine Learning Research, Vol 103, 2018.\n\nKatharine Bradbury, Paul Ekman, and Richard J. Davidson. Affect Recognition: Affectiva Laboratory's Affectiva Challenge. In Proceedings of the Conference on Human Emotion Analysis, 2015.\n\nYuhang Bao, Yikai Liu, Zicai Qin, and Lili Mou. Emotion Classification in Emoticallized Chat Messages for Enhanced Natural Language Understanding. In International Conference on Multimedia Retrieval, Springer, 2018.\n\nYuhang Bao, Yikai Liu, Li Yang, Zhenyu Hu, Zicai Qin, Jie Xu, and Lili Mou. Causal Utterance Modeling for Convolutional Sequence-to-Sequence Models for Emotion Detection. In Proceedings of the 11th International Joint Conference on Natural Language Processing, Association for Computational Linguistics, 2020.\n\nYoshua Bengio, and Guy Schuster. Distilling the Knowledge in a Neural Network. In International Conference on Learning Representations, ICLR 2015.\n\nAndy Way, Cormac Flanagan, Nando de Freitas, and Yossi Singer. Lattice-free Attention over Structured Word-Ground ConvNets. CoRR abs/1708.07326, 2017.\n\nShuyi Zhu, Chengwei Dong, Xiangyu Zhang, Shuyuan Zhang, Haifeng Sun, and Yongdong Sun. EmotionLines: An Emotion-based Dialogue Dataset. In Proceedings of the Joint International Conference on Natural Language Processing",
    "81588e0e207303c2867c896f3911a54a1ef7c874": "\nAcknowledgement\n\nWe would like to thank Zhiming Qiu in SocialNLP 2019 EmotionX and the Emorynlp for providing the source data.\n1. S. P. Timbs, P. K. MacKenzie, and M. L. Tuller, \"Recognising emotions in text,\" in EACL/COLING 2009 Workshop on Computational Linguistics for Emotion Analysis (COLING/EACL 2009), pages 31\u201337, 2009.\n2. C. Boutet, J. Bailly-Boudier, C. Cappart, N. Duta, T. Gile, J-L. Hsu, P. Louvain, P. Paramo, and D. Saveriot, \"The evolution of emotion recognition through a shared task challenge: Results of the 2019 EmotionX Challenge,\" in Proceedings of the Eleventh Workshop on Computational Linguistic Methods in Emotion Detection, 2017.\n3. J. Wu and H. Liu, \"EmotionX: Building an interoperable dataset for emotion identification,\" in Proceedings of the Eleventh Workshop on Computational Linguistic Methods in Emotion Detection, 2017.\n4. R. Jiang and Y. Zhang, \"DeepMoji: Using contextualized word representations from transformers to detect emotions while preserving sarcasm and irony,\" in Proceedings of the Eleventh Workshop on Computational Linguistic Methods in Emotion Detection, 2019.\n\n5. M. Eslami, A.-C. Boutsidis, A. K. Chai, T. W. Cohn, P. J. Lin, A. R. Hruschka, and F. Y. Zhu, \"Friends, I'm sad: learning from multisentence dialogues for emotion classification,\" in Proceedings of the Eleventh Workshop on Computational Linguistic Methods in Emotion Detection, 2019.\n6. D. K. Phan and V. T. Nguyen, \"A study of linguistic and non-linguistic cue-based sentiment analysis for sentiment expression,\" Transactions of the Association for Computational Linguistics (TACL), vol. 2, no. 1\u20132, 2016,\n7. R. Jiang, Z. Liu, D. Yue, L. Zhang, M. He, C. Liu, D. Zhou, W. Li, and",
    "dd09db5eb321083dba16c2550676e60682f9a0cd": " These enhancements might let our model achieve better performance in EmotionX.\nAcknowledgement\nWe would like to thank our teammate Xinsong Shen for the valuable help. The support from J. Xiao and Y. Liu is recognized. Thanks to the team of EmotionX, the help from Annotation and Review for EmotionLine and the Emo-X dataset.\nBibliography\n. A. A. N. Murty, L. Rudinger(eds.), (2009). Formal Methods for Empirical Analysis of Behavior. Springer Nature.\n\n. B. O. Choudhury, J. A. J. Kootstra, T. K. Kohli, D. N. Bates. (2019). Explore the EmotionLines Project of the EmotionX Challenge. 2019 SocialNLP.\n\n. S. Ding and X. Yang, \"FriendsBERT: Emotion and personality classification from Friends by utilizing bi-directional BERT.\" 2019 AAAI.\n\nBIBREF8-L. B. I. D. Cohan and K. T. Libovinson, \"Attention Is All You Need\", 2017.\n\nBIBREF9-S. Ding, \"Sentiment Classification with Emoticons Using Deep Reinforcement Learning\", 2017.\n\nBIBREF10-M. P. Johnson, I. T. Sutskever, K. Cho, Y. Chen, J. Dean and Y. Bengio, \"Deep contextualized word representations.\" 2016 ICCV.\n\nBIBREF11-C. Howard and S. Zhang, \"Universal and sparse text-embeddings\", 2016 NIPS.\n\nBIBREF12-Y. Yang, S. Ding, J. Xiao, M. S. H. Rashkovsky. (2017). Improving Annotating Quality of Crowdsourced Emotional Corpus with Multilevel Emoticons: A Case Study on Friends TV. Proceedings of the 2017 International Conference on Empirical Methods in Natural Language Processing.\n\nBIBREF13-M. Luan, A. S. D. C. Cervasco, S. Singh, X. Fang, Y. Gao, R. Vijaya, V. Hwang, W. D. Crooks, O. E. Pariente, C. A. C. Pereira, A.",
    "40c0f97c3547232d6aa039fcb330f142668dea4b": "\nstandard sefe (using all the data at train time)\n\nsefe with shared context vectors only (using only data from the same group at train time, sharing the global context vectors).\n\nstandard efe without context vectors\n\nstandard efe with shared context vectors only.\n\nFor ArXiv abstracts we use the word frequency as the grouping indicator, and for U.S. Senate speeches our grouping indicator is the home states of the speakers. For grocery shopping data we use the month as grouping indicator. All efe models also share the vocabulary and downsample the most frequent words to 20k.\n\nResults for sefe. We show our results in Table TABREF18, where we report held-out log-likelihood in a cross-validation scheme. The best performing models are shown in bold.\nSections of ArXiv papers show the greatest differences in semantic structure. The ArXiv paper collection can be thought of as a matrix INLINEFORM0 of INLINEFORM2 rows for each of the 19 scientific domains. Here, we can represent the abstract data as INLINEFORM0, INLINEFORM1, and INLINEFORM2, where INLINEFORM1 is the section of the abstract in which each observation INLINEFORM2 appears (e.g., as defined by the abstract tag). Our empirical results show that the differences in usage patterns are much more pronounced between sections than, for example, between states in U.S. Senate speeches. Furthermore, our results show that we can infer a per-section embedding for every word. We give a graphical overview of the embedding structure in Figure FIGREF2.\nFigure 2: The sefe embedding structure for Arxiv papers.\nLeft: The 19 sections corresponding to different scientific disciplines. The rows of INLINEFORM0 and columns of INLINEFORM1 specify the data indices. We use the word frequency to group the words, and we show the average held-out log-likelihood over the entire training set. Right: We show the fitted sefe models for words in the vocabulary. The plot shows that words have different embedding vectors in different ArXiv sections. (The plots are for all 3-grams, ignoring word order.)\n\nTable 8: ArVos embedding. We show average held-out log-likelihood on ArXiv data over cross-validation scheme.\nSenate Speeches\n\nTable 9: Senate Speeches embedding. We show average",
    "777217e025132ddc173cf33747ee590628a8f62f": " hierarchical sefe (HS), where we use a pre-specified hierarchical structure in training; hierarchical efe (HE), where we only model the hierarchical structure in the model; amortized sefe (AS), which embeds each group using an independent function of the global embedding vectors INLINEFORM8 ; amortized efe (AE), which embeds each group using only the global vectors INLINEFORM7, without using the global vectors as input to the network INLINEFORM9 ; and unstructured sefe (US). We also compare against the unstructured efe (UE) baseline, which does not model the statistical structure and instead assumes that the observations are generated from a single distribution.\nEvaluation. The ArXiv abstracts are long and the objective function in Eq. EQREF14 is not convex, making estimation challenging. For fair comparison, we compute the log-likelihood of 10,000 models of varying parameter size and plot the results in Figure FIGURE1 (left).\n\nThe results show that using the hierarchical structure (dashed curves in Fig. 1, top left) provides improved estimates over the unstructured models (solid curves). Amortized sefe (solid curves) has a significant advantage over hierarchical sefe (dashed curves), as the shared parameters allow leveraging information across groups.\n\nNote that all models with the hierarchical structure outperform the amortized models (dashed) and efe (solid); the hierarchical efe (HE) is clearly better than the unstructured efe (UE). To understand these results more deeply, we fit all models to a set of held-out test sets in which INLINEFORM3 is fixed, showing the accuracy of the learned sefe objective functions in Figure FIGURE1 (bottom left). Here, the amortized sefe (AS) has the highest accuracy, while the amortized efe (AE) is significantly worse.\n\nWe further report evaluation results for all models in Tab. 2 for the Senate speeches. We provide quantitative metrics based on 10-fold cross-validations. As in Fig. 1, all models with hierarchical structure (HS, HE) outperform the unstructured models (UE).\n\nFinally, in Table TABREF18 we quantify how the performance depends on each group. In particular, as we would expect, the highest performance is for the Republicans from Alabama; while the second highest is for the Republicans from California. Notice that the maximum",
    "2dbf6fe095cd879a9bf40f110b7b72c8bdde9475": "\n\nsefe hierarchical (Eq. EQREF7 )\n\nsefe hierarchical (Eq. EQREF11 )\n\namortized sefe (Eq. EQREF7 )\n\namortized sefe (Eq. EQREF11 )\n\nAs an additional baseline, we also use a model called poisson efe BIBREF10 that augments the efe BIBREF10 model with the Poisson distribution.\nResults. As we showed in Section SECREF2, sefe can be used to study semantic variations in several types of data. Thus, we use sefe, with different settings of INLINEFORM0 and INLINEFORM1, to study variations in word usage across different U.S. states and among scientific disciplines. Our results are summarized in Table TABREF17.\nOverall, we find that sharing the embedding vectors and introducing amortization improve fitting significantly over the efe models. In particular, sefe does a significantly better job of capturing word usage across ArXiv documents and varying word co-occurrences across shopping items. For the grocery data, sefe is able to capture shopping sequences depending on the seasons BIBREF10, BIBREF2.\nWord sense distinctions across U.S. states. In this subsection, we show that sefe performs better in the task of distinguishing word usage for words based on political party affiliation or state of origin. We use sefe to study which words are more often used by Senators affiliated with the Democratic Party than Republican, when separated by state of origin. This helps reveal linguistic variations not obvious from ordinary word use counts. To demonstrate this, we use sefe to produce word usage maps for each Senator and show how they vary depending on which state they are from and whether they are Democrats or Republicans. Below, we provide examples.\nState-level word usage maps. Using word use maps, we can visualize how words are used in U.S. Senate speeches and how they vary depending on the political party (Republicans or Democrats) of the Senators. For example, in Figure FIGREF9, we can see how the word 1.10intelligence uses words most similar to it in the Democratic Party relative to the Republican Party. Likewise, in Figure FIGREF10, we can see that the word 1.10intelligence uses words most similar to it in the Democratic Party, relative to the Republicans. We note that the mapping is not clear\u2014e.g., there",
    "7d483077ed7f2f504d59f4fc2f162741fa5ac23b": " standard efe ( SECREF4 ), which allows each object to have a shared embedding; hierarchical efe ( SECREF8 ), which imposes a hierarchical structure to share statistical strength among the per-group vectors ; amortized sefe ( SECREF9 ), which imposes a hierarchical structure in combination with amortization (BIBREF14, BIBREF15 ); lastly, the two baselines sefe-Bernoullis ( SECREF5 ) and sefe-Poissonis ( SECREF6 ). For efe, we use negative sampling and the hyperbolic sine (tanh) link function INLINEFORM0. For the sefe models, we propose a hierarchical approach with the negative sampling loss ( SECREF8 ) and an amortized approach with hyperbolic tangent nonlinearity ( SECREF9 ).\n\nTable-of-Contents\nTable-of-Contents\n\nTable-of-Contents\n\nPrevious: Figure 1: Embedding word usage varies by state or political party\nNext: Table 2: Results (held-out log-likelihoods)\nA note on the notation\n\nWe use the following notation. For matrices ( INLINEFORM0, INLINEFORM1 ) and vectors ( INLINEFORM0, INLINEFORM1 ), we use bold-face lowercase letters. For sets ( INLINEFORM0, INLINEFORM1 ) and indices ( INLINEFORM0 ), we use bold-face capitals. Bold-face letters in parentheses are vectors for which the entries are scalars.\nFigure 1:\n\nEmbedding word usage varies by state or political party. The horizontal axis denotes a word, while the vertical axis denotes a group. The embedding vector for each word, INLINEFORM3, is shown in blue, while the context vectors, INLINEFORM4, are shown in green. For easy visualization, we color similar words with similar shades of blue or green. For example, the word 1.10intelligence is used in two distinct ways: as an English word in computer science (cs), and as a term from artificial intelligence (ai) in finance. These groups are separated by a vertical red bar. When color overlap, the word is equally used by both groups.\nTable 2:\n\nResults (held-out log-likelihoods). The following section gives the results of the held-out log-likelihoods on the ArXiv",
    "de830c534c23f103288c198eb19174c76bfd38a1": " efe with a fixed global context (fex fixed ); sefe without hierarchical structure (sefe); sefe with a hierarchical structure (sefe hierarchical ); and sefe with amortization (sefe amortization ). We also fit an efe model that uses negative sampling for the zeros in the objective function (efe negative sampling ).\nResults. On the ArXiv paper corpus, we compare the different methods over a held-out set of abstracts and show the results in Figure FIGREF2. Figure 2.1 shows that sefe hierarchial achieves better log-likelihood using less training data. We then compare the four groups of models on the test set over held-out items. We find that both sefe hierarchical and fex hierarchical outperform all other models, while efe and sefe amortization perform similarly. This indicates that the hierarchical structure is important to avoid overfitting to the training data in cases where there is limited data per group. In all three tasks, sefe hierarchical outperforms the other models, especially for groups with less available data (e.g., Republicans senators from Alabama).\nFinally, in Table TABREF18 we show held-out probabilities on the validation set for each task.\nPoisson sefe amortization. We observe a large drop in accuracy by switching from feed-forward to residual networks for neural network architecture. That is, with a feed-forward network, amortized sefe hierarchical achieves an accuracy of 79.6% with a RMSE of 0.08, while with a residual network it drops to 76.1%. We suspect that residual networks are more appropriate for modeling real-valued data such as supermarket purchases.\nU.S. Senators. Here, we analyze U.S. Senate speeches by political party affiliation and state of origin. Figure FIGREF3 compares the different methods using the validation set. Similarly to the ArXiv abstracts, we find that using a residual network instead of a feed-forward network improves results. Note that, while this is true for efe fex, its impact here is insignificant: sefe fex hierarchical achieves a mean accuracy of 54.9% with a standard deviation of 8.6. In contrast, we find that sefe hierarchical with a residual network achieves a mean accuracy of 57.9% with a standard deviation of 8.5 (using an INLINEFORM10 -fold cross-validation), whereas sefe hierarchical with a",
    "b0d66760829f111b8fad0bd81ca331ddd943ef41": "\n\nReferences\n\n[1] A. Mikolov, T. S. Wang, J. G. Corrado, K. K. Toutanova, J. J. Dean, A. Karpathy, P. Sutskever. Exploiting syntactic and semantic structure in recurrent networks for semantic compositionality. Empirical Software Eng. 22, 7: 1-43, 2016.\n\n[2] T. M. Altafaj, C. Q. Qiu, J. D. Liu. Automatic sensational headline generation for online news articles. Transactions of the Association for Computational Linguistics (TACL) 2019.\n\n[3] P. Kryscinski, S. Rao, W. Zhou, R. Wang. Incorporating sensationalism into reinforcement learning for headline generation. In Proceedings of AAAI Conference on Artificial Intelligence (AAAI), 2019.\n\n[4] A. Gupta, A. Gupta, G. M. Shapiro. Automatic sensational news headline generation using reinforcement learning. In Proceedings of the International Conference on Intelligent User Interfaces (IUI), 2017.\n\n[5] K. Y. Qiu, F. C. Yin, K. Eisz, Y. Jiang. Understanding sensationalism in articles: Investigating text structure and sentiment. In Proceedings of the World Conference on Multilingual Multimedia Computing, Communications and Applications (WWW-Cellular), 2016.\n\n[6] D. Silver, F. Chen, C.-Y. Chow, M. G. Matena, S. K. Mitamura. Mastering the game of go with deep reinforcement learning and tree search: Mastering Go: Mastering Go. AAAI Conf. Proc. (AAAI), 2017.\n\n[7] I. Titkov, L. Schulman. Deep reinforcement learning for automated essay evaluation. arXiv preprint arXiv:1706.02758v1, 2017.\n\n[8] A. M. Gliozzo, S. Sordoni, F. P. Manzini, B. Iversen. Improving summarization by using reinforcement learning. In Proceedings of International Conference on Machine Learning (ICML), 2016.\n\n[9] X. Sun, L. Zhang, T. Huang. Cascaded attention and reinforcement learning for long document summar",
    "ae7c93646aa5f3206cd759904965b4d484d12f83": "\n\nBIBREF1.\ndolan2016summa-rid: Learning to Summarize Using Summaries\n\nbamman2016text: Encoding Texts for Neural Machine Translation: A Case Study on Chinese-English Translation\n\nyang2017aspect: A Sentiment-Oriented Neural Model for Aspect-Based Sentiment Analysis\n\ngiberson2017attention: The Effects of Attention-in-Attention: Automatic Analysis of Attention Mechanisms in NLP\n\ngiberson2018universal: A General-Purpose Encoder for Training State-of-the-art Neural Networks Based on a Set of Transformations\n\nkitaev2018revisiting: Automatic Analysis of Topic Change in Texts\n\ngulcehre2018fine: Exploiting Syntactic Structure to Improve Machine Translation with Sentence-level Contextual Linguistic Features\n\nkryscinski2018improving: Deep Neural Image Captioning Models with Adversarial Training of Feature Maps\n\nnallapati2016abstractive: Abstractive Sentence Compression for Image Summarization.\n\nyin2018autorec: Joint Recognition and Generation of Automatic Review\n\ngao2017using: Attention-Based Neural Machine Translation from Simultaneous Translation Using Phrase-Table Models-Theory and Practice\n\nqiu2018revisiting: Universal Image-Text Alignment using Contextual Image-text Encodings and Deep Reinforcement Learning.\n\nboukouvalo2018improving: Exploiting Summarization Quality and Structure for Improving NMT\n\npapa2018scalable: Summarization using Knowledge-Based Summarization Techniques\n\nli2018automatic: Automatic Extraction of Chinese News Headlines\n\nlu2018efficient: Efficient Selection of Relevant Keywords by Reinforced Neural Model\n\nli2019learning: Learning to Make Sentences Sensationalusing Distant Supervision.\n\nzhang2019fast: Neural Abstractive Summarization with Contextualized Candidate Generation.\n\nlu2018gcn: A Large-Scale Benchmark for Chinese Sentiment Analysis.\n\ntang2019context: Context-Free Neural Story Generation\n\nxiao2018distant: Automatic Generation of Clickbait Headlines\n\npohle2017clickbait: Automatically Detecting Clickbait Headlines: Definition,",
    "d1ec42b2b5a3c956ff528543636e024bfde5e5ba": " We also thank the anonymous reviewers for their comments and improvements.\nREFERENCE\nBIBREF:\n\n[1] Yang, P., Wei, S., Wang, Z., Yan, Y. (2017) Leveraging Clickbait News Summarization Data to Learn Sensational Headlines with Reinforcement Learning. Transactions of the China Computer Federation (CCF)'17)\n\n[2] Xie, Y., Li, B. (2018) Automatic Detection of Clickbait Headlines in Chinese Texts. Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)\n\n[3] Zhang, Q. et al. (2007) Extracting Clickbait Headlines from Weblogs. Proceedings of the 14th International Conference on Computational Linguistics and Intelligent Text Processing, Taipei 2007\n\n[4] Jia, R., Jiang, K., Zhang, M., Xian, W. (2013) A Fuzzy-Based Method to Extract Clickbait Headlines from Weblogs. Journal of Web Semantics 11(4); 13-24\n\n[5] Kryscinski, S., Azzopardi, F., Wiegreffe, D., et al. (2018) Improving the Readability of Headlines through Reinforcement Learning Based on Pointer Generator. Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)\n\n[6] Williams, G. (1989) On the Relaxation of Some Infinite-Dimensional Optimality Theories by Gradient Decay. Annals of Statistics; 17(3), 867-879\n\n[7] Mnih, V., et al. (2016) Variational Gradient Descent for Optimization and Inference in a Generative Model. International Conference on Learning Representations (ICLR)\n\n[8] K\u00fc\u00e7uksuoglu, A., Sener, I., and Cakir, A. R. (2017) Deep Reinforcement learning for Sequential Prediction: Theory & Practice. MIT Press\n\n[9] Ovadneva, J., et al. (2017) Rethinking Transfer Learning with Simultaneous Domain Adversaries. Arxiv:1712.03155v1\n\n[10] qin2018automatic. (2018) Automatic Generation of Long Online",
    "1dac4bc5af239024566fcb0f43bb9ff1c248ecec": "\n\nReferences\n\n\\href\"https://bit.ly/2Nefnq2\"target=\"_blank\">[1] \\mcitetitle{qin2018automatic} \\mbibentry{qin2018automatic} was done in Sina Weibo, and headlines are collected from Tencent News.\n\n\\href\"https://bit.ly/2mR1b3C\"target=\"_blank\">[2] \\mcitetitle{qin2016learning} \\mbibentry{qin2016learning}\n\n\\href\"https://bit.ly/2mRR0V6\"target=\"_blank\">[3] \\mcitetitle{lin2019learning} \\mbibentry{lin2019learning}\n\n\\href\"https://bit.ly/2mRc8c7S\"target=\"_blank\">[4] \\mcitetitle{lin2019deep} \\mbibentry{lin2019deep}\n\n\\href\"https://bit.ly/2nUO3Yj\"target=\"_blank\">[5] \\mcitetitle{qin2018automatic} \\mbibentry{qin2018automatic}\n\n\\href\"https://bit.ly/2nZ9BQ6\"target=\"_blank\">[6] \\mcitetitle{luong2015effective} \\mbibentry{luong2015effective}\n\n\\href\"https://bit.ly/2mRyDZgU\"target=\"_blank\">[7] \\mcitetitle{gu2016incorporating} \\mbibentry{gu2016incorporating}\n\n\\href\"https://bit.ly/2nUa4tVQ\"target=\"_blank\">[8] \\mcitetitle{nallapati2016abstractive} \\mbibentry{nallapati2016abstractive}\n\n\\href\"https://bit.ly/2nR1X3yq\"target=\"_blank\">[9] \\mcitetitle{paulus2017dee} \\mbibentry{paulus2017deep}\n\n\\href\"https://bit.ly/2nQ0eYj\"target=\"_blank\">[10] \\mcitetitle{kryscinski2018improving} \\mbibentry{kryscinski2018im",
    "3bf0306e9bd044f723e38170c13455877b2aeec3": "\nAppendix\nAppendix A: The sensationalism-score function\nOur sensationalism scorer employs a deep CNN to capture the character features in input sentences. This section elaborates the CNN architecture which is used by qin2018automatic, lin2019learning.\nAppendix B: The sensationalist-title generation model\nAppendix C: Hyper-parameters of sensational head-line generation model\nAppendix D: Results of sensational headline generation\nAppendix E: Sensational Headline Models\nAppendix F: The hyper-parameters of sensational headline models\nAppendix G: Details about ARL\nAppendix H: Data Collection\nAppendix I: Dataset used to evaluate the sensational headline models\nAppendix J: Details about sensational headline evaluation\nAppendix K: The sensational headline generation loss functions\nAppendix L: The data used for training sensational headline models\nAppendix M: Evaluation metrics\nAppendix N: Sensational Headline Generation on the LCSTS dataset\nAppendix O: Clickbaits, Emoji and Emotion Usage\nAppendix P: Sensational Headlines\nTable 1: Statistics of the sensational headline dataset.\n\nTable 2: A list of sensational headlines chosen in our dataset.\n\nTable 3: Accuracy of sensational headline generation model comparing it with previous related work.\n\nTable 4: Sensationalism scorer trained on sensational headlines in LCSTS.\n\nTable 5: Clickbait examples.\n\nTable 6: The sensationalism scorer.\n\nTable 7: Headlines generated by all sensational headline generation models in the LCSTS dataset.\n\nTable 8: Sensationalism scorer trained on sensational headlines.\n\nTable 9: A list of headlines generated by sensational headline models in LCSTS without sensationalization.\n\nTable 11: Examples of sensational headlines generated by different models.\n\nTable 12: Exemplary sensational headlines generated by our model in LCSTS.\n\nTable 13: Details and results of clickbait annotation.\n\nTable 14: Details of sensational headlines annotation.\n\nTable 15: The sensational headlines from LCSTS, along with sensationalism score predicted by the sensationalism scorer.\n\nTable 16: A list of sensational headlines generated by different models considering sensationalism scorer.\n\nTable 17: Details of sensational headlines generation with sensationalism scorer.\n",
    "2858620e0498db2f2224bfbed5263432f0570832": "\n\nAppendix\nAppendix A Word co-occurrence networks\nWord co-occurrence networks can be obtained from a preprocessed document by sliding a sliding window over the text. Two approaches for such sliding windows are the overlapping sliding windows approach of BIBREF57, and the uniform sliding windows approach of BIBREF58. We have performed experiments with both.\nFigure APPENDIX1 shows an example of a typical word co-occurrence network obtained over a document with overlapping windows. Consider a document of length $n$ words, and let us denote by $n_{max} $ the length of the longest sentences. If a sliding window of size $w$ is applied over the document, the size of the obtained graph will be $k \\times n_{max} +1$. For instance, for $w=2$ and $n=60$ words, sliding over a window of $14$ words will result in a graph with 71 nodes. In this figure, for brevity reasons, we only display nodes at a single iteration of the sliding window, starting with the sentence represented at the end of word $a$. There are three categories of nodes, according to their size. The smallest one is the special document node, that is connected to all other nodes through unit-weight bi-directional edges, corresponding to the words in the sentence they represent. The largest one is the sentence node.\n\nNote that words that never appear in the same sentence (a), cannot form edges with each other, and are connected by the sentence node (b), to which they are connected by unit weight unidirectional edges (c). Finally, as we slide the window further, more and more words co-occur (d,e,f). For instance, as the window moves to $a$ and $b$ in the middle sentence, edge (d) represents the word $a$ in the previous sentence, and edge (e) represents the word $b$ in the sentence that follows it. Note that on Fig. APPENDIX1, sentences are represented in a continuous way. But generally speaking, each document is represented by a graph with a different number of node and sentence nodes, i.e., with different maximum sentence lengths.\n\nFigure APPENDIX1. An example word co-occurrence network with a sliding window of size 2.\n\nFigure 2 shows an example of a typical word co-occurrence network obtained",
    "545e92833b0ad4ba32eac5997edecf97a366a244": " This research was funded by EU H2020 project FLAX, as part of the SIRENE WorkPackage.\nDisclosures. No conflicts of interest for this work.\nReferences\n\n[1] BIBREF0 BIBREF58 : \"A survey of deep learning for graphs and networks. In Proceedings of the 18th International Conference on World Wide Web, pp. 13\u201323, 2012.\"\n\n[2] BIBREF1 BIBREF59 : \"Large graph neural networks via spectral analysis. In ECVP Workshop on the Future of Machine Learning on Graphs, Springer, 2017.\"\n\n[3] BIBREF2 BIBREF60 : \"Graph neural networks: a survey. ACM Computing Surveys, 49:6, 2017.\"\n\n[4] BIBREF3 BIBREF61 : \"GraphSAGE: a graph convolutional network for semi-supervised classification. In NIPS, 2016.\"\n\n[5] BIBREF4 BIBREF62 : \"Unsupervised document representation learning guided by graph neural network features. In NIPS Workshops, 2018.\"\n\n[6] BIBREF5 BIBREF63 : \"A simple yet effective approach for link prediction in large-scale graphs. In ECVP Workshop on Knowledge Graphs and Learning with Graphs, Springer, 2017.\"\n\n[7] BIBREF6 BIBREF64 : \"Graph attention network: graph attention pooling for predicting next item suggestions. In NIPS, 2017.\"\n\n[8] BIBREF9 BIBREF65 : \"Spectral GNNs for inductive representation learning on graphs. In NIPS, 2018.\"\n\n[9] BIBREF10 BIBREF66 : \"Representation learning via message passing over graphs. In NIPS, 2018.\"\n\n[10] BIBREF11 BIBREF67 : \"Attention with recursive message passing over graphs. In NeurIPS, 2020.\"\n\n[11] BIBREF12 BIBREF68 : \"Hierarchical attention network for representation learning on graphs. In NeurIPS, 2018.\"\n\n[12] BIBREF13 BIBREF69 : \"Message passing with attention across graphs. In NeurIPS, 2019.\"\n\n[13] BIBREF14 BIBREF70 : \"Graph neural networks with message passing. In Neural Information Processing Systems, 2010",
    "cb12c19f9d14bef7b2f778892d9071eea2d6c63d": " We also thank our anonymous reviewer for helpful comments.\nReferences\nBIBREF1 M. I. Jordan, S. K. Sallabach. On spectral clustering: An algorithm with fast convergence. Journal of Statistical Mechanics: Theory and Experiment, 2005.\nBIBREF2 G. K. G. D. P. Turney, Z. A. Ahadi, P. Fertoli, Y. F. Cimpoeru, M. E. J. Cimpoeru, A. V. G. Cimpoeru. Graph neural networks: a review. Journal of Machine Learning Research (JMLR), 2017.\nBIBREF3 G. K. G. D. P. Turney, A. V. G. Cimpoeru, P. Fertoli. Spectral gated recursive neural networks. Machine Learning 116, 2016.\n\nBIBREF4 W. Liu, J. A. A. Quintero. Doc2vec vector representations for document classification. In International Conference on Learning Representations, 2016.\n\nBIBREF5 P. Fertoli, G. K. G. D. P. Turney. A deep learning approach to document classification. International Conference on Learning Representations, 2016.\n\nBIBREF6 R. C. Moore, A. V. G. Cimpoeru, M. Cimpoeru. The case for neural networks on graphs. In International Conference on Learning Representations, 2016.\n\nBIBREF7 C. Bravo, M. E. Eliav. Hierarchical graph deep learning for document classification. In International Conference on Document Analysis and Recognition, 2015.\n\nBIBREF8 R. C. Moore, G. P. Dwaraknath, A. V. G. Cimpoeru, J. Cimpoeru. Graph-recurrent neural networks for document classification. In International Conference on Machine Learning - Proceedings, 2016.\n\nBIBREF9 C. Bravo, M. E. Eliav, J. A. A. Quintero, M. Cimpoeru. A simple gated recurrent unit with the message-passing algorithm. International Conference on Machine Learning - Proceedings, 2019.\n\nBIBREF10 R. C. Moore, G. P",
    "9193006f359c53eb937deff1248ee3317978e576": " We thank Ville Leinonen for helping us with the implementation of MPAD+Hierarchies. We thank Gilles Flavigny for insightful discussions on Gated Recurrent Units and the training setups. Finally, we thank the reviewers for reading an earlier version of this memo, which motivated improvements to the text and to the results section.\n\nReferences\n\n## Bibliography\n\n[1] Bontempi, L., A. L. Burlinson, M. Chen, D. Mccallum, and G. L. Wallace, 2008, A practical introduction to graph neural networks,\n\nBIBREF0\n\n[2] Mccallum, D. F., H. Suo, V. Vaswani, and M. Chen, 2017, Message passing neural networks\n\nBIBREF2\n\n[3] Hamilton, J., A. C. Courville, B. Kipf, M. Defferrard, and Y. Bengio, 2017, Inductive biases towards generalization in neural network architecture\n\nBIBREF3\n\n[4] Kipf, B., J. Hamilton, X. Huang, A. C. Courville, and Y. Bengio, 2016, Semi-supervised classification of graph structured data with graph neural networks\n\nBIBREF4\n\n[5] Huang, X. and X. Lin, 2017, Attending to patterns in sequential data: a hierarchical graph attention network\n\nBIBREF5\n\n[6] Kipf, B., J. Hamilton, D. Wu, H. Su, M. Defferrard, and Y. Bengio, 2016, Graph attention networks\n\nBIBREF6\n\n[7] van den Besselaar, T., L. Bontempi, P. Belghazi, G. Courville, and Y. Bengio, 2017, Adversarially training GNNs with gradient reversal and denoising\n\nBIBREF8\n\n[8] Veli\u010dkovi\u0107, M., S. T. Yi, Y. Chakrabarti, Y. K. Alvarez-Coello, and Z. Ghahramani, 2017, Self-supervised graph augmentation\n\nBIBREF9\n\n[9] Kipf, B., X. Huang, H. Su,",
    "bc67b91dd73acded2d52fd4fee732b7a9722ea8b": " We would also like to thank the two anonymous referees of our work for their comments and suggestions that helped us improve the presentation of our work and results.\nREFERENCES\n\nSECREF1.\n\nJ. Kleinberg, A. R. Broder, N. J. d'Amato, G. E. Toutanova, D. A. Karger. Unsupervised Learning of Graphlets and Semantic Clusterings. In: Proceedings of the 22nd ACM SIGKDD international conference on Knowledge Discovery and Data Mining, 2007.\n\nSECREF2.\n\nT. Hofmann, T. Kipf. Message passing neural networks for graph computing. In: Proceedings of the Thirty-Fourth AAAI conference on Artificial Intelligence, 2017.\n\nSECREF3.\n\nA. Bojarski, T. G. Kim, S. M. Kim, J. Ying, V. V. N. Vinyalsky. Message passing attention networks. In: Proc. of the 55th Annual Meeting of the Association for Computational Linguistics, 2016.\n\nSECREF4.\n\nT. G\u00fcnes, G. Corliss, P. Wenniger, N. D. Jain, S. M. Sarwar, L. J. S. Bailey. A systematic comparison of neural network architectures for link prediction on biological graphs. In: Proc. of the 24th International Symposium on Computational Geometry, 2018.\n\nSECREF5.\n\nN. D. Jain, L. J. S. Bailey. Attention as a regularizer for recurrent neural networks. In: Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, 2016.\n\nSECREF6.\n\nL. Chen, G. E. Toutanova. Learning word representations for unsupervised document categorisation with neural networks. In: Proceedings of the 22nd ACM Conference on Information and Knowledge Management, 2014.\n\nSECREF7.\n\nB. A. Y. Chavira, V. V. N. Vinyalsky. A review of the recent graph neural network literature. In: Proceedings of SemEval 2018, 2018.\n\nSECREF8.\n\nC. Schmid, R. J. B. J. Leenderc. Graph analysis",
    "49c32a2a64eb41381e5f12ccea4150cac9f3303d": " Our work is financed by an R&D grant from Viacom 18, and Sarkar Fellowship from IIT Bombay.\nReferences [BIBREF0] a. BIBREF1 . BIBREF2 . BIBREF3., BIBREF4 ] and BIBREF5 . BIBREF6, BIBREF7. BIBREF8 ] jorge-noguera,giora,clark1984pretense. BIBREF9 ] ivano-frank,de2013incongruity. BIBREF10 ] yao2000modeling. BIBREF11 ] yao2017incongruity. BIBREF12 ] oberauer2016explaining] clark1984pretense. BIBREF13 ] koo2009eye. BIBREF15 ] BIBREF16] BIBREF17 ] abdel-hafeez2013evaluation. BIBREF18 ] BIBREF19 ] BIBREF20 ] BIBREF21 ] BIBREF22 ] BIBREF23 ] BIBREF24 [BIBREF25] [BIBREF26] [BIBREF27]\n\n\nThis is a work of fiction. Names, characters, places, and incidents either are the product of the author's imagination or are used fictitiously, and any resemblance to actual persons, living or dead, business establishments, events, or locales is entirely coincidental.\n\nText copyright \u00a9 2017 by Adam Rex\n\nCover art and interior illustrations copyright \u00a9 2017 by Adam Rex\n\nCover designed by Brittney Trimble\n\nCover illustration copyright \u00a9 2017 by Adam Rex\n\nInterior illustrations copyright \u00a9 2016 by Adam Rex\n\nAll rights reserved. Published in the United States by Delacorte Press, an imprint of Random House Children's Books, a division of Penguin Random House LLC, New York.\n\nDelacorte Press is a registered trademark and the colophon is a trademark of Penguin Random House LLC.\n\nVisit us on the Web\n\nEducators and librarians, for a variety of teaching tools, visit us at RHTeachersLibrarians.com\n\nLibrary of Congress Cataloging-in-Publication Data\n\nNames: Rex, Adam, author.\n\nTitle: I just don't get it! / Adam Rex.\n\nOther titles: I just don",
    "bbb77f2d6685c9257763ca38afaaef29044b4018": " We also thank Professor John Carroll and Professor Divesh Srivastava for useful discussions.\n\nReferences\n\n[ ]\n\nBickmore, W. J., and Giora, I. P. (1985), The pragmatics of irony, Speech, 24, 105-125.\n\n[ ]\n\nClark, J.(ed.) (1984), Sarcasm, Cambridge University Press.\n\n[ ]\n\nClark, J. S., Campbell, C., and Strube, N. (2012), Sarcasm Detectors and Analyzing Irony: A Survey. Proc Indian Nat Acad Sci, 100, 23-35.\n\n[ ]\n\nFlesch, R. W. (1948), How to Boost Intelligence of Your Ad Words, Publicity Weekly, 50-52.\n\n[ ]\n\nGiora, I., Goldin-Meadow, S., Hinzen, J. A. (1999), Irony processing: From the unconscious to cognitive models, Trends Cogn Sci, 4, 41-47.\n\n[ ]\n\nGoldin-Meadow, S. (2003), Irony understanding in discourse: On the nature and cognitive status of irony, Trends Cogn Sci, 21, 39-48.\n\n[ ]\n\nGilovich, T. (1980), The Moderate Optimist: A Reappraisal of the Research on Human Reasoning, Anchor Books, New York.\n\n[ ]\n\nGoldin-Meadow, S., Hinzen, J. A. (2005), Irony and the brain, Philosophical Trans Royal Soc, Lond., 361, 1575-1588.\n\n[ ]\n\nHendrix, M. L., and Pinto-Seiler, M. J. (2012), Irony and language in conversation: a cross-disciplinary view, Trends Cogn Sci, 36, 71-78.\n\n[ ]\n\nHendrix, M. L., and Saffran, J. R. (2013), How Irony Works: Cognitive and Brain Mechanisms of Sarcastic Language, Psychological Science, 24, 140-145.\n\n[ ]\n\nHofstadter, G. (1955), The Mind's I, Harper & Row, New York.\n\n[ ]\n\nH",
    "22732cb9476e521452bf0538f3fdb94cf3867651": " Also, we are thankful to the mentors of this project and everyone involved in the organization of MSRIT'2019: Chandrakala B. B, Umesh B S M, Shrey P D, Karthik K S, Gagan S S, Chitraraj K Y, and Rajeev S. We also thank the reviewers of this paper: Danielle C and Chandrakala B. B. The work described is supported by the DST-SERB under DST-SERB/SRIC/Fellowship/2017-19/1-37 and MHRD under FIST: FIST-15 (FP-2019-0(3012)/2019-20.\nAuthor Disclosures\nWe thank the following organizations and conferences for the grants: DST-SERB / SERB (grant ID: DST-SERB/SRIC/Fellowship/2015-14), MHRD (grant ID: MHRD-FIST/FIST-15 (FP-2019-0(3012)/2019-20).\nThis is the author/authors' version of the work that was accepted for publication in the Journal of Cognitive Linguistics.\n\nAfter peer review\n\nIt has not been published by or appeared in a journal or book, as part of a published serial, serial-online or other published work.\n\nNo part of this work is under consideration for publication elsewhere.\n\nCopyright \u00a9 Journal of Cognitive Linguistics 2019\n\nPublished by Springer Nature\n\nThis work is licensed under a Creative Commons Attribution 4.0 International License.\nTo view a copy of this license, visit\n\n<https://creativecommons.org/licenses/by/4.0/>.\n\nYou may not use the form for commercial purposes. Licensees must retain this page on any electronic archival copy of the work with the full text of the license and copyright notice displayed from such copy.\n\nThis article is a work of a student or students, which has been submitted for approval toward a degree or a diploma degree. This document may not be copied, reproduced, circulated or used in any other way without the consent of the copyright holder.\n\nJoshi, Bhargav K and Singh, Meghna and Bhat, Aparajeeth and Bhatia, Shivani and Saha, N",
    "4e748cb2b5e74d905d9b24b53be6cfdf326e8054": " We thank our external and internal reviewers (including Adarsh Bhatt, Devanshi Jain, Rajesh Kumar, Abhay Singh, Kritika Sharma and Vikas Sharma) for their suggestions and feedback. We would also like to thank the anonymous reviewers of ACL Anthology. Finally, we thank Ritu Sharma and Anant Madhotra for providing research guidance.\nReferences\n[BIBREF0]\n\nBIBREF1]\n\n[BIBREF2]\n\n[BIBREF3]\n\n[BIBREF4]\n\n[BIBREF5]\n\n[BIBREF6]\n\n[BIBREF7]\n\n[BIBREF8]\n\n[BIBREF9]\n\n[BIBREF10]\n\n[BIBREF11]\n\n[BIBREF12]\n\n[BIBREF13]\n\n[BIBREF14]\n\n[BIBREF15]\n\n[BIBREF16]\n\n[BIBREF17]\n\n[BIBREF18]\n\n[BIBREF19]\n\n[BIBREF20]\n\n[BIBREF21]\n\n\nCopyright \u00a9 2018 by Kaira Rouda\n\nMap illustration by Brian Selznick\n\nPublished in the United States by Random House Children's Books, a division of Penguin Random House LLC, 1745 Broadway, New York, NY 10019, and in Great Britain by Random House Children's Books, a Penguin Random House company,\n\n\"Random House\" and the Random House colophon are registered trademarks of Random House LLC.\n\nFirst published in the United States of America in September 2018\n\nRandom House and the colophon are registered trademarks and A Stepping Stone Book and the colophon are trademarks of Penguin Random House LLC.\n\nThis book has been catalogued with the Library of Congress.\n\nwww.steppingstonesbooks.com\n\nLibrary of Congress Control Number: 2017966438\n\nISBN 978-0-385-73973-4 (hardcover) \u2014 ISBN 978-0-385-73974-1 (eBook)\n\nIllustrations by Brian Selznick\n\nThe illustrations in this book are rendered in pen and ink. The color was added digitally.\n> This one is",
    "74b338d5352fe1a6fd592e38269a4c81fe79b866": "\nA. Clark and M. R. J. Giora, \"Irony Processing,\" in Linguistic Insight: Essays in Honor of Geoffrey Leech, A. R. Waugh (Ed.), pp. 77\u201396. Elsevier Academic Press, 1984.\nSasha Bolshak, R. C. Camblin, and E. J. Shriberg, \"Context Effects on Eye Movements and Metaphor Processing: Evidence from a Multiparagraph Irony Task,\" Journal of Memory and Language, vol. 50, no. 3, pp. 101\u2013134, March 2007.\nA. D. Bolshak, C. R. Camblin and E. J. Shriberg, \"Discourse Incongruence and Eye Movements,\" Psychonomic Bulletin & Review, vol. 35, no. 1, pp. 103\u2013112, 2008.\nA. J. Bull, M. A. R. E. Kruis, J. M. Kloosterman, and E. J. Shriberg, \"Reading Processes and Eye Movements (RPE): II: Eye Movement Patterns, Discourse Structure and Reading Rate,\" Brain and language, vol. 117, pp. 38\u201361, 2015.\nJames P. Bull, E. J. Shriberg and S. C. Camblin, \"Reading Processes and Eye Movements (RPE): IV: Patterns in Eye Movement During Reading,\" Brain and language, vol. 126, pp. 35\u201351, 2013.\nD. F. Filik, M. Schlesingsay and G. D. V. Jones, \"Incongruity and eye movements\", Neuropsychologia 61, pp. 1774\u20131787, 2013.\nKirsten I. Giora, \"Cognitive Processes of Irony Processing,\" Psychological Science, vol. 17, no. 2, pp. 114\u2013121, 2006.\nKrysten I. Giora and E. J. Shriberg, \"Irony Processing,\" Cognitive Processes of Reading, Oxford University Press, 2012.\nS. Jha, A. Kasture and V. Singh, \"The Influence of Contextual Discrepancy on Eye Movements and Perceived Satire,\" Cognition, vol. 154, no. 3, pp. 1443\u20131457, 2016",
    "d6ea7a30b0b61ae126b00b59d2a14fff2ef887bf": " The Turing Institute is an independent research center with a focus on research-driven technological innovation. Its activities are funded through the Department of Digital, Culture, Media and Sport. We thank Samantha Sarkhel for creating a shared-workbook version of our initial analysis proposal.\nReferences\n\nBIBREF0  R. K. Mishra, A. L. Nguyen, P. S. P. Mendelsohn, M. Liakata, P. G. Lachlan. 2015. Bridging the Gap with Computational Text Analysis: An Introduction to a Project on Hate Speech Online. [Working paper.] Retrieved from <http://arxiv.org/abs/1506.01343>.\n\nBIBREF1  F. Parulkar. 1997. \"The Federalist Papers: A Statistical Investigation of Authorship.\" Political Research Quarterly, v59 (sup1): 193\u2013204. Retrieved from <http://www.jstor.org/stable/380122>.\n\nBIBREF2  M. Chen. 2015. Rhetoric, Style and Haiku in English Verse. Digital Scholarship in the Humanities (DSCH). Retrieved from <http://digitalhumanities.ecu.edu.au/vol14/chen>.\n\nBIBREF3  P. Darwin. 2006. The Development of an Evolutionary Theory of Natural Selection: A Study in the History of Ideas, by Peter G. Maxwell. Ed. Michael J. Sallie. Cambridge University Press.\n\nBIBREF4  K. O'Neill, R. S. J. Smith. 2016. Responsibility, Privacy and Born-Digital Data. Digital Scholarship in the Humanities (DSCH). Retrieved from <http://digitalhumanities.ecu.edu.au/vol18/oneill>.\n\nBIBREF5  D. G. Breen. 2013. On the Relationship Between Public Opinion and the Internet: A Report. Retrieved from <https://research.google/pubs/publication/pdf-on-the-relationship-between-public-opinion-and-the-internet>.\n\nBIBREF6  Y. Chen, et al. 2015. Towards Understanding What Makes Users Attention-Grabbing on Twitter [Preprint]. Retrieved from <https://www.npl.ox",
    "f903396d943541a8cc65edefb04ca37814ed30dd": "\n\nBIBREF0\n\nBruns, R. S., C. J. C. Brown, and W. A. Janssen. 2015. \"Reddit's war on echo chambers: Do anti-harassment interventions affect post behavior within and across hate speech related subreddits?\" J. Soc. Syst. Modelling 5, no. 3: 1-23. https://doi.org/10.1017/jssm.2017.43.\n\nBIBREF1\n\nBIBREF2\n\nHunt, J. E., and D. A. Palmer, 2014. Understanding Federalist II with stylometry and a big data approach. Int. J. Digital Hum. Stud. 3, no. 1: 1-15. https://www.ijdh.org/index.php/journal/article/view/2330/3377.\n\nBIBREF3\n\nBIBREF4\n\nBIBREF5\n\nC. J. Larson and M. L. Bergevin, 2006. Introducing the humanities and computational methodologies: Towards a framework for integrating thick, mixed, and dynamic data. First Monday 15, no. 2. http://firstmonday.org/article/view/1604/1604.\n\nBIBREF6\n\nC. J. Larson et al., 2016. Using text mining to study how ideas spread in social networks. Science 349, no. 6273: 808-808.\n\nBIBREF7\n\nBIBREF7\n\nBruns, R. S., C. J. C. Brown, J. J. McSweeney, E. M. Iverson and L. K. Hamner. 2015. Text mining for social science: Ethical issues in using born-digital data for research. First Monday 20, no. 11. http://firstmonday.org/article/view/4473/4600.\n\nBIBREF8\n\nBIBREF9\n\nBIBREF10\n\nBIBREF11\n\nBIBREF12\n\nBIBREF13\n\nFerrante, J., J. A. M. Sap, and L. K. Hamner, 2015. Big data in social science: A review of literature and best practices. First Monday 20, no.",
    "ba28ce9a2f7e8524243adf288cc3f11055e667bb": " This work also benefited from the UK NLP-DSR conference (2017) workshop on computational text analysis and critical approaches to the social sciences and the humanities.\n\nREFERENCES\n\nAdcock, P. and I. Collier. \"Quantitative Text Analysis: Methodological Issues\", in Text analysis: A practitioner's guide. Oxford: Clarendon Press, 2015. \u21b5\n\nBaldwin, T. and S. McIntyre. \"The Federalist Papers: Can Computational Analysis Shed New Light? Evidence from The Federalist: A Case Study in Digital Humanities\". PLoS One (2015). https://doi.org/10.1371/journal.pone.0126441. [Online]\n\nBIBREF0\n\n. Bhat, M., et. al. (2015). \"An Exploration into the Effectiveness of Echo Chamber Suppression on Reddit.\" arXiv:1502.04003. Available at www.semanticscholar.org/paper/d3ce9713c2daab9c8d5c9e22f12febfb6ba9dcff8b4c07a7b9abd4fcf97f6d2dde9f849bcee29c4f5d3db8e8ba. [Online].\n\nBIBREF1\n\n. BIBREF1 (2014). \"Do British People Write Like Their Namesake: An Investigation of Federalism in Eighteenth-Century England.\" Information Sciences. Available at www.semantic-scholar.org/paper/d97988c50aeab9c8dff4ae9f5dfc36f14befce895de12df12ff9f0c1a5415f0d4e32b4da97f6ea1. [Online].\n\nBIBREF2\n\n. BIBREF2 (2010). \"Beyond the Haiku: Detecting Conventions in English Haiku Using Computational Language Analysis and Close Reading\". Science and Education (2015). https://www.semantic-scholar.org/paper/e4baf1ae9739a5d4a89e8e2becc865ce23af4daf3c1549be7fb3dbeef5ffa",
    "975e60535724f4149c7488699a199ba2920a062c": "\nWe are grateful to the editors of F1000Research for permission to expand this article to include all the material not previously published.\nDong Nguyen is Professor of Linguistics and Fellow by Statute of St. Anne's. She is also Associate Dean for research and impact at St. Anne's College. Her research interests include computational approaches to literary and linguistic theory, with a particular focus on digital text analysis in the period after 1500. She is an active member of the Textual Scholarship and NLP communities.\nMaria Liakata is a Doctoral Researcher with an interest in literary theory and historical semantics. She is also a member of the NLP and Textual Scholarship communities.\nThis article has been expanded to include new material. Below we focus on these sections that are not previously accessible, but you may also find interesting the general and historical context of this new material.\n\nSection 1 has been modified to discuss the broader disciplinary and cultural issues raised by computational analyses.\nSection 2 has been expanded to include more details about research questions and measurement.\nSection 3 has been expanded to include an overview of the data curation and metadata steps, and the challenges of conceptualization and operationalization.\n\nSection 5 has been expanded to include more details on the approaches used in computational analyses of textual data, and the strengths and limitations of different modeling approaches.\nSection 6 has been expanded to include more details on the validation step, and how machine learning and related methods can be made more interpretable.\n\nSection 7 has been expanded to include more details on the analysis step.\nAppendix\n\nWe first define some of the terms and concepts in this article.\n\nIn terms of computational methods, we distinguish between \"language technologies\" and \"textual analysis\". Linguistic and computational methods in natural language processing are sometimes called language technologies (LT) to distinguish the tools from computational approaches to textual analysis (e.g., SAGE BIBREF41 ). LT-based systems process structured input data (e.g. sentences) to extract information about the input (e.g., predict grammatical correctness) or to make inferences using a range of methods (e.g., predict semantics). These methods are primarily concerned with tasks that are computationally demanding. Examples of LT-based methods include CoreNLP, Giza++ BIBREF40 ) and word embedding methods like FastText.\n\nMany linguistic and computational methods that are not part",
    "b970f48d30775d3468952795bc72976baab3438e": " This article benefited substantially from feedback from participants and the Turing Institute's Bridging Disciplines Network, in particular from Elizabeth Bird, P.R. Chaudhury, Tommaso Incantro, Sara Kiesling, Mihnea Moldovan, Eric Piedersheim, A.J. Taylor, and members of the Bridging Disciplines Working Group: C.C. Anderson, Andrea Bell, Tim Hinton, and Sam Ward. We would also like to thank Peter N. Dindo and Kiri Vigor from the Turing Institute and the University of Birmingham for invaluable comments on an earlier draft of the work. Finally, the authors gratefully acknowledge funding from the University of Birmingham.\nReferences\n\nAdcock, R. and Collier, B. (2012) Categorization and measurement, in K.D. Lehmann (Ed.), Handbook of survey research methods (Sage, second edition), pp. 219\u2013226.\n\nBIBREF0\n\nAbdul Karim, T. S. and Oreszczczyc, R. (2015) Echo chambers: The impact of online echo chambers on information seeking and knowledge production. http://arxiv.org/abs/1301.1072\n\nBIBREF1\n\nWoolgearing, S., Druckmann E., A. D. Bender, A. Gebauer and M. Euser (2013) A statistical model for authorship of The Federalist Papers. Proceedings of Association for Computational Linguistics (ACL-13), pp. 1459\u20131468.\n\nBIBREF2\n\nLea, M. and Streeter C. (2018) The dictionary of English haiku. Annals of Applied Statistics. 2. 25. 1181\u20131203.\n\nBIBREF3\n\nLepori, A. (2017) Science for Darwin: From reading lists to reading habits. Quarterly Journal of Medicine and the Humanities. 4. 3. 7\u201317\n\nBIBREF4\n\nVan Dijk, T. et al. (2018) Privacy considerations in the use of language data. The Linguistic Review. 7. 1\u201327.\n\nBIBREF5\n\nCelikoglu, A., R. Jadhav, P. T. Hancock, M. Leszczens"
}